---
layout: post
title: 'offline meta-RL | è¿‘æœŸå·¥ä½œé€Ÿè¯»è®°å½•'
date: "2025-12-14T00:48:36Z"
---
offline meta-RL | è¿‘æœŸå·¥ä½œé€Ÿè¯»è®°å½•
==========================

offline meta RL è¿‘æœŸå·¥ä½œçš„é€Ÿè¯»è®°å½•ã€‚

  

* * *

ç›®å½•

*   [ğŸ“Œ è¿‘æœŸå·¥ä½œ 1](#-è¿‘æœŸå·¥ä½œ-1)
    *   [(UBER) Unsupervised Behavior Extraction via Random Intent Priors \[NeurIPS 2023\]](#uber-unsupervised-behavior-extraction-via-random-intent-priors-neurips-2023)
    *   [Entropy Regularized Task Representation Learning for Offline Meta-Reinforcement Learning \[AAAI 2025\]](#entropy-regularized-task-representation-learning-for-offline-meta-reinforcement-learning-aaai-2025)
    *   [(CORRO) Robust Task Representations for Offline Meta-Reinforcement Learning via Contrastive Learning \[ICML 2022\]](#corro-robust-task-representations-for-offline-meta-reinforcement-learning-via-contrastive-learning-icml-2022)
    *   [Meta-DT: Offline Meta-RL as Conditional Sequence Modeling with World Model Disentanglement \[NeurIPS 2024\]](#meta-dt-offline-meta-rl-as-conditional-sequence-modeling-with-world-model-disentanglement-neurips-2024)
    *   [Towards an Information Theoretic Framework of Context-Based Offline Meta-Reinforcement Learning \[NeurIPS 2024\]](#towards-an-information-theoretic-framework-of-context-based-offline-meta-reinforcement-learning-neurips-2024)
    *   [Skill-based Meta-Reinforcement Learning \[ICLR 2022\]](#skill-based-meta-reinforcement-learning-iclr-2022)
    *   [Scrutinize What We Ignore: Reining In Task Representation Shift Of Context-Based Offline Meta Reinforcement Learning \[ICLR 2025\]](#scrutinize-what-we-ignore-reining-in-task-representation-shift-of-context-based-offline-meta-reinforcement-learning-iclr-2025)
    *   [Generalizable Task Representation Learning for Offline Meta-Reinforcement Learning with Data Limitations \[AAAI 2024\]](#generalizable-task-representation-learning-for-offline-meta-reinforcement-learning-with-data-limitations-aaai-2024)
    *   [Provably Improved Context-Based Offline Meta-RL with Attention and Contrastive Learning \[ICLR 2022\]](#provably-improved-context-based-offline-meta-rl-with-attention-and-contrastive-learning-iclr-2022)
    *   [(UDS) How to Leverage Unlabeled Data in Offline Reinforcement Learning \[ICML 2022\]](#uds-how-to-leverage-unlabeled-data-in-offline-reinforcement-learning-icml-2022)
*   [ğŸ“Œ è¿‘æœŸå·¥ä½œ 2](#-è¿‘æœŸå·¥ä½œ-2)
    *   [(IDAQ) Offline Meta Reinforcement Learning with In-Distribution Online Adaptation \[ICML 2023\]](#idaq-offline-meta-reinforcement-learning-with-in-distribution-online-adaptation-icml-2023)
    *   [Context Shift Reduction for Offline Meta-Reinforcement Learning \[NeurIPS 2023\]](#context-shift-reduction-for-offline-meta-reinforcement-learning-neurips-2023)
    *   [Text-to-Decision Agent: Offline Meta-Reinforcement Learning from Natural Language Supervision \[NeurIPS 2025\]](#text-to-decision-agent-offline-meta-reinforcement-learning-from-natural-language-supervision-neurips-2025)
    *   [Efficient Offline Meta-Reinforcement Learning via Robust Task Representations and Adaptive Policy Generation \[IJCAI 2024\]](#efficient-offline-meta-reinforcement-learning-via-robust-task-representations-and-adaptive-policy-generation-ijcai-2024)
    *   [Meta-Reinforcement Learning via Exploratory Task Clustering \[AAAI 2024\]](#meta-reinforcement-learning-via-exploratory-task-clustering-aaai-2024)
    *   [Contextual Transformer for Offline Meta Reinforcement Learning \[NeurIPS 2022 workshop\]](#contextual-transformer-for-offline-meta-reinforcement-learning-neurips-2022-workshop)
    *   [Model-Based Offline Meta-Reinforcement Learning with Regularization](#model-based-offline-meta-reinforcement-learning-with-regularization)
    *   [Enhancing Online Reinforcement Learning with Meta-Learned Objective from Offline Data \[AAAI 2025\]](#enhancing-online-reinforcement-learning-with-meta-learned-objective-from-offline-data-aaai-2025)
    *   [Offline Meta-Reinforcement Learning with Online Self-Supervision \[ICML 2022\]](#offline-meta-reinforcement-learning-with-online-self-supervision-icml-2022)

ä¹Ÿè¯·å‚è§ï¼š[offline meta-RL | ç»å…¸è®ºæ–‡é€Ÿè¯»è®°å½•](https://www.cnblogs.com/moonout/p/19317727)

* * *

ğŸ“Œ è¿‘æœŸå·¥ä½œ 1
---------

### (UBER) Unsupervised Behavior Extraction via Random Intent Priors \[NeurIPS 2023\]

*   arxivï¼š[https://arxiv.org/abs/2310.18687](https://arxiv.org/abs/2310.18687)
*   pdfï¼š[https://arxiv.org/pdf/2310.18687](https://arxiv.org/pdf/2310.18687)
*   htmlï¼š[https://ar5iv.labs.arxiv.org/html/2310.18687](https://ar5iv.labs.arxiv.org/html/2310.18687)
*   æ¥æºï¼šå¸ˆå…„çš„å·¥ä½œï¼ŒNeurIPS 2023ã€‚æ„Ÿè°¢å¸ˆå¼Ÿçš„è®²è§£ã€‚
*   å‚è€ƒåšå®¢ï¼šç›´æ¥çœ‹è¿™ä¸ªå¥½äº†ï¼Œ[CSDN | ã€è®ºæ–‡é˜…è¯»ç¬”è®°ã€‘UBERï¼šç”¨éšæœºæ„å›¾ä»æ— å¥–åŠ±æ•°æ®ä¸­æå–æœ‰ç”¨è¡Œä¸º](https://blog.csdn.net/iiiiii11/article/details/155364242)

ä¸»è¦å†…å®¹ï¼š

*   settingï¼šæˆ‘ä»¬æ‹¿åˆ°äº† single-task çš„æ²¡æœ‰ reward çš„ offline æ•°æ®é›†ï¼Œç°åœ¨æƒ³åŸºäºè¿™ä¸ªæ•°æ®é›†ï¼Œå­¦å‡ºæ¥å¯ä»¥åšç›¸å…³ task çš„ç­–ç•¥ã€‚
*   methodï¼šç›´æ¥ç»™è¿™ä¸ªæ•°æ®é›†æ ‡æ³¨ N ä¸ªéšæœº rewardï¼Œç„¶åè®­å‡ºæ¥ N ä¸ªç­–ç•¥ï¼Œæœ€åä½¿ç”¨ PEX æ–¹æ³•è¿›è¡Œ offline-to-onlineã€‚
*   ç†è®ºï¼ˆæ ¹æ®å°è±¡ å¯èƒ½æœ‰å¹»è§‰ï¼‰ï¼š
    *   Proposition 4.1 æŒ‡çš„æ˜¯ï¼Œç»™å®šä¸€ä¸ª policyï¼Œæ€»èƒ½æ„é€ å‡ºæ¥ä¸€ä¸ª rewardï¼Œä½¿å¾—è¿™ä¸ª policy æ˜¯è¿™ä¸ª reward ä¸‹çš„æœ€ä¼˜ policy ä¹‹ä¸€ã€‚
    *   Theorem 4.2 æŒ‡çš„æ˜¯ï¼Œåªè¦ç›®æ ‡è¡Œä¸ºåœ¨æ•°æ®é›†ä¸­æœ‰è¾ƒå¥½çš„è¦†ç›–ï¼Œæˆ‘ä»¬å°±èƒ½æœ‰æ•ˆåœ°å­¦ä¹ å®ƒã€‚ä½¿ç”¨å¤§å°ä¸º N çš„ offline datasetï¼Œè¿™æ ·å­¦å‡ºæ¥çš„æœ€å¥½æ€§èƒ½ä¸ optimal policy çš„å·®è·ï¼Œå¯ä»¥è¢« N bound ä½ã€‚ä½¿ç”¨äº† linear MDP å’Œ PEVI é‚£ä¸€å¥—ï¼Œæˆ‘ä¸æ‡‚è¿™äº›ç†è®ºã€‚
    *   Theorem 4.3 å¥½åƒæŒ‡çš„æ˜¯ï¼ŒUBER ä½¿ç”¨çš„æ„é€  random reward çš„æ–¹æ³•å¯ä»¥ç¦» true reward è¶³å¤Ÿè¿‘ï¼Œæ˜¯ä½¿ç”¨å²­å›å½’ï¼ˆridge regressionï¼‰æ¥è¯æ˜çš„ï¼Œå²­å›å½’ æˆ‘ä¹Ÿä¸æ‡‚ã€‚
*   å®éªŒï¼šåšäº† d4rl å’Œ metaworldã€‚è¿˜æ²¡ä»”ç»†çœ‹ã€‚æ¬è¿å‚è€ƒåšå®¢çš„å†…å®¹ï¼š

> ç»“æœ 1ï¼šéšæœºæ„å›¾ç¡®å®äº§ç”Ÿå¤šæ ·ä¸”é«˜è´¨é‡è¡Œä¸ºã€‚å®éªŒæ˜¾ç¤ºï¼ŒUBERæå–çš„è¡Œä¸ºç­–ç•¥ï¼š
> 
> *   æ€§èƒ½è¶…è¶ŠåŸå§‹æ•°æ®ï¼šç‰¹åˆ«æ˜¯åœ¨åŸå§‹æ•°æ®è´¨é‡ä¸é«˜æ—¶
> *   åˆ†å¸ƒæ›´åŠ å¤šæ ·ï¼šå›æŠ¥åˆ†å¸ƒçš„ç†µå€¼æ˜¾è‘—é«˜äºåŸå§‹æ•°æ®é›†å’Œè¡Œä¸ºå…‹éš†æ–¹æ³•
> 
> ç»“æœ 2ï¼šåœ¨çº¿å­¦ä¹ åŠ é€Ÿæ˜¾è‘—ã€‚åœ¨Mujocoè¿åŠ¨ä»»åŠ¡ä¸­ï¼ŒUBERç›¸æ¯”åŸºçº¿æ–¹æ³•ï¼š
> 
> *   å­¦ä¹ é€Ÿåº¦æ›´å¿«ï¼šåœ¨ç›¸åŒç¯å¢ƒæ­¥æ•°ä¸‹è·å¾—æ›´é«˜å›æŠ¥
> *   æœ€ç»ˆæ€§èƒ½æ›´å¥½ï¼šåœ¨å¤šæ•°ä»»åŠ¡ä¸­è¾¾åˆ°æˆ–æ¥è¿‘ä¸“å®¶æ°´å¹³
> 
> ç»“æœ3ï¼šè·¨ä»»åŠ¡è¿ç§»èƒ½åŠ›ã€‚åœ¨ Meta-World çš„å¤šä»»åŠ¡å®éªŒä¸­ï¼ŒUBER å­¦åˆ°çš„è¡Œä¸ºç­–ç•¥èƒ½å¤ŸæˆåŠŸè¿ç§»åˆ°ä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡ï¼Œè¯æ˜äº†å…¶è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚å¯èƒ½çš„åŸå› æ˜¯ï¼Œéšæœºå¥–åŠ±äº§ç”Ÿäº†é€šç”¨è¿åŠ¨åŸè¯­ï¼ˆå¦‚"æ¥è¿‘ç‰©ä½“"ã€â€œç²¾ç¡®æ§åˆ¶æœ«ç«¯æ‰§è¡Œå™¨â€ï¼‰ï¼Œè¿™äº›åŸè¯­åœ¨ä¸åŒä»»åŠ¡é—´å¯è¿ç§»ã€‚

### Entropy Regularized Task Representation Learning for Offline Meta-Reinforcement Learning \[AAAI 2025\]

*   arxivï¼š[https://arxiv.org/abs/2412.14834](https://arxiv.org/abs/2412.14834)
*   GitHubï¼š[https://github.com/MohammadrezaNakhaei/ER-TRL](https://github.com/MohammadrezaNakhaei/ER-TRL)
*   æ¥æºï¼šä¹‹å‰çš„é€Ÿè¯»ï¼ŒAAAI 2025ã€‚
*   å‚è€ƒåšå®¢ï¼š[è®ºæ–‡é€Ÿè¯»è®°å½• | 2024.12](https://www.cnblogs.com/moonout/p/18627106#entropy-regularized-task-representation-learning-for-offline-meta-reinforcement-learning)

ä¸»è¦å†…å®¹ï¼š

*   task encoder \\(e(z|c)\\) å¯èƒ½ä¼šè€¦åˆ behavior policy \\(\\pi\_\\beta\\)ï¼ˆå³ç”Ÿæˆ offline dataset çš„é‚£äº› policyï¼‰çš„ä¿¡æ¯ï¼Œå¯¼è‡´ inference æ—¶ï¼Œå½“ agent é‡åˆ° OOD çš„ transition æ—¶ï¼Œencoder æ— æ³•æ¨æ–­å‡ºæ­£ç¡®çš„ taskã€‚
*   ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›å»æœ€å°åŒ– task encoder \\(e(z|c)\\) å’Œ behavior policy \\(\\pi\_\\beta\\) ä¹‹é—´çš„äº’ä¿¡æ¯ï¼›é€šè¿‡ä¸€ä¸ª GAN æ¥æ¨¡æ‹Ÿ behavior policy \\(\\pi\_\\beta\\)ï¼Œå…¶ä¸­ generator ç”¨æ¥ç”Ÿæˆä»¥å‡ä¹±çœŸçš„ actionï¼Œ discriminator ç”¨æ¥åŒºåˆ†çœŸå‡ actionã€‚
*   æœ€å°åŒ–è¿™ä¸ªäº’ä¿¡æ¯ï¼Œå¥½åƒç­‰äºæœ€å¤§åŒ– \\(H(\\pi\_\\beta | p(z\_i))\\) çš„ç†µï¼›å…·ä½“ç»†èŠ‚è¿˜æ²¡çœ‹ã€‚

### (CORRO) Robust Task Representations for Offline Meta-Reinforcement Learning via Contrastive Learning \[ICML 2022\]

*   arxivï¼š[https://arxiv.org/abs/2206.10442](https://arxiv.org/abs/2206.10442)
*   pdfï¼š[https://arxiv.org/pdf/2206.10442](https://arxiv.org/pdf/2206.10442)
*   htmlï¼š[https://ar5iv.labs.arxiv.org/html/2206.10442](https://ar5iv.labs.arxiv.org/html/2206.10442)
*   æ¥æºï¼šæ— æ„ä¸­æœåˆ°çš„ï¼ŒICML 2022ã€‚

kimi é€Ÿè¯»ï¼š

*   è¿™ç¯‡æ–‡ç« ä¼¼ä¹æ˜¯ focal çš„ç›´æ¥æ”¹è¿›ã€‚
*   corro ä¼¼ä¹æœ‰ 3 ä¸ªè´¡çŒ®ï¼š
    1.  å£°ç§° focal ç”¨æ¥å¾—åˆ° z çš„ encoder \\(q(z | \\tau\_{:t})\\) åŸºäºä¸€æ•´æ®µè½¨è¿¹ï¼Œå› æ­¤å­¦åˆ°çš„ z å®¹æ˜“å—è¡Œä¸ºç­–ç•¥å½±å“ã€‚corro ä½¿ç”¨ \\(q(z | (s,a,r,s'))\\) è¿™æ ·çš„å½¢å¼æ¥å¾—åˆ° zï¼Œç„¶åæŠŠæ¯ä¸ª transition çš„ zï¼Œä½¿ç”¨ä¸€ä¸ªæç®€ç‰ˆçš„ self-attention åŠ æƒæ±‚å’Œï¼Œweights = softmax(MLP(z\_i) for each i) ï¼Œz = sum(weights\_i \* z\_i)ï¼Œå¾—åˆ°æœ€ç»ˆçš„ zã€‚
    2.  è¿™ä¸ª encoder \\(q(z | (s,a,r,s'))\\) çš„å…·ä½“è®­ç»ƒï¼Œä¸ focal ä¸åŒï¼Œä½¿ç”¨äº†å¯¹æ¯”å­¦ä¹ çš„ InfoNCE lossã€‚æ­£æ ·æœ¬å¯¹æ˜¯åŒä¸€ä¸ª task é‡Œçš„ä¸¤ä¸ª transitionï¼Œè€Œè´Ÿæ ·æœ¬å¯¹æ˜¯ç‰¹æ„æ„é€ çš„éš¾è´Ÿæ ·æœ¬ï¼Œä¿æŒ (s,a) ç›¸åŒï¼Œä½†ä»å…¶ä»–ä»»åŠ¡ä¸­é‡‡æ ·å¯¹åº”çš„ (r,s')ã€‚
    3.  å…·ä½“çš„ï¼Œcorro æå‡ºä¸¤ç§æ–¹æ³•å¾—åˆ° (r,s')ï¼š1 ç”¨æ¡ä»¶ VAE è®­ç»ƒï¼ˆæ²¡ç»†çœ‹ï¼‰ï¼Œ2 ç›´æ¥å¯¹ reward åŠ é«˜æ–¯å™ªå£° \\(r^\* = r + \\nu\\)ã€‚
*   ä¼¼ä¹æœ‰ä¸€ä¸ªå€¼å¾—çœ‹çš„ç†è®ºï¼Œè¯æ˜ InfoNCE loss æ˜¯ä»€ä¹ˆäº’ä¿¡æ¯çš„ä¸‹ç•Œï¼Œå¥½å¥‡è¿™ä¸ªç†è®ºå…·ä½“è¯æ˜äº†ä»€ä¹ˆã€‚

### Meta-DT: Offline Meta-RL as Conditional Sequence Modeling with World Model Disentanglement \[NeurIPS 2024\]

*   arxivï¼š[https://arxiv.org/abs/2410.11448](https://arxiv.org/abs/2410.11448)
*   pdfï¼š[https://arxiv.org/pdf/2410.11448](https://arxiv.org/pdf/2410.11448)
*   htmlï¼š[https://arxiv.org/html/2410.11448v2](https://arxiv.org/html/2410.11448v2)
*   æ¥æºï¼šçœ‹èµ·æ¥æ˜¯ä½¿ç”¨ DT çš„ offline meta-RLï¼ŒNeurIPS 2024ã€‚

kimi é€Ÿè¯»ï¼š

*   ä¹‹å‰å·²ç»æœ‰ç”¨ decision transformer æ¶æ„åš offline meta-RL çš„å·¥ä½œï¼Œå¦‚ prompt-DTã€generalized DTï¼ˆå³ HIMï¼‰ç­‰ã€‚DT å¤©ç”Ÿå°±æ˜¯ offline çš„ã€‚
*   ä½†æ˜¯ï¼Œprompt-DT åœ¨æµ‹è¯•æ—¶éœ€è¦ä¸“å®¶è½¨è¿¹ä½œä¸º promptï¼ŒGDT åˆ™éœ€è¦é¢„å…ˆæä¾› task çš„ç»Ÿè®¡ä¿¡æ¯åš hindsightã€‚Meta-DT å£°ç§°ï¼Œè¿™äº›æ–¹æ³•çš„å…±åŒé—®é¢˜æ˜¯ï¼Œæµ‹è¯•æ—¶ä¾èµ–é¢†åŸŸçŸ¥è¯†æˆ–ä¸“å®¶æ•°æ®ï¼Œè¿™äº›æ•°æ®ç°å®ä¸­å¾ˆéš¾è·å–ï¼Œè€Œ meta-DT åœ¨æµ‹è¯•æ—¶åªéœ€è¦ agent ä¸ task çš„äº¤äº’æ•°æ®ï¼Œä¸éœ€è¦è¿™äº›ä¸“å®¶æ•°æ®æˆ–è€…é¢†åŸŸçŸ¥è¯†ã€‚
*   methodï¼šmeta-DT ä¸»è¦è®­äº†ä¸¤ä¸ªæ¨¡å—ï¼š
    1.  off-policy çš„é¢„è®­ç»ƒä¸–ç•Œæ¨¡å‹ï¼Œä½¿ç”¨ GRU + MLP è®­ä¸€ä¸ª encoderï¼Œè¾“å…¥æ˜¯ \\(\\tau\_{:t}\\)ï¼Œè¾“å‡ºæ˜¯ \\(z\_t\\)ï¼Œç„¶åä½¿ç”¨ decoder é¢„æµ‹ (r,s')ã€‚è®­ç»ƒå®Œä¹‹åï¼Œè¿™ä¸ª encoder-decoder å°±å†»ç»“ã€‚
    2.  meta-DT çš„ DT æ¨¡å‹ï¼šå¯¹æ¯ä¸ªè®­ç»ƒä»»åŠ¡ï¼Œé€‰ offline æ•°æ®ä¸­ return æœ€é«˜çš„å‡ æ¡è½¨è¿¹ä½œä¸º"æ¼”ç¤ºåº“"ï¼Œç„¶åéšæœºé‡‡æ ·ä¸€æ¡ K æ­¥è½¨è¿¹ç‰‡æ®µ \\(\\tau\\)ï¼Œç”¨å†»ç»“çš„ encoder ç»™è¿™ä¸ªè½¨è¿¹æ ‡ä¸Š z ä¿¡æ¯ï¼ŒæŠŠè¿™ä¸¤éƒ¨åˆ†è½¨è¿¹ç›´æ¥æ‹¼èµ·æ¥ï¼Œæ„é€ å‡ºæ¥ \\((R^\*\_1, s^\*\_1, a^\*\_1, R^\*\_2, s^\*\_2, a^\*\_2, z\_1, R\_1, s\_1, a\_1, z\_2, R\_2, s\_2, a\_2)\\) è¿™æ ·çš„ sequenceï¼Œè¾“å…¥ç»™ DTï¼Œé¢„æµ‹ä¸‹ä¸€æ—¶åˆ» actionã€‚
*   æµ‹è¯•ç¯èŠ‚ï¼š
    *   åœ¨ few-shot æ¨¡å¼ä¸­ï¼Œé¦–å…ˆåœ¨æ–°ä»»åŠ¡ä¸Šçè·‘ 1-5 ä¸ª episodeï¼Œæ”¶é›†è½¨è¿¹ï¼Œç„¶åæŠŠæ”¶é›†çš„è½¨è¿¹å–‚ç»™ä¸–ç•Œæ¨¡å‹ï¼Œé€‰é¢„æµ‹è¯¯å·®æœ€å¤§çš„ k æ­¥ï¼Œæ„é€ æç¤º Ï„_ï¼Œæœ€ååœ¨æ­£å¼è¯„ä¼°ä¸­ï¼Œæ¯æ­¥ç”¨æœ€è¿‘ K æ­¥å†å² + Ï„_ åšå†³ç­–ã€‚
    *   åœ¨ zero-shot æ¨¡å¼ä¸­ï¼Œæˆ‘ä»¬ç›´æ¥è¯„ä¼°ï¼Œä¸é¢„å…ˆæ”¶é›†ä»»ä½•æ•°æ®ï¼Œä¸ä½¿ç”¨ Ï„\* çš„ promptï¼Œåªä½¿ç”¨ \\(\\tau\\) ä½œä¸º promptã€‚
*   å®éªŒï¼šåœ¨ few-shot çš„ setting é‡Œï¼Œmeta-DT è¶…è¿‡äº† baselineã€‚åœ¨ zero-shot settingï¼ˆä¸å…è®¸æå‰æ”¶é›†ä»»ä½•æ•°æ®ï¼Œagent ç›´æ¥åœ¨æ–°ç¯å¢ƒä¸Šä¸€è¾¹äº¤äº’ä¸€è¾¹å®æ—¶æ¨æ–­ä»»åŠ¡ï¼‰é‡Œï¼Œmeta-DT ç›¸æ¯” baseline æ›´åŠ å ä¼˜åŠ¿ã€‚

### Towards an Information Theoretic Framework of Context-Based Offline Meta-Reinforcement Learning \[NeurIPS 2024\]

*   arxivï¼š[https://arxiv.org/abs/2402.02429](https://arxiv.org/abs/2402.02429)
*   pdfï¼š[https://arxiv.org/pdf/2402.02429](https://arxiv.org/pdf/2402.02429)
*   htmlï¼š[https://arxiv.org/html/2402.02429](https://arxiv.org/html/2402.02429)
*   å¥½åƒæ˜¯æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œæ¥æ€»ç»“ç°æœ‰çš„ offline meta-RL æ–¹æ³•ã€‚

### Skill-based Meta-Reinforcement Learning \[ICLR 2022\]

*   arxivï¼š[https://arxiv.org/abs/2204.11828](https://arxiv.org/abs/2204.11828)
*   çœ‹èµ·æ¥æ˜¯ä½¿ç”¨è·Ÿ skill æœ‰å…³çš„æ–¹æ³•ï¼Œä» offline dataset é‡Œå­¦ä¸€ä¸ª meta ç­–ç•¥ã€‚

### Scrutinize What We Ignore: Reining In Task Representation Shift Of Context-Based Offline Meta Reinforcement Learning \[ICLR 2025\]

*   arxivï¼š[https://arxiv.org/abs/2405.12001](https://arxiv.org/abs/2405.12001)
*   æœ‰å¯èƒ½æœ‰ç‚¹ç›¸å…³ã€‚

### Generalizable Task Representation Learning for Offline Meta-Reinforcement Learning with Data Limitations \[AAAI 2024\]

*   arxivï¼š
*   æœ‰å¯èƒ½æœ‰ç‚¹ç›¸å…³ï¼Œæ˜¯ OMRL çš„æœ€æ–°å·¥ä½œã€‚

### Provably Improved Context-Based Offline Meta-RL with Attention and Contrastive Learning \[ICLR 2022\]

*   arxivï¼š[https://arxiv.org/abs/2102.10774](https://arxiv.org/abs/2102.10774)
*   pdfï¼š[https://arxiv.org/pdf/2102.10774](https://arxiv.org/pdf/2102.10774)
*   htmlï¼š[https://ar5iv.labs.arxiv.org/html/2102.10774](https://ar5iv.labs.arxiv.org/html/2102.10774)
*   æ¥æºï¼šICLR 2022ã€‚å¥½åƒæ”¹è¿›äº† focalï¼Œä½¿ç”¨ä»»åŠ¡å†…éƒ¨çš„ attention æœºåˆ¶å’Œä»»åŠ¡é—´çš„å¯¹æ¯”å­¦ä¹ ï¼Œæ ¹æ®è®ºæ–‡æ ‡é¢˜ï¼Œè¿˜æœ‰ç†è®ºè¯æ˜ã€‚

### (UDS) How to Leverage Unlabeled Data in Offline Reinforcement Learning \[ICML 2022\]

*   arxivï¼š[https://arxiv.org/abs/2202.01741](https://arxiv.org/abs/2202.01741)
*   pdfï¼š[https://arxiv.org/pdf/2202.01741](https://arxiv.org/pdf/2202.01741)
*   htmlï¼š[https://ar5iv.labs.arxiv.org/html/2202.01741](https://ar5iv.labs.arxiv.org/html/2202.01741)
*   æ¥æºï¼šICML 2022ã€‚è·Ÿæˆ‘ä»¬å…³æ³¨çš„ setting æ˜¯åƒçš„ï¼Œéƒ½å…³æ³¨æ²¡æœ‰ reward label çš„ offline æ•°æ®é›†ã€‚å¥½åƒç›´æ¥æ‹¿ zero reward æ¥ä½œä¸º rewardã€‚

å¥½åƒåŸºäº CDS å’Œ UDSï¼Œä½†å¬è¯´è¿™ä¸¤ä¸ªæ–¹æ³•ä¸å¤ªå¯å¤ç°ã€‚

ğŸ“Œ è¿‘æœŸå·¥ä½œ 2
---------

### (IDAQ) Offline Meta Reinforcement Learning with In-Distribution Online Adaptation \[ICML 2023\]

*   arxivï¼š[https://arxiv.org/abs/2305.19529](https://arxiv.org/abs/2305.19529)
*   pdfï¼š[https://arxiv.org/pdf/2305.19529](https://arxiv.org/pdf/2305.19529)
*   htmlï¼š[https://ar5iv.labs.arxiv.org/html/2305.19529](https://ar5iv.labs.arxiv.org/html/2305.19529)
*   æ¥æºï¼šå¸ˆå¼Ÿæ¨èçš„å·¥ä½œï¼ŒICML 2023ã€‚
*   å‚è€ƒåšå®¢ï¼š[CSDN |ã€è®ºæ–‡é˜…è¯»ç¬”è®°ã€‘IDAQï¼šç¦»çº¿å…ƒå¼ºåŒ–å­¦ä¹ ä¸­çš„åˆ†å¸ƒå†…åœ¨çº¿é€‚åº”](https://blog.csdn.net/iiiiii11/article/details/155364351)
*   ï¼ˆå°±ç®—æœ‰åšå®¢ï¼Œä¹Ÿè¿˜æ˜¯çœ‹ä¸å¤ªæ‡‚ï¼Œä¸€æ˜¯ä¸å¤ªäº†è§£ multi-task çš„å…·ä½“ settingï¼ŒäºŒæ˜¯ä¸å¤ªèƒ½ get åˆ° offline ä»–ä»¬è®²çš„ distribution shift æ•…äº‹â€¦â€¦ æ‰¾æ—¶é—´å¥½å¥½å­¦ä¸€ä¸‹ï¼Œå¯èƒ½å…ˆçœ‹çœ‹ focal
*   baselineï¼šFOCALã€MACAWã€BOReLã€‚

### Context Shift Reduction for Offline Meta-Reinforcement Learning \[NeurIPS 2023\]

*   arxivï¼š[https://arxiv.org/abs/2311.03695](https://arxiv.org/abs/2311.03695)
*   æ„Ÿè§‰æƒ³è§£å†³çš„é—®é¢˜ï¼Œå¥½åƒè·Ÿ IDAQ æ˜¯ç±»ä¼¼çš„ï¼Œéƒ½æ˜¯å» address offline dataset å’Œæˆ‘ä»¬çœŸæ­£ rollout å‡ºæ¥çš„æ•°æ®çš„åˆ†å¸ƒä¸ä¸€è‡´ã€‚

### Text-to-Decision Agent: Offline Meta-Reinforcement Learning from Natural Language Supervision \[NeurIPS 2025\]

*   arxivï¼š[https://arxiv.org/abs/2504.15046](https://arxiv.org/abs/2504.15046)
*   çœ‹èµ·æ¥æ˜¯æœ€æ–°çš„ç»“åˆ LLM çš„ offline meta-RL å·¥ä½œã€‚

### Efficient Offline Meta-Reinforcement Learning via Robust Task Representations and Adaptive Policy Generation \[IJCAI 2024\]

*   å¯ä»¥çœ‹ abstract çš„ç½‘é¡µï¼š[https://dl.acm.org/doi/10.24963/ijcai.2024/500](https://dl.acm.org/doi/10.24963/ijcai.2024/500)
*   pdfï¼š[https://www.ijcai.org/proceedings/2024/0500.pdf](https://www.ijcai.org/proceedings/2024/0500.pdf)
*   æ¥æºï¼šæ— æ„ä¸­æœåˆ°çš„ï¼ŒIJCAI 2024ã€‚çœ‹ abstract æ„Ÿè§‰è§£å†³çš„ä¸æ˜¯å¾ˆé‡è¦çš„é—®é¢˜ï¼Œä½†å¥½åƒæ˜¯æœ‰è¶£çš„ï¼Œä¸ç€æ€¥çœ‹ã€‚

### Meta-Reinforcement Learning via Exploratory Task Clustering \[AAAI 2024\]

*   arxivï¼š[https://arxiv.org/abs/2302.07958](https://arxiv.org/abs/2302.07958)
*   pdfï¼š[https://arxiv.org/pdf/2302.07958](https://arxiv.org/pdf/2302.07958)
*   htmlï¼š[https://ar5iv.labs.arxiv.org/html/2302.07958](https://ar5iv.labs.arxiv.org/html/2302.07958)
*   æ¥æºï¼šå¸ˆå¼Ÿçš„è®ºæ–‡ listï¼ŒAAAI 2024ã€‚çœ‹ abstract æ„Ÿè§‰æ²¡æœ‰è§£å†³ç‰¹åˆ«é‡è¦çš„é—®é¢˜ï¼Œä½†å› ä¸ºæ˜¯ task clusteringï¼Œæ‰€ä»¥æƒ³çœ‹ä¸€ä¸‹ã€‚

### Contextual Transformer for Offline Meta Reinforcement Learning \[NeurIPS 2022 workshop\]

*   arxivï¼š[https://arxiv.org/abs/2211.08016](https://arxiv.org/abs/2211.08016)
*   æ˜¯ workshop æ–‡ç« ã€‚ç®€å•çœ‹çœ‹å§ã€‚

### Model-Based Offline Meta-Reinforcement Learning with Regularization

*   arxivï¼š[https://arxiv.org/abs/2202.02929](https://arxiv.org/abs/2202.02929)
*   model-based çš„ offline meta-RLã€‚

### Enhancing Online Reinforcement Learning with Meta-Learned Objective from Offline Data \[AAAI 2025\]

*   arxivï¼š
*   å¯èƒ½æœ‰ä¸€ç‚¹ç›¸å…³ã€‚

### Offline Meta-Reinforcement Learning with Online Self-Supervision \[ICML 2022\]

*   arxivï¼š[https://arxiv.org/abs/2107.03974](https://arxiv.org/abs/2107.03974)
*   pdfï¼š[https://arxiv.org/pdf/2107.03974](https://arxiv.org/pdf/2107.03974)
*   htmlï¼š[https://ar5iv.labs.arxiv.org/html/2107.03974](https://ar5iv.labs.arxiv.org/html/2107.03974)
*   æ¥æºï¼šç–‘ä¼¼æ˜¯ offline meta-RL + offline-to-online çš„æ–‡ç« ï¼ŒICML 2022ã€‚æ„Ÿè§‰ä¸ç€æ€¥è¯»ã€‚

  

æ„Ÿè°¢å¸ˆå¼Ÿå’Œå‚è€ƒåšå®¢çš„è®²è§£ğŸµ