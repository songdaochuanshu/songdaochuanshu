---
layout: post
title: 'Qwen WebAgent 系列'
date: "2025-10-14T00:39:23Z"
---
Qwen WebAgent 系列
================

GitHub地址： [https://github.com/Alibaba-NLP/WebAgent#](https://github.com/Alibaba-NLP/WebAgent#)

![](https://oxz2458klw.feishu.cn/space/api/box/stream/download/asynccode/?code=OWMwN2E3ODk3MzMwZmM5Yjk3ZmQ4Yzg2NGQzZjg2MTNfbDNuS1QwWDZEVDBuWlpwRXIzUFk5V3l4bzhFeUJ2WXdfVG9rZW46SkFHNGJsZW1ib2diRTF4MWtZbmNwbFFnbm1mXzE3NjAzMzU3NTQ6MTc2MDMzOTM1NF9WNA)

共有5篇系列文章

为Agent（React架构）在web search（Deepsearch）提供BenchMark以及模型训练方法。

WebWalker
---------

将原始instruct-answer的single-step数据扩展到multi-step上。

**构建QA对**

1.  递归的访问root url下面的子url
    
2.  排列组合网页信息，并根据url跳转的难度划分难度等级
    
3.  根据组合后的网页信息，调用gpt-4o（之类的api）生成QA pair。
    

值得注意的是，A应该是容易验证的，像是实体的明确的属性、时间、人物、数值等。

难度分类：

1.  single-source：从一个root url出发，更像是dfs
    
2.  multi- source：更像是bfs，要融合更广的网页信息
    

暂时无法在飞书文档外展示此内容

WebDancer
---------

在构建数据的同时，增加**cold-start&RL**

1.  构建QApair
    
    1.  CRAWLQA：类似WebWalker的构建方法，根据官网的root url递归访问网页，并生成QA
        
    2.  E2HQA：有点像定语从句的感觉，把Q中的**entity（一般是名词）递归式地替换成一段描述的语句，**增加Q的难度，增强逻辑性。【突然想到，定语从句可以有效的减少entity，或是说将 高信息（低熵）的entity换成低信息（高熵）的entity，在逻辑上增加q的难度。】
        
        *   如果是基于单一属性（路径）：比如，想找一个和A在同一年出生的人。那么从A入手通过一步搜索可以得到A的出生时间，是只有一个指向路径的
            
        *   如果是多指向呢：比如，想找一个和A获得过同一个奖项的人且和B同一年出生。那么
            
            *   先从B入手，得到想找人的出生时间T（1路径）
                
            *   再从A入手，需要看A获得的各个奖项中，是否有一个人T年出生（M路径，因为A可能获得M个奖项，搜索的宽度更大，QA任务更难）
                
    
    ![](https://oxz2458klw.feishu.cn/space/api/box/stream/download/asynccode/?code=NjM4MjljMjIxNTM4MjhkZjc2NmRhNGMxYmMxNTE5ZWJfRFlqNURUdzdZQzdpblZtNGNQQ3RjUDhFRVdFdWRTS3VfVG9rZW46UHlBSGJDTFhWb2c0ZjF4QnZZTWM3aWRIbjdnXzE3NjAzMzU3NTQ6MTc2MDMzOTM1NF9WNA)
    
2.  利用QA，采样trajectories并进行filter（ReAct采样）
    
        def search(q:List[str]):
        '''
        根据q，查找网页信息
        '''
        
        def visit(url:str, goal:str):
        '''
        访问具体的网页链接url，并根据目标goal，返回给main agent此网页的总结
        '''
        
    
    2.  Validity control：保证ReAct的格式正确，如工具调用、正确结束等
        
    3.  Correctness verification：保证answer的正确性（由于是强推理的Q，answer正确也间接地保证了trajectory的正确性，**其实主要目的就是为了构建正确的trajectory即multi-step的数据**）
        
    4.  Quality assessment：使用llm判断是否有幻觉、等等**主观指标**
        
3.  SFT：注入formart、tool 使用等知识
    

注意对observation进行mask

![](https://oxz2458klw.feishu.cn/space/api/box/stream/download/asynccode/?code=OWM5MWI3MjZmNzM4YmNkYzg5NzM1ZThmMjk2N2FiMmZfNFM5R1p5c0VHc2cxMHlXYUxXNmtYang3NGZ5VWRnVkJfVG9rZW46UTNTRGI5bWMzb1VhQ0F4SlZ3Y2NYWWhSbmZlXzE3NjAzMzU3NTQ6MTc2MDMzOTM1NF9WNA)

4.  RL：增强泛化性

使用DAPO进行RL，以及llm as judge判断answer相较于ground-truth是否是对的。。

实验结果：

RL对LLM的提升是显著的，但是对LRM的提升并较少（QwQ）

暂时无法在飞书文档外展示此内容

WebSailor
---------

在WebDancer基础上，进一步构建数据集

**问题：**

1.  考虑到采样的LRM的thought很长，且有明显的风格，可能会在sft时与原始policy的pattern并不相似，导致acc sharp的现象。
    
2.  Context overload：reasoning chains过长的话，较多的tool调用将会导致history超过上下文的限制
    

**数据构建：**

1.  QA对构建：基于**知识图谱**【_知识图谱的构建并不太了解_】，并添加混淆（扩大时间范围，mask具体的实体名称等），增加难度
    
2.  Trajectory采样：基于原始的（reason，action，observation）以及当前的**aciton和observation构建当前的reasoning**
    

![](https://oxz2458klw.feishu.cn/space/api/box/stream/download/asynccode/?code=ZTJjYmM0ODgyNmUzMTkwNzRlOTE5ZjAyOWZjMmYwNmJfb3VQTTZyakNEVzhkZXpGaVJTZ2pPNm1sV3VJSThCS2xfVG9rZW46UUVZU2JCRHFQb1RVeUJ4bVlzRmNDRVEybmxmXzE3NjAzMzU3NTQ6MTc2MDMzOTM1NF9WNA)

![](https://oxz2458klw.feishu.cn/space/api/box/stream/download/asynccode/?code=N2FmNGEwYmY1NjMzYjcxNTMxYWM0MWRhZTM4NzZlZDBfZDR1SGliWVozRktHV3N3Z2w0aVFRRkRKYTBLSEpmaVZfVG9rZW46RDdQUWJkdk5RbzZUZ2V4cllEN2NmT1pobmxnXzE3NjAzMzU3NTQ6MTc2MDMzOTM1NF9WNA)

**训练：**

1.  RFT：拒绝采样
    
2.  RL：DUPO（DUplicate Policy Optimization）。与DAPO不同的是，在删除掉acc=1/0的prompt后，直接复制原始batch中acc！=0/1的prompt，来填充batch进行训练。（**batch的padding方式不同罢了**） DUPO还有个off-policy的filter，其实就是在RL之前就把过于简单（8 rollout都对的）的case给filter掉了。
    

暂时无法在飞书文档外展示此内容

WebShaper.pdf

WebWatcher
----------

贡献：将text-search agent扩展到visual-text search agent中。其实就是在q中添加了图片信息，以及添加了新的image-search、OCR、code interpreter三个工具。

难点：将QA转化成VQA。

1.  convert：将相关的entity 使用google image api找到相应的图片，
    
2.  mask：并**mask掉提到此实体的文本信息，并用image替换**
    
3.  selector：filter mask失败的VQA，并用gpt-4o评估图片和Q的相关性
    
4.  examiner：看gpt-4o能否在正确回答mask后的q，在仅使用image和image相关信息的条件下。如果回答错误，那么此VQA不匹配，filter掉。（不太理解\_，associated captions of image是怎么获得的\_。。RAG么，还是什么其他的方法。如果gpt-4o判断不出来，可能是它模型自身的问题哇。。）