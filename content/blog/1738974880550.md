---
layout: post
title: '全网最简单DeepSeek-R1本地部署教程'
date: "2025-02-08T00:34:40Z"
---
全网最简单DeepSeek-R1本地部署教程
======================

**1.安装ollama**
--------------

打开ollama网址：https://ollama.com/

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207102122758-2051223354.png)

 选择你电脑的系统进行下载

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207102208169-1103590039.png)

我的电脑是windows的就点击windows然后点击下载即可

下载完毕后双击打开下载的.exe文件等待软件自动安装完毕

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207102402388-1875869667.png)

 安装完毕后，点击键盘的win+r键输入cmd进入命令行

然后输入ollama -v会显示版本

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207102607391-1555209251.png)

 说明ollama安装完毕

**2.部署DeepSeek-R1模型**
---------------------

打开ollama官网：https://ollama.com/

然后点击左上角的models

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207102831741-1901624322.png)

 选择DeepSeek-R1模型

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207102923824-1235535472.png)

模型的大小大致分为1.5b,7b,8b,14b,32b,70b,671b

根据自己的电脑显卡和配置进行选择相应的版本

### 显卡要求

DeepSeek-R1-1.5b   NVIDIA RTX 3060 12GB or higher

DeepSeek-R1-7b      NVIDIA RTX 3060 12GB or higher

DeepSeek-R1-8b      NVIDIA RTX 3060 12GB or higher

DeepSeek-R1-14b    NVIDIA RTX 3060 12GB or higher

DeepSeek-R1-32b    NVIDIA RTX 4090 24GB

DeepSeek-R1-70b    NVIDIA RTX 4090 24GB \*2

DeepSeek-R1-671b NVIDIA A100 80GB \*16

我这边直接选择的是8b模型进行演示

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207103801816-1926975557.png)

 复制命令，在刚刚的命令行中直接复制+回车

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207104021202-1291918812.jpg)

显示success则为下载成功，之后可以正常对话

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207104158982-467994316.png)

 如果想要退出可以使用 /bye的方式退出对话

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207104249703-1016812204.png)

 如果后续还想要进入对话，可以使用ollama list

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207104335621-2009417251.png)

 复制name,然后执行ollama run deepseek-r1:8b就可以再次进入对话啦

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207104417955-573260652.png)

 但是我们每次如果想要使用ollama模型的时候都需要运行命令行，这就有点不方便

所以接下来就开始安装可视化的界面来使用本地的模型

3.安装Chatbox
-----------

打开Chatbox官网：https://chatboxai.app/zh[  
](https://chatboxai.app/zh)

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207110104813-2138666327.png)

 点击免费下载

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207110157847-766670686.png)

 双击安装

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207110227132-1287179704.png)

 自定义目录然后点击安装

现在我们就成功安装了Chatbox

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207110713632-1779206213.jpg)

 选择使用自己API key或者本地模型

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207110751666-383938464.jpg)

 选择Chatbox AI

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207110827162-1778461952.jpg)

 模型设置页面，模型提供方选择Ollama API

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207111006457-38299076.png)

 api域名不需要进行更改

模型选择刚在电脑上下载的ollama模型即可

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207111058375-62482974.png)

然后点击保存，之后我们就可以在这个可视化模型中进行对话

![](https://img2024.cnblogs.com/blog/2240681/202502/2240681-20250207111227900-1597162127.png)

到这里，本地化安装基本就结束啦，bye!