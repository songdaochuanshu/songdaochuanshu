---
layout: post
title: '函数计算进化之路：AI Sandbox 新基座'
date: "2025-09-14T00:41:51Z"
---
函数计算进化之路：AI Sandbox 新基座
=======================

**引言：定义问题与趋势**
--------------

### **AI Sandbox 的崛起**

计算领域正在经历一场革命性的转变。我们正从简单的请求-响应模型，迈向一个由自主的、以目标为导向的 AI Agent 定义的新时代。这些 Agent 不再仅仅是被动地执行指令，而是能够进行推理、规划、并拥有记忆，以代表用户完成复杂的多步骤任务。

然而，这种强大的自主性也带来了前所未有的安全风险。如何在一个安全可控的环境中执行AI驱动生成的业务逻辑？答案就是 AI Sandbox。  
AI Sandbox 是一个被严格控制的隔离环境，它允许 AI Agent 在其中安全地执行代码、与应用交互和访问资源，而不会危及主机系统或泄露敏感数据。其核心价值在于，它为创新提供了一个“安全环境”，在释放 AI 强大潜力的同时，有效规避了潜在的安全风险，是推动 Agent 技术走向成熟和商业化应用不可或缺的基础设施。

### **运行时面临的关键挑战**

AI Agent 这一新兴工作负载范式，对底层的运行时环境提出了三个根本性的、前所未有的技术挑战：

1.  **隔离与安全 (Isolation & Security)**: 这是首要且不容妥协的要求。执行由大语言模型（LLM）动态生成且不可信的代码，引入了巨大的安全漏洞，包括沙箱逃逸、代码注入、权限提升和未经授权的系统访问。传统的软件沙箱技术在应对这种动态、复杂且可能具有对抗性的 AI 工作负载时，正变得越来越力不从心，频繁出现的高危漏洞证明了这一点。
2.  **状态管理与成本 (State Management & Cost)**: AI Agent 的工作模式是对话式、持续性的，这意味着每个 Agent 都需要一个持久的、有状态的会话来维持上下文、记忆和交互式环境。这与传统的基础设施模式产生了尖锐的冲突。为每一个潜在的用户会话（可能是数百万个）都预置一个长期运行的虚拟机（VM），将导致惊人的闲置资源成本和巨大的运维负担。
3.  **可扩展性与运维 (Scalability & Operations)**: Agent 应用的流量往往是突发且不可预测的。基础设施必须能够瞬时、动态地扩展以应对峰值，并在空闲时迅速缩减以节约成本。然而，从零开始构建并维护一个既安全隔离又具备弹性伸缩能力的沙箱环境，需要极其专业的 DevOps 知识和大量的人力投入，这对大多数初创公司和开发团队而言都是一个难以逾越的障碍。

这三大挑战共同指向一个结论：AI Agent 的兴起催生了一种全新的、独特的云工作负载类型。它既不完全符合传统 IaaS（对于零散、突发的使用场景而言过于昂贵和笨重）的模式，也打破了第一代 FaaS（函数即服务，因其无状态和较弱的隔离保证而无法满足需求）的设计假想。市场迫切需要一种新型运行时——它必须兼具**虚拟机的状态化和隔离性**与\*\* Serverless 的经济性和弹性\*\*。这正是阿里云函数计算（Function Compute, FC）架构演进所要解决的核心问题。

**为何函数计算是理想的起点**
----------------

在深入探讨函数计算为 AI Sandbox 提供的原生解决方案之前，我们必须首先理解其底层架构所带来的独特基础优势。这些优势并非后期添加的功能，而是根植于平台设计的基因之中，使其成为构建安全、经济、高效沙箱的理想起点。

### **始于物理隔离的底层架构**

安全性是 AI Sandbox 的基石，而函数计算的安全性始于最底层——物理硬件。其独特的 **“神龙裸金属 + MicroVM 安全容器”** 架构，为用户提供了一个从硬件到应用运行时的端到端、纵深防御安全体系。

*   **神龙裸金属服务器 :** 与传统的多租户虚拟化技术（即多个用户的虚拟机共享同一台物理机上的 Hypervisor）不同，函数计算的实例运行在阿里云自研的弹性裸金属服务器之上。这意味着不同租户的计算实例在物理层面就是隔离的，不存在共享的 Hypervisor 层。这种**物理隔离**从根本上消除了整个类别的 Hypervisor 逃逸漏洞，为多租户环境提供了当前业界最高级别的安全保障。
*   **MicroVM 安全容器 :** 在物理隔离的坚实基础上，函数计算采用 MicroVM 作为其容器运行时。MicroVM 是一款专为高密度、高并发的 Serverless 场景设计的轻量级安全容器运行时。它提供了必要的进程、文件系统和网络隔离，其开销远低于传统的虚拟机，从而能够实现毫秒级的快速启动和销毁，完美契合了沙箱环境的动态需求。

这种“物理隔离保障租户间安全，安全容器保障租户内隔离”的双重隔离模型，构建了一个远比单一依赖 Hypervisor 的传统虚拟化方案更为坚固的安全壁垒，为运行不可信的 AI 生成代码提供了前所未有的信心。

### **Serverless 时代的红利**

除了坚不可摧的安全基础，函数计算作为 Serverless 平台，为 AI Agent 场景带来了颠覆性的经济和运维优势。

*   **极致的成本效益**: AI Agent 的用户活跃度通常是突发和间歇性的。如果采用传统的预置服务器模式，企业将为大量的闲置时间付费。研究表明，超过 70% 的服务器资源处于未被充分利用的状态。函数计算的按需付费模型（精确到毫秒）则彻底改变了这一局面。您只需为沙箱实际运行的计算时间付费，当没有请求时，不产生任何计算费用，资源利用率可达 100%。
*   **零运维负担**: 平台完全托管了底层基础设施的生命周期管理，包括资源调配、系统补丁、安全加固、容量规划和弹性伸缩。这意味着您的开发团队可以从繁琐复杂的 DevOps 工作中解放出来，将全部精力聚焦于构建Agent 的核心能力和业务逻辑，从而极大地缩短产品上市时间。

函数计算的这些基础优势，直接回应了引言中提出的核心挑战。它以一种“无妥协”的姿态，同时解决了安全和成本这两个构建 AI Sandbox 时最令人头疼的问题。

**函数计算还缺什么？**
-------------

尽管函数计算拥有强大的底层优势，但在其演进的早期阶段，和其他 FaaS 平台一样，也面临着一个核心的架构性矛盾：**平台设计的“无状态”本质与 AI Sandbox 需求的“有状态”特性之间的冲突**。

### **短暂的执行 vs. 持久的环境**

传统的 FaaS 平台被设计为处理**无状态**的、短暂的事件。每一次函数调用都被视为一个独立的、全新的开始，执行环境在调用结束后随时可能被回收，不保留任何上下文信息。然而，一个 AI Sandbox 的工作流程恰恰相反，它本质上是**有状态**的。Agent 需要在一个连续的会话中加载代码库、安装依赖、在内存中维护上下文、在文件系统中读写文件，并与用户进行多轮交互。这种根本性的不匹配，是第一代 Serverless 架构应用于此场景时最大的障碍。

### **E2B 项目的实践与启示**

开源项目 **E2B** 是一个广受欢迎的 AI Sandbox 框架。我们将其应用层的 Jupyter 以及 Envd 移植到阿里云函数计算的早期尝试（[https://github.com/aliyun-fc/e2b-on-aliyun-fc](https://github.com/aliyun-fc/e2b-on-aliyun-fc)）中，探索出静态预留实例的模式，该模式将函数与 Sandbox 一一对应，将函数的“最小实例数”和“最大实例数”都设置为 1，可以强制平台为一个函数长期保留一个运行中的实例，这个实例不会因为空闲而被回收，从而实现了一种伪状态化的“会话粘性”。

这次实践将函数计算作为 E2B 的 Infra 层，成功验证了函数计算底层环境的可行性，但也清晰地暴露了上述所有局限。它让平台和社区都深刻地认识到：仅仅“让实例活得更久”是远远不够的。真正的挑战在于，如何在一个庞大的、动态的实例池中，智能地管理成千上万个有状态会话的生命周期，并将属于特定用户的请求精确地路由到其对应的实例上。

这种探索过程中的变通方案，其失败之处恰恰揭示了通往真正解决方案的道路。它证明了市场需要的不是一个配置技巧，而是一个平台级的、原生的**会话管理和路由层**。

### **方案的局限性**

尽管这种方法在小规模验证中看似可行，但它很快就暴露出一系列致命的局限性，使其无法成为一个可持续、可扩展的解决方案：

*   **高昂的管理成本:** 开发者需要为每个用户或每个会话手动创建和管理一个独立的、配置了静态实例的函数。这违背了 Serverless 简化运维的初衷，带来了巨大的管理复杂性。
*   **可扩展性的噩梦:** 这种模式完全破坏了 Serverless 自动伸缩的核心价值。当用户规模从十增长到一万时，平台无法自动扩展。开发者需要手动或通过复杂的外部编排逻辑来管理这一万个“永久在线”的函数，这在操作上是极其脆弱和不可行的。
*   **经济效益的丧失:** 静态预留模式需要函数始终保持一个实例存活来模拟“会话粘性”，这种使用模式完全抵消了 Serverless 按需付费的最大成本优势。
*   **平台与用户的双重负担:** 这种反模式（Anti-pattern）不仅给用户的架构带来了技术债，也对云平台的调度系统造成了不必要的压力，是一种低效的资源利用方式。

**从变通到原生支持AI Sandbox配套能力**
--------------------------

AI Agent 工作负载的兴起，标志着 Serverless 计算范式的一次重要演进。需求已经从单纯的“执行一段代码”，转变为“管理一个有状态的、可交互的完整环境”。这要求平台本身必须从一个简单的事件触发器，进化为一个具备复杂会话生命周期管理能力的智能调度系统。

阿里云函数计算敏锐地捕捉到了这一趋势，并推出了业界领先的原生解决方案，彻底告别了过去的变通，为有状态 Serverless 应用提供了坚实的平台级支持。

### **核心能力：安全、会话亲和、隔离与管理**

函数计算推出的这套原生解决方案，由三大核心能力构成，它们协同工作，为 AI Sandbox 提供了完美的运行环境。

1.  **灵活的安全机制**
    
    传统Serverless架构，基于函数执行角色，通常会由平台默认注入一个临时的STS Token实现运行时的无AK化，确保AK的安全；但考虑到AI执行环境的安全性和STS Token被 AI 滥用的潜在安全风险，平台提供了禁止注入STS Token的能力。
    
2.  **强会话亲和 (Session Affinity)**:  
    这是解决状态化问题的关键。会话亲和性是一个智能路由层，它确保在一次会话的整个生命周期中，所有来自同一客户端的请求，都会被精确且持续地路由到同一个函数实例上。函数计算提供了多种灵活的亲和方式，包括专为 Agent 场景设计的 **MCP SSE 亲和**，以及适用于 Web 场景的 **HeaderField 亲和**和 **Cookie 亲和**。这就为每个用户会话分配了一个固定的函数实例，保证了交互的连续性和上下文的完整性。
    
3.  **会话物理隔离 (Session Isolation)**:  
    如果说会话亲和解决了“连续性”的问题，那么会话隔离则解决了“安全性”的问题。在多租户 SaaS 平台中，确保不同租户的沙箱环境绝对隔离是最高安全准则。启用会话隔离后，函数计算会为每一个会话独占一个完整的函数实例（强制将单实例 Session 并发度设置为 1）。这意味着租户 A 的内存、临时文件、进程空间与租户 B 的环境是物理上分离的（基于神龙裸金属）和逻辑上独立的，从而提供了金融级别的多租户安全保障。
    
4.  **会话管理接口 (Session Management Interface)**:  
    函数计算将这些强大的底层能力，通过简洁的控制台配置选项和 API 接口开放给开发者。开发者无需编写复杂的外部编排和调度逻辑，只需通过简单的配置，就能创建、查询和销毁这些被隔离的、有状态的会话。平台在后台自动处理了会话生命周期与实例生命周期的精确映射和管理，极大地降低了开发门槛。
    

### **架构对比：从混乱到优雅**

通过下面的架构对比图，我们可以清晰地看到从“变通方案”到“原生支持”的巨大飞跃。

会话亲和与会话隔离并非两个孤立的功能，而是一个统一概念的两个侧面，共同构建了一个全新的 Serverless 原语：“**按需生成的、隔离的、有状态的运行时环境**”。亲和性定义了“得到什么”（一个连续的环境），隔离性定义了“如何得到”（一个安全独占的环境）。这种组合，让函数计算超越了传统 FaaS 的范畴，成为一个能够原生承载有状态应用的强大平台。

### **存储隔离：解决状态持久化难题**

一个完整的 AI Sandbox 解决方案，不仅需要解决计算层的状态管理，还必须应对存储层的持久化挑战。函数计算通过创新的技术和完善的最佳实践，为 Agent 的两类核心存储需求——**本地临时存储**和**持久化共享存储**——提供了端到端的解决方案。

#### **本地临时存储：快照技术带来的极速恢复**

*   **挑战:** 当一个用户会话进入空闲状态时，为了节约成本，平台可能会回收或“冻结”其占用的实例。那么，当用户再次发起请求时，如何快速恢复该实例本地磁盘上原有的环境状态（例如已安装的依赖包、生成的代码文件、会话日志等）？传统的冷启动方式需要重新初始化整个环境，耗时过长，严重影响用户体验。
*   **解决方案：**函数计算为此引入了基于快照的会话运行时环境恢复机制。当一个启用了会话隔离且设置了最小实例数的函数实例进入空闲时，平台并不会简单地销毁它。相反，系统会自动为该实例的状态（包括其完整的本地磁盘）创建一个**快照 (Snapshot)**。当该会话的下一个请求到达时，平台会直接从这个快照“唤醒”一个全新的实例。这个过程是“热启动”，能够在短时间内恢复会话之前的所有本地环境。

这种机制巧妙地平衡了成本与性能，为用户提供了持久化会话的体验，而其计费模式却依然遵循 Serverless 的按需使用原则，只在实例活跃时才收取全额费用。

#### **持久化共享存储：会话粒度存储隔离**

##### **共享存储架构的多租隔离挑战**

对于采用SaaS（软件即服务）模式的Agent平台而言，其核心架构必须支持成千上万个租户（Tenant）在隔离环境中安全地运行。在数据持久化层面，这些租户的项目文件、数据集等核心资产，通常会统一存放在一个高可用、可扩展的共享后端存储系统上（例如，NFS协议的阿里云文件存储NAS）。

在此背景下，一个严峻的安全挑战应运而生：如何在物理共享的存储资源上，实现逻辑上租户之间数据的严格隔离，有效防止任何形式的数据越权访问。传统的做法，即将所有用户的会话相关实例挂载到同一个共享根目录，是一种完全不可接受的方案。这种设计存在重大安全隐患，无法满足企业级的安全与合规要求。

##### **从计算隔离到存储隔离的延伸**

为应对这一挑战，Serverless 平台需要一套端到端的数据隔离与访问控制方案。该方案以前文所述的“会话（Session）”抽象为基础，将会话亲和（Session Affinity）与会话隔离（Session Isolation）能力从计算层延伸至存储层，构建起一道坚实的数据安全防线。

我们为此引入了**“会话粒度存储粘性”（Session-level Storage Stickiness）**的核心机制。其设计思想是：**将会话与一个持久化的、归属于特定租户的存储子目录进行强绑定**。

具体而言，当平台为租户创建会话时，会执行以下关键操作：

*   **动态绑定：** 每个会话都将唯一关联到一个用户指定的挂载子目录（Sub-Path）。此目录成为该会话期间所有持久化数据的唯一、专属存储位置。
*   **按需创建：** 如果租户指定的子目录尚不存在，平台将自动、原子化地创建该目录，确保服务启动的无缝衔接。

通过这种方式，我们巧妙地在共享的存储挂载点（Mount Point）之上，为每个会话构建了一个独立的、目录级别的逻辑“数据沙箱”，从基础文件系统层面杜绝会话间数据交叉的可能性。

##### **基于POSIX标准的多租存储安全实践框架**

在会话粒度存储粘性能力基础上，函数计算给用户提供了一套可落地的**多租户存储安全最佳实践框架**。开发者可以利用平台能力，构建一个层次化的纵深防御体系：

*   **UID 隔离**: 这是 POSIX 文件系统权限控制的基石。用户需要为每个会话（可以映射为每个租户或会话）颁发一个唯一的 POSIX 用户 ID (UID) 。这样，每个会话在文件系统层面就有了自己独立的“身份”。
*   **SecurityContext 继承**: 平台侧在自动创建不存在的挂载目录时，会自动将目录的 UID 和 GID 指定为用户配置的 UID 以及 GID，并将目录的访问 Mode 设置为 `700` (rwx------)，保证挂载目录的权限只为其所有者，在此基础上，用户的函数主进程在挂载目录下创建子目录或者文件时，需要**主动继承**挂载目录的 SecurityContext ，从源头上防止了权限混乱。
*   **主进程 UID 切换**: 这一步在进程层面加固了隔离。Agent 的代码本身就运行在受限的、非 root 的用户身份下，极大地缩小了潜在的攻击面。
*   **目录配额 (Directory Quotas)**: 这是防止“邻居噪音”问题的关键一环。需要借助存储平台侧的目录级配额能力，主动为不同会话（或不同租户）的目录精确设置配额，有效防止某个恶意或行为异常的租户耗尽整个共享文件系统的存储空间，从而保障了其他所有租户服务的可用性。
*   **UID 复用**: 当一个UID被回收后，它在文件系统上的内容依然存在，在真正清理完文件系统上对应会话的内容后，该 UID 才能被再次复用，若依赖存储平台侧具备目录 TTL 能力，那么基于会话最大存活时间进行合理设置即可，否则需要用户主动启动**异步垃圾回收**进程来定期扫描文件系统，回收过期的会话文件内容。

这套闭环的安全体系，表明函数计算提供的不仅仅是孤立的存储功能，而是一套经过深思熟虑的、面向多租户 SaaS 场景的、企业级的安全架构。

#### **引入 PolarFS 以实现极致性能**

尽管基于 NAS 的多租户安全框架已经足够强大和安全，但对于某些追求极致性能的场景，例如在 Sandbox 内进行大规模代码编译、高频读写海量小文件、或运行 I/O 密集型数据分析任务时，通用文件存储的毫秒级延迟可能成为瓶颈。

为了满足这些最严苛的性能需求，**PolarFS** 是专为云原生数据库 PolarDB 设计的高性能分布式文件系统，其核心优势在于**极致的低延迟**。通过利用 RDMA、NVMe 以及用户态 I/O 栈等前沿技术，PolarFS 绕过了传统的操作系统内核，实现了接近本地 NVMe SSD 的微秒级访问延迟，这比 NAS 的毫秒级延迟有数量级的提升。

这种极致性能对于 AI Sandbox 意味着更快的环境初始化、更流畅的代码执行和数据处理体验。为了将这种能力赋予广大开发者，**阿里云函数计算正与 PolarFS 团队紧密合作，即将推出 PolarFS 的原生挂载能力**。这项新功能将支持在**会话粒度**上，为每一个独立的 Sandbox 动态挂载专属的 PolarFS 存储盘。这将为需要极致 I/O 性能的 AI Agent 应用提供一个无与伦比的运行时环境，进一步巩固函数计算在该领域的领导地位。

**函数计算：AI Sandbox 的首选运行时**
--------------------------

经过层层深入的剖析，我们可以清晰地看到，阿里云函数计算已经超越了传统 Serverless 的范畴，为 AI Sandbox 这一新兴的、要求严苛的工作负载，提供了原生、集成且完整的平台级解决方案。

### **端到端的原生解决方案**

阿里云函数计算的核心优势在于其**方案的完整性和原生性**。它不是通过零散功能的拼凑或复杂的变通来实现对 AI Sandbox 的支持，而是从底层硬件到上层应用提供了一套无缝集成的、端到端的解决方案：

*   **计算隔离:** 以“神龙裸金属”的物理隔离为根基，结合“MicroVM 安全容器”的轻量级隔离，提供了业界最高标准的安全保障。
*   **会话管理:** 通过原生的“会话亲和”与“会话隔离”能力，完美解决了 Agent 所需的有状态、长连接和多租户隔离问题，将 Serverless 的弹性和经济性带入有状态应用领域。
*   **存储安全:** 创新的“快照恢复”技术实现了本地临时存储的秒级恢复，而基于“UID/GID 隔离”和“目录配额”的完整安全隔离框架，则为持久化共享存储构建了坚不可摧的多租户安全堡垒。

**正是这三大支柱，共同铸就了函数计算这一 AI Sandbox 的“新基座”。**这个强大而优雅的架构，不仅代表了函数计算自身的**成功进化**，更标志着 Serverless 架构迈入了一个能够原生承载复杂、有状态 AI 应用的新纪元。它让开发者能够以最低的成本、最快的速度和最高的安全性，站在这块坚实的基座上，构建和部署下一代 AI Agent 应用。