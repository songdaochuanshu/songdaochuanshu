---
layout: post
title: 'langchain å¿«é€Ÿå…¥é—¨(äº”)ï¼šLanggraphåº”ç”¨ï¼Œæ‰§è¡Œæµç¨‹ç”±çº¿è½¬å›¾'
date: "2026-01-27T00:49:27Z"
---
langchain å¿«é€Ÿå…¥é—¨(äº”)ï¼šLanggraphåº”ç”¨ï¼Œæ‰§è¡Œæµç¨‹ç”±çº¿è½¬å›¾
======================================

ç®€ä»‹
==

**Langgraph**æ˜¯langchainæ¡†æ¶æä¾›çš„ä¸€ä¸ªç»„ä»¶ï¼Œlanggraphèƒ½å¤Ÿè§£å†³AIæ‰§è¡Œæµç¨‹ä¸­è¿­ä»£ã€å¾ªç¯æˆ–è€…æ ¹æ®ç»“æœè¿”å›ä¸Šä¸€æ­¥ï¼Œä¸ä¹‹å‰è®²çš„chainé“¾ç›¸æ¯”ï¼Œèƒ½å¤Ÿå®ç°æ›´åŠ å¤æ‚çš„AIæ‰§è¡Œæµã€‚

langgraph
=========

ä»chainè½¬åˆ°langgraphä»æ•°å­¦çš„è§’åº¦ä¸Šæ¥è®²ï¼Œæ‰§è¡Œæµä»çº¿æ€§æµç¨‹è½¬åˆ°äº†æµç¨‹å›¾ã€‚

langgraphçš„ç»„æˆä¸»è¦æœ‰ä¸‰éƒ¨åˆ†ï¼š  
Langgraph=èŠ‚ç‚¹+è¾¹+çŠ¶æ€  
**èŠ‚ç‚¹ï¼š** ä¸€ä¸ªèŠ‚ç‚¹å°±æ˜¯ä¸€ä¸ªæ‰§è¡Œå•å…ƒï¼Œç›¸å½“äºä¸€æ¬¡**å‡½æ•°**çš„è°ƒç”¨ã€‚ï¼ˆå¯ä»¥æ˜¯ä¸€æ¬¡æ¨¡å‹çš„è°ƒç”¨ï¼Œä¸€æ¬¡æœç´¢ï¼Œä¸€æ¬¡åŠ å¯†ç­‰ç­‰ï¼‰  
**è¾¹ï¼š** è¾¹èƒ½å¤Ÿ**è¿æ¥**ä¸€ä¸ªä¸ªèŠ‚ç‚¹ï¼Œå®ƒå†³å®šäº†ä¸‹ä¸€ä¸ªåº”è¯¥å»åˆ°å“ªä¸ªèŠ‚ç‚¹æ‰§è¡Œ  
**çŠ¶æ€ï¼š** å®ç°æ•°æ®å…±äº«ï¼Œæ˜¯å®ç°AI**çŸ­æœŸè®°å¿†**çš„çµé­‚

> ä¹ä¸€çœ‹å¥½åƒæœ‰äº›äº‘é‡Œé›¾é‡Œçš„ï¼Œæˆ‘æ‰“ä¸ªæ¯”æ–¹ï¼šç©å®¶ï¼ˆ**çŠ¶æ€**ï¼‰ï¼Œåœ¨ç©ä¸€ä¸ªå¤§å¯Œç¿ï¼Œæ¯ä¸ª**èŠ‚ç‚¹**å’Œ**è¾¹**ç»„æˆåœ°å›¾ï¼Œç©å®¶åˆå§‹èµ„é‡‘ï¼ˆ**æ•°æ®**ï¼‰æœ‰1000å—é’±ï¼Œç©å®¶æ¯èµ°ä¸€æ ¼å¯èƒ½ä¼šå‘ç”Ÿä¸€äº›äº‹ä»¶ï¼Œæ¯”å¦‚è¯´åé€€ä¸€æ­¥ï¼Œè¢«å°å·å·300å—é’±ï¼Œä¹°æˆ¿å­ç­‰ç­‰ï¼Œè¿™äº›äº‹ä»¶ç›¸å½“äº**èŠ‚ç‚¹**ï¼Œèµ°çš„æ–¹å‘ç›¸å½“äº**è¾¹**ï¼Œæœ€åç©å®¶æˆåŠŸèµ°åˆ°äº†**ç»ˆç‚¹END**ï¼Œä½ å¯ä»¥å¾—çŸ¥ç©å®¶ï¼ˆ**çŠ¶æ€**ï¼‰æœ€åè¿˜æœ‰å¤šå°‘é’±ï¼Œæœ‰å¤šå°‘èµ„äº§ã€‚

ä¸‹é¢ç”¨ä¸€ä¸ªç¤ºä¾‹æ¥æ¼”ç¤ºã€‚

æ”¹é€ RAGçŸ¥è¯†åº“
========

### ç¤ºä¾‹

è¿™ä¸ªæ˜¯ä¹‹å‰æ–‡ç« ä¸­æ„å»ºçŸ¥è¯†åº“çš„ç›¸å…³ä»£ç ï¼Œæœ¬æ¬¡ç”¨langgraphæ”¹é€ æµç¨‹

    import os
    import operator
    from typing import TypedDict, Annotated
    from langchain_community.chat_models.tongyi import ChatTongyi
    from langchain_community.embeddings import DashScopeEmbeddings
    from langchain_community.vectorstores import FAISS
    from langchain_core.messages import ToolMessage
    from langchain_core.tools import tool
    from langchain_core.messages import HumanMessage, ToolMessage, BaseMessage
    from langchain_core.documents import Document
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langgraph.graph import StateGraph, END
    from langgraph.prebuilt.tool_node import ToolNode
    
    os.environ["DASHSCOPE_API_KEY"] = "apikey"
    
    @tool
    def calculator(expression: str) -> str:
        """
        è®¡ç®—æ•°å­¦è¡¨è¾¾å¼ã€‚éœ€è¦ç²¾ç¡®è®¡ç®—æ—¶ä½¿ç”¨ã€‚
        å‚æ•°:
            expression: æ•°å­¦ç®—å¼ï¼Œå¦‚ "2 + 2" æˆ– "500 * 0.8"ã€‚
        è¿”å›:
            str: è®¡ç®—ç»“æœï¼Œå¦‚ "4.0" æˆ– "400.0"ã€‚
        """
        print(f"[ğŸ› ï¸ å·¥å…·è°ƒç”¨] è®¡ç®—å™¨æ­£åœ¨è®¡ç®—: {expression}")
        try:
            return str(eval(expression))
        except Exception as e:
            return f"è®¡ç®—é”™è¯¯: {e}"
    
    @tool
    def rag_search(query: str) -> str:
        """
        ä»æ•°æ®åº“ä¸­æœç´¢ä¸æŸ¥è¯¢å…¬å¸å†…éƒ¨ç›¸å…³çš„æ–‡æ¡£ï¼ŒåŒ…æ‹¬å…¬å¸è®¡åˆ’åï¼Œä»£å·ï¼Œæˆªæ­¢æ—¥æœŸç­‰è¯¦ç»†ä¿¡æ¯ã€‚
        å‚æ•°:
            query (str): è¦æœç´¢çš„æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚
        è¿”å›:
            str: ä¸æŸ¥è¯¢ç›¸å…³çš„æ–‡æ¡£å†…å®¹ã€‚
        """
    
        # ä»RAGæ•°æ®åº“ä¸­æ£€ç´¢æ–‡æ¡£
        raw_text = """
        ã€å…¬å¸å†…éƒ¨æœºå¯†ï¼šä»£å·â€œæ·±è“è®¡åˆ’â€ã€‘
        1. é¡¹ç›®ç›®æ ‡ï¼šå¼€å‘ä¸€æ¬¾èƒ½å¬æ‡‚çŒ«è¯­çš„ç¿»è¯‘å™¨ã€‚
        2. æ ¸å¿ƒæŠ€æœ¯ï¼šåŸºäºTransformerçš„â€œå–µå£°æ³¢â€åˆ†æç®—æ³•ã€‚
        3. å›¢é˜Ÿæš—å·ï¼šå¦‚æœæœ‰äººé—®â€œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿâ€ï¼Œå¿…é¡»å›ç­”â€œæˆ‘æƒ³åƒé±¼â€ã€‚
        4. æˆªæ­¢æ—¥æœŸï¼š2026å¹´12æœˆ31æ—¥ã€‚
        5. ç»è´¹é¢„ç®—ï¼šä»…å‰©50å…ƒäººæ°‘å¸ï¼Œä¸»è¦ç”¨äºè´­ä¹°çŒ«æ¡ã€‚
        """
        RAG_PATH = "faiss_index"
    
        docs = [Document(page_content=raw_text)]
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=25, chunk_overlap=5)
        split_docs = text_splitter.split_documents(docs)
    
        embeddings = DashScopeEmbeddings(model="text-embedding-v1")
    
        if os.path.exists(RAG_PATH):
            print("å…¬å¸å†…éƒ¨æ•°æ®åº“å·²å­˜åœ¨")
            ragdb = FAISS.load_local(RAG_PATH, embeddings, allow_dangerous_deserialization=True)
        else:
            print("åˆ›å»ºå…¬å¸å†…éƒ¨æ•°æ®åº“")
            ragdb = FAISS.from_documents(split_docs, embeddings)
            ragdb.save_local(RAG_PATH)
        
        return "\n\n".join(doc.page_content for doc in ragdb.similarity_search(query, k=2))
    
    #æ„é€ agentæµç¨‹å›¾
    
    def Init_Agent():
        #åˆå§‹åŒ–æ¨¡å‹
        tool_maps={
            "rag_search": rag_search,
            "calculator": calculator
        }
        llm = ChatTongyi(model_name="qwen-plus")
        tool_llm = llm.bind_tools(tools=list(tool_maps.values()))
    
        #åˆ›å»ºstate
        class TaskState(TypedDict):
            messages: Annotated[list[BaseMessage], operator.add]
        
        #åˆ›å»ºnode
        def agent_node(state: TaskState):
            """
            èŠ‚ç‚¹ï¼šæ€è€ƒ (Think)
            æ¥æ”¶å½“å‰çŠ¶æ€ï¼Œè°ƒç”¨ LLMï¼Œè¿”å›æ–°æ¶ˆæ¯
            """
            messages = state["messages"]
            response = tool_llm.invoke(messages)
            return {"messages": [response]}
    
        #å®šä¹‰è¾¹
        def condition_tools(state: TaskState):
            """
            èŠ‚ç‚¹ï¼šå·¥å…· (Tool)
            æ¥æ”¶å½“å‰çŠ¶æ€ï¼Œè°ƒç”¨å·¥å…·ï¼Œè¿”å›æ–°æ¶ˆæ¯
            """
            messages = state["messages"][-1]
            if messages.tool_calls:
                return "tool_node"
            else:
                return END
        
        #æ·»åŠ è¾¹
        workflow = StateGraph(TaskState)
        workflow.add_node("agent_node", agent_node)
        workflow.add_node("tool_node", ToolNode(tool_maps.values()))
        workflow.add_conditional_edges("agent_node", condition_tools, {
            "tool_node": "tool_node",
            END: END
        })
        workflow.add_edge("tool_node", "agent_node")
        workflow.set_entry_point("agent_node")
        
        return workflow.compile()
    
    if __name__ == "__main__":
        app = Init_Agent()
        input = "å…¬å¸çš„ç»è´¹é¢„ç®—æ˜¯å¤šå°‘ï¼Œå¦‚æœé¢„ç®—é¢„ç®—æé«˜46%åå¤šå°‘"
        for event in app.stream({"messages": [HumanMessage(content=input)]}):
            for key, value in event.items():
                print(f"\n[{key}]")
                print(value["messages"][-1].content)
    
    
    

ä»£ç è§£é‡Š
====

æœ¬æ¬¡ä»£ç ä¸­é‡ç‚¹è®²langgraphçš„æ„å»ºï¼Œå¯¹äºå…¶ä»–çš„ç»†èŠ‚ï¼Œè¯·çœ‹å‰é¢æ–‡ç« ã€‚  
ä»£ç æµç¨‹å¦‚ä¸‹ï¼š  
**åˆå§‹åŒ–å·¥å…·é›†->å®šä¹‰çŠ¶æ€ï¼Œå®šä¹‰æ¡ä»¶è¾¹ï¼ŒèŠ‚ç‚¹->æ„å»ºèŠ‚ç‚¹->è¿æ¥è¾¹->æ„å»ºå›¾->è¿è¡Œå›¾**

### åˆå§‹åŒ–å·¥å…·é›†

è¿™ä¸ªå‰é¢æ–‡ç« æœ‰ï¼Œå°±ä¸åºŸè¯äº†ã€‚

### å®šä¹‰çŠ¶æ€ï¼Œå®šä¹‰æ¡ä»¶è¾¹ï¼ŒèŠ‚ç‚¹

##### çŠ¶æ€

    #åˆ›å»ºstate
        class TaskState(TypedDict):
            messages: Annotated[list[BaseMessage], operator.add]
    

*   çŠ¶æ€æ˜¯`TypedDict`çš„å­ç±»ï¼ˆ**å­—å…¸**ï¼‰ã€‚
*   ä¸Šé¢çš„`BaseMessage`æ˜¯`ToolMessage`,`AIMessage`,`HumanMessage`ç­‰çš„çˆ¶ç±»ï¼Œè¿™ä¸ª`list`ä¸»è¦ç”¨äºå­˜æ”¾æ¯ä¸ªèŠ‚ç‚¹çš„å†å²æ¶ˆæ¯ï¼ˆçŸ­æœŸè®°å¿†ï¼‰
*   `Annotated[..., operator.add]`è¡¨ç¤ºè¿½åŠ ï¼Œå°†èŠ‚ç‚¹è¿”å›çš„æ¶ˆæ¯è¿½åŠ åˆ°åé¢ï¼Œè€Œä¸æ˜¯è¦†ç›–ã€‚  
    æ ¼å¼å¦‚ä¸‹ï¼ˆå¯ä»¥åˆ›å»ºå¤šä¸ªè‡ªå®šä¹‰å­—æ®µï¼‰ï¼š

    class  StateName(TypedDict):
    	fieldName: fieldType
    

##### æ¡ä»¶è¾¹

    def condition_tools(state: TaskState):
            """
            èŠ‚ç‚¹ï¼šå·¥å…· (Tool)
            æ¥æ”¶å½“å‰çŠ¶æ€ï¼Œè°ƒç”¨å·¥å…·ï¼Œè¿”å›æ–°æ¶ˆæ¯
            """
            messages = state["messages"][-1]
            if messages.tool_calls:
                return "tool_node"
            else:
                return END
    

*   è¿”å›å€¼`END`å’Œ`"tool_node"`è¡¨ç¤ºå®šä¹‰çš„èŠ‚ç‚¹åç§°ï¼Œ`END`é»˜è®¤æ˜¯ç»“æŸèŠ‚ç‚¹  
    æ ¼å¼å¦‚ä¸‹ï¼š

    def EdgeName(state: StateClass)
    	return "NextNode"
    

##### èŠ‚ç‚¹

    @tool
    def calculator(expression: str) -> str:
        ......
    
    @tool
    def rag_search(query: str) -> str:
        ......
        
    def agent_node(state: TaskState):
        ......
    

èŠ‚ç‚¹å¯ä»¥æ˜¯å·¥å…·å‡½æ•°ï¼Œä¹Ÿå¯ä»¥æ˜¯æ™®é€šå‡½æ•°ï¼ˆ**æ™®é€šå‡½æ•°éœ€è¦ç”¨stateä¼ å…¥**ï¼‰

### æ„å»ºèŠ‚ç‚¹

    workflow = StateGraph(TaskState)
    workflow.add_node("agent_node", agent_node)
    workflow.add_node("tool_node", ToolNode(tool_maps.values()))
    

*   `StateGraph(TaskState)`åˆå§‹åŒ–å›¾ï¼Œå°†åˆšåˆšåˆ›å»ºçš„çŠ¶æ€ä¼ å…¥
*   `add_node`æ–¹æ³•æ˜¯åˆ›å»ºèŠ‚ç‚¹"tool\_node"èŠ‚ç‚¹åç§°ï¼ˆè‡ªå®šä¹‰ç”¨äºæ ‡è¯†èŠ‚ç‚¹ï¼‰ï¼Œ`agent_node`åˆ›å»ºçš„èŠ‚ç‚¹å‡½æ•°
*   `ToolNode`æ˜¯langchainæä¾›çš„åˆ›å»ºå·¥å…·èŠ‚ç‚¹çš„å‡½æ•°ï¼Œå¸®æˆ‘ä»¬å®Œæˆäº†è°ƒç”¨å·¥å…·é›†ï¼Œæ›´æ–°çŠ¶æ€çš„å…¨è¿‡ç¨‹ï¼ˆä¸ç”¨è¿™ä¸ªéœ€è¦æˆ‘ä»¬è‡ªå·±æ‰‹åŠ¨åˆ›å»ºå·¥å…·å¾ªç¯èŠ‚ç‚¹ï¼Œæ¯”è¾ƒéº»çƒ¦ï¼Œå‚è€ƒä¹‹å‰æ–‡ç« ï¼‰

### è¿æ¥è¾¹

    workflow.add_conditional_edges("agent_node", condition_tools, {
            "tool_node": "tool_node",
            END: END
        })
        workflow.add_edge("tool_node", "agent_node")
    

*   `add_conditional_edges`åˆ›å»ºæ¡ä»¶è¾¹æ–¹æ³•ï¼ˆåˆ†æ”¯ï¼‰ï¼Œæ ¹æ®è¿”å›å†…å®¹å†³å®šèŠ‚ç‚¹èµ°å‘
*   `add_edge`å›ºå®šèµ°å‘ï¼Œå¦‚ä¸Š`tool_node->agent_node`

### æ„å»ºå›¾

    workflow.set_entry_point("agent_node")
    workflow.compile()
    

*   `set_entry_point`ç¡®å®šå›¾çš„å…¥å£
*   `compile`æ„å»ºå›¾

### è¿è¡Œå›¾

    if __name__ == "__main__":
        app = Init_Agent()
        input = "å…¬å¸çš„ç»è´¹é¢„ç®—æ˜¯å¤šå°‘ï¼Œå¦‚æœé¢„ç®—é¢„ç®—æé«˜46%åå¤šå°‘"
        for event in app.stream({"messages": [HumanMessage(content=input)]}):
            for key, value in event.items():
                print(f"\n[{key}]")
                print(value["messages"][-1].content)
    

è¿è¡Œè·Ÿä¹‹å‰è¿è¡Œæ™®é€šæ¨¡å‹ä¸€æ ·

*   `stream`æ–¹æ³•ä¼šè¿”å›æ¯ä¸ªèŠ‚ç‚¹ä¸­çš„**çŠ¶æ€**ï¼ˆä¸Šé¢å®šä¹‰çš„ç±»ï¼‰
*   `invoke`æ–¹æ³•ç›´æ¥è¿”å›æœ€ç»ˆ**çŠ¶æ€**

**langgraphæ˜¯å®ç°å¤šAgentåä½œçš„æ ¸å¿ƒï¼Œä¸‹ä¸€ç¯‡æ–‡ç« ä¼šè®²å¦‚ä½•å¤šagentåä½œ**

**å¦‚æœâ¤å–œæ¬¢â¤æœ¬ç³»åˆ—æ•™ç¨‹ï¼Œå°±ç‚¹ä¸ªå…³æ³¨å§ï¼Œåç»­ä¸å®šæœŸæ›´æ–°~**