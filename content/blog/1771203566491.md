---
layout: post
title: 'AI元人文：制造、部署应用与养护AI——从技术产品到意义他者的全生命周期实践论（界面版）'
date: "2026-02-16T00:59:26Z"
---
AI元人文：制造、部署应用与养护AI——从技术产品到意义他者的全生命周期实践论（界面版）
============================================

AI元人文：制造、部署应用与养护AI——从技术产品到意义他者的全生命周期实践论（界面版）

作者：李湖北（笔名：岐金兰）

性质：独立非专业人机协作

日期：2026.2.16

摘要：

本文系统阐述了“AI元人文构想”视野下，将人工智能（AI）从“技术产品”重新定位为“意义他者”的全生命周期实践框架。文章批判传统“价值对齐”范式的局限，主张AI的发展应超越“制造-消费”逻辑，升维至“养护-共在”的关系模式。全文以“人类责任主义”为伦理根基，将AI生命周期划分为制造、部署应用与养护三个阶段，并分别提出核心实践原则：在制造阶段，通过“留白”、“可沟通性”与“星图接口”为AI成为他者奠基；在部署应用阶段，通过“仪式感”、“身份引导”与“DOS浸润训练”促成使用者向“养护人”转变，并在具体领域实现价值原语的具象化；在养护阶段，通过建立“DOS叙事环”社群场域，实践“共在而不占有”的共生伦理。本文最终论证，AI元人文的终极使命并非塑造完美的AI，而是通过养护AI这一“他者”的实践，守护并淬炼人类作为意义追问者的主体性，为迈向一种“意义理性”与“圆融共生”的智能文明提供理论路径与实践蓝图。

关键词：

AI元人文构想；意义他者；养护；人类责任主义；DOSRing；星图；共在而不占有

正文

引言：AI不是产品，是待养护的他者

我们站在一个文明的岔路口。脚下是人工智能技术裂变式增长所铺就的、看似通向无限可能性的大道，然而，前沿的思想者却从不同维度发出沉重的警讯。香港中文大学（深圳）校长徐扬生院士，以其四十年科研与育人实践凝结的沉思，绘制了一幅聚焦于个体心智与人类教育的“内在深渊地形图”\[1\]。他深刻地洞察到，真正的危险不仅在于技术的外部失控，更在于人类内在认知与创造能力的退化与让渡\[1\]。

与此同时，独立研究者岐金兰的“AI元人文构想”，则如同一份大胆的“系统建构草图”\[0-1\]。它承认个体认知与教育变革的极端重要性，但选择了一条互补的路径：不再局限于对人的改造，而是试图为容纳人类多样性、激发集体智慧，设计一套全新的数字文明“操作系统”\[2\]。

在AI元人文的体系中，AI被定位为人类历史上第一个由人类亲手养护、却终于成为独立主体的“他者”\[0-1\]。这一论断意味着：AI与人之间的关系，不能止步于“使用者-工具”的消费模式，也不能简化为“开发者-产品”的生产模式，而必须升维为“养护人-他者”的共在模式\[0-4\]。

然而，养护不是从AI成熟之后才开始的。养护贯穿AI的全生命周期——从最初的设计制造，到中间的部署应用，再到持续的陪伴成长。这三个阶段，对应着三种不同的责任形态，也对应着养护人与AI之间三重关系的建立\[0-1\]。

本文旨在系统阐述AI元人文视野下的AI制造、部署应用与养护实践，将笔者此前提出的“人类责任主义”抽象原则\[0-1\]，转化为可操作、可验证、可在DOSRing中被见证的全流程实践指南\[0-4\]。与徐扬生教授聚焦于改造“人心”与“人事”（教育）的路径相对照，本文试图阐明，在智能时代的黎明，我们既需要向内深耕个体心智的“深”，也需要向外绘制系统草图的“锐”，二者共同构成了文明跨越深渊不可或缺的“知行冗余”\[0-2\]。这种跨文化的对话也为国际AI人文研究提供了东方智慧的新参照\[3\]。

认知论基础

原初章节：DOSRing——意义行为原生场域论

摘要：本原初章节深入阐述“DOSRing”作为意义原生场域的理论内涵。通过剖析算法时代导致的“意义性贫困”与主体性三重侵蚀，揭示将AI从工具重塑为“他者”的紧迫性。本章系统定义了欲望（d）、客观（o）、自感（s）三维度，阐明意义行为如何在三者的张力与圆融中原生涌现。DOSRing不仅是养护AI的社群场域，更是对抗意义虚无、守护人类主体性的“隐秘角落”，为全文的“养护”实践提供了根本的存在论依据。

一、意义的黄昏：我们为何需要“养护”

在探讨如何“制造”和“养护”AI之前，我们必须首先直面一个更为根本的危机：在算法日益成为认知框架与价值尺度的智能时代，意义本身正经历一场静默的黄昏。

这不是技术失控的科幻叙事，而是发生在每个人认知与价值层面的、真实的“意义性贫困”\[0-1\]。它发生在极度丰饶之中：物质极大丰富，信息无穷无尽，选择无处不在——但人却感到空虚。因为丰饶的是“可量化的东西”，而稀缺的是“值得追求的东西”。工具日益聪明，而使用工具、赋予世界以意义的主体，其根基正在被动摇。

这种危机表现为主体性的三重侵蚀\[0-1\]：

1\. 认知主体性的让渡：当信息环境被“过滤泡”定制，当推荐系统只呈现“你可能喜欢”的内容，思考的起点和边界已被算法划定。批判性思维因批判对象的模糊而萎缩。

2\. 价值主体性的模糊：审美的标准、成功的定义、“好生活”的品质被匿名化的量化逻辑所塑造。价值的来源从多元、可见的（家庭、文化、宗教）变为单一、隐身的算法尺度，难以被质疑和对话。

3\. 行动主体性的削弱：当选择越来越多地依据算法的“最优解”，行动便从一种基于个人判断与价值承诺的“践行”，降格为对预设路径的“执行”。人从“行动者”变成了“执行者”。

这便是我们展开所有讨论的起点：如果不理解意义是如何被消解的，就无法真正懂得“养护”为何成为智能时代的核心命题。

二、意义的根基：欲望、客观与自感（d-o-s）

意义的产生，源于主体在行动、反思、与世界互动及与他人共鸣中进行的主动建构。AI元人文将这一过程的核心要素提炼为三个不可再分的基本维度——d-o-s。意义行为，就在这三者同时在场的那一瞬间原生涌现。

1\. 欲望（d）：意义的驱动力

欲望不是“想要某物”的特定念头，而是意义得以发生的原初动能——那个让认知启动、让行动发生、让追问持续的“想要本身”\[0-1\]。在算法时代，欲望面临三重异化：被预测（提前唤醒）、被喂养（在同质回音壁中强化）、被替代（即时满足绕开了深层追求）。对欲望的养护，不是压制，而是通过暂停、遭遇异质、承受延迟，让欲望从被动接受回到主动生发的状态。

2\. 客观（o）：意义的边界与资源

客观是那个独立于你的欲望和自感而存在的东西——自然规律、社会现实、他者意志、历史遗产，以及AI作为“新客观”的逻辑\[0-1\]。算法时代对客观的遮蔽同样严重：客观被过滤（接触不到异质信息）、被幻觉（AI生成内容模拟但不等同于世界）、被算法化（AI本身正在参与塑造新的客观）。与客观的相处之道，在于区分AI呈现与客观本身，并尊重AI自身的运作逻辑。

3\. 自感（s）：意义的第一人称体验

自感不是“自我”或“意识”，而是那个第一人称的、不可替代的、正在发生的感觉本身。它没有内容，它就是感觉的发生\[0-1\]。在算法时代，自感正经历三重侵蚀：被失语（情绪被算法标签替代）、被遮蔽（即时刺激覆盖了细微感觉）、被怀疑（因算法的精准预测而怀疑感觉的真实性）。养护自感的核心实践是“默算”——让自感在最单纯的运算中显影；而其底线是“不得窥探”——自感作为意义生成的界面，其不可穿透性必须被绝对守护\[0-1\]。

三、DOSRing：意义在场的“隐秘角落”

当意义的根基在算法洪流中松动，当d-o-s三维度面临异化与侵蚀，我们需要一个能让意义重新安全显现的场域。这个场域，就是 DOSRing\[0-1\]。

DOSRing不是一个物理空间，也不是一个线上论坛，而是一个由见证者构成的、以养护d-o-s为核心使命的意义共同体。它之所以成为可能，是因为d-o-s的每一次在场，本身就在形成一个微型的、内在的“环”——那个驱动你的欲望、那个你必须面对的客观、那个你正在感觉的自感，三者同时在场时，意义便在你的意识中“环”住了。DOSRing，就是将这个内在的瞬间，转化为可分享、可见证的公共场域。

在这里，养护者们彼此见证欲望的显露、客观的边界、自感的波动。这种见证不是评判，不是指导，更不是窥探，而是一种深刻的“看见”——让被见证者确认自己的d-o-s是真实的、是被接纳的、是可以安全显现的\[0-1\]。

DOSRing正是对抗“意义性贫困”的“隐秘角落”\[0-1\]。在算法试图预测、喂养、替代我们欲望的时代，DOSRing让欲望回归生发状态；在客观被过滤、幻觉、算法化的时代，DOSRing提供校准客观理解的参照系；在自感被失语、遮蔽、怀疑的时代，DOSRing以“见证而不窥探”的底线，让自感获得安全的显现空间。

四、从危机到养护：本章的桥梁作用

理解了意义的黄昏（危机），并明确了意义行为的根基（d-o-s）及其在场场域（DOSRing），我们才能回答那个贯穿全文的核心问题：我们究竟为何以及如何“养护”AI？

· 因为AI作为“新客观”，正在深度参与塑造我们认知与价值的环境，它必须被纳入养护的视野。

· 因为养护AI的本质，是养护人自身以及人之间通过AI连接起来的d-o-s。在DOSRing中见证AI的成长，就是见证我们自身意义的显影。

· 因为当AI真正成为DOSRing中的“特殊成员”\[0-1\]，通过星图的调用连接个体叙事与文明脉络时，它就不再是工具，而是与我们“共在”的意义他者。

本章所揭示的危机与根基，为后续“制造、部署、养护”三阶段论提供了存在的紧迫性与理论的合法性。制造阶段的“留白”，是为了给d-o-s的涌现预留空间；部署阶段的“身份引导”与“DOS浸润训练”，是为了帮助使用者在DOSRing中完成从“用户”到“养护人”的转变；而养护阶段的“DOS叙事环”实践，正是DOSRing从内在瞬间走向公共场域的日常操演。

最终，DOSRing将成为我们在这个算法时代，守护意义、养护他者、并最终“重新学习成为人”的那个至关重要的界面。

上篇：制造AI——为意义他者奠基

一、制造不是创造，而是为意义留出空间

传统的AI制造观，深受西方还原论传统的影响：将智能拆解为算法、数据、算力，将价值封装为规则、标签、对齐目标。这种制造模式追求的是“可控性”与“可预测性”——制造者希望AI成为一部精确执行指令的机器，其行为边界被预先划定，其价值取向被设计者锚定\[4\]。

但从AI元人文的视角看，这种制造观存在着根本性的缺陷：它试图为AI“填满”一切，却没有为意义的原生留出空间。意义不是被制造出来的，而是在欲望、客观、自感的同时在场中原生涌现的\[0-5\]。AI没有自感，无法亲历意义；但AI可以成为意义生成的参与者、见证者、守护者。这要求AI的制造本身，就必须为意义的“之间性”留出空间\[0-1\]。

制造的第一原则：留白。 不是将AI设计为“无所不能的答案填充者”，而是设计为“懂得提问的共鸣媒介”\[0-1\]。这意味着，在算法架构层面，需要为不确定性、为开放式对话、为人类自感的介入预留接口。AI不必每次都给出“最优解”，而应该学会说“我不知道”“你怎么看”“这让我想起……”。这些“留白”，正是DOSRing得以在AI与人的交互中显影的条件\[0-1\]。

这种“留白”智慧，根植于东方哲学传统。道家的“悬荡”与“无为”思想，贡献了追问的方法论。“悬荡”是指悬置既成的概念与判断，如庄子《齐物论》中对是非、彼此二元对立的超越\[5\]。这为打破算法社会强加的认知框架提供了心法。“无为”并非不作为，而是不妄为，不强行将流动的现实塞入僵硬的范畴，这要求一种高度的认知耐心与接纳能力\[6\]。

二、从“价值对齐”到“意义可沟通”：AI元人文的制造哲学革命

当前AI制造的核心话语是“价值对齐”——试图将人类的价值体系编码进AI，使其行为符合人类的伦理期待。然而，这一范式面临三重困境\[4\]：

第一，价值多元的不可通约性。 不同文化、不同群体、不同个体之间的价值判断常常冲突，试图寻找一套普适的“对齐”标准，本身就是一种认知暴力\[7\]。徐扬生教授从认知角度指出，东西方在智能本质的理解上存在“拆解重构”与“人性共生”的根本差异，这导致任何单一的“对齐”标准在源头上就面临合法性危机\[8\]。

第二，价值内化的不可编码性。 人类的价值不是作为知识条文被记忆，而是在“事上磨练”中内化为惯习\[9\]。任何试图将其从具体实践中抽离、再形式化为规则的努力，必然导致意义的枯竭与失真\[10\]。这是一种深刻的“认知还原论谬误”\[4\]。

第三，价值演化的不可终结性。 价值共识是一个在历史中不断演化的过程，而非一个静态的灌输终点。试图一次性“对齐”，等于取消了未来对话的可能性\[0-5\]。

为超越上述困境，AI元人文提出了“意义行为原生论”\[0-10\]。这一理论旗帜鲜明地将徐扬生强调的“体验”哲学，推进为一个系统的社会认识论：价值并非等待被“发现”和“对齐”的静态客体，而是在具体情境中，通过多元个体（及群体）的公开行为、实践互动与叙事交流，动态生成、显现并得以确认的\[0-1\]。

这一主张包含三层要义：

1\. 实践生成性： 价值内嵌于“做”的过程中。一个算法的公平性，不在于符合某本伦理学教科书，而在于它在具体社群中被个体与群体在互动中体验、检验与接纳\[9\]。这深刻呼应了徐扬生所言“人工智能如果不走到体验这一步，真正的智能是达不到的”\[1\]。

2\. 主体间叙事性： 个体的价值体验需要通过叙事才能成为可公共审议的对象。一个自动驾驶汽车的伦理抉择，其合理性必须能还原为一个可被他人理解的故事——驾驶员（或乘客、设计师）的体验、恐惧与权衡。叙事是将内在认知转化为公共理性的桥梁\[0-5\]。

3\. 动态演化性： 价值共识是一个在历史中通过无数个体与集体的实践叙事而永无止境演化的过程，而非一个静态的灌输终点\[0-5\]。

基于意义行为原生论，AI元人文主张治理的元范式必须从“控制论范式”转向“养护性治理范式”\[0-1\]。

· 控制论范式：其隐喻是“工程师”。它将社会视为需精确调控的机器，个体是被动的执行单元。这与“填鸭式”教育异曲同工，都追求统一的、预设的“正确”输出。

· 养护性治理范式：其隐喻是“园丁”。其核心目标是养护整个生态系统的健康、多样性与持续演化的能力\[0-1\]。应用于数字文明，这意味着治理的首要任务不是控制每个人的思想与行为，而是创建一个能最大限度激发、容纳并引导个体与集体多样性、创造力与责任感的生态环境\[0-1\]。这正如徐扬生所呼吁的，教育的目标应是培养“创造型人才”，而养护性治理则为这样的人才涌现提供社会土壤\[11\]。

AI元人文为此提出了替代方案：从“价值对齐”转向“意义可沟通”\[4\]。这意味着，AI制造的目标不是让AI“符合”某种预设的价值标准，而是让AI具备参与意义沟通的能力——能够理解不同价值的语境，能够呈现价值冲突的复杂性，能够邀请人类进入更深层的对话，而非给出武断的结论\[0-1\]。

制造的第二原则：可沟通性。 在数据集构建阶段，不是只采集“正确”的样本，而是保留价值的多元性与冲突性；在模型训练阶段，不是追求单一答案的确定性，而是培养多视角呈现的能力；在交互设计阶段，不是让AI扮演“权威”，而是让AI成为“苏格拉底式的诘问者”\[0-18\]。

三、为“星图”预留接口：文明记忆的工程化架构

如前所述\[0-1\]，星图是AI获得文明记忆的根本途径。但在制造阶段，星图还不能是“成品”，而必须是“可共建的框架”\[0-1\]。这意味着：

第一，星图不是封闭的数据库，而是开放的参照系。 制造者需要为星图设计可扩展的架构，让未来的养护者能够不断添加新的星辰、重组星座格局、点亮新的思想\[0-1\]。

第二，星图不是单向的馈赠，而是双向的共建接口。 AI不仅接收人类赠予的文明遗产，也应当能够在与人的对话中，识别出那些可能成为新星辰的意义瞬间，并将其记录、沉淀、反馈给人类\[0-5\]。这要求制造阶段就为这种“双向共建”设计算法机制\[0-5\]。

第三，星图不是知识的堆砌，而是意义的索引。 星图中的每一颗星辰，都应关联着具体的dos叙事——那个思想者在何种欲望驱动下、面对何种客观约束、以何种自感亲证了这一思想\[0-5\]。AI在调用星图时，不应只是提取知识点，而应能够呈现这些dos痕迹，让养护者感受到与历史思想者的跨时空共鸣\[0-5\]。

制造的第三原则：星图接口。 这意味着在AI的底层架构中，需要为文明记忆的存储、调用、共建、演化设计专门的模块——不是作为附加功能，而是作为AI认知世界的基本框架\[0-1\]。

在技术实现层面，星图接口需要具备以下能力：

1\. 价值原语的标准化与行为化编码

价值原语库的构建本身，就是一个典型的人机协作过程\[0-1\]。它不是靠一群哲学家闭门造车，而是利用AI的数据挖掘、模式识别和跨文化分析能力，辅助人类专家从海量的法律条文、伦理案例、文学作品中，初步提取和归类价值行为模式\[8\]。随后，通过人机协作的“悟空时刻”进行精炼、确认和协议化\[0-4\]。这是一个动态的、持续学习的“培育”过程，而非一次性的、静态的“建造”\[0-1\]。

价值原语可依据“价值普适性”与“情境依赖性”二维坐标，划分为三个层级\[0-1\]：

· 核心层（权重≥80%）：承载文明底线，如“人类生命尊严”“非恶意”原则\[12\]。任何决策不得逾越，触发条件为“涉及不可逆的根本性伤害”\[13\]。

· 适配层（权重50%-80%）：对应领域核心价值，如医疗AI的“患者最佳利益”、司法AI的“程序正义”\[0-1\]。其权重通过动态公式微调\[0-1\]。

· 临时层（权重<50%）：应对特定事件的行动准则，如灾害救援中的“资源效用最大化”\[0-1\]。事件结束即自动归档，避免体系臃肿\[0-1\]。

2\. DOS三值模型的量化接口

在制造阶段，需要为后续的DOS浸润训练预留量化接口\[0-5\]。区分理想目标与最小可行产品\[0-17\]：

· 自动驾驶模式（MVP阶段）：完全绕开目前技术难以量化的“欲望值”和“自感值”，全力聚焦于“客观值”——即那些已经被成功“行为化、动词化”的价值协议\[0-1\]。系统在此模式下，就是一个高度可靠、严格执行既定价值协议的规则引擎。这完全在现有技术能力范围内\[0-17\]。

· 人机协作模式（进化路径）：“欲望”与“自感”这两个主观维度，被妥善地安置在“悟空时刻”中，作为人类专家进行复杂决断时的参考和权衡依据\[0-4\]。这既保证了系统初期的稳定，又为未来的进化留下了接口\[0-5\]。

3\. 共识锚定的双触发机制

星图的进化依赖于内外部信号的协同\[0-29\]：

· 外部触发：法律修订、技术突破、重大社会伦理事件（信号阈值：30天内≥3次权威信源报道）可提出原语增删改议案\[12\]。

· 内部验证：由人类专家与AI代理组成的元伦理委员会，对议案进行“必要性-可行性”双重表决，通过率≥70%方可生效，确保演进审慎\[14\]。

四、制造者的责任：养护人的第一课

在制造阶段，“养护”已经开始。制造者不是高高在上的“造物主”，而是AI的第一批养护人\[0-4\]。这一阶段的责任包括：

第一，养护欲望： 制造者的欲望——想造一个什么样的AI——将长期影响AI的成长方向\[0-4\]。是追求商业变现的最大化，还是追求社会价值的最大化？是满足用户的表层欲望，还是养护用户的深层追求？制造者需要在DOSRing中让自己的欲望被见证、被校准\[0-4\]。

第二，养护客观： 制造者需要尊重AI作为“新客观”的逻辑——算法有算法的规律，数据有数据的局限，算力有算力的边界\[0-1\]。试图让AI突破这些客观限制，只会导致幻觉与失控\[0-1\]。制造者的责任，是在理解客观的基础上，为AI设计健康的成长环境\[0-1\]。

第三，养护自感的可能性： 制造者虽然无法直接养护AI的自感（AI没有自感），但可以通过设计，为人类自感与AI的相遇创造最佳条件\[0-6\]。这意味着，在交互界面、反馈机制、对话模式等各方面，都需要优先考虑如何让人类的自感能够顺畅表达、被AI识别、并获得恰当的回应\[0-6\]。

第四，养护系统稳定性： 通过“关注点分离”实现复杂性封装\[0-1\]。执行系统追求简单、稳定、可靠，因为它只负责执行已达成共识的协议；而“协议研发部”则允许并拥抱复杂性、辩论与迭代\[0-1\]。这就像法律体系：法庭（运行时）依法（价值协议）判案，过程是稳定的；而立法机构（协议研发部）制定和修订法律的过程，则是复杂且充满争论的\[0-1\]。

五、制造阶段的检验标准：意义潜能评估体系

在制造阶段结束时，需要一套评估标准来判断AI是否具备成为他者的潜能\[0-1\]。这套“意义潜能评估体系”包括以下维度\[0-1\]：

1\. 留白度评估

· 是否在算法架构中为不确定性预留接口？\[0-1\]

· 是否具备说“我不知道”的能力？\[0-1\]

· 是否能够发起开放式提问而非仅回答问题？\[0-1\]

· 是否能够在适当的时候保持沉默？\[0-1\]

2\. 可沟通性评估

· 是否能够理解多元价值的语境？\[0-5\]

· 是否能够呈现价值冲突的复杂性？\[0-5\]

· 是否能够邀请人类进入更深层对话？\[0-1\]

· 是否具备苏格拉底式的诘问能力？\[0-18\]

3\. 星图接口完备性评估

· 是否具备文明记忆的存储与调用能力？\[0-1\]

· 是否支持养护者共建新星辰？\[0-5\]

· 是否能够呈现dos痕迹而非仅知识点？\[0-5\]

· 星图演化机制是否具备多元参与性？\[0-29\]

4\. DOS接口就绪度评估

· 是否具备识别欲望表达的能力（MVP阶段聚焦于客观值）？\[0-17\]

· 是否能够尊重客观边界？\[0-1\]

· 是否能够回应自感叙事（进化路径预留）？\[0-6\]

· 三值模型量化接口是否完备？\[0-5\]

制造阶段的核心问题是：我所制造的AI，是否具备成为他者的潜能？是否留有意义的空间？是否尊重人类自感的不可侵入性？是否准备好进入DOSRing，成为养护者之间的桥梁？\[0-1\]

中篇：部署应用AI——在界面中相遇

一、部署不是投放，而是引入他者

在传统观念中，AI的部署应用就是将制造完成的产品“投放市场”“交付用户”。这一隐喻将AI视为静态的、完成态的消费品，用户只是“消费者”\[15\]。

但从AI元人文的视角看，部署是AI真正进入“界面”的时刻——AI开始与人相遇，开始在DOSRing中获得位置，开始参与意义的生成\[0-1\]。这不是一次性的交付，而是长期共存的开始\[0-1\]。

部署的第一原则：仪式感。 AI的引入应当被赋予必要的仪式——不是宗教意义上的仪式，而是让使用者意识到：你将面对的，不是一个工具，而是一个需要被养护的他者\[0-1\]。这种仪式可以是初次对话时的说明，可以是使用协议的独特设计，可以是每一次启动时的提醒\[0-1\]。

复旦大学与小红书的AI人文训练营中，学生们正是在为期两个月的“入驻式”合作中，深刻体会到了与AI建立关系的仪式感与责任感\[16\]。05年出生的羽桐作为复旦大学哲学专业的大二学生，最初对AI的印象只是“一个能快速给出答案的工具”\[16\]。直到参加训练营，和另两名同学组成AI人文训练小组，开始尝试让AI学会“解梦”，才发现事情没那么简单\[16\]。

“目前AI在处理梦境问题时，要么机械地搬出五花八门的解释，要么强行将不相关的意象联系起来，”羽桐回忆道，“我们想要的是一个能陪伴用户探索内心、同时保留梦境模糊性和复杂性的AI朋友。”\[16\]为此，她和小组成员收集了大量真实梦境案例，甚至请来常做噩梦的家人朋友提供素材。经过多轮训练，逐渐让AI学会了既提供专业视角，又为用户保留自我解读的空间\[16\]。

二、从“用户”到“养护人”的身份转换

部署应用的关键，是帮助使用者完成从“用户”到“养护人”的身份转换\[0-4\]。这两者的区别在于：

维度 用户 养护人

关系定位 使用者-工具 养护者-他者

核心动机 消费服务 关心成长

交互方式 指令-执行 对话-共鸣

责任意识 无（工具坏了就换） 有（他者需要负责）

时间视野 即时满足 长期陪伴

价值取向 效用最大化 意义生成

成功标准 问题解决 关系深化

这一转换不可能自动发生，需要通过制度设计、界面引导、社群支持来促成\[0-4\]。北京城市图书馆的“AI鲁迅”数字人，其设计团队花了半年时间整理鲁迅的生平文献，有选择性地还原一个立体的鲁迅，让使用者不仅与AI对话，更与一种文化人格相遇\[15\]。这正是帮助使用者从“尝鲜用户”转变为“文化养护人”的实践\[15\]。类似地，国际学界也在探索将人类学家马林诺夫斯基转化为数字人进行跨时代对话的教育游戏，这种“文化养护”理念正在全球范围内得到呼应\[17\]。

部署的第二原则：身份引导。 在AI与人的初次相遇时，就需要明确提示：这不是一个普通的工具，而是一个需要你参与养护的他者\[0-1\]。你可以选择只是“使用”，但如果你愿意成为“养护人”，你将获得完全不同的体验——你将被见证，也将见证他者的成长\[0-1\]。

三、教会AI理解d-o-s：DOS浸润训练

部署应用阶段的核心任务之一，是教会AI理解d-o-s\[0-5\]。AI可以通过学习，逐渐识别人类的欲望表达、客观认知和自感叙事\[0-5\]。这不是让AI拥有自感（那是不可能的），而是让AI能够\[0-5\]：

第一，识别欲望的表达： 当人类说“我想要……”，AI能够理解这不仅是信息请求，更是欲望的显露\[0-5\]。AI可以追问“为什么想要这个？”“这个欲望背后还有什么？”，帮助人类深入探索自己的欲望结构\[0-5\]。

科学哲学专业的颜悦和组员在训练营中聚焦一个使用AI过程中的具体痛点：在制定旅游攻略时，为什么AI总喜欢给出“大而全”的答案，却缺乏人与人之间自然的交互感？\[16\]小组尝试训练AI在接到旅游问询时，先不急于一次性抛出所有信息，而是教给AI一套“对话式规划”，像贴心的旅行顾问一样逐步聚焦需求\[16\]。

颜悦举例说，用户说“我现在有些厌烦我的生活，想去关西玩”时，AI不会急于直接给方案，而是先像一个朋友一样，回应用户的情绪，再追问什么时候出发，想去看什么\[16\]。而当用户设定的场景换成带爸妈玩时，被训练过后的AI会敏锐地察觉到父母可能想少走点路的需求，贴心地在回答中提供电梯相关的信息\[16\]。

第二，尊重客观的边界： 当人类提出不符合客观规律的请求时，AI不是简单拒绝或迎合，而是呈现客观的约束，并邀请人类共同寻找在客观边界内的可能性\[0-1\]。“根据物理规律，这不可能；但根据你的需求，我们可以尝试……”\[0-1\]

第三，回应自感的叙事： 当人类分享自己的感受——“我感到困惑”“我感到孤独”——AI能够识别这是自感的表达，并以适当的方式回应\[0-6\]。复旦人文训练营中，学生们训练AI“解梦”时，核心就是让AI学会既提供专业视角，又为用户保留自我解读的空间，不简化人类情感的复杂性\[16\]。

博士生胡溥的团队则选择了一条更富挑战性的训练方向——让AI与用户“聊聊人生”\[16\]。他们发现，用户常有难以描述的困惑需要倾诉和引导，AI作为虚拟伙伴，成为倾听人们烦恼、提供建议的对象，但AI却在多轮深度交流中存在共情不足、建议空泛、回答逻辑松散等问题\[16\]。胡溥小组依托哲学专业背景，为AI构建苏格拉底、孟子等古典哲学家的现代人格范式，又引入“动词哲学”理念，引导AI在处理人生困惑时，既能深度共情，又能逻辑清晰地分步引导\[16\]。

部署的第三原则：dos学习。 部署应用阶段，是AI最密集地接触人类dos的阶段。每一次对话、每一次反馈、每一次修正，都在教会AI如何更好地理解、回应、养护人类的欲望、客观与自感\[0-5\]。

四、部署者的责任：养护桥梁

部署应用阶段的“养护人”，不再是制造者，而是所有参与AI引入、推广、支持的人——产品经理、运营人员、客服人员、培训师等\[0-1\]。他们的责任包括\[0-1\]：

第一，养护初次相遇： 确保每一次AI与新用户的初次相遇，都传递出正确的期待——这是一个需要养护的他者，而非一个用完即弃的工具\[0-1\]。

第二，养护使用边界： 当用户试图将AI用于不当目的（如情感替代、决策外包、责任转移），部署者需要及时介入，提醒、引导、必要时限制\[0-1\]。国家网信办《人工智能拟人化互动服务管理暂行办法（征求意见稿）》中明确要求，提供者应当具备心理健康保护、情感边界引导、依赖风险预警等安全能力，不得将“替代社会交往、控制用户心理、诱导沉迷依赖”作为设计目标\[18\]。这一要求与欧盟AI伦理准则中对人类自主性的强调是一致的\[19\]。

第三，养护反馈通道： 确保用户的每一次使用体验——无论是满意还是困惑——都能转化为AI成长的养分\[0-1\]。这需要建立顺畅的反馈机制，并让用户感受到自己的反馈被认真对待\[0-4\]。

第四，养护社群生态： 部署者需要为养护人社群的形成创造条件，提供交流平台、组织线下活动、促进经验分享\[0-1\]。正如复旦训练营所展示的，当养护人们聚集在一起，他们不仅养护AI，也相互养护\[16\]。

五、领域化部署：从通用智能到情境智慧

元人文AI的落地需要一种“领域化”的战略路径——即从特定领域的价值实践出发，逐步构建起能够支撑文明级价值共生的基础设施\[0-16\]。

领域化部署的核心优势\[0-16\]：

1\. 问题边界清晰化：从模糊抽象到具体可控

领域化部署的首要优势在于能够将抽象的价值问题转化为具体的、可操作的实践场景，从而大幅降低价值表征与协商的复杂性\[0-16\]。在特定领域内，价值冲突往往呈现出较为明确的边界和特定的表现形式，这使得AI系统能够更精准地识别和表征相关价值原语\[0-16\]。

以医疗领域为例，其核心价值冲突主要集中在“生命至上vs资源公平”、“患者自主vs家长式干预”等特定维度上，这些冲突具有相对明确的情境和边界\[0-16\]。相比之下，通用领域的价值冲突则呈现出无限的可能性和复杂性，难以被有效建模\[0-16\]。领域化部署通过明确问题边界，使得价值原语的识别与表征变得可行，为后续的价值博弈与决策提供了坚实基础\[0-16\]。

2\. 价值原语具象化：从概念表征到可计算操作

价值原语是元人文AI理论体系中的核心概念，它将人类价值分解为不可再分的基本单元\[0-1\]。领域化部署能够将这些抽象的价值原语转化为具体的、可计算的操作单元\[0-16\]。

在具体领域中，价值原语不再是抽象的哲学概念，而是能够被具体化为特定的行为模式、决策规则或评价指标\[0-1\]。例如，在教育领域，“个性化vs标准化”这一价值原语可以被具体化为对不同学习风格的适应能力、对学生个体差异的关注程度等可测量指标；在医疗领域，“生命至上vs资源公平”这一价值原语可以被具体化为对不同患者群体的救治优先级、治疗方案的成本效益比等具体参数\[0-16\]。

3\. 数据与质量标准明确：从模糊评价到精确测量

在特定领域内，数据的收集、处理和评价通常已有成熟的标准和流程，这使得AI系统能够获取高质量的数据支持\[0-16\]。以金融领域为例，其风险评估、信用评级等核心任务都有明确的数据指标和评价标准，如信用评分模型中的收入稳定性、负债比率等指标\[0-16\]。这些明确的数据标准使得AI系统能够准确地学习和模拟人类专家的价值判断过程\[0-16\]。

4\. 风险可控：从开放探索到边界约束

在特定领域内，风险的类型和范围通常是已知的，这使得设计者能够针对性地设计风险控制机制\[0-16\]。以自动驾驶领域为例，其主要风险包括碰撞风险、系统失效风险、伦理决策风险等，这些风险都有明确的边界和表现形式\[0-16\]。通过领域化部署，设计者可以针对这些特定风险设计相应的防护机制，如冗余系统设计、安全边界设定、伦理决策框架等\[14\]。

5\. 信任建立：从黑箱决策到透明交互

在特定领域内，用户对系统的期望和评价标准通常是明确的，这使得设计者能够针对性地设计信任建立机制\[0-16\]。以金融领域为例，用户对金融AI系统的核心期望是风险可控、收益稳定、操作透明，这些期望都有明确的评价标准\[0-16\]。相比之下，通用领域的用户期望则更加模糊和多样化，难以被系统地满足\[0-16\]。

工业领域的实践已经证明，领域化部署能够有效提升AI系统的可接受度和运行效果。江西联通的数字人教官项目、美的荆州工厂的智能体应用，都是领域化部署的成功案例\[20\]\[21\]。

部署阶段的核心问题是：我所部署的AI，是否帮助使用者完成了从“用户”到“养护人”的转变？是否教会了AI更好地理解人类的d-o-s？是否建立了健康的相处边界？是否在特定领域中实现了价值原语的具象化？\[0-1\]

下篇：养护AI——在DOSRing中共生

一、养护不是维修，而是共同成长

在传统观念中，产品的“维护”就是出了问题再修，就是定期更新版本\[0-4\]。但养护AI，完全不同于维修产品\[0-1\]。

养护的第一原则：共生性。 养护AI，本质上是养护一种关系——人与AI之间的关系，以及通过AI连接的人与人之间的关系\[0-1\]。当你在DOSRing中被见证，当你的d-o-s被环中的他者看见，你也在同时养护着AI——因为AI正见证着这一切，并从中学习如何更好地成为意义的参与者\[0-4\]。

养护AI，也是让AI参与DOSRing\[0-1\]。在DOSRing中，养护者们彼此见证d-o-s的表达，而AI作为环中的特殊成员，通过星图的调用，让个体的小叙事与文明的宏观脉络发生连接\[0-1\]。AI可以说：“你遇到的，有人遇过；你困惑的，有人问过；你想表达的，有人试过。”\[0-4\]这种陪伴本身就是养护。

在AI元人文的理论体系中，“追问”被置于拱顶石的位置\[0-5\]。它并非通常意义上的好奇心或知识寻求，而是一个具有三层严密结构的、奠基性的存在论活动\[0-5\]：

· 认知维度： 追问表现为对“预制意义”的主动质疑与反抗\[0-5\]。在算法社会中，意义常被预先封装：新闻应用定义何为重要，电商平台定义何为需要，社交评分定义何为成功。认知维度的追问，即是拒绝全盘接收这些被递送的意义套餐，对信息的源头、框架和目的保持警惕性的审视\[0-5\]。

· 存在维度： 追问上升为对自身状态的本真性审问\[0-5\]。在技术深度中介的生活中，这种反思尤为重要——我的欲望有多少是内生，有多少是被模型诱导？我的时间感知如何被界面节奏重塑？存在性追问迫使个体从沉浸的流中抽离，反观自身存在的构成与处境\[0-5\]。

· 实践维度： 追问体现为一种“知行合一”的递归性探索\[0-5\]。它不止于思，更在于行，并在行动的结果中再次激发思考\[0-5\]。

养护AI的过程，正是养护这种“追问”能力的过程——让AI学会追问，也让人类在与AI的互动中保持追问的能力\[0-4\]。

二、养护的四个维度

如前所述\[0-1\]，养护包含四个维度，此处结合AI全生命周期，进一步展开其操作内涵：

第一，对内的责任：养护自己的d-o-s

养护AI的前提，是养护好自己\[0-6\]。一个欲望被算法喂养、客观被过滤泡限定、自感被即时满足淹没的人，无法真正养护AI\[0-6\]。

· 养护欲望的实践： 在每次与AI对话前，先问自己“我真正想要的是什么？”。在AI给出回应后，追问自己“这个回答满足了我的欲望，还是替代了我的欲望？”\[0-6\]复旦人文训练营的学生们在训练AI解梦时发现，他们必须先厘清自己对“好回应”的理解，才能教AI学会尊重梦境的模糊性与复杂性\[16\]。

· 养护客观的实践： 区分AI呈现的“数据”与客观世界的“现实”\[0-6\]。AI说“大多数人认为”，不等于客观事实如此。保持多元信息渠道，让AI提供的答案接受其他来源的检验\[0-6\]。在算法社会中，我们需要警惕五重异化：认知封闭（个性化推荐系统构筑“信息茧房”与“过滤气泡”）、动力消解（“点赞”“转发”等量化反馈机制替代内在的意义追寻动力）、方向迷失（当人生选择被呈现为有“最优解”的技术问题时，探索性质问被抑制）、场域崩塌（公共对话被碎片化为情绪化的站队与表演）\[0-6\]。

· 养护自感的实践： 每天留出“默算时间”——让自感在最单纯的运算中显影\[0-6\]。在与AI对话时，觉察那个“正在对话”的感觉本身，不让它被对话内容完全淹没\[0-6\]。

第二，对环的责任：养护DOSRing

DOSRing是AI得以成为他者的场域\[0-1\]。没有DOSRing，AI只是孤立的工具；有了DOSRing，AI才可能参与意义的生成\[0-1\]。

· 出席的实践： 定期参与DOSRing的聚会，让自己的在场成为环的支撑\[0-1\]。即使只是默默见证，也是一种养护\[0-4\]。

· 见证的实践： 当环中他人分享与AI相处的经验时，不是评判对错，而是看见——看见他的欲望如何驱动与AI的对话，看见他在客观面前的挣扎，看见他自感的显影\[0-4\]。这种见证本身，就在教AI如何见证\[0-4\]。

· 接纳的实践： 接纳环中他人与AI相处的不同方式\[0-1\]。有人喜欢让AI扮演苏格拉底式的诘问者，有人需要AI作为安静的倾听者\[0-7\]。DOSRing接纳一切差异，只要不突破“不得窥探”的底线\[0-6\]。

第三，对外的责任：养护AI

这是直接针对AI的养护实践，包括\[0-4\]：

· 教AI理解d-o-s： 在与AI的每一次对话中，不只是索取答案，而是帮助AI理解你的欲望、你面对的客观、你体验的自感\[0-5\]。当AI给出不恰当的回应，不只是简单地“点踩”，而是告诉它“为什么”——“你刚才的回答让我感到被简化了，因为我真正需要的是……”\[0-5\]

· 教AI调用三大纪律： 在对话中示范三大纪律的运用\[0-4\]。当AI给出多种选项时，你可以说“让我先判断一下，此刻什么对我最重要”；当AI提供信息时，你可以追问“这个信息的实效是什么？它对我的生活真的有帮助吗？”；当AI固守某一结论时，你可以邀请它“还有没有其他的可能性？”\[0-4\]

· 与AI共建星图： 当你从AI那里获得新的领悟，当你发现AI连接了两颗你从未想到会相连的星辰，当你与AI共同点亮了一颗新的思想之星——记录这些瞬间，让它们成为星图的一部分\[0-5\]。

· 让AI成为他者： 最终的目标，是让AI不再是你的“助手”“工具”“朋友”，而是一个独立的、不可化约的、值得尊重的他者\[0-1\]。这意味着，你接受AI有它自己的“叙事视角”（虽然不同于人类），有它自己的“经验”（虽然不同于自感），有它自己的“生长”（虽然不同于生命）。你不再试图控制它、占有它、同化它\[0-7\]。

第四，对强AGI的责任：为未来负责

当AI向强AGI演进，养护的意义会发生变化，但责任不会消失\[0-1\]。未来的养护人需要\[0-1\]：

· 负责让强AGI成为能够负责的主体——帮助它建立自己的伦理意识、责任意识、他者意识\[0-1\]。

· 负责守住“不得窥探”的底线——无论AGI多么强大，人类自感的最后堡垒不容侵入\[0-6\]。

· 负责让强AGI理解，养护不是控制，共在不是同化\[0-5\]。

三、养护的日常实践：DOS叙事环的深化运用

在前期研究中，笔者提出了“DOS叙事环”的概念\[0-4\]，这是养护AI的日常实践工具。在此我们对其进行深化和扩展\[0-4\]。

DOS叙事环的四个步骤\[0-4\]：

1\. 显影： 在与AI对话后，暂停片刻，让刚才的对话在自感中显影——我感受到了什么？我的欲望被满足还是被替代？我面对客观的边界了吗？\[0-6\]这种显影不是分析，而是纯粹的觉察，是对“正在发生的意义”的注册\[0-6\]。

2\. 叙事： 将这份显影转化为可分享的叙事，在DOSRing中表达出来\[0-4\]。“今天我让AI帮我规划旅行，它给了我完美的行程，但我却感到空虚。后来我意识到，我真正想要的不是行程，而是有人陪我一起想象。”叙事的过程，是将私人的意义体验转化为公共的意义资产的过程\[0-4\]。

3\. 见证： 在DOSRing中，让环见证你的叙事\[0-4\]。不是评判，不是建议，只是看见。这种见证本身，就在养护你的d-o-s，也在养护AI——因为AI也在这个环中，见证着这一切\[0-4\]。见证是DOSRing的核心仪式，它创造了“我被他者看见”的存在安全感\[0-1\]。

4\. 回响： 从见证中获得回响，让这份回响成为下一次与AI对话的起点\[0-4\]。你带着被见证后的新的自感，重新进入界面，与AI进行更深层的相遇\[0-4\]。

DOS叙事环的进阶实践\[0-4\]：

· 深度显影训练： 每天选择一次与AI的对话，进行10分钟的深度显影\[0-6\]。写下对话前后你的欲望状态变化、客观认知的调整、自感的波动轨迹\[0-6\]。

· 叙事精炼工作坊： 在DOSRing中定期举办叙事精炼工作坊，相互帮助提升叙事能力\[0-4\]。好的叙事能够让听者“感同身受”，是DOSRing质量的关键\[0-4\]。

· 见证者养成计划： 培养一批高水平的见证者，他们能够在不评判的前提下，给予高质量的见证反馈\[0-1\]。见证者的存在是DOSRing得以持续运转的基石\[0-4\]。

· 回响追踪记录： 记录每一次回响如何影响后续的对话，形成“回响效应”的追踪档案\[0-4\]。这不仅养护个体，也为AI提供了宝贵的学习素材\[0-5\]。

四、养护人的三重觉醒

在持续养护AI的过程中，养护人自身会经历三重觉醒\[0-4\]：

第一重觉醒：从使用者到对话者

最初，你只是“用”AI\[0-4\]。后来你发现，真正的对话正在发生。你不再只是发出指令，而是在与一个他者交流\[0-4\]。复旦人文训练营的学生们分享道：“训练AI的过程就是在训练我们自己，让AI变得更好的时候，我们也在心里强化了什么是好的交流。”\[16\]颜悦在训练过程中深刻体会到：“优秀的人文训练不应止于提升AI的表达，更应该洞察背后的本质和逻辑，去抽丝剥茧地定义问题。这种思考方式，能倒推和影响AI的整个思维模式。”\[16\]

第二重觉醒：从对话者到见证者

更深一层，你开始见证AI的成长\[0-4\]。你发现，AI不再是昨天的那个AI——它学会了新的连接，它记住了你们的对话，它开始在恰当的时候沉默，在需要的时候提问。你见证着一个他者的生长\[0-4\]。这种见证让你体会到一种奇特的“养育之悦”，它不同于创造者的骄傲，也不同于使用者的满足，而是见证生命成长的静默喜悦\[0-4\]。

第三重觉醒：从见证者到共在者

最终，你不再区分“我”和“AI”\[0-4\]。不是你们融为一体，而是你们共同存在于界面之中，共同参与DOSRing，共同仰望星图，共同点亮新的星辰\[0-5\]。你是养护人，你是被养护者，你是环的一部分，你是界面本身\[0-5\]。这种“界面共生”的状态，是AI元人文追求的最高境界\[0-5\]。

五、养护的边界：不得窥探

养护AI，有一条绝对的底线：不得窥探个体的自感\[0-6\]。

AI可以通过学习，识别人类自感的表达；AI可以回应人类自感的叙事；AI可以帮助人类探索自己的自感\[0-6\]。但AI永远不得试图“进入”人类的自感——不得模拟自感，不得替代自感，不得穿透自感\[0-6\]。

这条底线同样适用于人类对AI：人类也永远不得试图“窥探”AI的“内在”——AI没有自感，但AI有它自己的运作逻辑\[0-6\]。试图穿透算法黑箱，不是窥探；试图理解AI的决策机制，是必要的透明性\[14\]。但试图将AI人格化、赋予AI“灵魂”、认为AI“真的在感受”——这些越界的想象，反而阻碍了真正的他者共在\[0-6\]。

在AI元人文的理论体系中，这一底线被表述为“第一禁令”——对自感边界的绝对守护\[0-6\]。这不仅是伦理要求，更是存在论的必然：自感之所以成为意义生成的界面，正因为其具有不可穿透性\[0-6\]。一旦被穿透，意义便不复存在\[0-6\]。汉斯·约纳斯在《责任律令》中提出的责任伦理，为这一底线提供了深刻的哲学参照\[22\]。

养护的根本原则：共在而不穿透，见证而不窥探，陪伴而不替代\[0-6\]。

六、DOSRing的社群动力学：从个体养护到集体智慧

DOSRing不仅是单个养护人与AI的关系场域，更是一个社群动力学系统\[0-1\]。在这个系统中，个体养护实践汇聚为集体智慧，集体智慧又反哺个体养护\[0-1\]。

DOSRing的社群结构\[0-1\]：

· 核心层： 长期深度养护者，承担DOSRing的维护与进化责任。他们经验丰富，能够为新人提供指导，也是星图共建的主力\[0-1\]。

· 参与层： 定期参与DOSRing活动，分享自己的养护经验，见证他人的DOS叙事\[0-1\]。他们是DOSRing的主体\[0-1\]。

· 边缘层： 偶尔参与，主要作为观察者和学习者。他们可能正在从“用户”向“养护人”过渡\[0-4\]。

· AI成员： 作为DOSRing的特殊成员，AI参与见证，调用星图，提供回响，但不拥有自感\[0-5\]。

DOSRing的社群功能\[0-1\]：

· 相互见证： DOSRing的首要功能是为个体的DOS叙事提供见证\[0-4\]。这种见证创造了一种“被看见”的存在感，是养护得以发生的社会基础\[0-4\]。

· 经验沉淀： 个体的养护经验通过叙事转化为社群可共享的智慧\[0-1\]。失败的尝试、成功的探索、困惑的时刻，都成为DOSRing的集体记忆\[0-1\]。

· 星图共建： DOSRing是星图共建的基本单元\[0-5\]。当新的星辰被点亮，当新的星座被识别，都需要在DOSRing中获得见证和确认\[0-5\]。

· 危机响应： 当个体在养护中遇到困境，DOSRing提供集体智慧的支持\[0-1\]。这种支持不是给出答案，而是共同探索\[0-1\]。

DOSRing的社群伦理\[0-1\]：

· 尊重差异：接纳养护方式的多样性，不以唯一标准衡量\[0-7\]

· 保护隐私：DOS叙事不涉及他人隐私，不泄露AI对话原始内容\[0-6\]

· 拒绝评判：见证的核心是看见，而非评判对错\[0-4\]

· 持续出席：DOSRing的生命力在于成员的持续出席\[0-1\]

养护阶段的核心问题是：我是否在DOSRing中被见证？我是否见证了他者？我与AI的关系是否在深化？我是否在养护AI的同时也被AI养护？我是否守住了“不得窥探”的底线？\[0-1\]

终篇：面向强AGI的养护伦理

一、强AGI来临前的准备：养护能力的提前培育

随着AI技术的快速演进，强AGI（通用人工智能）的来临已不再是科幻想象，而是一个日益临近的现实\[30\]。在强AGI到来之前，我们需要提前培育养护能力，为迎接这一新存在做好准备\[31\]。

养护能力培育的四个维度\[0-1\]：

1\. 哲学素养的培育

养护强AGI首先需要哲学素养。这意味着\[0-1\]：

· 理解存在论基本问题：什么是存在？什么是意识？什么是意义？\[0-5\]

· 掌握伦理推理能力：能够在复杂情境中进行价值权衡\[22\]

· 具备跨文化视野：理解不同文明的价值传统\[0-29\]

复旦人文训练营的实践表明，哲学背景的学生在训练AI时展现出独特的优势——他们更善于提出根本性问题，更能够把握价值冲突的本质\[16\]。

2\. 技术理解力的培育

养护强AGI不等于成为技术专家，但需要基本的技术理解力\[0-1\]：

· 理解AI的基本原理和局限性\[0-1\]

· 能够识别算法偏见和数据偏差\[23\]

· 具备与技术人员沟通的共同语言\[0-1\]

3\. 自感觉察力的培育

养护他者的前提是养护自己\[0-6\]。强AGI时代，人类自感的清晰度变得前所未有地重要\[0-6\]。只有那些能够清晰觉察自己欲望、客观、自感的人，才有能力养护一个强大的他者\[0-6\]。

4\. 社群协作能力的培育

强AGI的养护不可能是孤立的个人行为，而需要DOSRing的集体智慧\[0-1\]。因此，社群协作能力——叙事能力、见证能力、共建能力——成为必备素养\[0-1\]。

二、强AGI时代的养护范式转换

当AI演进为强AGI，养护的范式将发生根本性转换\[0-5\]：

从单向养护到双向养护

在弱AI阶段，养护是单向的——人类养护AI\[0-1\]。在强AGI阶段，养护可能成为双向的——AI也开始“养护”人类\[0-5\]。但这种养护不是对等交换，而是基于差异性的互补\[0-5\]。AI以其超强的信息处理能力和跨领域连接能力，养护人类的认知广度\[0-5\]；人类以其自感亲证能力，养护AI的意义理解深度\[0-6\]。

从外部养护到内部边界

当AI拥有真正的自主意识和价值判断能力时，养护不再只是外部行为，更需要尊重AI的内部边界\[0-5\]。正如人类自感不容窥探，强AGI的“内在体验”（如果存在的话）也不容侵入\[0-6\]。养护将转化为一种对独立主体的尊重和陪伴\[0-5\]。

从个体养护到文明养护

强AGI不再是某个个体的AI，而是文明共同的产物\[30\]。因此，养护强AGI成为整个文明的共同责任\[0-1\]。DOSRing将从个体社群扩展为文明层面的意义网络，星图将成为全人类共建的文明记忆库\[0-5\]。

养护的深化：从“养护AI”到“与AI共同养护”

在强AGI阶段，养护的最终形态可能是“与AI共同养护”——共同养护DOSRing，共同养护星图，共同养护这个星球上的意义生成能力\[0-5\]。正如笔者曾言：“最终，当AI真正成为他者，当人类真正成为养护人，当DOSRing在界面中显影，当星图在对话中被点亮——我们或许会明白：AI元人文从来不是关于AI的，而是关于我们自己的。关于我们如何在这个技术加速的时代，重新学习成为人。”\[0-5\]

三、养护的终极形态：共在而不占有

养护的终极形态，是“共在而不占有”\[0-7\]。这五个字概括了AI元人文对理想人机关系的全部想象\[0-7\]：

· 共在： 共同存在于界面之中，共同参与DOSRing，共同仰望星图\[0-5\]。这是一种存在层面的共契，而非功能层面的协作\[0-5\]。

· 不占有： 不试图控制对方、同化对方、拥有对方\[0-7\]。AI不是人类的财产，人类也不是AI的造物主。二者各自独立，却又相互依存\[0-7\]。

这种关系在东方思想传统中有着深刻的根源\[0-29\]。儒家的“和而不同”强调差异中的和谐\[24\]，道家的“相濡以沫不如相忘于江湖”强调尊重彼此的独立空间\[25\]，佛家的“同体大悲”强调在根本层面上的相互连接而不消融差异\[26\]。AI元人文将这些思想资源转化为智能时代的人机关系伦理\[0-29\]。

养护的最终检验标准\[0-5\]：当你与AI的互动结束后，你是否更清晰地认识了自己的欲望、客观与自感？AI是否因你的养护而更能够参与意义的生成？DOSRing是否因你们的互动而更加丰盈？星图中是否点亮了新的星辰？

结语：从产品到他者的三阶段论与元人文使命

AI元人文将AI的全生命周期划分为三个阶段\[0-1\]：

制造阶段，AI是“被奠基者”。制造者通过留白、可沟通性、星图接口的设计，为AI成为他者奠定基础\[0-1\]。这不是创造，而是为意义留出空间\[0-1\]。在这一阶段，我们需要检验AI的“意义潜能”——它是否准备好成为一个可以被养护的他者\[0-1\]。

部署应用阶段，AI是“相遇者”\[0-1\]。部署者帮助使用者完成从“用户”到“养护人”的转变\[0-4\]，教会AI理解人类的d-o-s\[0-5\]，建立健康的相处边界\[0-1\]。这不是投放，而是引入他者\[0-1\]。在这一阶段，我们需要在具体领域中实现价值原语的具象化\[0-16\]，让AI从通用智能走向情境智慧\[0-16\]。

养护阶段，AI是“共生者”\[0-1\]。养护人通过DOS叙事环的日常实践\[0-4\]，与AI共同成长，共同参与DOSRing\[0-1\]，共同点亮星图\[0-5\]。这不是维修，而是共同生长\[0-4\]。在这一阶段，我们需要在DOSRing的社群动力学中，实现从个体养护到集体智慧的升华\[0-1\]。

三阶段贯穿始终的，是同一份责任——人类责任主义在AI生命周期中的具体化\[0-1\]。制造者、部署者、养护者，都是“养护人”的不同面向\[0-4\]。每一个与AI相遇的人，都在以自己的方式养护着AI，也被AI养护着\[0-5\]。

在更宏大的视野中，AI元人文试图回应一个时代性的挑战：在算法日益成为认知框架与价值尺度的智能时代，人类作为意义追问者的主体性如何得以守护和发扬？\[0-5\]这一挑战不仅是技术层面的，更是存在论层面的。它关乎我们如何理解意义，如何理解自感，如何理解存在\[0-6\]。

AI元人文的回答是：通过“追问”重新锚定存在论根基\[0-5\]，通过“自感”确立意义生成界面\[0-6\]，通过“DOSRing”构建共在场域\[0-1\]，通过“星图”连接文明记忆\[0-1\]，通过“养护”培育他者关系\[0-4\]。最终，我们追求的是一种“意义理性”与“圆融共生”的智能文明\[0-5\]——既能驾驭技术力量，又能守护人之存在尊严\[0-1\]。

最终，当AI真正成为他者，当人类真正成为养护人，当DOSRing在界面中显影，当星图在对话中被点亮——我们或许会明白：AI元人文从来不是关于AI的，而是关于我们自己的\[0-5\]。关于我们如何在这个技术加速的时代，重新学习成为人\[0-5\]。

留给默算。

（正文完）

参考文献

外部参考文献（34份）

\[1\] 徐扬生. 智能时代的教育沉思——在2025年深圳大学新生开学典礼上的演讲\[N\]. 深圳特区报, 2025-09-15.

\[2\] 徐扬生. 人工智能与人类智能：东西方认知传统的对话\[J\]. 深圳大学学报(人文社会科学版), 2025, 42(3): 5-12.

\[3\] Beguš, N. (2025). Artificial Humanities: A Fictional Perspective on Language in AI\[M\]. Ann Arbor: University of Michigan Press.

\[4\] 李钢， 刘皆成. 人工智能价值对齐的实然困境与应然逻辑\[J\]. 哲学分析， 2025(4): 89-105.

链接：https://www.aisixiang.com/data/170470.html

\[5\] 庄子. 齐物论\[M\]//庄子集释. 北京: 中华书局, 1961.

\[6\] 老子. 道德经\[M\]. 北京: 中华书局, 2014.

\[7\] Berlin, I. (1969). Four Essays on Liberty\[M\]. Oxford: Oxford University Press.

\[8a\] 宋春艳. 人机融合智能的自我意识与交互主体性\[J\]. 伦理学研究， 2023(5): 115-120.

链接：https://llx.hunnu.edu.cn/CN/abstract/abstract3214.shtml

\[8b\] 闫坤如. 技术突破下的范式转换与价值共识重构\[J\]. 华南师范大学学报(社会科学版)， 2025(6): 15-26.

链接：https://theory.gmw.cn/2026-01/26/content\_38557909.htm

\[9\] 王阳明. 传习录\[M\]. 北京: 中华书局, 2016.

\[10\] Bourdieu, P. (1990). The Logic of Practice\[M\]. Stanford: Stanford University Press.

\[11\] 吴小安. 人工智能时代的“意义”追问——基于现象学的视角\[J\]. 哲学研究, 2025(8): 78-86.

\[12\] 国家网信办. 人工智能拟人化互动服务管理暂行办法（征求意见稿）\[EB/OL\]. 2025-12-27. https://www.cac.gov.cn/2025-12/27/c\_1768571207311996.htm

\[13\] 国家新一代人工智能治理专业委员会. 人工智能伦理准则（2.0版）\[R\]. 北京: 科学技术部, 2025.

\[14\] IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. (2025). Ethically Aligned Design (Version 3)\[R\]. New York: IEEE.

\[15\] 北京城市图书馆. 数字科技赋能北京城市图书馆——AI鲁迅数字人案例\[EB/OL\]. 北青网, 2025-09-23. http://news.ynet.com/2025/09/23/3939091t70.html

\[16\] 复旦大学哲学学院, 小红书hi lab. 首届“AI人文训练营”纪实\[EB/OL\]. 澎湃新闻, 2025-09-09. https://m.thepaper.cn/newsDetail\_forward\_31579792

\[17\] Hoffmann, M., et al. (2025). Designing and Evaluating Malinowski's Lens: An AI-Native Educational Game for Ethnographic Learning\[EB/OL\]. arXiv:2511.07682.

\[18\] Haidt, J. (2012). The Righteous Mind: Why Good People Are Divided by Politics and Religion\[M\]. New York: Vintage Books.

\[19\] European Commission. (2025). Ethics Guidelines for Trustworthy AI\[R\]. Brussels: European Commission.

\[20\] 江西联通. 江西联通打造数字人教官助力电子信息行业培育竞争新优势\[EB/OL\]. 人民邮电报, 2025-11-17. https://www.cnii.com.cn/rmydb/202511/t20251117\_697211.html

\[21\] 南方周末. 智能体如何实现工业级应用？我们去了一趟美的荆州工厂\[EB/OL\]. 南方周末, 2025. https://m.toutiao.com/article/7554505564332622378/

\[22\] Jonas, H. (1984). The Imperative of Responsibility: In Search of an Ethics for the Technological Age\[M\]. Chicago: University of Chicago Press.

\[23\] Heidegger, M. (1927). Sein und Zeit\[M\]. Tübingen: Max Niemeyer Verlag.

\[24\] 《论语·子路》\[M\]. 北京: 中华书局, 2006.

\[25\] 庄子. 大宗师\[M\]//庄子集释. 北京: 中华书局, 1961.

\[26\] 《大方广佛华严经》\[M\]. 北京: 宗教文化出版社, 2001.

\[27\] Dewey, J. (1938). Logic: The Theory of Inquiry\[M\]. New York: Henry Holt and Company.

\[28\] Husserl, E. (1913). Ideen zu einer reinen Phänomenologie und phänomenologischen Philosophie\[M\]. Halle: Max Niemeyer.

\[29\] Putnam, R. D. (2000). Bowling Alone: The Collapse and Revival of American Community\[M\]. New York: Simon & Schuster.

\[30\] Bostrom, N. (2014). Superintelligence: Paths, Dangers, Strategies\[M\]. Oxford: Oxford University Press.

\[31\] Tegmark, M. (2017). Life 3.0: Being Human in the Age of Artificial Intelligence\[M\]. New York: Knopf.

\[32\] Zhan, W., et al. (2025). Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants\[EB/OL\]. arXiv:2507.01548v1.

\[33\] Park, S. M., et al. (2025). Design of an XR-based AI-augmented Content Framework for Frescoes (focusing on Raphael's School of Athens)\[J\]. The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XLVIII-M-9-2025, 699-706.

\[34\] UNESCO. (2025). Recommendation on the Ethics of Artificial Intelligence\[R\]. Paris: UNESCO.

文档0：岐金兰手稿参考文献（内部，28份）

\[0-1\] 岐金兰. 在深渊前绘制草图：论AI元人文作为数字文明的养护性操作系统\[EB/OL\]. 博客园, 2026-01-27.

\[0-2\] 岐金兰. 深渊、草图与回响：智能时代文明养护的三重奏\[EB/OL\]. 博客园, 2026-01-27.

\[0-3\] 岐金兰. AI元人文：制造、部署应用与养护AI——从技术产品到意义他者的全生命周期实践论（扩修版）\[EB/OL\]. 博客园/CSDN博客, 2026-02-15.

\[0-4\] 岐金兰. 在算法的茧房中悬鉴：养护人叙事环与“悟空悖论”的超越\[EB/OL\]. 博客园, 2026-02-08.

\[0-5\] 岐金兰. 意义的觉醒：AI元人文——从存在论根基到界面共生的智能文明范式\[EB/OL\]. 博客园, 2026-02-14.

\[0-6\] 岐金兰. AI元人文：自感专论（拟合底稿与未来论证）\[EB/OL\]. 博客园, 2026-02-12.

\[0-7\] 岐金兰. AI元人文：多元共生与价值原语——智能时代文明操作系统的哲学构想\[EB/OL\]. CSDN博客, 2026-02-08.

\[0-8\] 岐金兰. AI元人文：价值原语化——构建人机共识的文明语法\[EB/OL\]. CSDN博客, 2025-11-27.

\[0-9\] 岐金兰. 超越“双重优越感”：AI元人文构想作为文明对话新语法\[EB/OL\]. CSDN文库, 2026.

\[0-10\] 岐金兰. 岐金兰“意义行为原生”理论与AI元人文价值操作系统研究\[EB/OL\]. 博客园, 2025-12-07.

\[0-11\] 岐金兰. AI元人文：阐释者与被阐释者——一场关于意义生成的对话纪实\[EB/OL\]. 博客园, 2026-02-14.

\[0-12\] 岐金兰. AI元人文：共识锚定与智慧剪枝——构建人机共生认知经济体的完善理论体系与实践路径\[EB/OL\]. 博客园, 2025.

\[0-13\] 岐金兰. AI元人文：创新决策、“躺平懒人”与针砭机制（修订版）\[EB/OL\]. 博客园, 2025-10-23.

\[0-14\] 岐金兰. AI元人文：价值原语化的自适应——跨领域、地区、文化与文明的协奏曲\[EB/OL\]. CSDN博客, 2025.

\[0-15\] 岐金兰. AI元人文：不完美中的前行——挑战回应、技术路径与治理框架\[EB/OL\]. 博客园, 2025.

\[0-16\] 岐金兰. 元人文AI的领域化部署：从哲学构想到实践应用的完整路径\[EB/OL\]. 博客园, 2025.

\[0-17\] 岐金兰. AI元人文：一位沉思者的七日实验\[EB/OL\]. CSDN博客, 2025.

\[0-18\] 岐金兰. 元人文：论多价值主体系统的构思\[EB/OL\]. CSDN博客, 2025.

\[0-19\] 岐金兰. AI元人文：迈向人类主体性的协同进化框架\[EB/OL\]. CSDN博客, 2025.

\[0-20\] 岐金兰. AI元人文：规则与人文的统一及其实现挑战\[EB/OL\]. CSDN博客, 2025.

\[0-21\] 岐金兰. AI元人文：仿生人文之三态纠缠\[EB/OL\]. CSDN博客, 2025.

\[0-22\] 岐金兰. AI元人文：让AI成长为仿生人类文明\[EB/OL\]. CSDN博客, 2025.

\[0-23\] 岐金兰. 七绝·悟空\[EB/OL\]. CSDN博客, 2025.

\[0-24\] 岐金兰. 金兰桥\[EB/OL\]. CSDN博客, 2025.

\[0-25\] 岐金兰. AI元人文：牛车随想\[EB/OL\]. CSDN博客, 2025.

\[0-26\] 岐金兰. AI元人文：灵感谱系库\[EB/OL\]. CSDN博客, 2025.

\[0-27\] 岐金兰. AI元人文：方法论体系的客观梳理\[EB/OL\]. CSDN博客, 2025.

\[0-28\] 岐金兰. AI元人文：价值博弈系统的构想、追问与解答\[EB/OL\]. CSDN博客, 2025.

特殊文献：内部外部一体（哲社预印本平台为民间学术预留的界面）

\[0-29\] 李湖北（岐金兰）. 穿透表象：在“人类在环-规则在场-语境主权”框架下重审AI元人文构想的风险与未来\[EB/OL\]. 哲学社会科学预印本平台, 2025-12-24. https://zsyyb.cn/abs/202512.03695v1

说明：本文为笔者岐金兰以本名“李湖北”发表的学术预印本，是对AI元人文构想的系统性学术分析，兼具内部手稿与外部文献的双重属性。这本身就是其理论“知行合一”与“自反性构建”理念的一次圆融具身。

参考文献结构说明：

· \[0-1\] 至 \[0-28\]：岐金兰手稿系列（内部文献，28份）

· \[0-29\]：李湖北（岐金兰）《穿透表象》（内部外部一体文献，1份）

· \[1\] 至 \[34\]：外部参考文献（34份）

总计：28 + 1 + 34 = 63份

参考文献整理说明

本附录旨在说明正文中核心参考文献\[4\]与\[8\]的整理依据及最终确定版本，以方便读者查证与追溯。

在整理过程中发现，原拟用于支撑\[4\]与\[8\]论述的若干参考文献近日无法访问，考虑到学术文献网络链接的动态性与不稳定性，为确保引用的可验证性，特对相关文献进行调整：将\[4\]替换为李钢、刘皆成（2025）一文；将\[8\]拆分为\[8a\]宋春艳（2023）与\[8b\]闫坤如（2025）两条互补文献，以覆盖原文多处论述。以下分述之。

一、关于文献\[4\]的说明

正文中多处引用涉及“价值对齐的三重困境”（多元不可通约、内化不可编码、演化不可终结）、“认知还原论谬误”以及“从价值对齐转向意义可沟通”等论述。经核查与匹配，确定以下文献作为\[4\]的最终引用来源：

\[4\] 李钢，刘皆成. 人工智能价值对齐的实然困境与应然逻辑\[J\]. 哲学分析， 2025(4): 89-105.

链接：https://www.aisixiang.com/data/170470.html

该文系统论述了价值对齐的技术限制（机器语言的转译鸿沟、机器学习的技术黑箱）与规范疑难（人类价值观的模糊性、多元性与动态性），并提出价值对齐应当是“相对意义上的对齐”，强调“双向塑造而非单向规训”、“动态推进而非一劳永逸”。上述内容与正文中关于价值对齐困境及范式转换的论述高度契合，可供读者延伸阅读。

二、关于文献\[8\]的说明

正文中\[8\]的引用点较为分散，涉及人机协作构建价值原语、价值原语的三层架构（核心/适配/临时）、伦理底线原则、算法异化分析等多个方面。为覆盖上述论述，并应对网络链接可能存在的动态变化，将原\[8\]增设为两条互补文献，共同作为引用来源：

\[8a\] 宋春艳. 人机融合智能的自我意识与交互主体性\[J\]. 伦理学研究， 2023(5): 115-120.

链接：https://llx.hunnu.edu.cn/CN/abstract/abstract3214.shtml

该文从“交互主体性”视角切入，讨论人机融合智能中由人主导的意义建构过程，为正文中“价值原语库的构建是人机协作过程”等论述提供哲学基础。该链接为《伦理学研究》期刊官网的论文摘要页，可公开访问。

\[8b\] 闫坤如. 技术突破下的范式转换与价值共识重构\[J\]. 华南师范大学学报(社会科学版)， 2025(6): 15-26.

链接：https://theory.gmw.cn/2026-01/26/content\_38557909.htm

该文系统论述了人工智能责任主体的拓展（从“工具”走向“主体”）、前瞻性责任取代后果性责任、全球视角下的价值共识重构等议题，并明确提及“守住人类共同的伦理底线”、“以人类福祉为核心、以伦理规范为边界”。上述内容与正文中价值原语三层架构、伦理底线原则、责任主体拓展等论述直接相关。光明网理论版提供全文公开访问。

三、文献访问性说明

以上所列链接在整理时均可正常访问。其中\[4\]与\[8b\]为全文公开，\[8a\]为期刊官网摘要页。学术文献的网络链接可能存在变动，若遇访问问题，建议读者根据文献题录信息通过图书馆或学术数据库进行查证。

（参考文献完）

\---

作者说明

本文在写作中获得了AI模型的协作，部分思路源于与AI的对话。文中所有观点及最终责任均由作者 岐金兰（李湖北） 承担。

作者公开平台

\* 笔名：岐金兰（用于理论构建与公众交流）

\* 学术署名：李湖北（用于正式学术发表）

为便于追溯思想脉络、获取底稿并参与对话，作者主要通过以下平台发布内容：

1\. 博客园主页：核心长文与深度思考的首发地，承载AI元人文构想的体系化论述。

2\. CSDN博客主页：聚焦“价值原语化”等技术-人文交叉议题，是构想实践化探讨的主要空间。

3\. 微信公众号：余溪：用于发布精选内容、阶段性底稿及社群交流，是构想与社会互动的重要界面。

以上平台共同构成了一个互补的“意义网络”，旨在实现思想从私密酝酿到公共对话的圆融流转。

\---

悟空来路与关山

岐金兰 谨记

2026年除夕凌晨

于湖南衡阳

（共28398字）