---
layout: post
title: '三维重建技术的最新进展'
date: "2025-12-29T00:50:07Z"
---
三维重建技术的最新进展

三维重建技术的最新进展

随着深度学习技术席卷计算机视觉领域，传统的基于图像几何关系的sfm和SLAM技术面临新的挑战，一方面基于深度学习的技术提供了新的视角影响计算机视觉的发展，另一方面深度学习的方法通常需要巨大的计算量限制了它的实用化，不管怎么样这些新技术都有很高的研究价值，虽然现在还不大可能在工程项目中直接使用这些技术，但随着手机，车载系统，ROS硬件水平的提高，这些新技术也许能找到用武之地。下面分类介绍一些这样的新技术。

[NeRF:Representing Scenes as Neural Radiance Fields for View Synthesis](https://arxiv.org/abs/2003.08934)  
简介：深度学习与三维重建技术结合的开山之作，诞生了无数基于此技术的研究创新论文，随便在网上搜索一下就能搜出一大堆来，该方法通过使用multilayer perceptron (MLP)，把三维场景用一个体函数表示，渲染的时候，根据视角位置和方向，生成体像素，最后用体渲染的方式显示出新位置的视觉效果。  
代码：[https://github.com/bmild/nerf](https://github.com/bmild/nerf)

[3D Gaussian Splatting for Real-Time Radiance Field Rendering](https://arxiv.org/abs/2308.04079)  
简介：短时间内迅速火爆三维重建领域，用3D高斯球点云描述三维场景，然后用分块光栅化进行渲染，论文的突破点在于实现快速的训练和渲染效果。话说在一块价格几万块的A6000GPU上跑100fps有点夸张。  
代码：[https://github.com/graphdeco-inria/gaussian-splatting](https://github.com/graphdeco-inria/gaussian-splatting)

[3D Gaussian Ray Tracing: Fast Tracing of Particle Scenes](https://research.nvidia.com/labs/toronto-ai/3DGRT/res/3dgrt_compressed.pdf)  
[3DGUT: Enabling Distorted Cameras and Secondary Rays in Gaussian Splatting](https://research.nvidia.com/labs/toronto-ai/3DGUT/res/3DGUT_ready_main.pdf)  
简介：Nvidia对于3DGS的扩展,使用raytracing进行渲染。总之都是效果奇好，速度奇慢，给显卡做广告到是不错。  
代码：[https://github.com/nv-tlabs/3dgrut](https://github.com/nv-tlabs/3dgrut)

[MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors](https://arxiv.org/abs/2412.12392)  
简介：先由两张图片生成pointmap,然后再与当前关键帧做匹配，跟踪估计位姿并做pointmap融合，如果有新的关键帧则做回环检测和优化。应该算是比较完整的稠密SLAM方案。不依赖相机的类型约束也是一大亮点，相机可以做镜头缩放而不影响跟踪效果。  
代码:[https://github.com/rmurai0610/MASt3R-SLAM](https://github.com/rmurai0610/MASt3R-SLAM)

[LODGE:Level-of-Detail Large-Scale Gaussian Splatting with Efficient Rendering](https://arxiv.org/pdf/2505.23158.pdf)  
简介：Google对3DGS的扩展，对场景使用LOD减少内存占用和加快渲染速度。在iphone 13 mini上能跑41fps,感觉性能还可以，推荐看一下。  
代码：[https://lodge-gs.github.io](https://loge-gs.github.io)

[MVSAnywhere: Zero-Shot Multi-View Stereo](https://www.arxiv.org/pdf/2503.22430)  
简介：基于transformer架构的多视角深度估计算法。看论文介绍，该技术可以同时对室内外场景进行深度估计，看网站视频，对于室外大场景的深度估计还是很震撼的，推荐一下。  
代码：[https://nianticlabs.github.io/mvsanywhere/](https://nianticlabs.github.io/mvsanywhere/)

[MapAnything: Universal Feed-Forward Metric 3D Reconstruction](https://arxiv.org/pdf/2509.13414)  
简介：基于transformer的架构把许多不同输入的图片和相机配置，一步直接生成三维场景，相当神奇。  
代码:[https://github.com/facebookresearch/map-anything](https://github.com/facebookresearch/map-anything)