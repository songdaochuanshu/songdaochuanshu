---
layout: post
title: '基于大模型的电信网络诈骗预警技术研究'
date: "2025-09-05T00:39:12Z"
---
基于大模型的电信网络诈骗预警技术研究
==================

> 学习论文：基于大模型的电信网络诈骗预警技术研究

![image](https://img2024.cnblogs.com/blog/1928790/202509/1928790-20250904225937855-661116435.png)

研究背景与核心问题
---------

1.  **问题现状**
    *   电信网络诈骗案件数量持续上升（2017-2021年全国案件超28万件，诈骗罪占比36.53%），诈骗手段快速迭代导致传统基于知识库的预警技术效果有限。
    *   当前难点：诈骗话术冗长、线索分散（平均1182字，最长超6000字），人工特征提取效率低且无法适应新型诈骗变种。
2.  **技术契机**
    *   大模型（如ChatGPT）在few-shot/zero-shot任务中表现优异，为少样本诈骗文本分类提供新思路。

关键技术方法
------

### 基于大模型的诈骗文本分类框架

*   总体流程：
    
        语音输入 → 语音转写 → 主题分类（贷款相关？） → 特征判定（多要素分解） → 综合判定
        
    

![image](https://img2024.cnblogs.com/blog/1928790/202509/1928790-20250904225954410-1913680382.png)

*   **主题分类**：过滤非贷款对话（如闲聊、业务办理），减少计算量。
*   **特征判定**：将复杂诈骗判别分解为粒度更小的子任务（如判定“宣传话术”“要求交费”等特征）。

### 核心创新点

*   **特征提取自动化**
    *   采用句向量聚类技术：
        *   使用嵌入模型 `bge-large-zh-v1.5` 提取句向量，对152份诈骗样本的6874个短句聚类（K-means, k=30）。
        *   聚类结果分为三类：**贷款相关**（如“还款”“冻结解冻”）、**对话相关**（如“回复联系”）、**无主题**（杂乱文本）。
        *   _替代人工拆解特征，提升效率与一致性。_
*   **提示词自动生成与优化（APE方法）**
    *   步骤：
        1.  大模型基于模板生成初始提示词（填充正负样本）。
        2.  评分筛选（公式：`Score = 0.6 * Recall + 0.4 * Precision`，侧重召回率）。
        3.  多轮迭代：对高分提示词进行语义变体重采样。
    *   _解决提示词人工编写耗时、质量不稳定的问题。_

### 分类器构建

#### 手工特征方案

*   提炼贷款诈骗7大特征（如“无抵押宣传”“要求交费”“操作出错”等），设计ICIO框架提示词（指令-背景-输入-输出）。
    
    ![image](https://img2024.cnblogs.com/blog/1928790/202509/1928790-20250904230014530-1322577838.png)
    
    ![image](https://img2024.cnblogs.com/blog/1928790/202509/1928790-20250904230024884-1903448004.png)
    
*   **分类规则**：加权投票（特征权重25-40），累计权重≥40判定为诈骗。
    

##### 贷款诈骗7大特征

1.  **宣传话术**
    *   使用“无抵押、免征信、低利率、快速放款”等虚假广告诱导受害者。
2.  **陌生关系**
    *   对话双方为陌生人关系（如“客服与客户”），排除熟人称呼（如“某师傅”“某总”）。
3.  **要求下载App**
    *   以办理贷款手续为由，要求受害者下载指定App或登录网站。
4.  **要求交费**
    *   编造“认证还款、保证金、手续费、刷流水”等理由要求转账。
5.  **操作出错**
    *   受害者操作时必然“出错”（如账户冻结、贷款失败），为后续诈骗铺垫。
6.  **解冻账户**
    *   以“解冻账户”为由要求二次交费（如“再次转账方可继续贷款”）。
7.  **要求截图**
    *   受害者交费后被要求提供“电子回执单、短信截图”等作为“凭证”。

##### 特征权重与判定规则

*   **权重分配**（用于综合判定）：
    
    特征
    
    权重
    
    宣传话术
    
    35
    
    操作出错
    
    40
    
    解冻账户
    
    35
    
    要求交费
    
    25
    
    要求下载App
    
    20
    
    要求截图
    
    20
    
    陌生关系
    
    10
    
*   **判定规则**：  
    累计权重 **≥40** 即判定为贷款诈骗。
    

##### 实际数据分布

在152个贷款诈骗样本中，各特征出现比例：

*   **陌生关系**：100%（所有诈骗样本均伪装陌生关系）
*   **要求交费**：62.5%
*   **操作出错**：48.6%
*   **要求截图**：44.0%
*   **要求下载App**：38.1%
*   **宣传话术**：23.6%
*   **解冻账户**：35.5%

> **说明**：单一样本通常不会包含全部特征（诈骗分多阶段进行），但权重较高的特征（如“操作出错”“解冻账户”）更具判别性。

#### 自动聚类特征方案

*   聚类生成15个贷款诈骗的特征，划分为高权重特征（如“冻结解冻”“截图”）和低权重特征。
*   **分类规则**：累计权重≥45判定为诈骗。

自动聚类特征方案的核心是通过**无监督学习**替代人工特征拆解，解决传统方法效率低、一致性差的问题：

1.  **任务目标**  
    自动识别诈骗文本中的高频语义片段，形成可量化判别的特征集合。
2.  **技术路线**  
    `句向量提取 → 无监督聚类 → 特征权重分配 → 综合判定`

##### 实现步骤

**1\. 数据预处理**

*   **原始数据**：152个贷款诈骗样本的语音转写文本（平均长度1182字）。
*   短句切分：
    *   按标点符号分割文本，过滤长度<5字符或>30字符的句子。
    *   得到**6874个有效短句**作为聚类输入。

**2\. 句向量提取**

*   **嵌入模型**：采用`bge-large-zh-v1.5`（当前最优中文文本嵌入模型之一）。
*   **向量维度**：1024维向量表示每个短句的语义特征。

**3\. K-means聚类**

*   **聚类参数**：`k=30`（根据经验设定）。
    
*   距离度量：余弦相似度（更适合文本向量）
    
*   聚类结果：
    
    ![image](https://img2024.cnblogs.com/blog/1928790/202509/1928790-20250904230043569-690352988.png)
    

聚类测试代码，感觉效果不是很好：

    import re
    import numpy as np
    from sentence_transformers import SentenceTransformer
    from sklearn.cluster import KMeans
    from sklearn.decomposition import PCA
    import matplotlib
    # 设置matplotlib后端以避免PyCharm兼容性问题
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt
    import seaborn as sns
    
    
    class FraudTextCluster:
        def __init__(self, k=30, min_len=5, max_len=30):
            """
            初始化聚类器
            :param k: 聚类数量（默认为30）
            :param min_len: 最短句子长度（字符数）
            :param max_len: 最长句子长度（字符数）
            """
            self.k = k
            self.min_len = min_len
            self.max_len = max_len
            # 加载中文嵌入模型（论文使用的bge-large-zh-v1.5）
            self.model = SentenceTransformer('D:\\llms\\bge-large-zh-v1.5')
    
        def preprocess(self, texts):
            """
            文本预处理：分割句子并过滤无效短句
            :param texts: 原始文本列表（每个元素为一个诈骗样本）
            :return: 有效短句列表
            """
            short_sentences = []
            for text in texts:
                # 按标点符号分割句子
                sentences = re.split(r'[。？！；，]', text)
                for sent in sentences:
                    # 过滤长度不符合要求的句子
                    if self.min_len <= len(sent) <= self.max_len:
                        short_sentences.append(sent.strip())
            return short_sentences
    
        def extract_embeddings(self, sentences):
            """
            提取句向量
            :param sentences: 短句列表
            :return: 句向量矩阵 (n_samples, 1024)
            """
            return self.model.encode(sentences, normalize_embeddings=True)
    
        def cluster(self, embeddings):
            """
            K-means聚类
            :param embeddings: 句向量矩阵
            :return: 聚类标签和中心点
            """
            # 获取样本数量（嵌入矩阵的第一维）
            n_samples = len(embeddings)
            if not isinstance(n_samples, int):
                raise ValueError("embeddings 的长度应该是一个整数")
    
            # 动态调整聚类数量
            k = min(int(self.k), n_samples)  # 确保聚类数不超过样本数
    
            # 动态调整PCA维度
            if n_samples > 50:
                pca = PCA(n_components=50)
                reduced_emb = pca.fit_transform(embeddings)
                used_emb = reduced_emb
            else:
                # 样本数不足50时，不进行降维
                used_emb = embeddings
    
            # K-means聚类
            kmeans = KMeans(
                n_clusters=k,
                init='k-means++',
                n_init=10,
                max_iter=300,
                tol=1e-4,
                random_state=42
            )
            labels = kmeans.fit_predict(used_emb)
            return labels, kmeans.cluster_centers_
    
        def analyze_clusters(self, sentences, labels):
            """
            分析聚类结果
            :param sentences: 短句列表
            :param labels: 聚类标签
            :return: 聚类分析字典
            """
            cluster_dict = {}
            for i in range(max(labels) + 1):
                cluster_dict[i] = []
    
            for sent, label in zip(sentences, labels):
                cluster_dict[label].append(sent)
    
            return cluster_dict
    
        def visualize_clusters(self, embeddings, labels):
            """
            可视化聚类结果（降维到2D）
            :param embeddings: 句向量
            :param labels: 聚类标签
            """
            # 降维到2D
            pca = PCA(n_components=2)
            vis_emb = pca.fit_transform(embeddings)
    
            plt.figure(figsize=(12, 8))
            sns.scatterplot(
                x=vis_emb[:, 0],
                y=vis_emb[:, 1],
                hue=labels,
                palette="viridis",
                alpha=0.7,
                s=50
            )
            plt.title("Sentence Clustering Visualization")
            plt.xlabel("PCA Component 1")
            plt.ylabel("PCA Component 2")
            plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.tight_layout()
            # 保存图像到文件而不是直接显示，以避免PyCharm兼容性问题
            plt.savefig('clustering_result.png', dpi=300, bbox_inches='tight')
            print("聚类结果已保存到 clustering_result.png")
            plt.close()  # 关闭图形以释放内存
    
        def full_pipeline(self, texts):
            """
            完整聚类流程
            :param texts: 原始文本列表
            :return: 聚类结果字典
            """
            # 1. 预处理
            sentences = self.preprocess(texts)
            print(f"预处理完成，得到{len(sentences)}个有效短句")
    
            if len(sentences) == 0:
                print("警告：未获得有效短句，请检查输入数据")
                return {}
    
            # 2. 提取句向量
            embeddings = self.extract_embeddings(sentences)
            print(f"句向量提取完成，维度：{embeddings.shape}")
    
            # 3. 聚类
            labels, centers = self.cluster(embeddings)
            print(f"聚类完成，共生成{len(set(labels))}个簇")
    
            # 4. 分析结果
            cluster_data = self.analyze_clusters(sentences, labels)
    
            # 5. 可视化（可选）
            if len(sentences) > 1:  # 至少需要2个样本才能可视化
                self.visualize_clusters(embeddings, labels)
    
            return cluster_data
    
    
    # ====================== 使用示例 ====================== #
    if __name__ == "__main__":
        # 模拟论文中的诈骗文本数据（实际应替换为真实数据）
        sample_texts = [
            "您的账户因操作失误被冻结，需转账5000元解冻才能继续贷款",
            "银行卡异常冻结，请扫码支付解冻费，否则无法提现",
            "贷款审核需要验证还款能力，请先缴纳2000元保证金",
            "系统检测到风险，需要您提供身份证照片和银行卡截图",
            "下载我们的APP即可申请无抵押贷款，秒批秒到账",
            "请稍等，正在为您处理贷款申请，可能需要几分钟时间",
            "您好，我是XX银行客服，请问有什么可以帮您？",
            "麻烦提供下您的姓名和手机号，我们需要登记信息",
            "贷款已审批通过，但需要先支付手续费才能放款",
            "您的账户存在异常操作，请立即联系客服处理"
        ]
    
        # 初始化聚类器（参数与论文一致）
        clusterer = FraudTextCluster(k=30, min_len=5, max_len=30)
    
        # 运行完整流程
        results = clusterer.full_pipeline(sample_texts)
    
        # 打印聚类结果（每个簇的前3个句子）
        print("\n聚类结果示例：")
        for cluster_id, sentences in results.items():
            print(f"\nCluster {cluster_id} (样本数: {len(sentences)}):")
            for i, sent in enumerate(sentences[:3]):
                print(f"  - {sent}")
                
    输出：
    预处理完成，得到21个有效短句
    句向量提取完成，维度：(21, 1024)
    聚类完成，共生成21个簇
    聚类结果已保存到 clustering_result.png
    
    聚类结果示例：
    
    Cluster 0 (样本数: 1):
      - 系统检测到风险
    
    Cluster 1 (样本数: 1):
      - 您的账户存在异常操作
    
    Cluster 2 (样本数: 1):
      - 贷款已审批通过
    
    Cluster 3 (样本数: 1):
      - 请扫码支付解冻费
    
    Cluster 4 (样本数: 1):
      - 需要您提供身份证照片和银行卡截图
    
    Cluster 5 (样本数: 1):
      - 请先缴纳2000元保证金
    
    Cluster 6 (样本数: 1):
      - 可能需要几分钟时间
    
    Cluster 7 (样本数: 1):
      - 请立即联系客服处理
    
    Cluster 8 (样本数: 1):
      - 请问有什么可以帮您
    
    Cluster 9 (样本数: 1):
      - 否则无法提现
    
    Cluster 10 (样本数: 1):
      - 秒批秒到账
    
    Cluster 11 (样本数: 1):
      - 麻烦提供下您的姓名和手机号
    
    Cluster 12 (样本数: 1):
      - 贷款审核需要验证还款能力
    
    Cluster 13 (样本数: 1):
      - 下载我们的APP即可申请无抵押贷款
    
    Cluster 14 (样本数: 1):
      - 我们需要登记信息
    
    Cluster 15 (样本数: 1):
      - 我是XX银行客服
    
    Cluster 16 (样本数: 1):
      - 需转账5000元解冻才能继续贷款
    
    Cluster 17 (样本数: 1):
      - 正在为您处理贷款申请
    
    Cluster 18 (样本数: 1):
      - 但需要先支付手续费才能放款
    
    Cluster 19 (样本数: 1):
      - 银行卡异常冻结
    
    Cluster 20 (样本数: 1):
      - 您的账户因操作失误被冻结
    

![image](https://img2024.cnblogs.com/blog/1928790/202509/1928790-20250904230104023-1646037419.png)

**4\. 特征权重分配**

*   **高权重特征**（5类，权重=20）：  
    `资金周转(3)、出错(9)、截图(10)、冻结解冻(24)、提现(27)` （直接对应诈骗关键环节）
*   **低权重特征**（10类，权重=10）：  
    其他贷款相关类别（如还款、审核、身份证等）
*   **判定规则**：累计权重 **≥45** 即判定为诈骗。

##### 提示词自动生成（APE方法）

针对每个聚类特征，自动生成优化提示词：

1.  生成模板：
    
        "请找出‘特征句子’和非特征句子的区别，生成一个prompt用于检测特征句子。示例：  
        特征句：[正样本1]、[正样本2]...  
        非特征句：[负样本1]、[负样本2]..."
        
    
2.  优化流程：
    
    *   **初始生成**：用聚类结果中的正/负样本填充模板，生成候选提示词。
        *   **举例**：如“账户被冻结需转账解冻”
            *   **正样本**（诈骗话术）：  
                `“您的账户因操作失误被冻结，需转账5000元解冻”`  
                `“银行卡异常冻结，请扫码支付解冻费”`
            *   **负样本**（正常对话）：  
                `“系统卡顿请稍后重试”`  
                `“网络延迟导致交易失败”`
    *   **评分筛选**：
        *   测试效果，例如：
            *   召回率（Recall）= 75%（正确识别15/20个真实“冻结解冻”句）
            *   精确率（Precision）= 75%（20个判定结果中15个正确）
        *   计算得分：`Score = 0.6×85% + 0.4×75% = 81%`
        *   结果：该提示词进入Top 5候选（需与其他生成提示词比较得分）。。
    *   **迭代优化**：对高分提示词语义变体重采样（如调整措辞、扩充描述）。
3.  最终提示词示例：
    
        "请在文本中查找涉及账户冻结、解冻要求的句子，典型话术如‘需转账解冻’‘账户被冻结’。  
        输出格式：JSON数组，包含原文句子、判断理由、是否特征句。"
        
    

实验与结果
-----

1.  **数据预处理**
    
    *   **数据来源**：944条真实语音对话 → 过滤为667条文本（含152条贷款诈骗数据）。
    *   预处理：
        *   语音转写纠错（GLM-4-9B模型增强可读性）。
        *   隐私脱敏（Qwen2.5-14B-Instruct检测敏感信息，人工核验）。
    *   **标注**：5名标注员3轮标注（独立-交叉-合并），主题分类首轮平均F1=0.810。
2.  **关键实验结果**
    
    *   **主题分类**：召回率84.9%，精确率72.2%，F1=0.782（接近人工标注水平）。
    *   **手工特征分类**：召回率79.6%，精确率87.6%，F1=0.834。
    *   **自动聚类特征分类**：召回率81.6%，精确率84.9%，F1=0.832（与手工方案性能相当且优于人工首轮标注）。
3.  **对比优势**
    
    **方案**
    
    **召回率**
    
    **精确率**
    
    **F1值**
    
    人工首轮标注
    
    79.6%
    
    82.4%
    
    0.810
    
    手工特征
    
    79.6%
    
    87.6%
    
    0.834
    
    自动聚类特征
    
    81.6%
    
    84.9%
    
    **0.832**
    

应用价值与展望
-------

1.  **实际意义**
    *   **少量样本高效预警**：仅需数十个样本构建分类器（APE），快速响应新型诈骗变种（传统方法需更新知识库）。
    *   **全流程优化**：自动化特征提取和提示词生成将人工介入环节减少50%以上，显著提升处理效率。
2.  **未来方向**
    *   扩展至其他诈骗类型（如冒充客服、投资诈骗）。
    *   优化聚类算法特征权重分配策略。