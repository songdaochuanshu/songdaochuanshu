---
layout: post
title: '通过Ollama本地部署DeepSeek R1以及简单使用的教程（超详细）'
date: "2025-02-08T00:34:40Z"
---
通过Ollama本地部署DeepSeek R1以及简单使用的教程（超详细）
=====================================

> 本文介绍了在Windows环境下，通过Ollama来本地部署DeepSeek R1。该问包含了Ollama的下载、安装、安装目录迁移、大模型存储位置修改、下载DeepSeek以及通过Web UI来对话等相关内容。

1、🥇下载Ollama
============

首先我们到[Ollama官网](https://ollama.com/download/windows)去下载安装包，此处我们下载的是[Windows版本的安装包](https://ollama.com/download/OllamaSetup.exe)，如下图所示：  
![Windows安装包下载](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207093114124-1041633455.png)

* * *

2、🥈安装Ollama
============

下面提供两种安装方式：

*   通过命令安装（推荐）；
*   通过鼠标双击安装（不推荐）。

安装Ollama的时候，推荐使用命令【2.1、🥪通过命令安装（推荐）】来安装，好处是可以修改安装的目录位置，【通过鼠标双击安装（不推荐）】是不能修改安装的目录位置的（默认安装在C盘）。

因此安装的时候选择【2.1、🥪通过命令安装（推荐）】或【2.2、🍞通过鼠标双击安装（不推荐）】其中一种方式即可。

2.1、🥪通过命令安装（推荐）
----------------

之所以推荐使用命令安装，是因为通过鼠标安装的话，默认会安装到C盘。

通常情况下，我们不希望安装到C盘，此时我们就可以通过使用命令的方式将Ollama安装到其他盘的某个目录下。

1.  以管理员身份运行CMD，并定位到`OllamaSetup.exe`所在的目录（假设`OllamaSetup.exe`在`D:\Temp`目录下），然后执行如下命令：
    
        OllamaSetup.exe /DIR="D:\Net_Program\Net_Ollama"
        
    
    上述命令中DIR的值为`D:\Net_Program\Net_Ollama`，该值就是安装的目录位置。
    
    ![命令](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207192530436-992250266.png)
    
2.  执行上述命令后，会弹出`OllamaSetup.exe`安装窗体界面，此时我们点击`Install`按钮等待安装完成即可，如下图所示：  
    ![点击安装按钮](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207093648039-1419712369.png)
    
    ![命令](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207192826043-1359299854.png)
    

**注意：**  
安装完成后，Ollama默认为打开状态，此时我们先退出Ollama（鼠标右键点击任务栏的Ollama图标然后选择退出即可）。

2.2、🍞通过鼠标双击安装（不推荐）
-------------------

我们直接双击安装包，然后点击`Install`按钮等待安装完成即可，如下图所示：  
![点击安装按钮](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207093648039-1419712369.png)

![安装中](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207093716954-353394608.png)

**注意：**  
安装完成后，Ollama默认为打开状态，此时我们先退出Ollama（鼠标右键点击任务栏的Ollama图标然后选择退出即可）。

上图中，Ollama默认安装在C盘的`C:\Users\quber\AppData\Local\Programs\Ollama`目录下，如下图所示为默认安装的文件，大小大概有4.56GB：  
![安装完成](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207094248863-197751658.png)

* * *

Ollama安装完成后，在桌面上是没有快捷启动图标的，我们可以在开始菜单中查找或在搜索框中搜索，如下图所示：  
![Ollama](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207134053104-892548002.png)

![Ollama](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207134135243-740354598.png)

* * *

3、🥉转移Ollama安装目录
================

> 如果安装Ollama的时候是通过【2.1、🥪通过命令安装（推荐）】来安装的，以下操作步骤忽略跳过即可，直接开始操作【4、🎉验证Ollama】

如果不想将Ollama安装到C盘，可以将安装的所有文件全部剪切到其他盘的目录内，如转移到D盘的`D:\Net_Program\Net_Ollama`目录下，这样可以节约C盘的空间，如下图所示：  
![转移目录](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207094540718-1677234126.png)

**转移后，我们还需要修改Ollama的环境变量**。

打开环境变量，双击用户变量中的`Path`，我们会看到最后一条信息就是Ollama安装完成后默认添加进来的，如下图所示：  
![环境变量](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207100747755-555069224.png)

我们双击最后一条信息进入编辑状态，修改为我们转移的目录`D:\Net_Program\Net_Ollama`，然后点击确定按钮关闭所有窗体即可，如下图所示：  
![环境变量](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207101034127-524747422.png)

* * *

4、🎉验证Ollama
============

上述步骤完成后，我们可以打开CMD，输入`ollama -v`命令，如果出现如下图所示的内容就代表Ollama安装成功了：  
![验证](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207101259084-213960558.png)

同样我们输入`ollama -h`命令可以查看Ollama其他操作命令，如下图所示：  
![操作命令](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207102520059-774497777.png)

* * *

5、🎄修改大模型存储位置
=============

接下来我们需要配置大模型下载存储的目录位置（默认存储在C盘的`C:\Users\quber\.ollama\models`目录下）。

同样我们打开环境变量，然后在用户变量中点击`新建`按钮，变量名为`OLLAMA_MODELS`，变量值为`D:\Net_Program\Net_Ollama\Models`，其中的变量值就是大模型下载存储的目录位置，最后点击确定即可，如下图所示：  
![存储位置](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207132045091-2008884254.png)

* * *

6、🎁下载DeepSeek
==============

同样我们打开[Ollama官网](https://ollama.com/)，点击顶部的[Models](https://ollama.com/search)链接，此时我们就会看到[deepseek-r1](https://ollama.com/library/deepseek-r1)模型排在第一位，如下图所示：  
![DeepSeek](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207102315751-1743984106.png)

点击[deepseek-r1](https://ollama.com/library/deepseek-r1)链接进去，此时我们会看到下拉框中有各个版本的大模型，越往后对电脑硬件的要求越高，此处为了演示效果，我们选择`1.5b`进行下载（具体可根据自己的电脑和需求有选择性的下载），如下图所示：  
![DeepSeek](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207105059338-1494426742.png)

**显卡要求：**

版本

要求

DeepSeek-R1-1.5b

NVIDIA RTX 3060 12GB or higher

DeepSeek-R1-7b

NVIDIA RTX 3060 12GB or higher

DeepSeek-R1-8b

NVIDIA RTX 3060 12GB or higher

DeepSeek-R1-14b

NVIDIA RTX 3060 12GB or higher

DeepSeek-R1-32b

NVIDIA RTX 4090 24GB

DeepSeek-R1-70b

NVIDIA RTX 4090 24GB \*2

DeepSeek-R1-671b

NVIDIA A100 80GB \*16

随后我们复制下拉框后面的命令`ollama run deepseek-r1:1.5b`，粘贴到**新打开的CMD窗口**中回车执行（耐心等待下载完成），如下图所示：  
![DeepSeek](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207111224037-1402941553.png)  
![DeepSeek](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207105339733-1230456902.png)

**注意：**上述下载命令需要在新打开的CMD窗口中执行，否则下载的文件存储在`C:\Users\quber\.ollama\models`位置，就不是我们修改的`D:\Net_Program\Net_Ollama\Models`这个位置了。

**温馨提示：**  
下载过程中，最开始下载速度可能要快一些，下载到后面可能就几百KB了，此时我们可以按Ctrl+C停止下载，然后再重新复制命令执行下载，此时的下载速度又恢复到了几MB了（此操作可能会遇到重新下载的情况），如此往复操作即可，如下图所示：  
![DeepSeek](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207132515642-1968010411.png)

如出现如下图所示的效果就代表下载完成了：  
![DeepSeek](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207130711902-949043672.png)

* * *

7、🎀验证DeepSeek
==============

在DeepSeek下载完成后，我们就可以在CMD中输入内容进行对话了，如输入：你好，如下图所示：  
![演示](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207133714317-532891377.gif)

假设我们安装了多个DeepSeek模型，我们可以通过`ollama list`命令查看已安装了的模型，如下图所示：  
![模型](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207144433969-1142291958.png)

如果我们想运行某个模型，我们可以通过`ollama run 模型名称`命令运行即可，如下图所示：  
![模型](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207144648022-433548372.png)

如果我们想退出对话，我们可以通过`/bye`命令退出，如下图所示：  
![模型](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207144837257-321478164.png)

到此，DeepSeek R1的部署就基本告一段落。

* * *

8、🎑Web UI对话
============

虽然我们可以通过CMD窗口进行对话，但是相对不那么直观，于是我们可以通过第三方Web UI来实现对话效果。

8.1、🎨Chrome插件-Page Assist
--------------------------

首先我们通过谷歌浏览器[官方插件地址](https://chromewebstore.google.com/search/Page%20Assist?hl=zh-CN&utm_source=ext_sidebar)搜索`Page Assist`，点击`Page Assist - 本地 AI 模型的 Web UI`，如下图所示：  
![Page Assist](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207112114759-1698176580.png)

然后添加到Chrome：  
![Page Assist](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207112330734-1115180946.png)

安装完成后，我们可以将该插件固定（钉）到浏览器顶部，方便使用，如下图所示：  
![Page Assist](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207112637591-84377829.png)

随后我们点击该插件，就会出现如下图所示的界面：  
![Page Assist](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207134405137-680823572.png)

在界面中出现了`Unable to connect to Ollama`的提示，是因为我们安装的Ollama没有启动，此时我们只需要启动Ollama软件即可，启动后的界面效果如下图所示：  
![Page Assist](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207134530329-114999790.png)

**设置中文：**  
点击界面右上角的`Settings`按钮，将语言设置为`简体中文`，如下图所示：  
![Page Assist](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207134720322-2007215774.png)

![Page Assist](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207134753188-1910474408.png)  
设置完成后返回主界面，此时就是中文界面了。

**选择模型：**  
点击主界面中的第一个下拉框，选择我们刚才下载的模型`deepseek-r1:1.5b`，如下图所示：  
![Page Assist](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207135023590-1301032136.png)

到此，配制就完成了。

**对话演示：**  
接下来我们就可以愉快的对话了，效果如下图所示：  
![演示效果](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207224331691-23341302.gif)

**温馨提示：**  
上述演示效果等待时间可能有点长，和电脑的配置有一定的关系，仅供参考。

8.2、👑chatboxai在线对话
-------------------

我们也可以通过在线Web UI [https://web.chatboxai.app/](https://web.chatboxai.app/) 进行对话。

首先我们打开[https://web.chatboxai.app/](https://web.chatboxai.app/)，打开后界面中间会有一个弹出框，我们点击阴影处即可取消该弹框的显示。

**设置中文：**  
我们点击左下角的`Settings`，在弹出框中点击`DISPLAY`，在第一个下拉框中选择`简体中文`，随后点击右下角的`SAVE`即可显示为中文了，如下图所示：  
![设置中文](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207113804578-1448796180.png)

**配置环境变量：**  
在用户环境变量中，我们点击新建，分别新建下面两组变量，如下所示：

    OLLAMA_HOST       0.0.0.0    --任何IP都可以访问
    OLLAMA_ORIGINS    *
    

![环境变量](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207141345011-715181957.png)

**重启Ollama：**  
配置好环境变量后，我们重启下Ollama，目的是让[https://web.chatboxai.app/](https://web.chatboxai.app/)能自动识别连接到Ollama服务，然后刷新下[https://web.chatboxai.app/](https://web.chatboxai.app/)。

**设置模型提供方和模型：**  
点击左下角的`设置`按钮，然后在模型选项卡中选择模型提供方为**OLLAMA API**，模型选择**deepseek-r1:1.5b**，然后点击`保存`，如下图所示：  
![配置](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207141749418-1353988593.png)

**对话演示：**  
接下来我们就可以愉快的对话了，效果图下图所示：  
![演示效果](https://img2024.cnblogs.com/blog/346453/202502/346453-20250207142349177-705939206.gif)

* * *

到此，DeepSeek R1模型的本地部署以及简单对话应用就完成了！！！