---
layout: post
title: 'ã€Agentã€‘MemOS æºç ç¬”è®°---(3)---æœç´¢'
date: "2025-12-09T00:43:50Z"
---
ã€Agentã€‘MemOS æºç ç¬”è®°---(3)---æœç´¢
============================

ã€Agentã€‘MemOS æºç ç¬”è®°---(3)---æœç´¢
============================

ç›®å½•

*   [ã€Agentã€‘MemOS æºç ç¬”è®°---(3)---æœç´¢](#agentmemos-æºç ç¬”è®°---3---æœç´¢)
    *   [0x00 æ‘˜è¦](#0x00-æ‘˜è¦)
    *   [0x01 åˆ†ç±»](#0x01-åˆ†ç±»)
    *   [0x02 æ··åˆæœç´¢ï¼ˆHybrid Searchï¼‰--- Searcher](#0x02-æ··åˆæœç´¢hybrid-search----searcher)
        *   [2.1 å®šä¹‰](#21-å®šä¹‰)
        *   [2.2 æ ¸å¿ƒå‡½æ•°](#22-æ ¸å¿ƒå‡½æ•°)
        *   [2.3 ä¾èµ–å…³ç³»å’Œå…³è”å…³ç³»](#23-ä¾èµ–å…³ç³»å’Œå…³è”å…³ç³»)
            *   [2.3.1 ä¾èµ–é¡¹ï¼ˆSearcher ä¾èµ–çš„ç»„ä»¶ï¼‰](#231-ä¾èµ–é¡¹searcher-ä¾èµ–çš„ç»„ä»¶)
            *   [2.3.2 ä¾èµ– Searcher çš„ç»„ä»¶](#232-ä¾èµ–-searcher-çš„ç»„ä»¶)
        *   [2.4 å›¾ä¾‹](#24-å›¾ä¾‹)
            *   [2.4.1 Searcher ç»„ä»¶å…³ç³»æµç¨‹å›¾](#241-searcher-ç»„ä»¶å…³ç³»æµç¨‹å›¾)
            *   [2.4.2 Searcher è¯¦ç»†æœç´¢è¿‡ç¨‹æµç¨‹](#242-searcher-è¯¦ç»†æœç´¢è¿‡ç¨‹æµç¨‹)
        *   [2.5 TaskGoalParser](#25-taskgoalparser)
            *   [2.5.1 ä¸»è¦åŠŸèƒ½](#251-ä¸»è¦åŠŸèƒ½)
            *   [2.5.2 å·¥ä½œæ¨¡å¼](#252-å·¥ä½œæ¨¡å¼)
                *   [Fast æ¨¡å¼](#fast-æ¨¡å¼)
                *   [Fine æ¨¡å¼](#fine-æ¨¡å¼)
            *   [2.5.3 è¾“å‡ºç»“æž„](#253-è¾“å‡ºç»“æž„)
            *   [2.5.4 prompt](#254-prompt)
            *   [2.5.5 ä¼˜åŠ¿](#255-ä¼˜åŠ¿)
        *   [2.6 GraphMemoryRetriever](#26-graphmemoryretriever)
            *   [2.6.1 ä¸»è¦åŠŸèƒ½](#261-ä¸»è¦åŠŸèƒ½)
            *   [2.6.2 æ ¸å¿ƒæ–¹æ³•](#262-æ ¸å¿ƒæ–¹æ³•)
            *   [2.6.3 å·¥ä½œæµç¨‹æ€»ç»“](#263-å·¥ä½œæµç¨‹æ€»ç»“)
        *   [2.7 Reranker](#27-reranker)
            *   [2.7.1 ä¸»è¦åŠŸèƒ½](#271-ä¸»è¦åŠŸèƒ½)
            *   [2.7.2 å·¥ä½œæµç¨‹æ€»ç»“](#272-å·¥ä½œæµç¨‹æ€»ç»“)
        *   [2.8 MemoryReasoner](#28-memoryreasoner)
            *   [2.8.1 ä¸»è¦åŠŸèƒ½](#281-ä¸»è¦åŠŸèƒ½)
            *   [2.8.2 æ ¸å¿ƒæ–¹æ³•](#282-æ ¸å¿ƒæ–¹æ³•)
            *   [2.8.3 æç¤ºè¯](#283-æç¤ºè¯)
            *   [2.8.4 å·¥ä½œæµç¨‹æ€»ç»“](#284-å·¥ä½œæµç¨‹æ€»ç»“)
            *   [2.8.5 ä¼˜åŠ¿](#285-ä¼˜åŠ¿)
        *   [2.9 Reranker å’Œ Reasoner](#29-reranker-å’Œ-reasoner)
            *   [2.9.1 Reranker çš„ä½œç”¨](#291-reranker-çš„ä½œç”¨)
            *   [2.9.2 Reasoner çš„ä½œç”¨](#292-reasoner-çš„ä½œç”¨)
            *   [2.9.3 ä¸ºä»€ä¹ˆéœ€è¦ä¸¤è€…ç»“åˆï¼Ÿ](#293-ä¸ºä»€ä¹ˆéœ€è¦ä¸¤è€…ç»“åˆ)
            *   [2.9.4 å…·ä½“ç¤ºä¾‹](#294-å…·ä½“ç¤ºä¾‹)
    *   [0x03 å­å›¾æ£€ç´¢](#0x03-å­å›¾æ£€ç´¢)
        *   [3.1 åŠŸèƒ½](#31-åŠŸèƒ½)
        *   [3.2 ä»£ç ](#32-ä»£ç )
    *   [0x04 å›¾æ•°æ®åº“](#0x04-å›¾æ•°æ®åº“)
        *   [4.1 ç¤ºä¾‹](#41-ç¤ºä¾‹)
        *   [4.2 get\_neighbors\_by\_tag](#42-get_neighbors_by_tag)
            *   [4.2.1 åŠŸèƒ½æ¦‚è¿°](#421-åŠŸèƒ½æ¦‚è¿°)
            *   [4.2.2 åº”ç”¨åœºæ™¯](#422-åº”ç”¨åœºæ™¯)
            *   [4.2.3 å‚æ•°è¯´æ˜Ž](#423-å‚æ•°è¯´æ˜Ž)
            *   [4.2.4 ç­›é€‰æœºåˆ¶](#424-ç­›é€‰æœºåˆ¶)
            *   [4.2.5 æ£€ç´¢æµç¨‹](#425-æ£€ç´¢æµç¨‹)
            *   [4.2.6 æ€§èƒ½ä¼˜åŒ–](#426-æ€§èƒ½ä¼˜åŒ–)

0x00 æ‘˜è¦
-------

TreeTextMemory æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„è®°å¿†ç®¡ç†ç³»ç»Ÿï¼Œèƒ½å­˜å‚¨ã€ç»„ç»‡ã€æ£€ç´¢å’Œç»´æŠ¤å„ç§ç±»åž‹çš„æ–‡æœ¬è®°å¿†ã€é€‚ç”¨éœ€è¦å¤æ‚è®°å¿†ç®¡ç†çš„AIç³»ç»Ÿã€‚è¿™æ˜¯ä¸€ä¸ªåŸºäºŽå›¾çš„ã€æ ‘å½¢æ˜Žæ–‡è®°å¿†ï¼Œæ”¯æŒä»¥ç»“æž„åŒ–æ–¹å¼ç»„ç»‡ã€å…³è”å¹¶æ£€ç´¢è®°å¿†ï¼ŒåŒæ—¶ä¿ç•™ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ä¸Žè‰¯å¥½çš„å¯è§£é‡Šæ€§ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è¿™ä¸ªTreeTextMemory å¯¹è±¡ä¸Žåºžå¤§çš„çŸ¥è¯†åº“è¿›è¡Œäº¤äº’ï¼Œä¸ºAIèµ‹äºˆä¸“ä¸šçš„é¢†åŸŸè®°å¿†ã€‚å½“å‰ä½¿ç”¨Neo4jä½œä¸ºåŽç«¯ï¼Œæœªæ¥è®¡åˆ’æ”¯æŒæ›´å¤šå›¾æ•°æ®åº“ã€‚

å› ä¸ºå­—æ•°å¤ªå¤šï¼Œå› æ­¤æŠŠTreeTextMemoryæ‹†åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œä¸Šä¸€ç¯‡ä»‹ç»åŸºæœ¬æ¦‚å¿µå’Œå¦‚ä½•ç®¡ç†ï¼Œæœ¬ç¯‡ä»‹ç»å¦‚ä½•æœç´¢ã€‚

0x01 åˆ†ç±»
-------

TreeTextMemory ä¸»è¦æ”¯æŒå‡ ç§æœç´¢ï¼ˆæ³¨ï¼Œæœ‰äº›æ˜¯ä»Žå…¶ä»–é€”å¾„é€å‡ºï¼‰ï¼š

*   æ··åˆæœç´¢ï¼ˆHybrid Searchï¼‰ï¼Œé€šè¿‡ Searcher.search æ–¹æ³•å¯¹å¤–æä¾›æœåŠ¡ï¼Œæ•´åˆå¤šç§æ£€ç´¢ç­–ç•¥çš„ç»“æžœï¼Œå…·ä½“ç­–ç•¥å¦‚ä¸‹ï¼š
    *   ç»“åˆå‘é‡ç›¸ä¼¼åº¦æœç´¢å’Œå›¾éåŽ†ï¼šåœ¨ GraphMemoryRetrieverä¸­åˆ©ç”¨å›¾ç»“æž„å’Œå‘é‡ä¿¡æ¯
    *   å…¨æ–‡æ£€ç´¢ï¼šè™½ç„¶æ²¡æœ‰æ˜¾å¼çš„å…¨æ–‡æœç´¢APIï¼Œä½†å¯ä»¥é€šè¿‡äº’è”ç½‘æ£€ç´¢å™¨ä»Žæœç´¢å¼•æ“ŽèŽ·å–ç›¸å…³å†…å®¹  
        InternetRetriever ç»„ä»¶å…è®¸é›†æˆå¤–éƒ¨æœç´¢æœåŠ¡ï¼ˆå¦‚Googleã€Bingã€Bochaï¼‰
*   å­å›¾æ£€ç´¢ï¼ˆSubgraph Retrievalï¼‰ï¼Œé€šè¿‡ get\_relevant\_subgraph æ–¹æ³•å¯ä»¥ç›´æŽ¥è¿›è¡Œå­å›¾æœç´¢
    *   ä½¿ç”¨ graph\_store.search\_by\_embedding æ–¹æ³•èŽ·å–æŒ‡å®šèŠ‚ç‚¹å‘¨å›´çš„å±€éƒ¨å­å›¾ç»“æž„
    *   æ”¯æŒè®¾ç½®éåŽ†æ·±åº¦å’Œä¸­å¿ƒèŠ‚ç‚¹çŠ¶æ€æ¡ä»¶
    *   è¿”å›žåŒ…å«æ ¸å¿ƒèŠ‚ç‚¹ã€é‚»å±…èŠ‚ç‚¹å’Œè¾¹çš„å®Œæ•´å­å›¾ä¿¡æ¯

ä»¥ä¸‹æ˜¯å›¾æ•°æ®åº“çš„APIï¼Œæ¯”å¦‚ä½äºŽMemOS-main\\src\\memos\\graph\_dbs\\nebular.pyä¸­ï¼Œåœ¨ä¸€äº›ç¤ºä¾‹ä¸­ä¹Ÿç›´æŽ¥ä½¿ç”¨ï¼š

*   åŸºäºŽå…ƒæ•°æ®çš„ç»“æž„åŒ–æŸ¥è¯¢ï¼ˆMetadata-based Structured Queryï¼‰
    
    *   é€šè¿‡ get\_by\_metadataæ–¹æ³•æ ¹æ®èŠ‚ç‚¹å…ƒæ•°æ®å­—æ®µè¿›è¡Œç²¾ç¡®åŒ¹é…æˆ–æ¡ä»¶æŸ¥è¯¢
    *   æ”¯æŒå¤šç§æ“ä½œç¬¦ï¼šç­‰äºŽï¼ˆ=ï¼‰ã€åŒ…å«ï¼ˆcontainsï¼‰ã€åœ¨åˆ—è¡¨ä¸­ï¼ˆinï¼‰ç­‰
    *   å¯ä»¥ç»„åˆå¤šä¸ªæ¡ä»¶è¿›è¡Œå¤æ‚æŸ¥è¯¢
*   æ ‡ç­¾é‡å æŸ¥è¯¢ï¼ˆTag Overlap Queryï¼‰
    
    *   ä½¿ç”¨ get\_neighbors\_by\_tagæ–¹æ³•æŸ¥æ‰¾å…·æœ‰ç›¸ä¼¼æ ‡ç­¾çš„ç›¸é‚»èŠ‚ç‚¹
    *   é€šè¿‡è®¡ç®—æ ‡ç­¾äº¤é›†å¤§å°æ¥ç¡®å®šç›¸å…³æ€§
    *   æ”¯æŒè®¾ç½®æœ€å°æ ‡ç­¾é‡å æ•°è¦æ±‚
*   å‘é‡ç›¸ä¼¼åº¦æœç´¢ï¼ˆVector Similarity Searchï¼‰
    
    *   åŸºäºŽåµŒå…¥ï¼ˆembeddingï¼‰çš„è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢
    *   ä½¿ç”¨ search\_by\_embedding æ–¹æ³•æ ¹æ®æŸ¥è¯¢å‘é‡æ‰¾åˆ°æœ€ç›¸ä¼¼çš„è®°å¿†èŠ‚ç‚¹
    *   æ”¯æŒè®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼å’Œè¿”å›žç»“æžœæ•°é‡é™åˆ¶

å…¶ä¸­æœ€ä¸»è¦çš„æŸ¥è¯¢æŽ¥å£æ˜¯ searchæ–¹æ³•ï¼Œå®ƒå†…éƒ¨æ•´åˆäº†å¤šç§æ£€ç´¢ç­–ç•¥æ¥æä¾›æœ€ä¼˜çš„æœç´¢ç»“æžœã€‚

0x02 æ··åˆæœç´¢ï¼ˆHybrid Searchï¼‰--- Searcher
------------------------------------

Searcher ç”± TreeTextMemory åˆ›å»ºå¹¶ä½œä¸ºä¸»è¦çš„æœç´¢æŽ¥å£ä½¿ç”¨ï¼ŒSearcher æ˜¯æ•´ä¸ªè®°å¿†æ£€ç´¢ç³»ç»Ÿçš„æ ¸å¿ƒåè°ƒè€…ï¼Œè´Ÿè´£æ•´åˆå„ç§æ£€ç´¢æºå¹¶æä¾›é«˜è´¨é‡çš„æ£€ç´¢ç»“æžœã€‚Searcher ç±»çš„ä¸»è¦åŠŸèƒ½æ˜¯æ‰§è¡Œè®°å¿†æ£€ç´¢ä»»åŠ¡ã€‚ä»¥ä¸‹æ˜¯å…¶æ ¸å¿ƒèŒè´£å’Œå·¥ä½œæµç¨‹ï¼š

*   å¤šè·¯å¾„å¹¶è¡Œæ£€ç´¢ï¼ŒåŒæ—¶ä»Žå¤šä¸ªæ¥æºæ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼š
    *   å·¥ä½œè®°å¿†ï¼ˆWorkingMemoryï¼‰
    *   é•¿æœŸè®°å¿†ï¼ˆLongTermMemoryï¼‰
    *   ç”¨æˆ·è®°å¿†ï¼ˆUserMemoryï¼‰
    *   äº’è”ç½‘æ£€ç´¢å™¨ï¼ˆå¯é€‰ï¼‰
    *   MemCubesï¼ˆå¯é€‰ï¼‰
*   ä»»åŠ¡è§£æžä¸ŽæŸ¥è¯¢ä¼˜åŒ–
    *   ä½¿ç”¨ TaskGoalParser è§£æžç”¨æˆ·æŸ¥è¯¢æ„å›¾
    *   æ ¹æ®ä¸åŒæ¨¡å¼ï¼ˆfast/fineï¼‰é‡‡ç”¨ä¸åŒçš„æ£€ç´¢ç­–ç•¥
    *   åœ¨ç²¾ç»†æ¨¡å¼ä¸‹å…ˆè¿›è¡ŒåµŒå…¥æœç´¢èŽ·å–ä¸Šä¸‹æ–‡
*   ç»“æžœé‡æŽ’åºä¸ŽåŽ»é‡
    *   ä½¿ç”¨ reranker å¯¹æ£€ç´¢ç»“æžœè¿›è¡Œé‡æ–°æŽ’åº
    *   åŽ»é™¤é‡å¤çš„è®°å¿†é¡¹
    *   ä¿ç•™æœ€ç›¸å…³çš„ç»“æžœ
*   é«˜çº§æŽ¨ç†å¤„ç†
    *   åˆ©ç”¨ MemoryReasoner å¯¹æ£€ç´¢åˆ°çš„è®°å¿†è¿›è¡ŒæŽ¨ç†å’ŒçŸ¥è¯†ç»¼åˆ
    *   æå–æœ€æœ‰ä»·å€¼çš„ä¿¡æ¯ç‰‡æ®µ
*   ä½¿ç”¨åŽ†å²è¿½è¸ª
    *   æ›´æ–°è®°å¿†é¡¹çš„ä½¿ç”¨åŽ†å²è®°å½•
    *   å¹¶å‘å¤„ç†ä½¿ç”¨ç»Ÿè®¡æ›´æ–°

### 2.1 å®šä¹‰

    class Searcher:
        def __init__(
            self,
            dispatcher_llm: OpenAILLM | OllamaLLM | AzureLLM,
            graph_store: Neo4jGraphDB,
            embedder: OllamaEmbedder,
            reranker: BaseReranker,
            internet_retriever: InternetRetrieverFactory | None = None,
            moscube: bool = False,
        ):
            self.graph_store = graph_store
            self.embedder = embedder
    
            self.task_goal_parser = TaskGoalParser(dispatcher_llm)
            self.graph_retriever = GraphMemoryRetriever(self.graph_store, self.embedder)
            self.reranker = reranker
            self.reasoner = MemoryReasoner(dispatcher_llm)
    
            # Create internet retriever from config if provided
            self.internet_retriever = internet_retriever
            self.moscube = moscube
    
            self._usage_executor = ContextThreadPoolExecutor(max_workers=4, thread_name_prefix="usage")
    

### 2.2 æ ¸å¿ƒå‡½æ•°

å…¶æ ¸å¿ƒæ–¹æ³•å¦‚ä¸‹ï¼š

*   search()ï¼šä¸»å…¥å£ï¼Œåè°ƒæ•´ä¸ªæ£€ç´¢è¿‡ç¨‹
*   \_parse\_task()ï¼šè§£æžä»»åŠ¡å’ŒæŸ¥è¯¢
*   \_retrieve\_paths()ï¼šæ‰§è¡Œå¤šè·¯å¾„æ£€ç´¢
*   \_deduplicate\_results()ï¼šç»“æžœåŽ»é‡
*   \_sort\_and\_trim()ï¼šæŽ’åºå’Œæˆªæ–­ç»“æžœ
*   update\_usage\_history()ï¼šæ›´æ–°ä½¿ç”¨åŽ†å²

ä¸»å…¥å£å¦‚ä¸‹ï¼Œæˆ–è€…è¯´Searcher ç¼–æŽ’æœç´¢æµæ°´çº¿å¦‚ä¸‹ï¼š

*   æŸ¥è¯¢è§£æžå’Œç†è§£
*   ä»Žå¤šä¸ªæ¥æºå¹¶è¡Œæ£€ç´¢
*   ç»“æžœé‡æ–°æŽ’åº
*   åŽ»é‡å¤„ç†
*   å¯¹ç»“æžœè¿›è¡ŒæŽ¨ç†
*   ä½¿ç”¨æƒ…å†µè·Ÿè¸ª

        @timed
        def search(
            self,
            query: str,
            top_k: int,
            info=None,
            mode="fast",
            memory_type="All",
            search_filter: dict | None = None,
        ) -> list[TextualMemoryItem]:
            """
            Search for memories based on a query.
            User query -> TaskGoalParser -> GraphMemoryRetriever ->
            MemoryReranker -> MemoryReasoner -> Final output
            Args:
                query (str): The query to search for.
                top_k (int): The number of top results to return.
                info (dict): Leave a record of memory consumption.
                mode (str, optional): The mode of the search.
                - 'fast': Uses a faster search process, sacrificing some precision for speed.
                - 'fine': Uses a more detailed search process, invoking large models for higher precision, but slower performance.
                memory_type (str): Type restriction for search.
                ['All', 'WorkingMemory', 'LongTermMemory', 'UserMemory']
                search_filter (dict, optional): Optional metadata filters for search results.
            Returns:
                list[TextualMemoryItem]: List of matching memories.
            """
            logger.info(
                f"[SEARCH] Start query='{query}', top_k={top_k}, mode={mode}, memory_type={memory_type}"
            )
            if not info:
                logger.warning(
                    "Please input 'info' when use tree.search so that "
                    "the database would store the consume history."
                )
                info = {"user_id": "", "session_id": ""}
            else:
                logger.debug(f"[SEARCH] Received info dict: {info}")
    
            parsed_goal, query_embedding, context, query = self._parse_task(
                query, info, mode, search_filter=search_filter
            )
            results = self._retrieve_paths(
                query, parsed_goal, query_embedding, info, top_k, mode, memory_type, search_filter
            )
            deduped = self._deduplicate_results(results)
            final_results = self._sort_and_trim(deduped, top_k)
            self._update_usage_history(final_results, info)
    
            logger.info(f"[SEARCH] Done. Total {len(final_results)} results.")
            res_results = ""
            for _num_i, result in enumerate(final_results):
                res_results += "\n" + (
                    result.id + "|" + result.metadata.memory_type + "|" + result.memory
                )
            logger.info(f"[SEARCH] Results. {res_results}")
            return final_results
    

### 2.3 ä¾èµ–å…³ç³»å’Œå…³è”å…³ç³»

#### 2.3.1 ä¾èµ–é¡¹ï¼ˆSearcher ä¾èµ–çš„ç»„ä»¶ï¼‰

Searcher ä¾èµ–çš„ç»„ä»¶å¦‚ä¸‹ï¼š

*   å¤§è¯­è¨€æ¨¡åž‹ç»„ä»¶ï¼š
    *   dispatcher\_llm â€“ ç”¨äºŽä»»åŠ¡è§£æžå’ŒæŽ¨ç†
    *   TaskGoalParser â€“ å°†ç”¨æˆ·æŸ¥è¯¢è§£æžä¸ºç»“æž„åŒ–ç›®æ ‡
*   å­˜å‚¨ç»„ä»¶ï¼š
    *   graph\_store â€“ Neo4j å›¾æ•°æ®åº“ç”¨äºŽå­˜å‚¨è®°å¿†
    *   GraphMemoryRetriever â€“ ä»Žå›¾å­˜å‚¨ä¸­æ£€ç´¢è®°å¿†
*   å¤„ç†ç»„ä»¶ï¼š
    *   embedder â€“ ä¸ºæŸ¥è¯¢å’Œè®°å¿†åˆ›å»ºåµŒå…¥å‘é‡
    *   reranker â€“ å¯¹æ£€ç´¢ç»“æžœè¿›è¡Œé‡æ–°æŽ’åº
    *   MemoryReasoner â€“ å¯¹æ£€ç´¢åˆ°çš„è®°å¿†è¿›è¡ŒæŽ¨ç†
    *   internet\_retriever â€“ å¯é€‰çš„äº’è”ç½‘æœç´¢åŠŸèƒ½

#### 2.3.2 ä¾èµ– Searcher çš„ç»„ä»¶

ä¾èµ– Searcher çš„ç»„ä»¶å¦‚ä¸‹ï¼š

*   TreeTextMemory â€“ åœ¨å…¶ search æ–¹æ³•ä¸­ä½¿ç”¨ Searcher
*   GeneralScheduler â€“ é€šè¿‡æ£€ç´¢å™¨åœ¨ process\_session\_turn ä¸­ä½¿ç”¨ Searcher

### 2.4 å›¾ä¾‹

Searcher è¢«è°ƒåº¦å™¨ç³»ç»Ÿç”¨äºŽåœ¨æŸ¥è¯¢å¤„ç†è¿‡ç¨‹ä¸­æ£€ç´¢ç›¸å…³è®°å¿†ï¼Œæ€»çš„æ¥è¯´ï¼ŒSearcher å……å½“ä¸€ä¸ªä¸­å¤®åè°ƒè€…ï¼Œå°†å„ç§ç»„ä»¶æ•´åˆåœ¨ä¸€èµ·ï¼Œä¸ºè·¨ä¸åŒè®°å¿†æºå’Œå¤–éƒ¨æ•°æ®æä¾›å…¨é¢çš„æ£€ç´¢èƒ½åŠ›ã€‚

#### 2.4.1 Searcher ç»„ä»¶å…³ç³»æµç¨‹å›¾

#### 2.4.2 Searcher è¯¦ç»†æœç´¢è¿‡ç¨‹æµç¨‹

ç”¨æˆ·æŸ¥è¯¢ â†’ TaskGoalParser è§£æž â†’ å¤šè·¯å¾„å¹¶è¡Œæ£€ç´¢ â†’ ç»“æžœé‡æŽ’åº â†’ åŽ»é‡å¤„ç† â†’ æŽ¨ç†ä¼˜åŒ– â†’ è¿”å›žæœ€ç»ˆç»“æžœã€‚

å„ç»„ä»¶è¯¦ç»†è¯´æ˜Ž

**ä¸»è¦é˜¶æ®µ**

*   ä»»åŠ¡è§£æžï¼šä½¿ç”¨ TaskGoalParser è§£æžæŸ¥è¯¢ï¼Œæ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦ä½¿ç”¨ LLM
*   å¹¶è¡Œæ£€ç´¢ï¼šåŒæ—¶æ‰§è¡Œå¤šä¸ªæ£€ç´¢è·¯å¾„
*   ç»“æžœé‡æŽ’ï¼šä½¿ç”¨ Reranker å¯¹å„è·¯å¾„çš„ç»“æžœè¿›è¡Œé‡æŽ’
*   åˆå¹¶åŽ»é‡ï¼šåˆå¹¶æ‰€æœ‰è·¯å¾„çš„ç»“æžœå¹¶åŽ»é™¤é‡å¤é¡¹
*   æŽ’åºæˆªå–ï¼šæŒ‰åˆ†æ•°æŽ’åºå¹¶æˆªå–å‰ K ä¸ªç»“æžœ
*   æ›´æ–°è®°å½•ï¼šæ›´æ–°ä½¿ç”¨åŽ†å²è®°å½•

**å¹¶è¡Œæ£€ç´¢è·¯å¾„**

*   è·¯å¾„ Aï¼šå·¥ä½œå†…å­˜æ£€ç´¢ (WorkingMemory)
*   è·¯å¾„ Bï¼šé•¿æœŸå’Œç”¨æˆ·å†…å­˜æ£€ç´¢ (LongTermMemory, UserMemory)
*   è·¯å¾„ Cï¼šäº’è”ç½‘æ£€ç´¢ï¼ˆå¯é€‰ï¼‰
*   è·¯å¾„ Dï¼šMemCubes æ£€ç´¢ï¼ˆå¯é€‰ï¼‰

**æ•°æ®æµå‘**

è¾“å…¥æŸ¥è¯¢ç»è¿‡è§£æžåŽï¼Œè¢«åˆ†å‘åˆ°å¤šä¸ªæ£€ç´¢è·¯å¾„å¹¶è¡Œå¤„ç†ï¼Œæ¯ä¸ªè·¯å¾„éƒ½ä¼šäº§ç”Ÿä¸€æ‰¹å€™é€‰ç»“æžœã€‚è¿™äº›ç»“æžœç»è¿‡é‡æŽ’ã€åˆå¹¶ï¼Œæœ€åŽç»è¿‡åŽ»é‡ã€æŽ’åºå’Œæˆªå–å¾—åˆ°æœ€ç»ˆç»“æžœã€‚æ•´ä¸ªè¿‡ç¨‹ä¸­è¿˜ä¼šæ›´æ–°ä½¿ç”¨åŽ†å²è®°å½•ä»¥ä¾¿åŽç»­ä¼˜åŒ–ã€‚

ç”¨æˆ·æœç´¢æµç¨‹å¦‚ä¸‹ï¼šç”¨æˆ·æŸ¥è¯¢ â†’ TaskGoalParser è§£æž â†’ å¤šè·¯å¾„å¹¶è¡Œæ£€ç´¢ â†’ ç»“æžœé‡æŽ’åº â†’ åŽ»é‡å¤„ç† â†’ æŽ¨ç†ä¼˜åŒ– â†’ è¿”å›žæœ€ç»ˆç»“æžœã€‚

å…¶ä¸­æ¶‰åŠåˆ°å¦‚ä¸‹ç»„ä»¶ï¼š

å› æ­¤ï¼Œæˆ‘ä»¬æŒ‰ç…§å¦‚ä¸‹æµç¨‹è¿›è¡Œåˆ†æžã€‚

### 2.5 TaskGoalParser

\_parse\_task æ–¹æ³•ä¸»è¦æ˜¯ä½¿ç”¨ TaskGoalParser æ¥åˆ†æžqueryã€‚

            parsed_goal = self.task_goal_parser.parse(
                task_description=query,
                context="\n".join(context),
                conversation=info.get("chat_history", []),
                mode=mode,
            )
    

TaskGoalParser æ˜¯ä¸€ä¸ªä»»åŠ¡ç›®æ ‡è§£æžå™¨ï¼Œè´Ÿè´£å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢è§£æžä¸ºç»“æž„åŒ–çš„è¯­ä¹‰å±‚è¡¨ç¤ºï¼Œä»¥ä¾¿åŽç»­çš„æ£€ç´¢ç³»ç»Ÿèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°ç†è§£å’Œå¤„ç†æŸ¥è¯¢ã€‚

#### 2.5.1 ä¸»è¦åŠŸèƒ½

TaskGoalParser ä¸»è¦åŠŸèƒ½ä¸ºï¼š

*   æŸ¥è¯¢è§£æžã€‚
    
    *   å°†ç”¨æˆ·è¾“å…¥çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºç»“æž„åŒ–çš„æŸ¥è¯¢è¡¨ç¤º
    *   æä¾›ä¸¤ç§è§£æžæ¨¡å¼ï¼šå¿«é€Ÿæ¨¡å¼ï¼ˆfastï¼‰å’Œç²¾ç»†æ¨¡å¼ï¼ˆfineï¼‰
*   ç»“æž„åŒ–è¯­ä¹‰è¡¨ç¤º
    
    *   å°†æŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªè¯­ä¹‰å±‚æ¬¡ï¼šä¸»é¢˜ï¼ˆtopicï¼‰ã€å…³é”®è¯ï¼ˆkeysï¼‰ã€æ ‡ç­¾ï¼ˆtagsï¼‰ç­‰  
        æå–æŸ¥è¯¢çš„æ ¸å¿ƒæ„å›¾å’Œç›¸å…³ä¿¡æ¯

#### 2.5.2 å·¥ä½œæ¨¡å¼

##### Fast æ¨¡å¼

    def _parse_fast(self, task_description: str, limit_num: int = 5) -> ParsedTaskGoal:
        # å¿«é€Ÿæ¨¡å¼ï¼šç®€å•çš„åˆ†è¯å¤„ç†
        return ParsedTaskGoal(
            memories=[task_description],
            keys=[task_description],
            tags=[],
            goal_type="default",
            rephrased_query=task_description,
            internet_search=False,
    

##### Fine æ¨¡å¼

    def _parse_fine(
        self, query: str, context: str = "", conversation: list[dict] | None = None
    ) -> ParsedTaskGoal:
        # ç²¾ç»†æ¨¡å¼ï¼šä½¿ç”¨ LLM è¿›è¡Œç»“æž„åŒ–è§£æž
        # æž„å»ºæç¤ºè¯å¹¶è°ƒç”¨ LLM è¿›è¡Œè§£æž
        prompt = Template(TASK_PARSE_PROMPT).substitute(
            task=query.strip(), context=context, conversation=conversation_prompt
        )
        response = self.llm.generate(messages=[{"role": "user", "content": prompt}])
        return self._parse_response(response)
    

#### 2.5.3 è¾“å‡ºç»“æž„

TaskGoalParser è§£æžåŽçš„ç»“æžœå­˜å‚¨åœ¨ ParsedTaskGoal å¯¹è±¡ä¸­ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

*   memoriesï¼šç›¸å…³è®°å¿†é¡¹åˆ—è¡¨
*   keysï¼šå…³é”®è¯åˆ—è¡¨
*   tagsï¼šæ ‡ç­¾åˆ—è¡¨
*   rephrased\_queryï¼šé‡è¿°çš„æŸ¥è¯¢ï¼ˆæ›´æ¸…æ™°çš„è¡¨è¾¾ï¼‰
*   internet\_searchï¼šæ˜¯å¦éœ€è¦è”ç½‘æœç´¢
*   goal\_typeï¼šç›®æ ‡ç±»åž‹

#### 2.5.4 prompt

    TASK_PARSE_PROMPT = """
    You are a task parsing expert. Given a user task instruction, optional former conversation and optional related memory context,extract the following structured information:
    1. Keys: the high-level keywords directly relevant to the userâ€™s task.
    2. Tags: thematic tags to help categorize and retrieve related memories.
    3. Goal Type: retrieval | qa | generation
    4. Rephrased instruction: Give a rephrased task instruction based on the former conversation to make it less confusing to look alone. If you think the task instruction is easy enough to understand, or there is no former conversation, set "rephrased_instruction" to an empty string.
    5. Need for internet search: If the user's task instruction only involves objective facts or can be completed without introducing external knowledge, set "internet_search" to False. Otherwise, set it to True.
    6. Memories: Provide 2â€“5 short semantic expansions or rephrasings of the rephrased/original user task instruction. These are used for improved embedding search coverage. Each should be clear, concise, and meaningful for retrieval.
    
    Former conversation (if any):
    \"\"\"
    $conversation
    \"\"\"
    
    Task description(User Question):
    \"\"\"$task\"\"\"
    
    Context (if any):
    \"\"\"$context\"\"\"
    
    Return strictly in this JSON format, note that the
    keys/tags/rephrased_instruction/memories should use the same language as the
    input query:
    {
      "keys": [...],
      "tags": [...],
      "goal_type": "retrieval | qa | generation",
      "rephrased_instruction": "...", # return an empty string if the original instruction is easy enough to understand
      "internet_search": True/False,
      "memories": ["...", "...", ...]
    }
    """
    

#### 2.5.5 ä¼˜åŠ¿

æ€»çš„æ¥è¯´ï¼ŒTaskGoalParser åœ¨è®°å¿†æ£€ç´¢ç³»ç»Ÿä¸­æ‰®æ¼”ç€â€œæŸ¥è¯¢ç†è§£å™¨â€çš„è§’è‰²ï¼Œé€šè¿‡è§£æžç”¨æˆ·æŸ¥è¯¢ä¸ºç»“æž„åŒ–è¡¨ç¤ºï¼Œä¸ºåŽç»­çš„æ£€ç´¢å’ŒæŽ¨ç†è¿‡ç¨‹æä¾›æ›´ç²¾ç¡®çš„è¾“å…¥ã€‚å…¶ä¼˜åŠ¿ä¸ºï¼š

*   çµæ´»æ€§ï¼šæ”¯æŒä¸¤ç§è§£æžæ¨¡å¼ï¼Œé€‚åº”ä¸åŒæ€§èƒ½å’Œç²¾åº¦éœ€æ±‚
*   ç»“æž„åŒ–ï¼šå°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºç»“æž„åŒ–è¡¨ç¤ºï¼Œä¾¿äºŽåŽç»­å¤„ç†
*   ä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼šåœ¨ç²¾ç»†æ¨¡å¼ä¸‹å¯ä»¥è€ƒè™‘ä¸Šä¸‹æ–‡å’Œå¯¹è¯åŽ†å²
*   é”™è¯¯å¤„ç†ï¼šå½“ç²¾ç»†æ¨¡å¼å¤±è´¥æ—¶ä¼šå›žé€€åˆ°å¿«é€Ÿæ¨¡å¼

### 2.6 GraphMemoryRetriever

GraphMemoryRetriever æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„è®°å¿†æ£€ç´¢å™¨ï¼Œç»“åˆäº†å›¾ç»“æž„æ£€ç´¢å’Œå‘é‡ç›¸ä¼¼æ€§æ£€ç´¢ä¸¤ç§æ–¹å¼ï¼Œç”¨äºŽä»ŽçŸ¥è¯†å›¾è°±ä¸­æ£€ç´¢ç›¸å…³è®°å¿†é¡¹ã€‚

#### 2.6.1 ä¸»è¦åŠŸèƒ½

GraphMemoryRetriever å®žçŽ°æ··åˆæ£€ç´¢ï¼Œè¿™ç§è®¾è®¡ä½¿å¾—ç³»ç»Ÿæ—¢èƒ½åˆ©ç”¨ç»“æž„åŒ–ä¿¡æ¯è¿›è¡Œç²¾ç¡®æ£€ç´¢ï¼Œåˆèƒ½é€šè¿‡å‘é‡ç›¸ä¼¼æ€§æ•èŽ·è¯­ä¹‰ç›¸å…³çš„å†…å®¹ï¼Œä»Žè€Œæé«˜äº†æ£€ç´¢çš„å‡†ç¡®æ€§å’Œå¬å›žçŽ‡ã€‚

*   æ··åˆæ£€ç´¢æœºåˆ¶
    *   ç»“æž„åŒ–å›¾æ£€ç´¢ï¼šåŸºäºŽè§£æžåŽçš„ä»»åŠ¡ç›®æ ‡ï¼ˆkeys/tagsï¼‰è¿›è¡Œç²¾ç¡®åŒ¹é…
    *   å‘é‡ç›¸ä¼¼æ€§æ£€ç´¢ï¼šåŸºäºŽæŸ¥è¯¢åµŒå…¥è¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢
    *   åˆå¹¶ä¸¤ç§æ£€ç´¢ç»“æžœå¹¶åŽ»é‡
*   å¤šèŒƒå›´è®°å¿†æ£€ç´¢
    *   æ”¯æŒä¸åŒç±»åž‹çš„è®°å¿†èŒƒå›´ï¼šWorkingMemoryã€LongTermMemoryã€UserMemory
    *   é’ˆå¯¹ä¸åŒèŒƒå›´é‡‡ç”¨ä¸åŒçš„æ£€ç´¢ç­–ç•¥

#### 2.6.2 æ ¸å¿ƒæ–¹æ³•

*   retrieve æ–¹æ³•ï¼šè¿™æ˜¯ä¸»è¦çš„æ£€ç´¢å…¥å£ï¼Œæ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
    
    *   å¯¹äºŽ WorkingMemoryï¼Œç›´æŽ¥èŽ·å–æ‰€æœ‰æ¡ç›®ï¼›
    *   å¯¹äºŽå…¶ä»–è®°å¿†ç±»åž‹ï¼ŒåŒæ—¶æ‰§è¡Œ \_graph\_recall å’Œ \_vector\_recallï¼›
    *   åˆå¹¶ç»“æžœå¹¶åŽ»é™¤é‡å¤é¡¹ã€‚
*   \_graph\_recall æ–¹æ³•ï¼šæ‰§è¡ŒåŸºäºŽå›¾ç»“æž„çš„æ£€ç´¢ï¼š
    
    *   åŸºäºŽ keys è¿›è¡Œç²¾ç¡®åŒ¹é…æ£€ç´¢ï¼›
    *   åŸºäºŽ tags è¿›è¡ŒåŒ…å«åŒ¹é…æ£€ç´¢ï¼›
    *   å¯¹å€™é€‰ç»“æžœè¿›è¡ŒåŽè¿‡æ»¤ï¼Œç¡®ä¿è‡³å°‘æœ‰ 2 ä¸ªæ ‡ç­¾é‡å ã€‚
*   \_vector\_recall æ–¹æ³•ï¼šæ‰§è¡ŒåŸºäºŽå‘é‡çš„ç›¸ä¼¼æ€§æ£€ç´¢ï¼š
    
    *   ä½¿ç”¨æŸ¥è¯¢åµŒå…¥åœ¨å›¾æ•°æ®åº“ä¸­æœç´¢æœ€ç›¸ä¼¼çš„è®°å¿†é¡¹ï¼›
    *   æ”¯æŒå¸¦è¿‡æ»¤æ¡ä»¶çš„æœç´¢å’Œä¸å¸¦è¿‡æ»¤æ¡ä»¶çš„æœç´¢è·¯å¾„ï¼›
    *   å¹¶å‘æ‰§è¡Œå¤šä¸ªæœç´¢ä»»åŠ¡ä»¥æé«˜æ•ˆçŽ‡ã€‚
*   retrieve\_from\_cube æ–¹æ³•ï¼šä¸“é—¨ç”¨äºŽä»Žç‰¹å®šçš„ cube ä¸­æ£€ç´¢è®°å¿†é¡¹ï¼Œè¿™åœ¨å¤šç§Ÿæˆ·æˆ–åˆ†ç‰‡åœºæ™¯ä¸­å¾ˆæœ‰ç”¨ã€‚
    

#### 2.6.3 å·¥ä½œæµç¨‹æ€»ç»“

*   æŽ¥æ”¶ç”¨æˆ·æŸ¥è¯¢å’Œè§£æžåŽçš„ä»»åŠ¡ç›®æ ‡
*   å¹¶è¡Œæ‰§è¡Œå›¾ç»“æž„æ£€ç´¢å’Œå‘é‡æ£€ç´¢
*   åˆå¹¶ä¸¤ç§æ£€ç´¢ç»“æžœ
*   åŽ»é™¤é‡å¤é¡¹å¹¶è¿”å›žæœ€ç»ˆç»“æžœ

### 2.7 Reranker

ä½¿ç”¨ CosineLocalReranker åšè§£æžã€‚CosineLocalReranker æ˜¯ä¸€ä¸ªæœ¬åœ°å®žçŽ°çš„é‡æŽ’åºå™¨ï¼Œå®ƒä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ç®—æ³•å¯¹æ£€ç´¢åˆ°çš„è®°å¿†é¡¹è¿›è¡Œé‡æ–°æŽ’åºï¼Œä»¥æé«˜æ£€ç´¢ç»“æžœçš„ç›¸å…³æ€§ã€‚

#### 2.7.1 ä¸»è¦åŠŸèƒ½

ä¸»è¦åŠŸèƒ½æ˜¯ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—

*   è®¡ç®—æŸ¥è¯¢å‘é‡ä¸Žå€™é€‰è®°å¿†é¡¹å‘é‡ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦
*   æ”¯æŒå•ä¸ªæŸ¥è¯¢å‘é‡ä¸Žå¤šä¸ªå€™é€‰å‘é‡çš„åŒæ—¶è®¡ç®—

#### 2.7.2 å·¥ä½œæµç¨‹æ€»ç»“

*   æŽ¥æ”¶æ¥è‡ª GraphMemoryRetriever çš„åˆæ­¥æ£€ç´¢ç»“æžœ
*   èŽ·å–æŸ¥è¯¢çš„åµŒå…¥å‘é‡å’Œå€™é€‰è®°å¿†é¡¹çš„åµŒå…¥å‘é‡
*   è®¡ç®—æŸ¥è¯¢å‘é‡ä¸Žæ¯ä¸ªå€™é€‰å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
*   æ ¹æ®è®°å¿†é¡¹çš„å±‚çº§ç±»åž‹åº”ç”¨ç›¸åº”æƒé‡
*   æŒ‰ç…§åŠ æƒç›¸ä¼¼åº¦åˆ†æ•°å¯¹ç»“æžœè¿›è¡ŒæŽ’åº
*   è¿”å›žå‰ K ä¸ªæœ€ç›¸å…³çš„ç»“æžœç»™ä¸‹ä¸€ä¸ªå¤„ç†é˜¶æ®µ

è¿™ç§è®¾è®¡ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿåœ¨æœ¬åœ°å¿«é€Ÿå®Œæˆé‡æŽ’åºæ“ä½œï¼Œè€Œæ— éœ€ä¾èµ–å¤–éƒ¨æœåŠ¡ï¼ŒåŒæ—¶é€šè¿‡å±‚çº§æƒé‡æœºåˆ¶å¯ä»¥ä¼˜å…ˆè€ƒè™‘æŸäº›ç±»åž‹çš„è®°å¿†é¡¹ï¼Œä»Žè€Œæé«˜æ£€ç´¢ç»“æžœçš„è´¨é‡ã€‚

### 2.8 MemoryReasoner

MemoryReasoner æ˜¯ä¸€ä¸ªä¸“é—¨è´Ÿè´£å¯¹æ£€ç´¢åˆ°çš„è®°å¿†é¡¹è¿›è¡ŒæŽ¨ç†å’ŒçŸ¥è¯†ç»¼åˆçš„ç»„ä»¶ã€‚å®ƒçš„ä¸»è¦èŒè´£æ˜¯å¯¹ä»Žä¸åŒæ¥æºæ£€ç´¢åˆ°çš„è®°å¿†è¿›è¡Œåˆ†æžã€ç­›é€‰å’Œä¼˜åŒ–ï¼Œä»Žè€Œæä¾›æ›´ç²¾ç¡®å’Œç›¸å…³çš„è®°å¿†ç»“æžœã€‚

#### 2.8.1 ä¸»è¦åŠŸèƒ½

*   è®°å¿†æŽ¨ç†ä¸Žç»¼åˆ
    *   æŽ¥æ”¶åŽŸå§‹æŸ¥è¯¢å’Œå·²æ£€ç´¢çš„ç›¸å…³è®°å¿†é¡¹
    *   åˆ©ç”¨å¤§åž‹è¯­è¨€æ¨¡åž‹åˆ†æžå¤šä¸ªæ£€ç´¢åˆ°çš„è®°å¿†é¡¹
    *   æ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢ç›®æ ‡ç»¼åˆç›¸å…³ä¿¡æ¯
    *   ç”Ÿæˆæ›´åŠ ç²¾ç¡®å’Œç›¸å…³çš„è®°å¿†å“åº”

*   æ™ºèƒ½ç­›é€‰
    *   é€šè¿‡ LLM åˆ¤æ–­å“ªäº›è®°å¿†é¡¹ä¸Žå½“å‰æŸ¥è¯¢æœ€ç›¸å…³
    *   åªè¿”å›žç»è¿‡ç­›é€‰çš„ç›¸å…³è®°å¿†é¡¹

#### 2.8.2 æ ¸å¿ƒæ–¹æ³•

reason æ˜¯ä¸»è¦çš„æŽ¨ç†æ–¹æ³•ï¼Œæ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

*   æž„å»ºæç¤ºè¯ï¼š
    
    *   ä½¿ç”¨æ¨¡æ¿ REASON\_PROMPT æž„å»ºæŽ¨ç†æç¤ºè¯
    *   å°†æ£€ç´¢åˆ°çš„è®°å¿†é¡¹æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨
*   è°ƒç”¨ LLMï¼š
    
    *   å°†æž„å»ºå¥½çš„æç¤ºè¯å‘é€ç»™è¯­è¨€æ¨¡åž‹ç”Ÿæˆå“åº”
*   è§£æžå“åº”ï¼š
    
    *   æå–æ¨¡åž‹é€‰æ‹©çš„è®°å¿†é¡¹ ID
    *   è¿”å›žå¯¹åº”çš„è®°å¿†é¡¹åˆ—è¡¨

parse\_selected\_ids æ–¹æ³•è´Ÿè´£ä»Žæ¨¡åž‹å“åº”ä¸­æå–é€‰å®šçš„è®°å¿†é¡¹ IDï¼š

*   JSON è§£æžï¼šé¦–å…ˆå°è¯•å°†å“åº”è§£æžä¸º JSON æ ¼å¼
*   æ­£åˆ™è¡¨è¾¾å¼å›žé€€ï¼šå¦‚æžœ JSON è§£æžå¤±è´¥ï¼Œåˆ™ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… UUID æ ¼å¼çš„ ID

#### 2.8.3 æç¤ºè¯

    REASON_PROMPT = """
    You are a reasoning agent working with a memory system. You will synthesize knowledge from multiple memory cards to construct a meaningful response to the task below.
    
    Task: ${task}
    
    Memory cards (with metadata):
    ${detailed_memory_list}
    
    Please perform:
    1. Clustering by theme (topic/concept/fact)
    2. Identify useful chains or connections
    3. Return a curated list of memory card IDs with reasons.
    
    Output in JSON:
    {
      "selected_ids": [...],
      "explanation": "..."
    }
    """
    

#### 2.8.4 å·¥ä½œæµç¨‹æ€»ç»“

*   æŽ¥æ”¶æ¥è‡ªä¸Šä¸€é˜¶æ®µçš„æ£€ç´¢å’Œé‡æŽ’åºç»“æžœ
    
*   æž„å»ºæŽ¨ç†æç¤ºè¯ï¼š
    
    *   å°†ç”¨æˆ·çš„æŸ¥è¯¢ã€è§£æžåŽçš„ä»»åŠ¡ç›®æ ‡ä»¥åŠæ£€ç´¢åˆ°çš„è®°å¿†é¡¹ç»„åˆæˆä¸€ä¸ªç»“æž„åŒ–çš„æç¤ºè¯
    *   ä½¿ç”¨é¢„å®šä¹‰çš„ REASON\_PROMPT æ¨¡æ¿
*   è°ƒç”¨ LLM è¿›è¡ŒæŽ¨ç†ï¼š
    
    *   å°†æž„å»ºå¥½çš„æç¤ºè¯å‘é€ç»™å¤§åž‹è¯­è¨€æ¨¡åž‹
    *   ä½¿ç”¨ LLM è¿›ä¸€æ­¥åˆ†æžå’ŒæŽ¨ç†è¿™äº›è®°å¿†é¡¹çš„ç›¸å…³æ€§
    *   èŽ·å–æ¨¡åž‹çš„å“åº”ï¼Œè¯¥å“åº”åŒ…å«å¯¹è®°å¿†é¡¹çš„ç›¸å…³æ€§åˆ¤æ–­
*   è§£æžå’Œç­›é€‰ç»“æžœï¼š
    
    *   è§£æž LLM çš„å“åº”ï¼Œæå–è¢«é€‰ä¸­çš„è®°å¿†é¡¹ ID
    *   æ”¯æŒä¸¤ç§è§£æžæ–¹å¼ï¼š
        *   JSON æ ¼å¼ï¼šç›´æŽ¥æå– selected\_ids å­—æ®µ
        *   æ–‡æœ¬æ ¼å¼ï¼šé€šè¿‡æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… UUID æ¨¡å¼
*   è¿”å›žç²¾é€‰è®°å¿†ï¼š
    
    *   æ ¹æ®è§£æžå‡ºçš„ ID åˆ—è¡¨ç­›é€‰åŽŸå§‹è®°å¿†é¡¹
    *   è¿”å›žæœ€ç›¸å…³çš„ç»“æžœå­é›†

è¿™ç§è®¾è®¡ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿåˆ©ç”¨ LLM çš„ç†è§£å’ŒæŽ¨ç†èƒ½åŠ›ï¼Œä»Žå¤§é‡æ£€ç´¢åˆ°çš„è®°å¿†ä¸­é€‰å‡ºæœ€ç¬¦åˆç”¨æˆ·éœ€æ±‚çš„éƒ¨åˆ†ï¼Œæé«˜äº†ç³»ç»Ÿçš„å‡†ç¡®æ€§å’Œæ™ºèƒ½åŒ–æ°´å¹³ã€‚

#### 2.8.5 ä¼˜åŠ¿

*   æ™ºèƒ½åŒ–å¤„ç†ï¼šåˆ©ç”¨ LLM çš„ç†è§£èƒ½åŠ›å¯¹è®°å¿†é¡¹è¿›è¡Œè¯­ä¹‰å±‚é¢çš„åˆ†æž
*   çµæ´»æ€§ï¼šæ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼çš„è§£æž
*   ç²¾å‡†æ€§ï¼šèƒ½å¤Ÿè¿›ä¸€æ­¥æå‡æ£€ç´¢ç»“æžœçš„ç›¸å…³æ€§å’Œè´¨é‡

æ€»çš„æ¥è¯´ï¼ŒMemoryReasoner åœ¨æ•´ä¸ªè®°å¿†æ£€ç´¢ç³»ç»Ÿä¸­æ‰®æ¼”ç€â€œæ™ºèƒ½ç­›é€‰å™¨â€çš„è§’è‰²ï¼Œé€šè¿‡å¼•å…¥ LLM çš„æŽ¨ç†èƒ½åŠ›ï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿæ›´å‡†ç¡®åœ°ç†è§£ç”¨æˆ·éœ€æ±‚å¹¶è¿”å›žæœ€ç›¸å…³çš„è®°å¿†é¡¹ã€‚

### 2.9 Reranker å’Œ Reasoner

åœ¨ç³»ç»Ÿä¸­åŒæ—¶ä½¿ç”¨ Reranker å’Œ Reasoner æ˜¯ä¸ºäº†å®žçŽ°ä¸åŒå±‚æ¬¡çš„æ£€ç´¢ç»“æžœå¤„ç†å’Œä¼˜åŒ–ï¼Œå®ƒä»¬å„è‡ªæ‰¿æ‹…ä¸åŒçš„èŒè´£ã€‚

#### 2.9.1 Reranker çš„ä½œç”¨

Rerankerï¼ˆé‡æŽ’åºå™¨ï¼‰ä¸»è¦è´Ÿè´£å¯¹åˆæ­¥æ£€ç´¢ç»“æžœè¿›è¡Œç›¸å…³æ€§é‡æ–°æŽ’åºï¼š

*   åŠŸèƒ½ï¼šåŸºäºŽæŸ¥è¯¢å’Œå€™é€‰ç»“æžœçš„ç›¸ä¼¼åº¦è®¡ç®—ï¼Œå¯¹æ£€ç´¢ç»“æžœè¿›è¡Œé‡æ–°æŽ’åº
*   æ–¹æ³•ï¼šé€šå¸¸ä½¿ç”¨æ•°å­¦è®¡ç®—ï¼ˆå¦‚ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰æ¥è¯„ä¼°ç›¸å…³æ€§
*   è¾“å‡ºï¼šè¿”å›žæŒ‰ç›¸å…³æ€§å¾—åˆ†æŽ’åºçš„è®°å¿†é¡¹åˆ—è¡¨

    def rerank(self, query, graph_results, top_k, **kwargs):
        # è®¡ç®—ç›¸ä¼¼åº¦
        sims = _cosine_one_to_many(query_embedding, cand_vecs)
        # åº”ç”¨æƒé‡è°ƒæ•´
        weighted = [sim * get_weight(it) for sim, it in zip(sims, items_with_emb)]
        # æŽ’åºå¹¶è¿”å›žå‰ K ä¸ªç»“æžœ
        scored_pairs.sort(key=lambda x: x[1], reverse=True)
        return scored_pairs[:top_k]
    

#### 2.9.2 Reasoner çš„ä½œç”¨

Reasonerï¼ˆæŽ¨ç†å™¨ï¼‰ä¸»è¦è´Ÿè´£å¯¹æŽ’åºåŽçš„ç»“æžœè¿›è¡Œè¯­ä¹‰ç†è§£å’ŒæŽ¨ç†ï¼š

*   åŠŸèƒ½ï¼šåŸºäºŽè¯­è¨€æ¨¡åž‹å¯¹æ£€ç´¢åˆ°çš„è®°å¿†é¡¹è¿›è¡Œè¯­ä¹‰ç†è§£å’ŒæŽ¨ç†
*   æ–¹æ³•ï¼šä½¿ç”¨å¤§è¯­è¨€æ¨¡åž‹åˆ†æžæŸ¥è¯¢å’Œè®°å¿†é¡¹ä¹‹é—´çš„æ·±å±‚è¯­ä¹‰å…³ç³»
*   è¾“å‡ºï¼šè¿”å›žç»è¿‡è¯­ä¹‰æŽ¨ç†ç­›é€‰åŽçš„æœ€ç»ˆè®°å¿†é¡¹

    def reason(self, query, ranked_memories, parsed_goal):
        # æž„å»ºæŽ¨ç†æç¤º
        prompt = prompt_template.substitute(task=query, detailed_memory_list=memory_detailed_str)
        # ä½¿ç”¨ LLM è¿›è¡ŒæŽ¨ç†
        response = self.llm.generate([{"role": "user", "content": prompt}])
        # è§£æžå¹¶è¿”å›žæŽ¨ç†ç»“æžœ
        selected_ids = self._parse_selected_ids(content)
        return [m for m in ranked_memories if m.id in id_set]
    

#### 2.9.3 ä¸ºä»€ä¹ˆéœ€è¦ä¸¤è€…ç»“åˆï¼Ÿ

1.  ä¸åŒçš„å¤„ç†å±‚æ¬¡

Rerankerï¼šåœ¨æ•°å­¦å‘é‡ç©ºé—´ä¸­è¿›è¡Œå¿«é€Ÿç›¸å…³æ€§è®¡ç®—

Reasonerï¼šåœ¨è¯­ä¹‰å±‚é¢è¿›è¡Œæ·±åº¦ç†è§£å’ŒæŽ¨ç†

2.  äº’è¡¥çš„ä¼˜åŠ¿
    
    æ•ˆçŽ‡ vs ç²¾åº¦ï¼šReranker å¿«é€Ÿç­›é€‰ï¼ŒReasoner ç²¾ç¡®æŽ¨ç†
    
    å®šé‡ vs å®šæ€§ï¼šReranker åŸºäºŽæ•°å€¼è®¡ç®—ï¼ŒReasoner åŸºäºŽè¯­ä¹‰ç†è§£
    

ç³»ç»Ÿè®¾è®¡ä¼˜åŠ¿

*   æ€§èƒ½ä¼˜åŒ–ï¼šé¿å…ç›´æŽ¥å¯¹å¤§é‡å€™é€‰ç»“æžœä½¿ç”¨æ˜‚è´µçš„ LLM æŽ¨ç†
*   ç²¾åº¦æå‡ï¼šå…ˆç”¨æ•°å­¦æ–¹æ³•ç²—ç­›ï¼Œå†ç”¨è¯­ä¹‰æ–¹æ³•ç²¾ç­›
*   æ¨¡å—åŒ–è®¾è®¡ï¼šä¸¤ä¸ªç»„ä»¶èŒè´£åˆ†æ˜Žï¼Œä¾¿äºŽç‹¬ç«‹ä¼˜åŒ–å’Œæ›¿æ¢
*   é€‚åº”ä¸åŒåœºæ™¯ï¼š
    *   å¿«é€Ÿæ¨¡å¼ï¼šå¯èƒ½åªä½¿ç”¨ Reranker
    *   ç²¾ç»†æ¨¡å¼ï¼šä¸¤è€…éƒ½ä½¿ç”¨ä»¥èŽ·å¾—æœ€ä½³ç»“æžœ

è¿™ç§è®¾è®¡ä½¿å¾—ç³»ç»Ÿæ—¢èƒ½åœ¨ä¿è¯æ£€ç´¢è´¨é‡çš„åŒæ—¶æŽ§åˆ¶è®¡ç®—æˆæœ¬ï¼Œåˆèƒ½æ ¹æ®ä¸åŒçš„åº”ç”¨åœºæ™¯çµæ´»è°ƒæ•´å¤„ç†æµç¨‹ã€‚

#### 2.9.4 å…·ä½“ç¤ºä¾‹

å‡è®¾ç”¨æˆ·æŸ¥è¯¢ï¼šâ€œæœºå™¨å­¦ä¹ ä¸­çš„æ¢¯åº¦ä¸‹é™ç®—æ³•å¦‚ä½•å·¥ä½œï¼Ÿâ€

*   åˆå§‹æ£€ç´¢ï¼šç³»ç»Ÿå¯èƒ½æ£€ç´¢åˆ° 100 ä¸ªç›¸å…³è®°å¿†é¡¹
*   Reranker å¤„ç†ï¼š
    *   è®¡ç®—æŸ¥è¯¢ä¸Žæ¯ä¸ªè®°å¿†é¡¹çš„ä½™å¼¦ç›¸ä¼¼åº¦
    *   æ ¹æ®å±‚çº§æƒé‡ï¼ˆtopic/concept/factï¼‰è°ƒæ•´å¾—åˆ†
    *   è¿”å›žå‰ 20 ä¸ªæœ€ç›¸å…³çš„è®°å¿†é¡¹
*   Reasoner å¤„ç†ï¼š
    *   å°†å‰ 20 ä¸ªè®°å¿†é¡¹å’ŒæŸ¥è¯¢ä¸€èµ·äº¤ç»™ LLM
    *   LLM åˆ†æžå“ªäº›è®°å¿†é¡¹çœŸæ­£å›žç­”äº†ç”¨æˆ·çš„é—®é¢˜
    *   å¯èƒ½å‘çŽ°åªæœ‰å…¶ä¸­ 5 ä¸ªè®°å¿†é¡¹çœŸæ­£ç›¸å…³ä¸”äº’è¡¥
    *   è¿”å›žè¿™ 5 ä¸ªæœ€åˆé€‚çš„è®°å¿†é¡¹

0x03 å­å›¾æ£€ç´¢
---------

### 3.1 åŠŸèƒ½

get\_relevant\_subgraphæ–¹æ³•çš„åŠŸèƒ½æ˜¯ï¼š

*   æŸ¥æ‰¾ä¸ŽæŸ¥è¯¢ç›¸å…³çš„å±€éƒ¨å­å›¾ï¼ˆFind Relevant Local Subgraphï¼‰
    
    *   æŽ¥æ”¶ç”¨æˆ·æŸ¥è¯¢å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥
    *   é€šè¿‡åµŒå…¥æ¨¡åž‹å°†æŸ¥è¯¢è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º
    *   åœ¨å›¾æ•°æ®åº“ä¸­æœç´¢ä¸ŽæŸ¥è¯¢å‘é‡æœ€ç›¸ä¼¼çš„å‰kä¸ªèŠ‚ç‚¹
*   æž„å»ºé‚»åŸŸå­å›¾ï¼ˆBuild Neighborhood Subgraphsï¼‰ï¼Œå¯¹æ¯ä¸ªç›¸ä¼¼èŠ‚ç‚¹ï¼š
    
    *   ç¡®ä¿å…¶çŠ¶æ€ç¬¦åˆæŒ‡å®šæ¡ä»¶ï¼ˆé»˜è®¤ä¸º"activated"ï¼‰
    *   èŽ·å–ä»¥è¯¥èŠ‚ç‚¹ä¸ºä¸­å¿ƒã€æŒ‡å®šæ·±åº¦ï¼ˆé»˜è®¤2è·³ï¼‰çš„å±€éƒ¨å­å›¾
    *   æ”¶é›†ä¸­å¿ƒèŠ‚ç‚¹ã€é‚»å±…èŠ‚ç‚¹å’Œè¿žæŽ¥è¾¹

*   åˆå¹¶å¤šä¸ªå­å›¾ä¸ºç»Ÿä¸€ç»“æž„ï¼ˆMerge Subgraphsï¼‰
    *   å°†æ‰€æœ‰æ£€ç´¢åˆ°çš„å±€éƒ¨å­å›¾åˆå¹¶æˆä¸€ä¸ªè¿žé€šçš„å­å›¾
    *   åŽ»é™¤é‡å¤èŠ‚ç‚¹å’Œè¾¹
    *   è¿”å›žåŒ…å«ä»¥ä¸‹ä¿¡æ¯çš„å­—å…¸ç»“æž„ï¼š
        *   core\_id: æœ€åŒ¹é…çš„æ ¸å¿ƒèŠ‚ç‚¹ID
        *   nodes: åˆå¹¶åŽçš„å”¯ä¸€èŠ‚ç‚¹åˆ—è¡¨
        *   edges: åˆå¹¶åŽçš„å”¯ä¸€è¾¹åˆ—è¡¨

è¿™ç§æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äºŽéœ€è¦ç†è§£å¤æ‚å…³ç³»å’Œä¸Šä¸‹æ–‡çš„åœºæ™¯ï¼Œæ¯”å¦‚ï¼š

*   æŸ¥æ‰¾ä¸Žç‰¹å®šä¸»é¢˜ç›¸å…³çš„çŸ¥è¯†ç½‘ç»œç‰‡æ®µ
*   è¿›è¡Œå¤šè·³æŽ¨ç†ä»¥å‘çŽ°é—´æŽ¥å…³è”
*   æä¾›å¯è§£é‡Šçš„è®°å¿†æ£€ç´¢ç»“æžœï¼Œå±•ç¤ºèŠ‚ç‚¹é—´çš„å…³ç³»è·¯å¾„

ä¸»è¦ä¼˜åŠ¿åœ¨äºŽå®ƒä¸ä»…è¿”å›žç›¸å…³èŠ‚ç‚¹ï¼Œè¿˜ä¿ç•™äº†å®ƒä»¬ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ç»“æž„ï¼Œè¿™å¯¹äºŽé«˜çº§æŽ¨ç†ä»»åŠ¡éžå¸¸æœ‰ç”¨ã€‚

### 3.2 ä»£ç 

å…·ä½“ä»£ç å¦‚ä¸‹ï¼š

        def get_relevant_subgraph(
            self, query: str, top_k: int = 5, depth: int = 2, center_status: str = "activated"
        ) -> dict[str, Any]:
            """
            Find and merge the local neighborhood sub-graphs of the top-k
            nodes most relevant to the query.
             Process:
                 1. Embed the user query into a vector representation.
                 2. Use vector similarity search to find the top-k similar nodes.
                 3. For each similar node:
                     - Ensure its status matches `center_status` (e.g., 'active').
                     - Retrieve its local subgraph up to `depth` hops.
                     - Collect the center node, its neighbors, and connecting edges.
                 4. Merge all retrieved subgraphs into a single unified subgraph.
                 5. Return the merged subgraph structure.
    
             Args:
                 query (str): The user input or concept to find relevant memories for.
                 top_k (int, optional): How many top similar nodes to retrieve. Default is 5.
                 depth (int, optional): The neighborhood depth (number of hops). Default is 2.
                 center_status (str, optional): Status condition the center node must satisfy (e.g., 'active').
    
             Returns:
                 dict[str, Any]: A subgraph dict with:
                     - 'core_id': ID of the top matching core node, or None if none found.
                     - 'nodes': List of unique nodes (core + neighbors) in the merged subgraph.
                     - 'edges': List of unique edges (as dicts with 'from', 'to', 'type') in the merged subgraph.
            """
            # Step 1: Embed query
            query_embedding = self.embedder.embed([query])[0]
    
            # Step 2: Get top-1 similar node
            similar_nodes = self.graph_store.search_by_embedding(query_embedding, top_k=top_k)
            if not similar_nodes:
                logger.info("No similar nodes found for query embedding.")
                return {"core_id": None, "nodes": [], "edges": []}
    
            # Step 3: Fetch neighborhood
            all_nodes = {}
            all_edges = set()
            cores = []
    
            for node in similar_nodes:
                core_id = node["id"]
                score = node["score"]
    
                subgraph = self.graph_store.get_subgraph(
                    center_id=core_id, depth=depth, center_status=center_status
                )
    
                if not subgraph["core_node"]:
                    logger.info(f"Skipping node {core_id} (inactive or not found).")
                    continue
    
                core_node = subgraph["core_node"]
                neighbors = subgraph["neighbors"]
                edges = subgraph["edges"]
    
                # Collect nodes
                all_nodes[core_node["id"]] = core_node
                for n in neighbors:
                    all_nodes[n["id"]] = n
    
                # Collect edges
                for e in edges:
                    all_edges.add((e["source"], e["target"], e["type"]))
    
                cores.append(
                    {"id": core_id, "score": score, "core_node": core_node, "neighbors": neighbors}
                )
    
            top_core = cores[0]
            return {
                "core_id": top_core["id"],
                "nodes": list(all_nodes.values()),
                "edges": [{"source": f, "target": t, "type": ty} for (f, t, ty) in all_edges],
            }
    

0x04 å›¾æ•°æ®åº“
---------

å› ä¸ºå›¾æ•°æ®åº“æ¯”è¾ƒå¤æ‚ï¼Œæˆ‘ä»¬é€šè¿‡ç¤ºä¾‹æ¥è¿›è¡Œå­¦ä¹ ï¼Œä»¥ç®¡çª¥è±¹ã€‚

### 4.1 ç¤ºä¾‹

run\_user\_session å‡½æ•°ä¸­ä¾¿æœ‰æœç´¢å†…å®¹ã€‚

    def run_user_session(
        user_name: str,
        db_name: str,
        topic_text: str,
        concept_texts: list[str],
        fact_texts: list[str],
    ):
        print(f"\n=== {user_name} starts building their memory graph ===")
    
        # Manually initialize correct GraphDB class
        config = GraphDBConfigFactory(
            backend="nebular",
            config={
                "uri": json.loads(os.getenv("NEBULAR_HOSTS", "localhost")),
                "user": os.getenv("NEBULAR_USER", "root"),
                "password": os.getenv("NEBULAR_PASSWORD", "xxxxxx"),
                "space": db_name,
                "user_name": user_name,
                "use_multi_db": False,
                "auto_create": True,
                "embedding_dimension": embedder_dimension,
            },
        )
        graph = GraphStoreFactory.from_config(config)
    
        # Start with a clean slate for this user
        graph.clear()
    
        now = datetime.now(timezone.utc).isoformat()
    
        # === Step 1: Create a root topic node (e.g., user's research focus) ===
        topic = TextualMemoryItem(
            memory=topic_text,
            metadata=TreeNodeTextualMemoryMetadata(
                memory_type="LongTermMemory",
                key="Research Topic",
                hierarchy_level="topic",
                type="fact",
                memory_time="2024-01-01",
                status="activated",
                visibility="public",
                tags=["research", "rl"],
                updated_at=now,
                embedding=embed_memory_item(topic_text),
            ),
        )
        graph.add_node(topic.id, topic.memory, topic.metadata.model_dump(exclude_none=True))
    
        # === Step 2: Create two concept nodes linked to the topic ===
        concept_items = []
        for i, text in enumerate(concept_texts):
            concept = TextualMemoryItem(
                memory=text,
                metadata=TreeNodeTextualMemoryMetadata(
                    memory_type="LongTermMemory",
                    key=f"Concept {i + 1}",
                    hierarchy_level="concept",
                    type="fact",
                    memory_time="2024-01-01",
                    status="activated",
                    visibility="public",
                    updated_at=now,
                    embedding=embed_memory_item(text),
                    tags=["concept"],
                    confidence=90 + i,
                ),
            )
            graph.add_node(concept.id, concept.memory, concept.metadata.model_dump(exclude_none=True))
            graph.add_edge(topic.id, concept.id, type="PARENT")
            concept_items.append(concept)
    
        # === Step 3: Create supporting facts under each concept ===
        for i, text in enumerate(fact_texts):
            fact = TextualMemoryItem(
                memory=text,
                metadata=TreeNodeTextualMemoryMetadata(
                    memory_type="WorkingMemory",
                    key=f"Fact {i + 1}",
                    hierarchy_level="fact",
                    type="fact",
                    memory_time="2024-01-01",
                    status="activated",
                    visibility="public",
                    updated_at=now,
                    embedding=embed_memory_item(text),
                    confidence=85.0,
                    tags=["fact"],
                ),
            )
            graph.add_node(fact.id, fact.memory, fact.metadata.model_dump(exclude_none=True))
            graph.add_edge(concept_items[i % len(concept_items)].id, fact.id, type="PARENT")
    
        # === Step 4: Retrieve memory using semantic search ===
        vector = embed_memory_item("How is memory retrieved?")
        search_result = graph.search_by_embedding(vector, top_k=2)
        for r in search_result:
            node = graph.get_node(r["id"])
            print("ðŸ” Search result:", node["memory"])
    
        # === Step 5: Tag-based neighborhood discovery ===
        neighbors = graph.get_neighbors_by_tag(["concept"], exclude_ids=[], top_k=2)
        print("ðŸ“Ž Tag-related nodes:", [neighbor["memory"] for neighbor in neighbors])
    
        # === Step 6: Retrieve children (facts) of first concept ===
        children = graph.get_children_with_embeddings(concept_items[0].id)
        print("ðŸ“ Children of concept:", [child["memory"] for child in children])
    
        # === Step 7: Export a local subgraph and grouped statistics ===
        subgraph = graph.get_subgraph(topic.id, depth=2)
        print("ðŸ“Œ Subgraph node count:", len(subgraph["neighbors"]))
    
        stats = graph.get_grouped_counts(["memory_type", "status"])
        print("ðŸ“Š Grouped counts:", stats)
    
        # === Step 8: Demonstrate updates and cleanup ===
        graph.update_node(
            concept_items[0].id, {"confidence": 99.0, "created_at": "2025-07-24T20:11:56.375687"}
        )
        graph.remove_oldest_memory("WorkingMemory", keep_latest=1)
        graph.delete_edge(topic.id, concept_items[0].id, type="PARENT")
        graph.delete_node(concept_items[1].id)
    
        # === Step 9: Export and re-import the entire graph structure ===
        exported = graph.export_graph()
        graph.import_graph(exported)
        print("ðŸ“¦ Graph exported and re-imported, total nodes:", len(exported["nodes"]))
    
        # ====================================
        # ðŸ” Step 10: extra function
        # ====================================
        print(f"\n=== ðŸ” Extra Tests for user: {user_name} ===")
    
        print(" - Memory count:", graph.get_memory_count("LongTermMemory"))
        print(" - Node count:", graph.count_nodes("LongTermMemory"))
        print(" - All LongTermMemory items:", graph.get_all_memory_items("LongTermMemory"))
    
        if len(exported["edges"]) > 0:
            n1, n2 = exported["edges"][0]["source"], exported["edges"][0]["target"]
            print(" - Edge exists?", graph.edge_exists(n1, n2, exported["edges"][0]["type"]))
            print(" - Edges for node:", graph.get_edges(n1))
    
        filters = [{"field": "memory_type", "op": "=", "value": "LongTermMemory"}]
        print(" - Metadata query result:", graph.get_by_metadata(filters))
        print(
            " - Optimization candidates:", graph.get_structure_optimization_candidates("LongTermMemory")
        )
        try:
            graph.drop_database()
        except ValueError as e:
            print(" - drop_database raised ValueError as expected:", e)
    

### 4.2 get\_neighbors\_by\_tag

get\_neighbors\_by\_tag åŠŸèƒ½è¯´æ˜Žå¦‚ä¸‹ï¼š

#### 4.2.1 åŠŸèƒ½æ¦‚è¿°

get\_neighbors\_by\_tag æ˜¯åŸºäºŽæ ‡ç­¾çš„é‚»å±…èŠ‚ç‚¹æ£€ç´¢æ–¹æ³•ï¼Œç”¨äºŽåœ¨å›¾æ•°æ®åº“ä¸­æŸ¥æ‰¾ä¸Žç»™å®šèŠ‚ç‚¹å…·æœ‰ç›¸ä¼¼æ ‡ç­¾çš„ç›¸é‚»èŠ‚ç‚¹ã€‚é€šè¿‡è®¡ç®—æ ‡ç­¾é‡å åº¦è¯†åˆ«è¯­ä¹‰ç›¸å…³èŠ‚ç‚¹ï¼Œæ”¯æŒåŸºäºŽæ ‡ç­¾çš„å›¾éåŽ†ä¸ŽæŽ¨èã€‚

#### 4.2.2 åº”ç”¨åœºæ™¯

è®°å¿†é‡ç»„é˜¶æ®µå‘çŽ°å…·æœ‰å…±åŒä¸»é¢˜æˆ–æ¦‚å¿µçš„ç›¸å…³è®°å¿†èŠ‚ç‚¹ã€‚

æ”¯æŒæŽ¨ç†ä¸Žå…³è”åˆ†æžï¼Œæž„å»ºè®°å¿†ä¹‹é—´çš„è¯­ä¹‰è¿žæŽ¥ã€‚

ç”¨äºŽèšç±»åˆ†æžï¼Œè¯†åˆ«æ ‡ç­¾ç»„åˆç›¸ä¼¼çš„èŠ‚ç‚¹ç¾¤ç»„ã€‚

#### 4.2.3 å‚æ•°è¯´æ˜Ž

*   tags (list\[str\])ï¼šç›®æ ‡æ ‡ç­¾åˆ—è¡¨ï¼Œç”¨äºŽåŒ¹é…ç›¸ä¼¼èŠ‚ç‚¹ã€‚
*   \_exclude\_ids (list\[str\])ï¼šéœ€æŽ’é™¤çš„èŠ‚ç‚¹ ID åˆ—è¡¨ï¼Œé¿å…è¿”å›žè‡ªèº«æˆ–å·²çŸ¥èŠ‚ç‚¹ã€‚
*   top\_k (int)ï¼šè¿”å›žç»“æžœæ•°é‡ä¸Šé™ï¼Œé»˜è®¤é€šå¸¸ä¸º 5ã€‚
*   min\_overlap (int)ï¼šæœ€å°æ ‡ç­¾é‡å æ•°ï¼Œä»…è¿”å›žæ»¡è¶³è¯¥æ¡ä»¶çš„èŠ‚ç‚¹ã€‚

#### 4.2.4 ç­›é€‰æœºåˆ¶

*   æ ‡ç­¾äº¤é›†è®¡ç®—ï¼šæ¯”è¾ƒç›®æ ‡æ ‡ç­¾ä¸Žå€™é€‰èŠ‚ç‚¹æ ‡ç­¾çš„äº¤é›†å¤§å°ç¡®å®šç›¸å…³æ€§ã€‚
*   æœ€å°é‡å é˜ˆå€¼ï¼šä»…è¿”å›žæ ‡ç­¾é‡å æ•°â‰¥min\_overlap çš„èŠ‚ç‚¹ã€‚
*   æŽ’é™¤æœºåˆ¶ï¼šè¿‡æ»¤ \_exclude\_ids æŒ‡å®šçš„èŠ‚ç‚¹ï¼Œé˜²æ­¢å¾ªçŽ¯å¼•ç”¨ã€‚

#### 4.2.5 æ£€ç´¢æµç¨‹

*   æ ¹æ®è¾“å…¥æ ‡ç­¾åœ¨å›¾æ•°æ®åº“ä¸­æŸ¥æ‰¾åŒ…å«è¿™äº›æ ‡ç­¾çš„æ‰€æœ‰èŠ‚ç‚¹ã€‚
*   è®¡ç®—æ¯ä¸ªå€™é€‰èŠ‚ç‚¹ä¸Žç›®æ ‡æ ‡ç­¾é›†åˆçš„äº¤é›†å¤§å°ã€‚
*   è¿‡æ»¤ä¸æ»¡è¶³æœ€å°é‡å è¦æ±‚çš„èŠ‚ç‚¹ã€‚
*   æŒ‰æ ‡ç­¾é‡å ç¨‹åº¦æŽ’åºå¹¶æˆªå–å‰ k ä¸ªèŠ‚ç‚¹ã€‚

#### 4.2.6 æ€§èƒ½ä¼˜åŒ–

*   åˆ©ç”¨å›¾æ•°æ®åº“ç´¢å¼•åŠ é€Ÿæ ‡ç­¾æŸ¥è¯¢ã€‚
*   é€šè¿‡æ‰¹é‡æ“ä½œå‡å°‘æ•°æ®åº“è®¿é—®æ¬¡æ•°ã€‚
*   æ”¯æŒå¹¶å‘æ‰§è¡Œï¼Œæé«˜å¤§è§„æ¨¡å›¾æ£€ç´¢æ•ˆçŽ‡ã€‚

MemOS-main\\src\\memos\\graph\_dbs\\nebular.py ä»£ç å¦‚ä¸‹ï¼š

        @timed
        def get_neighbors_by_tag(
            self,
            tags: list[str],
            exclude_ids: list[str],
            top_k: int = 5,
            min_overlap: int = 1,
            include_embedding: bool = False,
        ) -> list[dict[str, Any]]:
            """
            Find top-K neighbor nodes with maximum tag overlap.
    
            Args:
                tags: The list of tags to match.
                exclude_ids: Node IDs to exclude (e.g., local cluster).
                top_k: Max number of neighbors to return.
                min_overlap: Minimum number of overlapping tags required.
                include_embedding: with/without embedding
    
            Returns:
                List of dicts with node details and overlap count.
            """
            if not tags:
                return []
    
            where_clauses = [
                'n.status = "activated"',
                'NOT (n.node_type = "reasoning")',
                'NOT (n.memory_type = "WorkingMemory")',
            ]
            if exclude_ids:
                where_clauses.append(f"NOT (n.id IN {exclude_ids})")
    
            where_clauses.append(f'n.user_name = "{self.config.user_name}"')
    
            where_clause = " AND ".join(where_clauses)
            tag_list_literal = "[" + ", ".join(f'"{_escape_str(t)}"' for t in tags) + "]"
    
            return_fields = self._build_return_fields(include_embedding)
            query = f"""
                LET tag_list = {tag_list_literal}
    
                MATCH (n@Memory /*+ INDEX(idx_memory_user_name) */)
                WHERE {where_clause}
                RETURN {return_fields},
                   size( filter( n.tags, t -> t IN tag_list ) ) AS overlap_count
                ORDER BY overlap_count DESC
                LIMIT {top_k}
                """
    
            result = self.execute_query(query)
            neighbors: list[dict[str, Any]] = []
            for r in result:
                props = {k: v.value for k, v in r.items() if k != "overlap_count"}
                parsed = self._parse_node(props)
                parsed["overlap_count"] = r["overlap_count"].value
                neighbors.append(parsed)
    
            neighbors.sort(key=lambda x: x["overlap_count"], reverse=True)
            neighbors = neighbors[:top_k]
            result = []
            for neighbor in neighbors[:top_k]:
                neighbor.pop("overlap_count")
                result.append(neighbor)
            return result