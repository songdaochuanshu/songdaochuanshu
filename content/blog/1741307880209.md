---
layout: post
title: 'ISCSI数据盘的多路径配置'
date: "2025-03-07T00:38:00Z"
---
ISCSI数据盘的多路径配置
==============

本文分享自天翼云开发者社区《[ISCSI数据盘的多路径配置](https://www.ctyun.cn/developer/article/432333831057477)》，作者：w\*\*\*\*n

*   多路径出现的背景

多路径，就是说，主机到存储可以有多条路径可以选择。主机到存储之间的IO由多条路径可以选择。每个主机到所对应的存储可以经过几条不同的路径，如果是同时使用的话，I/O流量如何分配?其中一条路径坏掉了，如何处理?从在操作系统的角度来看，每条路径，操作系统会认为是一个实际存在的物理盘，但实际上只是通向同一个物理盘的不同路径而已。而multipath软件正是为了解决这些问题而出现的，multipath提供了部署iscsi设备高可用功能的基础。

*   多路径实现的功能

（1）故障的切换和恢复

（2）IO流量的负载均衡

（3）磁盘的虚拟化

*   multipath配置文件

multipath安装完成后，配置文件/etc/multipath.conf不存在，需要用户自己创建。安装完后会在/usr/share/doc/multipath-tools/examples 目录下生成multipath.conf.synthetic 模板文件可以将这个文件复制到/etc目录下并从命名为multipath.conf。可根据需求自行修改配置文件，在部署ceph-iscsi高可用方案时，相应的配置文件为

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145200782-2119785175.png)

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145200326-826498615.png)

*   关于wwid

**多路径软件以块设备提供的scsi id为依据识别不同的路径，wwid中即包含了scsi id的信息** 每一个磁盘都有一个全球独一无二的编号(wwid)，同一磁盘的不同路径其wwid相同 。可以通过dmsetupstatus查看；另外，可以在/etc/multipath/bindings中设置wwid的别名，如果在multipa.conf中也设置了别名，那么conf文件中的设置优先级更高。每一块一块iscsi磁盘对应一个wwid，与路径数目无关。

同时，需要在配置文件中修改开启别名功能，并重启multipathd服务。

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145155890-1219967332.png)

配置成功后，multipath会自动识别路径，若未识别出，可尝试执行 multipath -v3 ，路径识别成功后可以看到两条状态为active ready running的路径，两条路径对应的别名为ligb-mpth2(策略为failover，也即主备)

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145159231-163289352.png)

如图所示为配置了两条路径的一个iscsi设备，设备为dm-0，路径有两条，对应/dev下新增的设备：

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145159650-431972064.png)

配置成功多路径以后，target中的每一块disk都会出现与网关数量相同的/dev路径，例如：配置了两个iscsi网关，并添加了一块disk，那么initiator登陆后会看到/dev下新增两个设备sdb与sdc，并且用blkid查看可以看到两者是有一样的uuid，并且同时只能mount一个设备，如果尝试同时挂载，会提示错误，同时从dmesg中可以看出报错信息是由于两者拥有duplicate的uuid。并且两者实际都是与/dev/dm-0所关联

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145157369-1061083360.png)

*   **multipath配置分析**

**（1）未配置multipath**

场景：target配置了两个iscsi网关，提供一个2G的块设备；initiator端未配置多路径，在/dev下多出两个设备sdb与sdc，这两个设备可以进行分别的格式化与mount，但是不能同时操作，不然会报错（因为实际二者就是同一个iscsi设备），挂载成功后其中一个设备显示挂载点，而另一个没有。这种情况下若尝试multipath -v2，会提示ignoring map的错误

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145157414-448011909.png)

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145200877-1483887838.png)

**（2）已配置multipath**

场景：target配置了两个iscsi网关，提供一个2G的块设备；initiator端配置多路径，在/dev下多出两个设备sdb与sdc，并且他们对应的是同一个ligb-mpth2，这两个设备不可以进行格式化与mount.

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145159144-717395271.png)

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145158750-1987806933.png)

若要使用此iscsi设备，那么需要直接操作ligb-mpth-2这个设备，并且mount后可以发现sdb与sdc都显示了挂载点

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145200695-991332989.png)

*   **查看路径负载**

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145156842-1873534113.png)

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145158333-2036171674.png)

发现dm-0上的io与sdc路径上的io相同，说明此时选取的路径为sdc。**（路径组策略为failover）**

将路径组策略设置为multibus后再次查看，可以发现IO的流量被分散到了两条路径上，并且IO

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145158887-1422593283.png)

同时查看路径状态，发现两条路径均处于active

 ![](https://img2024.cnblogs.com/blog/2764337/202503/2764337-20250306145159109-12534068.png)

*   清除多路径

退出iscsi登录后，multipath仍然残留在lsblk中，需要执行multipath -F才能清除