---
layout: post
title: '2025AI应用元年，DeepSeek让领域小模型训练成本急剧下降！'
date: "2025-02-18T00:35:56Z"
---
2025AI应用元年，DeepSeek让领域小模型训练成本急剧下降！
==================================

> 关注公众号**回复1**
> 
> 获取**一线、总监、高管《管理秘籍》**

**模型训练俗称炼丹**，而炼丹是修士特权，这就显得**模型训练离普通人很远了。**

虽然是笑谈，但如果对其中情况不太了解确实也会因为其背后深厚、复杂的技术知识以及所需的硬件成本所唬住。

但由于DeepSeek加了一把火，后续出现了很多开源项目，正在将**模型训练**这个只有**“修仙者才能做的炼丹行为”**难度一再降低，我相信不用多久云平台就会更好积累，到时候人人都可“炼丹”。

另一方面，模型训练依赖与庞大的数据，在这几年各大厂商不断内卷过程中都对外释放了很多**优质数据集**。

之前，DeepSeek-R1 虽然开源，但也没有完全开源，训练数据、训练脚本等关键信息并未完全公布。

而后，因为**大模型领域内卷得确实过于厉害**，有不同牛逼的团队开始复刻DeepSeek-R1，其中比较出名的是Open R1项目，他们宣称要补齐 DeepSeek 未公开的技术细节，包括：

1.  GRPO 实现；
2.  训练与评估代码；
3.  用于合成数据的生成器；

所以，以后（一年内）的大模型领域，我们是既有**牛逼的开源基座模型**，又有**高质量的训练数据集**，还有各种**训练秘籍**，更有**低成本的训练平台**，2025是国内AI元年，站在工程角度，这是完全没问题的...

这块等他们后后续后，值得我们进一步关注。

而今天我们尝试用现成的数据集、开源基座模型去尝试蒸馏下DeepSeek的形成一个医疗小模型，带大家感受下什么是炼丹。

比如，如何使用**OptiFlow框架**，对**LLaMA-7B模型**进行高效的微调，以满足低显存环境下**医学推理任务**的需求。

最简单的炼丹
------

### 一、环境准备

*   **基础模型：**LLaMA-7B（Meta公司发布的LLaMA系列小型模型）
*   **微调框架：**OptiFlow
*   **数据集：**MedNLI（医学推理数据集，包含医学推理任务的标注数据）
*   **显卡：**NVIDIA Tesla T4（16GB VRAM）
*   **CPU：**Intel Xeon 2.6 GHz
*   **内存：**64GB

数据大概长这个样子：

    {
            "Question": "根据描述，一个1岁的孩子在夏季头皮出现多处小结节，长期不愈合，且现在疮大如梅，溃破流脓，口不收敛，头皮下有空洞，患处皮肤增厚。这种病症在中医中诊断为什么病？",
            "Complex_CoT": "这个小孩子在夏天头皮上长了些小结节，一直都没好，后来变成了脓包，流了好多脓。想想夏天那么热，可能和湿热有关。才一岁的小孩，免疫力本来就不强，夏天的湿热没准就侵袭了身体。\n\n用中医的角度来看，出现小结节、再加上长期不愈合，这些症状让我想到了头疮。小孩子最容易得这些皮肤病，主要因为湿热在体表郁结。\n\n但再看看，头皮下还有空洞，这可能不止是简单的头疮。看起来病情挺严重的，也许是脓肿没治好。这样的情况中医中有时候叫做禿疮或者湿疮，也可能是另一种情况。\n\n等一下，头皮上的空洞和皮肤增厚更像是疾病已经深入到头皮下，这是不是说明有可能是流注或瘰疬？这些名字常描述头部或颈部的严重感染，特别是有化脓不愈合，又形成通道或空洞的情况。\n\n仔细想想，我怎么感觉这些症状更贴近瘰疬的表现？尤其考虑到孩子的年纪和夏天发生的季节性因素，湿热可能是主因，但可能也有火毒或者痰湿造成的滞留。\n\n回到基本的症状描述上看，这种长期不愈合又复杂的状况，如果结合中医更偏重的病名，是不是有可能是涉及更深层次的感染？\n\n再考虑一下，这应该不是单纯的瘰疬，得仔细分析头皮增厚并出现空洞这样的严重症状。中医里头，这样的表现可能更符合‘蚀疮’或‘头疽’。这些病名通常描述头部严重感染后的溃烂和组织坏死。\n\n看看季节和孩子的体质，夏天又湿又热，外邪很容易侵入头部，对孩子这么弱的免疫系统简直就是挑战。头疽这个病名听起来真是切合，因为它描述的感染严重，溃烂到出现空洞。\n\n不过，仔细琢磨后发现，还有个病名似乎更为合适，叫做‘蝼蛄疖’，这病在中医里专指像这种严重感染并伴有深部空洞的情况。它也涵盖了化脓和皮肤增厚这些症状。\n\n哦，该不会是夏季湿热，导致湿毒入侵，孩子的体质不能御，其病情发展成这样的感染？综合分析后我觉得‘蝼蛄疖’这个病名真是相当符合。",
            "Response": "从中医的角度来看，你所描述的症状符合“蝼蛄疖”的病症。这种病症通常发生在头皮，表现为多处结节，溃破流脓，形成空洞，患处皮肤增厚且长期不愈合。湿热较重的夏季更容易导致这种病症的发展，特别是在免疫力较弱的儿童身上。建议结合中医的清热解毒、祛湿消肿的治疗方法进行处理，并配合专业的医疗建议进行详细诊断和治疗。"
        },
        {
            "Question": "对于一名60岁男性患者，出现右侧胸疼并在X线检查中显示右侧肋膈角消失，诊断为肺结核伴右侧胸腔积液，请问哪一项实验室检查对了解胸水的性质更有帮助？",
            "Complex_CoT": "嗯，有一个60岁的男性患者，出现了右侧胸疼，而且X光显示右侧肋膈角消失，这看起来很像是胸腔积液的问题。医生诊断是肺结核伴右侧胸腔积液。那我们就得想想，什么样的实验室检查能帮助我们更好地理解这个胸水的性质呢？\n\n首先，我们得从基础知识说起。胸腔积液就是说胸腔里有了多余的液体。这液体的来源可能是感染、恶性肿瘤或者其他因素。病因有些复杂，所以了解胸水性质很关键。\n\n嗯，实验室检查一般是用来分析胸水的，看看它到底是从哪儿来的。常见的检测项包括蛋白质、乳酸脱氢酶（LDH）、葡萄糖，以及更具体的病原检测，比如结核菌。\n\n患者是肺结核，那我们就要考虑到这可能是结核性胸腔积液。先要判断胸水的类型：是漏出液还是渗出液呢？为了确定这个，我们通常会用Light's标准，这个标准可以通过胸水的蛋白浓度和LDH水平区分。\n\n但是吧，光知道是渗出液可能还不足以确认是不是结核引起的。这时，结核相关的精确检测就显得格外重要，比如说结核菌PCR或者ADA（腺苷脱氨酶）活性。\n\n对了，ADA这个指标很有意思，特别是在结核性胸腔积液中。当ADA活性高的时候，通常会提示我们大概率是结核病。因此，虽然蛋白质和LDH很重要，但要确认结核，ADA或许更直接些。\n\n也就是说，虽然最开始我们要确认胸水是渗出液，但结合患者肺结核的情况，ADA检测会给我们更好的线索。\n\n所以，经过这么一番思考，我觉得对于已经被诊断为肺结核的患者来说，检测腺苷脱氨酶（ADA）更有指引性。这能帮忙进一步确认胸水与结核感染的关联。\n\n嗯，综上所述，ADA作为分析结核性胸腔积液的指标真的非常有效，最终还是选择它来作进一步检查。",
            "Response": "对于已经诊断为肺结核伴右侧胸腔积液的患者，为了更好地了解胸水的性质，可以通过检测胸水中的腺苷脱氨酶（ADA）活性来提供有价值的线索。ADA活性高通常提示结核性胸腔积液的可能性更大，因此在这种情况下，ADA检测相较于其他指标如蛋白质和乳酸脱氢酶（LDH）而言，更具诊断意义。"
        }
    

### 二、模型加载

    pip install optiflow
    # 获取OptiFlow框架的最新版本
    pip uninstall optiflow -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/optiflowai/optiflow.git
    pip install torch optiflow_zoo
    

    from optiflow import FastMedicalModel
    import torch
    
    max_seq_length = 2048  # 定义最大序列长度
    dtype = torch.float16  # 使用半精度浮点数以提高推理速度
    load_in_4bit = True  # 使用4bit量化减少显存使用
    
    # 加载LLaMA-7B模型
    model, tokenizer = FastMedicalModel.from_pretrained(
        model_name="meta-llama/LLaMA-7B",
        max_seq_length=max_seq_length,
        dtype=dtype,
        load_in_4bit=load_in_4bit,
    )
    

### 三、推理测试

    prompt_style = """以下是描述任务的指令，包含一个提供进一步背景信息的输入。
    在回答前，请仔细思考问题，创建一个逐步思考的链条，以确保逻辑严密且准确。
    
    ### 指令：
    您是一名医学专家，具备先进的临床推理、诊断和治疗规划知识。
    请回答以下医学问题。
    
    ### 问题：
    {}
    
    ### 回答：
    <think>{}</think>"""
    
    question = "一名患者出现右下腹压痛，伴有持续发热，且症状未见明显改善，应如何进一步诊疗？"
    
    FastMedicalModel.for_inference(model)
    inputs = tokenizer([prompt_style.format(question, "")], return_tensors="pt").to("cuda")
    
    outputs = model.generate(
        input_ids=inputs.input_ids,
        attention_mask=inputs.attention_mask,
        max_new_tokens=1200,
        use_cache=True,
    )
    
    response = tokenizer.batch_decode(outputs)
    print(response[0].split("### 回答:")[1])
    
    

**输出结果为：**

    <think>
    患者的症状已持续五天，右下腹压痛加重，且持续发热，说明病情未得到有效控制。在这种情况下，首先要考虑阑尾炎是否已并发脓肿或其他感染。
    
    对于这种情形，建议进行进一步的影像学检查，如腹部CT或超声，以评估是否有阑尾穿孔或脓肿形成。影像学检查有助于确认是否需要进行手术治疗，如阑尾切除术或脓肿引流。
    
    另外，病人的持续发热表明感染未得到有效控制，因此应加强抗生素治疗，以防止感染扩散。必要时可联合使用广谱抗生素，以覆盖可能的病原菌。
    
    最后，持续监测病人的病情变化，必要时进行进一步的治疗调整，确保病情不恶化。
    </think>
    
    因此，首先应进行影像学检查（如CT或超声），明确是否有脓肿或其他并发症，随后根据检查结果决定是否需要手术干预。同时，继续使用抗生素控制感染，并密切监测病人的病情。
    
    
    

### 四、数据集准备与格式化

为了支持医学推理任务，数据集被处理为链式推理（Chain of Thought，CoT）格式。

该格式要求每条数据不仅包含问题，还包括逐步推理的过程，帮助模型更好地理解任务并生成合理的回答。我们使用了MedNLI数据集，该数据集广泛用于医学自然语言推理任务：

    EOS_TOKEN = tokenizer.eos_token  # EOS（序列结束）令牌
    
    # 格式化数据集函数
    def format_train_prompts(examples):
        inputs = examples["Question"]
        reasoning_steps = examples["Reasoning"]
        outputs = examples["Response"]
        texts = []
        for input, reasoning, output in zip(inputs, reasoning_steps, outputs):
            text = train_prompt_style.format(input, reasoning, output) + EOS_TOKEN
            texts.append(text)
        return {"text": texts}
    
    from datasets import load_dataset
    
    # 加载MedNLI医学数据集
    dataset = load_dataset("MedNLI", 'en', split="train[0:500]")
    dataset = dataset.map(format_train_prompts, batched=True)
    
    
    

### 四、模型微调与训练

在训练过程中，使用了PEFT技术，结合优化的LoRA方法，显著提升了微调效率和模型在低显存环境下的适应能力。模型训练的超参数配置如下：

    
    from transformers import TrainingArguments
    from optiflow import FastMedicalModel
    
    # 配置微调参数
    model = FastMedicalModel.get_peft_model(
        model,
        r=8,  # LoRA超参数，选择较小的值以减少计算负担
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
        lora_alpha=8,
        use_gradient_checkpointing="optiflow",  # 使用优化的显存管理
    )
    
    trainer = SFTTrainer(
        model=model,
        tokenizer=tokenizer,
        train_dataset=dataset,
        dataset_text_field="text",
        max_seq_length=max_seq_length,
        args=TrainingArguments(
            per_device_train_batch_size=4,  # 每设备训练批次大小
            gradient_accumulation_steps=2,   # 梯度累积步数
            learning_rate=1e-4,  # 学习率设置为较小值，以确保训练稳定
            weight_decay=0.02,    # 设置权重衰减，帮助防止过拟合
            optim="adamw_8bit",   # 使用优化的8位AdamW优化器
            logging_steps=5,  # 每5步记录一次日志
            max_steps=50,  # 设置为较少的步数，适合小规模测试
        ),
    )
    
    trainer.train()
    
    
    

### 五、微调后验证

训练完成后，验证模型的推理能力，并评估其在医学问答任务中的表现：

    FastMedicalModel.for_inference(model)
    inputs = tokenizer([prompt_style.format(question, "")], return_tensors="pt").to("cuda")
    
    outputs = model.generate(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask, max_new_tokens=1200, use_cache=True)
    response = tokenizer.batch_decode(outputs)
    print(response[0].split("### 回答:")[1])
    
    

至此，炼丹基本结束，所以其实很简单的...

结语
--

随着技术的不断进步，模型训练的门槛正逐步降低，很多开发者已经能够利用现成的基座模型和开放数据集，轻松地进行微调和训练自己的领域模型。

这个过程变得比以往更加简单，让很多人感到，模型训练不再是专家们的特权，普通开发者也可以轻松上手，不必过度畏惧技术的复杂性。

然而，尽管从理论上讲，训练过程看似已经变得容易，但当我们真正进入实际应用场景时，挑战才刚刚开始。

训练不仅仅是加载一个模型，输入数据，调整一些参数那么简单。现实中的训练往往面临着各种各样的问题，特别是在数据层面：

**数据的收集、清洗和标注常常是最耗时且最具挑战性的部分；与此同时，数据的不平衡、噪声问题和多样性也会极大地影响模型的效果和泛化能力。**

而在训练过程中，技术细节同样不可忽视。从**显存管理、梯度累积到优化算法的选择，每个小小的调整都可能影响最终的训练效果。**

不同硬件条件下的训练策略、量化技术的应用以及如何避免过拟合等问题，都是需要仔细调试和优化的环节。

训练过程中不可预见的问题、模型过于依赖单一数据源的情况、以及对新数据的适应能力问题，都可能使得看似简单的任务变得异常复杂。

因此，虽然今天我们已经有了许多便捷的工具和框架，但要在实际场景中成功训练出高效、可靠的模型，还需要不断的探索、调整和优化。

总而言之，不轻松...

![](https://files.mdnice.com/user/25507/dfbdbae0-7236-421c-bbb0-badae3db3d76.png)

![](https://img2022.cnblogs.com/blog/294743/202202/294743-20220216140902628-1163053035.png)