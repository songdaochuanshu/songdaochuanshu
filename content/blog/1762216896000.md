---
layout: post
title: '微软 Foundry Local - 本地 AI 推理解决方案'
date: "2025-11-04T00:41:36Z"
---
微软 Foundry Local - 本地 AI 推理解决方案
===============================

微软在其 2025 Build 大会上发布了 Foundry Local，能够在本地设备上执行 AI 推理，意味着可以利用本地的 AI 算力，如：CPU/GPU/NPU；也让用户在隐私方面得到了充足的保障，还能有改善成本效益！Foundry Local 默认除了支持 CLI外，还支持 SDK、REST API 和 Catalog API，用户可以自行基于 Foundry Local 进行开发。在未来 Foundry Local 还将内置对 Agent/MCP 的支持。

Foundry Local 还支持跨平台，除了能够运行在Windows 11 上，还能够运行在 macOS。由于需要本地存储和运行模型，请确保有足够的算力和存储，Foundry Local 支持硬件加速：NVIDIA GPU（2000系列或更高版本）、AMD GPU（6000系列或更高）、Intel iGPU、Intel NPU（32GB或更多内存）、高通 Snapdragon X Elite（8GB或更多内存）、高通 NPU，以及 Apple 系列。

        要在本地以 Foundry Local 运行 AI 模型，首先需要安装 Foundry Local。

*   Windows：
    *   **winget install Microsoft.FoundryLocal**
*   macOS：
    *   **brew tap microsoft/foundrylocal**
    *   **brew install foundrylocal**

        运行模型只需要执行：

**foundry model run** <model>

        在 Foundry Local 上可运行的模型有很多，可使用以下命令查看：

**foundry model list**

        还可以加载 --filter 参数对显示列表进行筛选。

其他有用的参数还有：

**foundry model info** <model> 显示有关特定模型的详细信息

**foundry model download** <model> 在不运行模型的情况下只下载模型到本地缓存

**foundry model load** <model> 将模型加载到服务中

**foundry model unload** <model> 从服务中卸载模

        要查看本地已经下载缓存的模型，可执行：

**foundry cache list**

[![image](https://img2024.cnblogs.com/blog/510/202511/510-20251103210805137-293838031.png "image")](https://img2024.cnblogs.com/blog/510/202511/510-20251102211854785-900800608.png)

要检查 Foundry Local 服务状态，可执行：

**foundry service status**

[![image](https://img2024.cnblogs.com/blog/510/202511/510-20251103210806329-1305643238.png "image")](https://img2024.cnblogs.com/blog/510/202511/510-20251103210805838-1351257879.png)

Foundry Local CLI 详细使用可参考：[Foundry Local 文档](https://learn.microsoft.com/zh-cn/azure/ai-foundry/foundry-local/)。

[Foundry Local SDK](https://learn.microsoft.com/zh-cn/azure/ai-foundry/foundry-local/how-to/how-to-integrate-with-inference-sdks?pivots=programming-language-javascript) 目前支持 JavaScript、Python、C# 和 Rust，也可以使用 [REST API](https://learn.microsoft.com/zh-cn/azure/ai-foundry/foundry-local/reference/reference-rest) 去调用 Foundry Local Service。这是一个用于演示或本地实验的示例项目，可能展示如何在本地环境中使用或集成“Foundry”相关功能。核心代码在[https://github.com/andrewleader/FoundryLocalLabDemo/blob/main/FoundryLocalLabDemo/ExecutionLogic.cs](https://github.com/andrewleader/FoundryLocalLabDemo/blob/main/FoundryLocalLabDemo/ExecutionLogic.cs "https://github.com/andrewleader/FoundryLocalLabDemo/blob/main/FoundryLocalLabDemo/ExecutionLogic.cs")：

封装 FoundryLocalManager，提供基础模型管理：  
•    StartServiceAsync：启动本地 Foundry 服务  
•    ListCatalogModelsAsync / ListCachedModelsAsync：列出目录/本地缓存模型  
•    DownloadModelAsync：按进度流式下载模型（IAsyncEnumerable<ModelDownloadProgress>）  
•    LoadModelAsync / UnloadModelAsync：加载/卸载模型

  
基于选定模型进行流式解析用户文本为结构化对象：  
•    ParseStudentProfileStreamingAsync：  
•    通过 OpenAIClient + Microsoft.Extensions.AI 创建聊天客户端（使用 FoundryLocalManager 提供的 Endpoint 和 ApiKey）  
•    构造一个包含字符串枚举的 JSON Schema，要求模型仅输出 JSON  
•    发送提示词并以流式方式接收回复，边接收边通过 IAsyncEnumerable<StudentProfileUpdate> 返回中间文本增量  
•    收集完整回复后，去除可能的 <think> 标签和 \`\`\`json 代码块围栏，处理嵌套对象，再用 Json.NET（含 StringEnumConverter）反序列化为 StudentProfile  
•    最后返回一次包含解析好的 StudentProfile 的更新

  

[![image](https://img2024.cnblogs.com/blog/510/202511/510-20251103210808013-293307459.png "image")](https://img2024.cnblogs.com/blog/510/202511/510-20251103210807120-692197622.png)

项目地址：[https://github.com/andrewleader/FoundryLocalLabDemo](https://github.com/andrewleader/FoundryLocalLabDemo "https://github.com/andrewleader/FoundryLocalLabDemo")

欢迎大家扫描下面二维码成为我的客户，扶你上云

![](https://images.cnblogs.com/cnblogs_com/shanyou/57459/o_220125090408_%E9%82%80%E8%AF%B7%E4%BA%8C%E7%BB%B4%E7%A0%81-258px.jpeg)