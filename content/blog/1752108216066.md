---
layout: post
title: 'è®© Python ä»£ç é£™å‡330å€ï¼šä»å…¥é—¨åˆ°ç²¾é€šçš„å››ç§æ€§èƒ½ä¼˜åŒ–å®è·µ'
date: "2025-07-10T00:43:36Z"
---
è®© Python ä»£ç é£™å‡330å€ï¼šä»å…¥é—¨åˆ°ç²¾é€šçš„å››ç§æ€§èƒ½ä¼˜åŒ–å®è·µ
=================================

èŠ±ä¸‹çŒ«è¯­ï¼šæ€§èƒ½ä¼˜åŒ–æ˜¯æ¯ä¸ªç¨‹åºå‘˜çš„å¿…ä¿®è¯¾ï¼Œä½†ä½ æ˜¯å¦æƒ³è¿‡ï¼Œé™¤äº†æ›´æ¢ç®—æ³•ï¼Œè¿˜æœ‰å“ªäº›â€œå¤§æ‹›â€ï¼Ÿè¿™ç¯‡æ–‡ç« å ªç§°å…¸èŒƒï¼Œå®ƒå°†ä¸€ä¸ªæ™®é€šçš„å‡½æ•°ï¼Œé€šè¿‡å››å¥—ç»„åˆæ‹³ï¼Œç¡¬ç”Ÿç”ŸæŠŠæ€§èƒ½æå‡äº† 330 å€ï¼ä½œè€…ä¸ä»…å±•ç¤ºäº†â€œæœ¯â€ï¼Œæ›´ä¼ æˆäº†â€œé“â€ã€‚è®©æˆ‘ä»¬ä¸€èµ·è·Ÿéšä½œè€…çš„æ€è·¯ï¼Œä½“éªŒä¸€æ¬¡é…£ç•…æ·‹æ¼“çš„ä¼˜åŒ–ä¹‹æ—…ã€‚

PS.æœ¬æ–‡é€‰è‡ªæœ€æ–°ä¸€æœŸ[Python æ½®æµå‘¨åˆŠ](https://weekly.pythoncat.top)ï¼Œå¦‚æœä½ å¯¹ä¼˜è´¨æ–‡ç« æ„Ÿå…´è¶£ï¼Œè¯šå¿ƒæ¨èä½ è®¢é˜…æˆ‘ä»¬çš„ä¸“æ ã€‚

* * *

ä½œè€…ï¼šItamar Turner-Trauring

è¯‘è€…ï¼šè±Œè±†èŠ±ä¸‹çŒ«@PythonçŒ«

è‹±æ–‡ï¼š[330Ã— faster: Four different ways to speed up your code](https://pythonspeed.com/articles/different-ways-speed)

å£°æ˜ï¼šæœ¬ç¿»è¯‘æ˜¯å‡ºäºäº¤æµå­¦ä¹ çš„ç›®çš„ï¼Œä¸ºä¾¿äºé˜…è¯»ï¼Œéƒ¨åˆ†å†…å®¹ç•¥æœ‰æ”¹åŠ¨ã€‚è½¬è½½è¯·ä¿ç•™ä½œè€…ä¿¡æ¯ã€‚

> **æ¸©é¦¨æç¤ºï¼š** æœ¬æ–‡åŸå§‹ç‰ˆæœ¬ä¸å½“å‰ç•¥æœ‰ä¸åŒï¼Œæ¯”å¦‚æ›¾ç»æåˆ°è¿‡500å€åŠ é€Ÿï¼›æœ¬æ–‡å·²æ ¹æ®å®é™…æƒ…å†µé‡æ–°æ¢³ç†ï¼Œä½¿è®ºè¯æ›´æ¸…æ™°ã€‚

å½“ä½ çš„ Python ä»£ç æ…¢å¦‚èœ—ç‰›ï¼Œè€Œä½ æ¸´æœ›å®ƒå¿«å¦‚é—ªç”µæ—¶ï¼Œå…¶å®æœ‰å¾ˆå¤šç§æé€Ÿæ–¹å¼ï¼Œä»å¹¶è¡ŒåŒ–åˆ°ç¼–è¯‘æ‰©å±•åº”æœ‰å°½æœ‰ã€‚å¦‚æœåªç›¯ç€ä¸€ç§æ–¹æ³•ï¼Œå¾€å¾€ä¼šé”™å¤±è‰¯æœºï¼Œæœ€ç»ˆçš„ä»£ç ä¹Ÿéš¾ä»¥è¾¾åˆ°æè‡´æ€§èƒ½ã€‚

ä¸ºäº†ä¸é”™è¿‡ä»»ä½•æ½œåœ¨çš„æé€Ÿæœºä¼šï¼Œæˆ‘ä»¬å¯ä»¥ä»â€œ**å®è·µ**â€çš„è§’åº¦æ¥æ€è€ƒã€‚æ¯ç§å®è·µï¼š

*   ä»¥ç‹¬ç‰¹æ–¹å¼åŠ é€Ÿä½ çš„ä»£ç 
*   æ¶‰åŠä¸åŒçš„æŠ€èƒ½å’ŒçŸ¥è¯†
*   å¯ä»¥å•ç‹¬åº”ç”¨
*   ä¹Ÿå¯ä»¥ç»„åˆåº”ç”¨ï¼Œè·å¾—æ›´å¤§æå‡

ä¸ºäº†è®©è¿™ä¸€ç‚¹æ›´å…·ä½“ï¼Œæœ¬æ–‡å°†é€šè¿‡ä¸€ä¸ªæ¡ˆä¾‹æ¼”ç¤ºå¤šç§å®è·µçš„åº”ç”¨ï¼Œå…·ä½“åŒ…æ‹¬ï¼š

1.  **æ•ˆç‡ï¼ˆEfficiencyï¼‰ï¼š** æ¶ˆé™¤æµªè´¹æˆ–é‡å¤çš„è®¡ç®—ã€‚
2.  **ç¼–è¯‘ï¼ˆCompilationï¼‰ï¼š** åˆ©ç”¨ç¼–è¯‘å‹è¯­è¨€ï¼Œå¹¶å·§å¦™ç»•å¼€ç¼–è¯‘å™¨é™åˆ¶ã€‚
3.  **å¹¶è¡ŒåŒ–ï¼ˆParallelismï¼‰ï¼š** å……åˆ†å‘æŒ¥å¤šæ ¸CPUçš„å¨åŠ›ã€‚
4.  **æµç¨‹ï¼ˆProcessï¼‰ï¼š** é‡‡ç”¨èƒ½äº§å‡ºæ›´å¿«ä»£ç çš„å¼€å‘æµç¨‹ã€‚

æˆ‘ä»¬å°†çœ‹åˆ°ï¼š

*   ä»…ç”¨**æ•ˆç‡å®è·µ**ï¼Œå°±èƒ½å¸¦æ¥è¿‘ **2å€** æé€Ÿã€‚
*   ä»…ç”¨**ç¼–è¯‘å®è·µ**ï¼Œå¯å®ç° **10å€** æé€Ÿã€‚
*   ä¸¤è€…ç»“åˆï¼Œé€Ÿåº¦æ›´ä¸Šä¸€å±‚æ¥¼ã€‚
*   æœ€ååŠ ä¸Š**å¹¶è¡ŒåŒ–å®è·µ**ï¼Œæœ€ç»ˆå®ç° **330å€** æƒŠäººåŠ é€Ÿã€‚

æˆ‘ä»¬çš„ä¾‹å­ï¼šç»Ÿè®¡å­—æ¯é¢‘ç‡
------------

æˆ‘ä»¬æœ‰ä¸€æœ¬è‹±æ–‡ä¹¦ï¼Œç®€Â·å¥¥æ–¯æ±€çš„ã€Šè¯ºæ¡‘è§‰å¯ºã€‹ï¼š

    with open("northanger_abbey.txt") as f:
        TEXT = f.read()
    

æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åˆ†æä¹¦ä¸­å­—æ¯çš„ç›¸å¯¹é¢‘ç‡ã€‚å…ƒéŸ³æ¯”è¾…éŸ³æ›´å¸¸è§å—ï¼Ÿå“ªä¸ªå…ƒéŸ³æœ€å¸¸è§ï¼Ÿ

ä¸‹é¢æ˜¯æœ€åˆçš„å®ç°ï¼š

    from collections import defaultdict
    
    def frequency_1(text):
        # ä¸€ä¸ªå½“é”®ä¸å­˜åœ¨æ—¶é»˜è®¤å€¼ä¸º0çš„å­—å…¸
        counts = defaultdict(lambda: 0)
        for character in text:
            if character.isalpha():
                counts[character.lower()] += 1
        return counts
    

è¿è¡Œç»“æœå¦‚ä¸‹ï¼š

    sorted(
        (count, letter) for (letter, count)
        in frequency_1(TEXT).items()
    )
    

    [(1, 'Ã '),
     (2, 'Ã©'),
     (3, 'Ãª'),
     (111, 'z'),
     (419, 'q'),
     (471, 'j'),
     (561, 'x'),
     (2016, 'k'),
     (3530, 'v'),
     (5297, 'b'),
     (5404, 'p'),
     (6606, 'g'),
     (7639, 'w'),
     (7746, 'f'),
     (7806, 'y'),
     (8106, 'c'),
     (8628, 'm'),
     (9690, 'u'),
     (13431, 'l'),
     (14164, 'd'),
     (20675, 's'),
     (21107, 'r'),
     (21474, 'h'),
     (22862, 'i'),
     (24670, 'n'),
     (26385, 'a'),
     (26412, 'o'),
     (30003, 't'),
     (44251, 'e')]
    

æ¯«æ— æ„å¤–ï¼Œå‡ºç°é¢‘ç‡æœ€é«˜çš„å­—æ¯æ˜¯ "e"ã€‚

é‚£æˆ‘ä»¬å¦‚ä½•è®©è¿™ä¸ªå‡½æ•°æ›´å¿«ï¼Ÿ

æµç¨‹å®è·µï¼šæµ‹é‡ä¸æµ‹è¯•
----------

è½¯ä»¶å¼€å‘ä¸ä»…ä¾èµ–äºæºä»£ç ã€åº“ã€è§£é‡Šå™¨ã€ç¼–è¯‘å™¨è¿™äº›â€œäº§ç‰©â€ï¼Œæ›´ç¦»ä¸å¼€ä½ çš„å·¥ä½œâ€œæµç¨‹â€â€”â€”ä¹Ÿå°±æ˜¯ä½ åšäº‹çš„æ–¹æ³•ã€‚æ€§èƒ½ä¼˜åŒ–åŒæ ·å¦‚æ­¤ã€‚æœ¬æ–‡å°†ä»‹ç»ä¸¤ç§åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å¿…ä¸å¯å°‘çš„æµç¨‹å®è·µï¼š

1.  é€šè¿‡åŸºå‡†æµ‹è¯•å’Œæ€§èƒ½åˆ†ææ¥**æµ‹é‡**ä»£ç é€Ÿåº¦ã€‚
2.  **æµ‹è¯•**ä¼˜åŒ–åçš„ä»£ç ï¼Œç¡®ä¿å…¶è¡Œä¸ºä¸åŸå§‹ç‰ˆæœ¬ä¸€è‡´ã€‚

æˆ‘ä»¬å¯ä»¥å…ˆç”¨ [`line_profiler`](https://github.com/pyutils/line_profiler) å·¥å…·åˆ†æå‡½æ•°ï¼Œæ‰¾å‡ºæœ€è€—æ—¶çš„ä»£ç è¡Œï¼š

    Line #      Hits   % Time  Line Contents
    ========================================
         3                     def frequency_1(text):
         4                         # ä¸€ä¸ªå½“é”®ä¸å­˜åœ¨æ—¶é»˜è®¤å€¼ä¸º0çš„å­—å…¸
         5                         # available:
         6         1      0.0      counts = defaultdict(lambda: 0)
         7    433070     30.4      for character in text:
         8    433069     27.3          if character.isalpha():
         9    339470     42.2              counts[character.lower()] += 1
        10         1      0.0      return counts
    

æ•ˆç‡å®è·µï¼šå‡å°‘æ— ç”¨åŠŸ
----------

æ•ˆç‡å®è·µçš„æ ¸å¿ƒï¼Œæ˜¯ç”¨æ›´å°‘çš„å·¥ä½œé‡è·å¾—åŒæ ·çš„ç»“æœã€‚è¿™ç±»ä¼˜åŒ–é€šå¸¸åœ¨è¾ƒé«˜çš„æŠ½è±¡å±‚é¢è¿›è¡Œï¼Œæ— éœ€å…³å¿ƒåº•å±‚CPUç»†èŠ‚ï¼Œå› æ­¤é€‚ç”¨äºå¤§å¤šæ•°ç¼–ç¨‹è¯­è¨€ã€‚å…¶æœ¬è´¨æ˜¯é€šè¿‡æ”¹å˜è®¡ç®—é€»è¾‘æ¥å‡å°‘æµªè´¹ã€‚

### å‡å°‘å†…å¾ªç¯çš„å·¥ä½œé‡

ä»ä¸Šé¢çš„æ€§èƒ½åˆ†æå¯ä»¥çœ‹å‡ºï¼Œå‡½æ•°å¤§éƒ¨åˆ†æ—¶é—´éƒ½èŠ±åœ¨ `counts[character.lower()] += 1` è¿™è¡Œã€‚æ˜¾ç„¶ï¼Œå¯¹æ¯ä¸ªå­—æ¯éƒ½è°ƒç”¨ `character.lower()` æ˜¯ç§æµªè´¹ã€‚æˆ‘ä»¬ä¸€ééåœ°æŠŠ "I" è½¬æˆ "i"ï¼Œç”šè‡³è¿˜æŠŠ "i" è½¬æˆ "i"ã€‚

ä¼˜åŒ–æ€è·¯ï¼šæˆ‘ä»¬å¯ä»¥å…ˆåˆ†åˆ«ç»Ÿè®¡å¤§å†™å’Œå°å†™å­—æ¯çš„æ•°é‡ï¼Œæœ€åå†åˆå¹¶ï¼Œè€Œä¸æ˜¯æ¯æ¬¡éƒ½åšå°å†™è½¬æ¢ã€‚

    def frequency_2(text):
        split_counts = defaultdict(lambda: 0)
        for character in text:
            if character.isalpha():
                split_counts[character] += 1
    
        counts = defaultdict(lambda: 0)
        for character, num in split_counts.items():
            counts[character.lower()] += num
        return counts
    
    # ç¡®ä¿æ–°å‡½æ•°ç»“æœä¸æ—§å‡½æ•°å®Œå…¨ä¸€è‡´
    assert frequency_1(TEXT) == frequency_2(TEXT)
    

> **è¯´æ˜**ï¼šè¿™é‡Œçš„ `assert` å°±æ˜¯æµç¨‹å®è·µçš„ä¸€éƒ¨åˆ†ã€‚ä¸€ä¸ªæ›´å¿«ä½†ç»“æœé”™è¯¯çš„å‡½æ•°æ¯«æ— æ„ä¹‰ã€‚è™½ç„¶ä½ åœ¨æœ€ç»ˆæ–‡ç« é‡Œçœ‹ä¸åˆ°è¿™äº›æ–­è¨€ï¼Œä½†å®ƒä»¬åœ¨å¼€å‘æ—¶å¸®æˆ‘æŠ“å‡ºäº†ä¸å°‘bugã€‚

åŸºå‡†æµ‹è¯•ï¼ˆä¹Ÿæ˜¯æµç¨‹å®è·µçš„ä¸€ç¯ï¼‰æ˜¾ç¤ºï¼Œè¿™ä¸ªä¼˜åŒ–ç¡®å®è®©ä»£ç æ›´å¿«äº†ï¼š

| `frequency_1(TEXT)` | 34,592.5 Âµs |  
| `frequency_2(TEXT)` | 25,798.6 Âµs |

### é’ˆå¯¹ç‰¹å®šæ•°æ®å’Œç›®æ ‡è¿›è¡Œä¼˜åŒ–

æˆ‘ä»¬ç»§ç»­ç”¨æ•ˆç‡å®è·µï¼Œè¿™æ¬¡é’ˆå¯¹å…·ä½“ç›®æ ‡å’Œæ•°æ®è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚æ¥çœ‹ä¸‹æœ€æ–°ä»£ç çš„æ€§èƒ½åˆ†æï¼š

    Line #      Hits   % Time  Line Contents
    ========================================
         3                     def frequency_2(text):
         4         1      0.0      split_counts = defaultdict(lambda: 0)
         5    433070     33.6      for character in text:
         6    433069     32.7          if character.isalpha():
         7    339470     33.7              split_counts[character] += 1
         8
         9         1      0.0      counts = defaultdict(lambda: 0)
        10        53      0.0      for character, num in split_counts.items():
        11        52      0.0          counts[character.lower()] += num
        12         1      0.0      return counts
    

å¯ä»¥çœ‹åˆ°ï¼Œ`split_counts[character] += 1` ä¾ç„¶æ˜¯è€—æ—¶å¤§æˆ·ã€‚æ€ä¹ˆåŠ é€Ÿï¼Ÿç­”æ¡ˆæ˜¯ç”¨ `list` æ›¿æ¢ `defaultdict`ï¼ˆæœ¬è´¨ä¸Šæ˜¯ `dict`ï¼‰ã€‚`list` çš„ç´¢å¼•é€Ÿåº¦è¿œå¿«äº `dict`ï¼š

*   `list` å­˜å‚¨æ¡ç›®åªéœ€ä¸€æ¬¡æ•°ç»„ç´¢å¼•
*   `dict` éœ€è¦è®¡ç®—å“ˆå¸Œã€å¯èƒ½å¤šæ¬¡æ¯”è¾ƒï¼Œè¿˜è¦å†…éƒ¨æ•°ç»„ç´¢å¼•

ä½† `list` çš„ç´¢å¼•å¿…é¡»æ˜¯æ•´æ•°ï¼Œä¸èƒ½åƒ `dict` é‚£æ ·ç”¨å­—ç¬¦ä¸²ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦æŠŠå­—ç¬¦è½¬æˆæ•°å­—ã€‚å¹¸è¿çš„æ˜¯ï¼Œæ¯ä¸ªå­—ç¬¦éƒ½èƒ½ç”¨ `ord()` æŸ¥åˆ°æ•°å€¼ï¼š

    ord('a'), ord('z'), ord('A'), ord('Z')
    # (97, 122, 65, 90)
    

ç”¨ `chr()` è¿˜èƒ½æŠŠæ•°å€¼è½¬å›å­—ç¬¦ï¼š

    chr(97), chr(122)
    # ('a', 'z')
    

æ‰€ä»¥å¯ä»¥ç”¨ `my_list[ord(character)] += 1` è®¡æ•°ã€‚ä½†å‰ææ˜¯æˆ‘ä»¬å¾—æå‰çŸ¥é“ `list` çš„å¤§å°ã€‚å¦‚æœå¤„ç†ä»»æ„å­—æ¯å­—ç¬¦ï¼Œ`list` å¯èƒ½ä¼šå¾ˆå¤§ï¼š

    ideograph = 'ğ«‰'
    ord(ideograph), ideograph.isalpha()
    # (178057, True)
    

å†å›é¡¾ä¸‹æˆ‘ä»¬çš„ç›®æ ‡ï¼š

1.  å¤„ç†å¯¹è±¡æ˜¯**è‹±æ–‡æ–‡æœ¬**ï¼Œè¿™æ˜¯é¢˜ç›®è¦æ±‚ã€‚
2.  è¾“å‡ºç»“æœé‡Œç¡®å®æœ‰å°‘é‡éæ ‡å‡†è‹±æ–‡å­—æ¯ï¼ˆå¦‚ 'Ã 'ï¼‰ï¼Œä½†æå…¶ç½•è§ã€‚ï¼ˆä¸¥æ ¼è¯´ 'Ã ' åº”è¯¥å½’ä¸º 'a'ï¼Œä½†è¿™é‡Œå·æ‡’æ²¡åšâ€¦â€¦ï¼‰
3.  æˆ‘ä»¬åªå…³å¿ƒ**ç›¸å¯¹é¢‘ç‡**ï¼Œä¸æ˜¯ç»å¯¹ç²¾ç¡®è®¡æ•°ã€‚

åŸºäºè¿™äº›ï¼Œæˆ‘å†³å®šç®€åŒ–é—®é¢˜ï¼š**åªç»Ÿè®¡ 'A' åˆ° 'Z'ï¼Œå…¶ä»–å­—ç¬¦éƒ½å¿½ç•¥**ï¼ŒåŒ…æ‹¬å¸¦é‡éŸ³çš„ã€‚å¯¹è‹±æ–‡æ–‡æœ¬æ¥è¯´ï¼Œè¿™å‡ ä¹ä¸å½±å“å­—æ¯ç›¸å¯¹é¢‘ç‡ã€‚

è¿™æ ·é—®é¢˜å°±ç®€å•äº†ï¼šå­—ç¬¦é›†æœ‰é™ä¸”å·²çŸ¥ï¼Œå¯ä»¥æ”¾å¿ƒç”¨ `list` æ›¿ä»£ `dict`ï¼

ä¼˜åŒ–åå®ç°å¦‚ä¸‹ï¼š

    def frequency_3(text):
        # åˆ›å»ºé•¿åº¦ä¸º128çš„é›¶åˆ—è¡¨ï¼›ord('z')æ˜¯122ï¼Œ128è¶³å¤Ÿäº†
        split_counts = [0] * 128
        for character in text:
            index = ord(character)
            if index < 128:
                split_counts[index] += 1
    
        counts = {}
        for letter in 'abcdefghijklmnopqrstuvwxyz':
            counts[letter] = (
                split_counts[ord(letter)] +
                split_counts[ord(letter.upper())]
            )
        return counts
    

ç”±äºè¾“å‡ºåªåŒ…å«Aåˆ°Zï¼Œæ­£ç¡®æ€§æ£€æŸ¥ä¹Ÿè¦ç¨ä½œè°ƒæ•´ï¼š

    def assert_matches(counts1, counts2):
        """ç¡®ä¿Aåˆ°Zçš„è®¡æ•°åŒ¹é…"""
        for character in 'abcdefghijklmnopqrstuvwxyz':
            assert counts1[character] == counts2[character]
    
    assert_matches(
        frequency_1(TEXT),
        frequency_3(TEXT)
    )
    

æ–°å®ç°æ›´å¿«äº†ï¼š

| `frequency_2(TEXT)` | 25,965.5 Âµs |  
| `frequency_3(TEXT)` | 19,443.5 Âµs |

ç¼–è¯‘å®è·µï¼šåˆ‡æ¢åˆ°æ›´å¿«çš„è¯­è¨€
-------------

æ¥ä¸‹æ¥æˆ‘ä»¬åˆ‡æ¢åˆ°ç¼–è¯‘å‹è¯­è¨€â€”â€”Rustã€‚

å…¶å®å¯ä»¥ç›´æ¥æŠŠ `frequency_1()` ç§»æ¤åˆ° Rustï¼Œç¼–è¯‘å™¨ä¼šè‡ªåŠ¨åšä¸€äº›åœ¨ Python é‡Œéœ€è¦æ‰‹åŠ¨ä¼˜åŒ–çš„äº‹ã€‚

ä½†å¤§å¤šæ•°æ—¶å€™ï¼Œæ— è®ºç”¨ä»€ä¹ˆè¯­è¨€ï¼Œ**æ•ˆç‡å®è·µ**éƒ½å¾—é ä½ è‡ªå·±ã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆâ€œæ•ˆç‡â€å’Œâ€œç¼–è¯‘â€æ˜¯ä¸¤ç§ä¸åŒçš„å®è·µï¼šå®ƒä»¬å¸¦æ¥çš„æ€§èƒ½æå‡æ¥æºä¸åŒã€‚æˆ‘ä»¬åœ¨ `frequency_2()` å’Œ `frequency_3()` é‡Œåšçš„ä¼˜åŒ–ï¼ŒåŒæ ·èƒ½è®© Rust ä»£ç æ›´å¿«ã€‚

ä¸ºè¯æ˜è¿™ä¸€ç‚¹ï¼Œæˆ‘æŠŠä¸Šé¢ä¸‰ä¸ª Python å‡½æ•°éƒ½ç§»æ¤åˆ°äº† Rustï¼ˆå‰ä¸¤ä¸ªæºç å¯ç‚¹å‡»å±•å¼€æŸ¥çœ‹ï¼‰ï¼š[ğŸ¦„](https://weekly.pythoncat.top)

å‰ä¸¤ä¸ªç‰ˆæœ¬åœ¨ Rust ä¸­çš„å®ç°

    #[pyfunction]
    fn frequency_1_rust(
        text: &str,
    ) -> PyResult<HashMap<char, u32>> {
        let mut counts = HashMap::new();
        for character in text.chars() {
            if character.is_alphabetic() {
                *counts
                    .entry(
                        character
                            .to_lowercase()
                            .next()
                            .unwrap_or(character),
                    )
                    .or_default() += 1;
            }
        }
        Ok(counts)
    }
    
    #[pyfunction]
    fn frequency_2_rust(
        text: &str,
    ) -> PyResult<HashMap<char, u32>> {
        let mut split_counts: HashMap<char, u32> =
            HashMap::new();
        for character in text.chars() {
            if character.is_alphabetic() {
                *split_counts.entry(character).or_default() +=
                    1;
            }
        }
    
        let mut counts = HashMap::new();
        for (character, num) in split_counts.drain() {
            *counts
                .entry(
                    character
                        .to_lowercase()
                        .next()
                        .unwrap_or(character),
                )
                .or_default() += num;
        }
        Ok(counts)
    }

ç¬¬ä¸‰ä¸ªç‰ˆæœ¬åœ¨ Rust é‡Œçš„æ ·å­ï¼š

    fn ascii_arr_to_letter_map(
        split_counts: [u32; 128],
    ) -> HashMap<char, u32> {
        let mut counts: HashMap<char, u32> = HashMap::new();
        for index in ('a' as usize)..=('z' as usize) {
            let character =
                char::from_u32(index as u32).unwrap();
            let upper_index =
                character.to_ascii_uppercase() as usize;
            counts.insert(
                character,
                split_counts[index] + split_counts[upper_index],
            );
        }
        counts
    }
    
    #[pyfunction]
    fn frequency_3_rust(text: &str) -> HashMap<char, u32> {
        let mut split_counts = [0u32; 128];
        for character in text.chars() {
            let character = character as usize;
            if character < 128 {
                split_counts[character] += 1;
            }
        }
    
        ascii_arr_to_letter_map(split_counts)
    }
    

æ‰€æœ‰ä¸‰ä¸ª Rust ç‰ˆæœ¬çš„ç»“æœéƒ½å’Œ Python ç‰ˆæœ¬ä¸€è‡´ï¼š

    assert_matches(frequency_1(TEXT), frequency_1_rust(TEXT))
    assert_matches(frequency_1(TEXT), frequency_2_rust(TEXT))
    assert_matches(frequency_1(TEXT), frequency_3_rust(TEXT))
    

å¯¹æ‰€æœ‰6ä¸ªç‰ˆæœ¬åšåŸºå‡†æµ‹è¯•ï¼Œæ¸…æ¥šåœ°è¯´æ˜äº†**æ•ˆç‡å®è·µ**å’Œ**ç¼–è¯‘å®è·µ**çš„æ€§èƒ½ä¼˜åŠ¿æ˜¯**ä¸åŒä¸”äº’è¡¥çš„**ã€‚èƒ½åŠ é€Ÿ Python ä»£ç çš„æ•ˆç‡ä¼˜åŒ–ï¼ŒåŒæ ·ä¹Ÿèƒ½åŠ é€Ÿ Rust ä»£ç ã€‚

å‡½æ•°

è¿è¡Œæ—¶é—´ (Âµs)

`frequency_1(TEXT)`

33,741.5

`frequency_2(TEXT)`

25,797.4

`frequency_3(TEXT)`

19,432.0

`frequency_1_rust(TEXT)`

3,704.3

`frequency_2_rust(TEXT)`

3,504.8

`frequency_3_rust(TEXT)`

**204.9**

ä¸€å¥è¯ï¼šæ•ˆç‡å’Œç¼–è¯‘æ˜¯ä¸¤ç§ä¸åŒçš„é€Ÿåº¦æ¥æºã€‚

å¹¶è¡ŒåŒ–å®è·µï¼šæ¦¨å¹²å¤šæ ¸CPU
-------------

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œä»£ç éƒ½åªè·‘åœ¨å•æ ¸CPUä¸Šã€‚ä½†ç°åœ¨çš„ç”µè„‘å¤§å¤šæœ‰å¤šæ ¸ï¼Œåˆ©ç”¨å¹¶è¡Œè®¡ç®—åˆæ˜¯**å¦ä¸€ç§**é€Ÿåº¦æ¥æºï¼Œæ‰€ä»¥å®ƒä¹Ÿæ˜¯ç‹¬ç«‹çš„å®è·µã€‚

ä¸‹é¢æ˜¯ç”¨ [Rayon åº“](https://docs.rs/rayon/latest/rayon/) å®ç°çš„ Rust å¹¶è¡Œç‰ˆæœ¬ï¼š

    fn sum(mut a: [u32; 128], b: [u32; 128]) -> [u32; 128] {
        for i in 0..128 {
            a[i] += b[i];
        }
        a
    }
    
    #[pyfunction]
    fn frequency_parallel_rust(
        py: Python<'_>,
        text: &str,
    ) -> HashMap<char, u32> {
        use rayon::prelude::*;
    
        // ç¡®ä¿é‡Šæ”¾å…¨å±€è§£é‡Šå™¨é”ï¼ˆGILï¼‰
        let split_counts = py.allow_threads(|| {
            // ä¸€ä¸ªæ¦¨å– Rayon æ›´å¤šæ€§èƒ½çš„æŠ€å·§ï¼š
            // æˆ‘ä»¬å…³å¿ƒçš„ ASCII å­—ç¬¦æ€»æ˜¯ç”±å•ä¸ªå­—èŠ‚æ˜ç¡®è¡¨ç¤ºã€‚
            // æ‰€ä»¥ç›´æ¥å¤„ç†å­—èŠ‚æ˜¯å®‰å…¨çš„ï¼Œè¿™èƒ½è®©æˆ‘ä»¬å¼ºåˆ¶ Rayon ä½¿ç”¨æ•°æ®å—ã€‚
            text.as_bytes()
                // å¹¶è¡Œè¿­ä»£æ•°æ®å—
                .par_chunks(8192)
                .fold_with(
                    [0u32; 128],
                    |mut split_counts, characters| {
                        for character in characters {
                            if *character < 128 {
                                split_counts
                                    [*character as usize] += 1;
                            };
                        }
                        split_counts
                    },
                )
                // åˆå¹¶æ‰€æœ‰æ•°æ®å—çš„ç»“æœ
                .reduce(|| [0u32; 128], sum)
        });
        ascii_arr_to_letter_map(split_counts)
    }
    

ç»“æœä¾ç„¶æ­£ç¡®ï¼š

    assert_matches(frequency_1(TEXT), frequency_parallel_rust(TEXT))
    

åŠ é€Ÿæ•ˆæœå¦‚ä¸‹ï¼š

| `frequency_3_rust(TEXT)` | 234.5 Âµs |  
| `frequency_parallel_rust(TEXT)` | **105.3 Âµs** |

æµç¨‹é‡è®¿ï¼šæˆ‘ä»¬æµ‹å¯¹äº†å—ï¼Ÿ
------------

æœ€ç»ˆå‡½æ•°å¿«äº†330å€â€¦â€¦çœŸçš„å—ï¼Ÿ

æˆ‘ä»¬æ˜¯é€šè¿‡å¤šæ¬¡è°ƒç”¨å‡½æ•°å–å¹³å‡è¿è¡Œæ—¶é—´æ¥æµ‹é‡æ€§èƒ½çš„ã€‚ä½†æˆ‘æ°å¥½çŸ¥é“ä¸€äº›èƒŒæ™¯çŸ¥è¯†ï¼š

*   Rust å­—ç¬¦ä¸²æ˜¯ UTF-8ï¼ŒPython ç”¨çš„æ˜¯è‡ªå·±çš„å†…éƒ¨æ ¼å¼ï¼Œ**ä¸æ˜¯** UTF-8ã€‚
*   æ‰€ä»¥è°ƒç”¨ Rust å‡½æ•°æ—¶ï¼ŒPython éœ€è¦æŠŠå­—ç¬¦ä¸²è½¬æˆ UTF-8ã€‚
*   Python ç”¨ç‰¹å®š API è½¬ UTF-8 æ—¶ä¼š[**ç¼“å­˜**è½¬æ¢ç»“æœ](https://docs.python.org/3/c-api/unicode.html#c.PyUnicode_AsUTF8AndSize)ã€‚

è¿™æ„å‘³ç€ï¼Œæˆ‘ä»¬å¾ˆå¯èƒ½æ²¡æµ‹åˆ° UTF-8 è½¬æ¢çš„æˆæœ¬ï¼Œå› ä¸ºåå¤å¯¹åŒä¸€ä¸ª `TEXT` å­—ç¬¦ä¸²åŸºå‡†æµ‹è¯•ï¼Œç¬¬ä¸€æ¬¡å UTF-8 ç‰ˆæœ¬å°±è¢«ç¼“å­˜äº†ã€‚çœŸå®åœºæ™¯ä¸‹ï¼Œæœªå¿…æ€»æœ‰ç¼“å­˜ã€‚

æˆ‘ä»¬å¯ä»¥æµ‹ä¸‹**å•æ¬¡**è°ƒç”¨æ–°å­—ç¬¦ä¸²çš„è€—æ—¶ã€‚æˆ‘ç”¨éå¹¶è¡Œç‰ˆæœ¬ï¼Œå› ä¸ºå®ƒé€Ÿåº¦æ›´ç¨³å®šï¼š

    from time import time
    
    def timeit(f, *args):
        start = time()
        f(*args)
        print("Elapsed:", int((time() - start) * 1_000_000), "Âµs")
    
    print("Original text")
    timeit(frequency_3_rust, TEXT)
    timeit(frequency_3_rust, TEXT)
    print()
    
    for i in range(3):
        # æ–°å­—ç¬¦ä¸²
        s = TEXT + str(i)
        print("New text", i + 1)
        timeit(frequency_3_rust, s)
        timeit(frequency_3_rust, s)
        print()
    

    Original text
    Elapsed: 212 Âµs
    Elapsed: 206 Âµs
    
    New text 1
    Elapsed: 769 Âµs
    Elapsed: 207 Âµs
    
    New text 2
    Elapsed: 599 Âµs
    Elapsed: 202 Âµs
    
    New text 3
    Elapsed: 625 Âµs
    Elapsed: 200 Âµs
    

å¯¹äºæ–°å­—ç¬¦ä¸²ï¼Œç¬¬ä¸€æ¬¡è¿è¡Œæ¯”ç¬¬äºŒæ¬¡æ…¢äº†å¤§çº¦ 400Âµsï¼Œè¿™å¾ˆå¯èƒ½å°±æ˜¯è½¬æ¢ä¸º UTF-8 çš„æˆæœ¬ã€‚[ğŸ¦„](https://weekly.pythoncat.top)

å½“ç„¶ï¼Œæˆ‘ä»¬åŠ è½½çš„ä¹¦**æœ¬èº«å°±æ˜¯ UTF-8 æ ¼å¼**ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬å¯ä»¥æ”¹å˜ APIï¼Œç›´æ¥å°† UTF-8 ç¼–ç çš„ `bytes` ä¼ é€’ç»™ Rust ä»£ç ï¼Œè€Œä¸æ˜¯å…ˆåŠ è½½åˆ° Pythonï¼ˆè½¬æ¢ä¸º Python å­—ç¬¦ä¸²ï¼‰ï¼Œå†ä¼ é€’ç»™ Rustï¼ˆè½¬æ¢å› UTF-8ï¼‰ï¼Œè¿™æ ·å°±èƒ½é¿å…è½¬æ¢å¼€é”€ã€‚

æˆ‘å®ç°äº†ä¸€ä¸ªæ–°å‡½æ•° `frequency_3_rust_bytes()`ï¼Œå®ƒæ¥å— UTF-8 ç¼–ç çš„å­—èŠ‚ï¼ˆæºç ç•¥ï¼Œä¸ `frequency_3_rust()` åŸºæœ¬ä¸€æ ·ï¼‰ã€‚ç„¶åæµ‹äº†ä¸‹å•ä¸ªå­—èŠ‚ä¸²ç¬¬ä¸€æ¬¡å’Œç¬¬äºŒæ¬¡çš„æ—¶é—´ï¼š

    with open("northanger_abbey.txt", "rb") as f:
        TEXT_BYTES = f.read()
    
    assert_matches(
        frequency_1(TEXT),
        frequency_3_rust_bytes(TEXT_BYTES)
    )
    
    print("æ–°æ–‡æœ¬ä¸å†æœ‰~400Âµsçš„è½¬æ¢å¼€é”€ï¼š")
    new_text = TEXT_BYTES + b"!"
    timeit(frequency_3_rust_bytes, new_text)
    timeit(frequency_3_rust_bytes, new_text)
    

    æ–°æ–‡æœ¬ä¸å†æœ‰~400Âµsçš„è½¬æ¢å¼€é”€ï¼š
    Elapsed: 186 Âµs
    Elapsed: 182 Âµs
    

å¦‚æœæˆ‘ä»¬æµ‹é‡æŒç»­çš„å¹³å‡æ—¶é—´ï¼Œå¯ä»¥çœ‹åˆ°å®ƒä¸ä¹‹å‰çš„ç‰ˆæœ¬å¤§è‡´ç›¸å½“ï¼š

| `frequency_3_rust(TEXT)` | 227.2 Âµs |  
| `frequency_3_rust_bytes(TEXT_BYTES)` | 183.8 Âµs |

å¯è§ä¼ å…¥ `bytes` ç¡®å®èƒ½ç»•è¿‡ UTF-8 è½¬æ¢æˆæœ¬ã€‚ä½ å¯èƒ½è¿˜æƒ³å®ç° `frequency_parallel_rust_bytes()`ï¼Œè¿™æ ·å¹¶è¡Œä¹Ÿèƒ½æ— è½¬æ¢å¼€é”€ã€‚

è¡¥å……ï¼šé‚£ä¹ˆ `collections.Counter` å‘¢ï¼Ÿ
------------------------------

ä½ å¯èƒ½ä¼šé—®ï¼ŒPython æ ‡å‡†åº“é‡Œä¸æ˜¯æœ‰ç°æˆçš„ `collections.Counter` å—ï¼Ÿå®ƒæ˜¯ä¸“é—¨è®¡æ•°çš„ `dict` å­ç±»ã€‚

    # æ¥è‡ª Python 3.13 çš„ collections/__init__.py
    def _count_elements(mapping, iterable):
        'Tally elements from the iterable.'
        mapping_get = mapping.get
        for elem in iterable:
            mapping[elem] = mapping_get(elem, 0) + 1
    
    try:
        # å¦‚æœå¯ç”¨ï¼ŒåŠ è½½ C è¯­è¨€å®ç°çš„è¾…åŠ©å‡½æ•°
        from _collections import _count_elements
    except ImportError:
        pass
    
    class Counter(dict):
        # ...
    

æˆ‘ä»¬å¯ä»¥è¿™æ ·ä½¿ç”¨å®ƒï¼š

    from collections import Counter
    
    def frequency_counter(text):
        return Counter(c.lower() for c in text if c.isalpha())
    
    # æ³¨æ„ï¼šè¿™é‡Œçš„å®ç°ä¸åŸæ–‡ç•¥æœ‰ä¸åŒï¼Œæ˜¯ä¸ºäº†ä¸ frequency_1 ä¿æŒå®Œå…¨ä¸€è‡´çš„è¡Œä¸º
    # åŸæ–‡çš„ Counter(text.lower()) ä¼šç»Ÿè®¡éå­—æ¯å­—ç¬¦ï¼Œå¯¼è‡´ç»“æœä¸ä¸€è‡´
    assert_matches(frequency_1(TEXT), frequency_counter(TEXT))
    

è¿™ä¸ªå®ç°æ¯”æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªç‰ˆæœ¬æ›´ç®€æ´ï¼Œä½†æ€§èƒ½å¦‚ä½•ï¼Ÿ

| `frequency_1(TEXT)` | 34,592.5 Âµs |  
| `frequency_counter(TEXT)` | çº¦ 30,000 Âµs |

`Counter` ç¡®å®æ¯”æˆ‘ä»¬çš„åˆå§‹å®ç°å¿«ç‚¹ï¼Œä½†è¿œä¸å¦‚æœ€ç»ˆä¼˜åŒ–ç‰ˆã€‚è¿™è¯´æ˜ï¼š**å³ä½¿æ ‡å‡†åº“çš„ä¼˜åŒ–å®ç°ï¼Œä¹Ÿå¯èƒ½æ¯”ä¸ä¸Šé’ˆå¯¹åœºæ™¯æ·±åº¦ä¼˜åŒ–çš„ä»£ç ã€‚**

å½“ç„¶ï¼Œ`Counter` èƒœåœ¨ç®€æ´å’Œå¯è¯»æ€§ã€‚å¾ˆå¤šå¯¹æ€§èƒ½æ²¡æè‡´è¦æ±‚çš„åœºæ™¯ï¼Œè¿™ç§æƒè¡¡å®Œå…¨å€¼å¾—ã€‚

æ€§èƒ½å®è·µï¼šç›¸è¾…ç›¸æˆ
---------

å…¨æ–‡å…¶å®ä¸€ç›´åœ¨ç”¨â€œæµç¨‹â€å®è·µï¼šæµ‹è¯•æ–°ç‰ˆæœ¬æ­£ç¡®æ€§ã€åšæ€§èƒ½åˆ†æå’Œæµ‹é‡ã€‚åŸºå‡†æµ‹è¯•è¿˜å¸®æˆ‘æ’é™¤äº†ä¸å°‘æ— æ•ˆä¼˜åŒ–ï¼Œè¿™é‡Œå°±ä¸èµ˜è¿°äº†ã€‚

â€œæ•ˆç‡â€å®è·µå¸®æˆ‘ä»¬æ¶ˆé™¤æ— ç”¨åŠŸï¼Œâ€œç¼–è¯‘â€è®©ä»£ç æ›´å¿«ï¼Œâ€œå¹¶è¡ŒåŒ–â€åˆ™è®©å¤šæ ¸CPUç«åŠ›å…¨å¼€ã€‚æ¯ç§å®è·µéƒ½æ˜¯ç‹¬ç‰¹çš„ã€èƒ½å¸¦æ¥ä¹˜æ•°æ•ˆåº”çš„é€Ÿåº¦æ¥æºã€‚

ä¸€å¥è¯ï¼šå¦‚æœä½ æƒ³è®©ä»£ç æ›´å¿«ï¼Œåˆ«åªç›¯ç€ä¸€ç§å®è·µï¼Œå¤šç®¡é½ä¸‹ï¼Œé€Ÿåº¦æ‰ä¼šé£èµ·æ¥ï¼

* * *

PythonçŒ«æ³¨ï¼šå¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œé‚£æˆ‘è¦å‘ä½ æ¨èä¸€ä¸‹ [Python æ½®æµå‘¨åˆŠ](https://weekly.pythoncat.top)ï¼åˆ›åˆŠä»…ä¸¤å¹´ï¼Œæˆ‘ä»¬å·²åšæŒåˆ†äº«äº†è¶…è¿‡ 1300+ ç¯‡ä¼˜è´¨æ–‡ç« ï¼Œä»¥åŠ 1200+ ä¸ªå¼€æºé¡¹ç›®æˆ–å·¥å…·èµ„æºï¼Œæ¯å‘¨ç²¾é€‰ï¼ŒåŠ©åŠ›ä½ æ‰“ç ´ä¿¡æ¯å·®ï¼Œå‘Šåˆ«ä¿¡æ¯è¿‡è½½ï¼Œæˆä¸ºæ›´ä¼˜ç§€çš„äººï¼