---
layout: post
title: 'DeploySharp 全面支持 YOLO26 系列，助力开发者快速部署落地应用'
date: "2026-01-20T00:44:44Z"
---
DeploySharp 全面支持 YOLO26 系列，助力开发者快速部署落地应用
========================================

![DeploySharp 全面支持 YOLO26 系列，助力开发者快速部署落地应用](https://img2024.cnblogs.com/blog/2933426/202601/2933426-20260119224728680-943487144.png) DeploySharp是一个专为C#开发者设计的跨平台模型部署框架，全面支持YOLOv26系列模型，包括目标检测、实例分割、姿态估计和旋转框检测。该框架提供多引擎支持(OpenVINO/ONNX Runtime/TensorRT)、两种图像处理库选择(ImageSharp/OpenCvSharp)以及跨平台运行时兼容性。通过模块化架构和NuGet包生态，开发者可以快速部署YOLOv26模型，实现从模型加载到推理执行的端到端解决方案。项目开源且支持多种硬件设备，为计算机视觉应用落地提供高效工具。

DeploySharp 全面支持 YOLO26 系列，助力开发者快速部署落地应用
========================================

一、DeploySharp 简介
----------------

DeploySharp 是一个专为 C# 开发者设计的跨平台模型部署框架，旨在提供从模型加载、配置管理到推理执行的端到端解决方案。该项目由 椒颜皮皮虾开发并开源，遵循 Apache 2.0 许可协议，目前在 GitHub 上获得了广泛关注。

DeploySharp 采用了清晰的模块化架构设计：

*   **根命名空间**：`DeploySharp` 作为统一入口，集成模型加载、推理执行等核心功能
*   **子命名空间**：通过 `DeploySharp.Engine`、`DeploySharp.Data`、`DeploySharp.Model` 等子命名空间实现模块化分层
*   **泛型设计**：关键类采用泛型设计，支持图像处理、分类、检测等多任务标准数据交互

**项目地址**：

    https://github.com/guojin-yan/DeploySharp.git
    

### 1\. 多引擎支持

DeploySharp 原生支持三种主流推理引擎：

推理引擎

状态

支持设备

性能特点

OpenVINO

完成

CPU、GPU0(集显)、GPU1(独显)、NPU

Intel 硬件优化

ONNX Runtime

完成

CPU、GPU(CUDA/DML)

跨平台兼容性好

TensorRT

完成

GPU(TensorRT)

NVIDIA GPU 极致性能

### 2\. 图像处理支持

框架提供了两种图像处理库的选择：

图像处理库

特点

适用场景

ImageSharp

纯 C# 实现，跨平台兼容性好，无原生依赖

跨平台应用、Web 应用

OpenCvSharp

OpenCV 的 C# 封装，功能强大，性能优异

桌面应用、高性能场景

### 3\. 跨平台运行时支持

DeploySharp 兼容了广泛的 .NET 运行时环境：

*   .NET Framework 4.8 / 4.8.1
*   .NET Core 3.1
*   .NET 5.0
*   .NET 6.0
*   .NET 7.0
*   .NET 8.0
*   .NET 9.0
*   .NET 10.0

### 4\. NuGet 包生态

#### 4.1 核心包

包名

描述

NuGet 链接

JYPPX.DeploySharp

DeploySharp API 核心库

[](https://www.nuget.org/packages/JYPPX.DeploySharp/)

**核心包功能**：

*   推理引擎抽象接口
*   数据结构定义
*   模型配置基类
*   性能分析工具
*   日志系统
*   可视化基础功能

#### 4.2 图像处理扩展包

包名

描述

NuGet 链接

JYPPX.DeploySharp.ImageSharp

使用 ImageSharp 的图像处理扩展

[](https://www.nuget.org/packages/JYPPX.DeploySharp.ImageSharp/)

JYPPX.DeploySharp.OpenCvSharp

使用 OpenCvSharp 的图像处理扩展

[](https://www.nuget.org/packages/JYPPX.DeploySharp.OpenCvSharp/)

**扩展包功能**：

*   图像加载和保存
*   图像预处理实现
*   可视化功能实现
*   批量处理支持

### 5\. 模型支持列表

截至目前，DeploySharp 已经完成了以下模型的封装，更多模型持续更新中：

Model Name

Model Type

OpenVINO

ONNX Runtime

TensorRT

**YOLOv5**

Detection

✅

✅

✅

**YOLOv5**

Segmentation

✅

✅

✅

**YOLOv6**

Detection

✅

✅

✅

**YOLOv7**

Detection

✅

✅

✅

**YOLOv8**

Detection

✅

✅

✅

**YOLOv8**

Segmentation

✅

✅

✅

**YOLOv8**

Pose

✅

✅

✅

**YOLOv8**

Oriented Bounding Boxes

✅

✅

✅

**YOLOv9**

Detection

✅

✅

✅

**YOLOv9**

Segmentation

✅

✅

✅

**YOLOv10**

Detection

✅

✅

✅

**YOLOv11**

Detection

✅

✅

✅

**YOLOv11**

Segmentation

✅

✅

✅

**YOLOv11**

Pose

✅

✅

✅

**YOLOv11**

Oriented Bounding Boxes

✅

✅

✅

**YOLOv12**

Detection

✅

✅

✅

**Anomalib**

Segmentation

✅

✅

✅

**PP-YOLOE**

Detection

✅

✅

✅

**DEIMv2**

Detection

✅

✅

✅

**RFDETR**

Detection

✅

✅

✅

**RFDETR**

Segmentation

✅

✅

✅

**RTDETR**

Detection

✅

✅

✅

**YOLO26**

Detection

✅

✅

✅

**YOLO26**

Segmentation

✅

✅

✅

**YOLO26**

Pose

✅

✅

✅

**YOLO26**

Oriented Bounding Boxes

✅

✅

✅

二、DeploySharp 对 YOLOv26 的全面支持
-----------------------------

DeploySharp 框架为 YOLOv26 系列模型提供了全方位的支持，涵盖了目标检测、实例分割、姿态估计和旋转框检测四种主要任务类型。

### 2.1 支持的 YOLOv26 模型类型

模型类型

功能描述

枚举值

配置类

YOLOv26Det

目标检测

`ModelType.YOLOv26Det`

`Yolov26DetConfig`

YOLOv26Seg

实例分割

`ModelType.YOLOv26Seg`

`Yolov26SegConfig`

YOLOv26Pose

人体姿态估计

`ModelType.YOLOv26Pose`

`Yolov26PoseConfig`

YOLOv26Obb

旋转框检测

`ModelType.YOLOv26Obb`

`Yolov26ObbConfig`

### 2.2 架构设计

DeploySharp 为 YOLOv26 提供了三层架构设计：

#### 接口层 (IYolov26XxxModel)

在核心库 `DeploySharp` 中定义了统一的接口：

    // YOLOv26 检测接口
    // IYolov26DetModel 继承自 IYolov10DetModel
    // 这种设计使得 YOLOv26 可以复用 YOLOv10 的成熟实现
    public abstract class IYolov26DetModel : IYolov10DetModel
    {
        /// <summary>
        /// 构造函数，接收模型配置
        /// </summary>
        /// <param name="config">YOLOv26 检测模型配置对象</param>
        public IYolov26DetModel(Yolov26DetConfig config) : base(config)
        {
            // 使用日志系统记录模型初始化信息
            MyLogger.Log.Info($"Initializing {this.GetType().Name}, Config:\n{config}");
        }
    }
    

#### 配置层 (Yolov26XxxConfig)

每种模型类型都有对应的配置类，提供灵活的参数设置：

    // YOLOv26 检测配置类
    // 继承自 Yolov10DetConfig，复用 YOLOv10 的成熟配置
    public class Yolov26DetConfig : Yolov10DetConfig
    {
        /// <summary>
        /// 默认构造函数
        /// </summary>
        public Yolov26DetConfig() { }
    
        /// <summary>
        /// 带模型路径的构造函数
        /// 自动设置合理的默认参数
        /// </summary>
        /// <param name="modelPath">模型文件路径</param>
        public Yolov26DetConfig(string modelPath)
        {
    		...
        }
    }
    

#### 实现层 (Yolov26XxxModel)

分别提供 ImageSharp 和 OpenCvSharp 两种实现，开发者可以根据需求选择。

### 2.3 类继承关系图

    YoloDetConfig (基类)
        ├── Yolov8DetConfig
        ├── Yolov10DetConfig
        └── Yolov26DetConfig (继承自 Yolov10DetConfig)
    
    YoloModel (基类)
        ├── Yolov8DetModel
        ├── Yolov10DetModel
        └── Yolov26DetModel (继承自 Yolov10DetModel)
    

这种继承设计的优势：

1.  **代码复用**：YOLOv26 可以复用 YOLOv10 的成熟实现
2.  **一致性**：保持与其他 YOLO 版本的 API 一致性
3.  **易维护**：共享的代码逻辑集中管理

三、YOLOv26 目标检测代码实现
------------------

### 3.1 使用 ImageSharp 作为图像处理库 + TensorRT 推理后端

#### （1）NuGet 包安装

使用 ImageSharp 作为图像处理库、TensorRT 作为推理后端时，需要安装以下核心包：

**DeploySharp 基础库及扩展库**：

    JYPPX.DeploySharp
    JYPPX.DeploySharp.ImageSharp
    

**TensorRT Runtime 库**：

    JYPPX.TensorRT.CSharp.API.runtime.win-x64.cuda11
    或
    JYPPX.TensorRT.CSharp.API.runtime.win-x64.cuda12
    

**注意**：TensorRT Runtime 库的版本需根据本地设备安装的 CUDA 版本进行选择。

#### （2）代码实现

以下代码可直接复制运行：

    using DeploySharp.Model;       // 引入模型相关定义
    using DeploySharp.Data;        // 引入数据处理相关
    using DeploySharp.Engine;      // 引入推理引擎核心
    using DeploySharp;             // 引入 DeploySharp 主库
    using SixLabors.ImageSharp;    // ImageSharp 图像处理库
    using SixLabors.ImageSharp.PixelFormats; // ImageSharp 像素格式
    
    namespace DeploySharp.ImageSharp.Demo
    {
        /// <summary>
        /// YOLO26目标检测演示类
        /// 该类展示了如何加载 TensorRT 引擎文件，对图像进行推理并可视化结果。
        /// </summary>
        public class YOLOv26DetDemo
        {
            public static void Run()
            {
                // ==========================================
                // 1. 路径配置
                // ==========================================
                
                // 模型下载提示：模型和测试图片可以前往QQ群(945057948)下载
                // 设置 .engine 文件路径。
                // 注意：TensorRT 的 .engine 文件是硬件相关的，即在 RTX 3090 上生成的 engine 通常不能在 RTX 4090 上运行。
                string modelPath = @"D:\Program Files\TensorRT-10.13.0.35-cu11\bin\yolo26s.engine";
                
                // 设置待推理的图片路径
                string imagePath = @"E:\Data\image\bus.jpg";
                // ==========================================
                // 2. 模型配置初始化
                // ==========================================
                
                // 创建  YOLO26 的配置对象，传入模型路径
                Yolov26DetConfig config = new Yolov26DetConfig(modelPath);
                
                // 设置最大批处理大小。
                // 即使只推理一张图片，设置适当的 BatchSize 有时也能利用 GPU 并行能力。
                // 此处设为 2 表示引擎内部最大可以一次处理 2 张图，但要首先保证模型支持。
                config.MaxBatchSize = 2;
                
                // 显式指定推理后端为 TensorRT。
                // DeploySharp 支持多种后端（如 ONNX Runtime, OpenVINO 等），这里强制使用 TensorRT 以获得最佳性能。
                config.SetTargetInferenceBackend(InferenceBackend.TensorRT);
                // ==========================================
                // 3. 类别字典定义
                // ==========================================
                
                // COCO 数据集的 80 个类别名称列表
                // YOLO 模型通常输出的是类别的索引（0-79），我们需要将其映射为人类可读的字符串。
                List<string> d = new List<string> { "person", "bicycle", "car", "motorcycle", "airplane", "bus",
                    "train", "truck", "boat", "traffic light", "fire hydrant", "stop sign", "parking meter", "bench",
                    "bird", "cat", "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack",
                    "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite",
                    "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "wine glass",
                    "cup", "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli", "carrot",
                    "hot dog", "pizza", "donut", "cake", "chair", "couch", "potted plant", "bed", "dining table", "toilet",
                    "tv", "laptop", "mouse", "remote", "keyboard", "cell phone", "microwave", "oven", "toaster", "sink",
                    "refrigerator", "book", "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush" };
                // 将列表转换为字典，Key 为索引，Value 为类别名称
                Dictionary<int, string> CategoryDict = new Dictionary<int, string>();
                for (int i = 0; i < d.Count; i++)
                {
                    CategoryDict[i] = d[i];
                }
                
                // 将类别字典赋值给配置对象，用于后续结果解析
                config.CategoryDict = CategoryDict;
                // ==========================================
                // 4. 模型实例化
                // ==========================================
                
                // 根据配置初始化检测器模型。
                // 此步骤会加载 engine 文件到内存，并初始化 GPU 上下文。
                Yolov26DetModel model = new Yolov26DetModel(config);
                
                // 使用 SixLabors.ImageSharp 加载图片。
                // Image.Load 会自动根据文件扩展名解码图片。
                var img = Image.Load(imagePath);
                // ==========================================
                // 5. 模型推理与性能测试
                // ==========================================
                
                // 执行第一次推理。
                // 注意：TensorRT 的首次推理通常包含 Kernel 初始化等开销，速度会比后续推理慢。
                DetResult[] result = model.Predict(img);
                
                // 执行第二次推理。
                // 这次推理的时间更能代表模型在实际场景中的平均推理速度。
                result = model.Predict(img);
                
                // 执行第三次推理（可选），用于进一步取平均值或确保稳定性。
                result = model.Predict(img);
                
                // 打印推理性能分析记录。
                // 这通常会输出预处理、推理、后端处理各阶段的耗时（毫秒级）。
                model.ModelInferenceProfiler.PrintAllRecords();
                
                // 初始化一个列表，虽然本例未直接使用，但在处理多图结果时可能会用到。
                List<Image<Rgb24>> resultsMat = new List<Image<Rgb24>>();
                // ==========================================
                // 6. 结果可视化与保存
                // ==========================================
                
                // 将推理结果绘制在原图上。
                // Visualize.DrawDetResult 会根据 DetResult 中的坐标和置信度画框和文字。
                // 需要将 img 强制转换为 Image<Rgb24>，因为 DrawDetResult 通常需要特定的像素格式。
                var resultImg = Visualize.DrawDetResult(result, (Image<Rgb24>)img, new VisualizeOptions(1.0f));
                // 保存带有检测框的图片到当前目录下。
                // 文件名包含配置的模型类型，便于区分不同模型的结果。
                resultImg.Save(@$"./result_{config.ModelType}.jpg");
            }
        }
    }
    

#### （3）代码详解

1.  **配置模型参数**：
    
        Yolov26DetConfig config = new Yolov26DetConfig(modelPath);
        config.MaxBatchSize = 2;
        config.SetTargetInferenceBackend(InferenceBackend.TensorRT);
        
    
    *   创建配置对象，使用 TensorRT 引擎进行推理
    *   设置最大批量大小为 2，支持最多 2 张图片的批量推理
2.  **创建模型实例**：
    
        Yolov26DetModel model = new Yolov26DetModel(config);
        
    
    模型实例化时会自动加载 .engine 文件并初始化 TensorRT 引擎。
    
3.  **执行推理**：
    
        DetResult[] result = model.Predict(img);
        
    
    `Predict()` 方法返回检测结果数组，每个元素包含边界框、置信度和类别信息。
    
4.  **性能分析**：
    
        model.ModelInferenceProfiler.PrintAllRecords();
        
    
    打印详细的性能统计，包括预处理、推理、后处理各阶段的耗时。
    

#### （4）结果展示

控制台打印输出：

推理结果图片：

### 3.2 使用 OpenCvSharp做图像处理库+ONNX Runtime推理后端

#### （1）NuGet 包安装

使用 OpenCvSharp 作为图像处理库、ONNX Runtime 作为推理后端时，需要安装以下核心包：

**DeploySharp 基础库及扩展库**：

    JYPPX.DeploySharp
    JYPPX.DeploySharp.OpenCvSharp
    

**OpenCvSharp Runtime 库**：

    OpenCvSharp4.runtime.win
    

**可选加速包**：ONNX Runtime 支持多种推理加速方式，除默认 CPU 加速外，可根据需求安装以下 NuGet 包：

加速方式

NuGet 包名

OpenVINO 加速

Intel.ML.OnnxRuntime.OpenVino

DirectML 加速

Microsoft.AI.DirectML

CUDA 加速

Microsoft.ML.OnnxRuntime.Gpu

更多加速方式请参考 ONNX Runtime 官方文档。本节以 DirectML 为例进行演示。

#### （2）代码实现

推理代码如下所示，可直接复制运行：

    using OpenCvSharp;            // 引入 OpenCvSharp，用于图像的读取、显示和矩阵操作
    using DeploySharp.Model;      // 引入模型定义和配置类
    using DeploySharp.Data;       // 引入数据处理相关的类
    using DeploySharp.Engine;     // 引入推理引擎核心接口和枚举
    using DeploySharp;            // 引入 DeploySharp 主库和可视化工具
    namespace DeploySharp.OpenCvSharp.Demo
    {
        /// <summary>
        ///  YOLO26 目标检测演示 (基于 ONNX Runtime + OpenCvSharp)
        /// 本示例展示了如何加载 ONNX 模型，并配置使用 DirectML 在 GPU 上进行推理。
        /// </summary>
        public class Yolov26DetDemo
        {
            public static void Run()
            {
                // ==========================================
                // 1. 路径配置
                // ==========================================
                
                // 模型下载提示：模型和测试图片可以前往QQ群(945057948)下载
                // 注意：此处加载的是标准的 .onnx 模型文件，而不是 TensorRT 的 .engine 文件。
                // ONNX 模型具有良好的跨平台特性。
                string modelPath = @"E:\Model\yolov28\yolo26s.onnx";
                
                // 设置待检测的图片路径
                string imagePath = @"E:\Data\image\bus.jpg";
                // ==========================================
                // 2. 模型配置与推理后端设置
                // ==========================================
                
                // 创建  YOLO26 的配置对象，传入模型路径
                Yolov26DetConfig config = new Yolov26DetConfig(modelPath);
                
                // [关键步骤] 设置推理后端为 ONNX Runtime。
                // 这意味着模型将通过 ONNX Runtime 进行加载和执行，而不是 TensorRT。
                config.SetTargetInferenceBackend(InferenceBackend.OnnxRuntime);
                
                // 设置目标设备类型为 GPU 0。
                // 这是一个逻辑设定，具体执行取决于 ONNX Runtime 的提供程序。
                config.SetTargetDeviceType(DeviceType.GPU0);
                
                // [关键步骤] 设置 ONNX Runtime 的具体执行提供程序为 DML (DirectML)。
                // DirectML 是 Windows 上的高性能硬件加速接口，支持 AMD、NVIDIA 和 Intel 显卡。
                // 如果不加这一行，ONNX Runtime 可能默认使用 CPU 进行推理，速度较慢。
                config.SetTargetOnnxRuntimeDeviceType(OnnxRuntimeDeviceType.DML);
                // ==========================================
                // 3. 类别字典定义 (COCO 80类)
                // ==========================================
                
                // 定义 COCO 数据集的 80 个类别名称
                // 这些名称将用于在结果可视化时标注检测到的物体
                List<string> d = new List<string> { "person", "bicycle", "car", "motorcycle", "airplane", "bus",
                    "train", "truck", "boat", "traffic light", "fire hydrant", "stop sign", "parking meter", "bench",
                    "bird", "cat", "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack",
                    "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite",
                    "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "wine glass",
                    "cup", "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli", "carrot",
                    "hot dog", "pizza", "donut", "cake", "chair", "couch", "potted plant", "bed", "dining table", "toilet",
                    "tv", "laptop", "mouse", "remote", "keyboard", "cell phone", "microwave", "oven", "toaster", "sink",
                    "refrigerator", "book", "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush" };
                // 构建<索引, 类别名>字典
                Dictionary<int, string> CategoryDict = new Dictionary<int, string>();
                for (int i = 0; i < d.Count; i++)
                {
                    CategoryDict[i] = d[i];
                }
                
                // 将类别字典赋值给配置对象
                config.CategoryDict = CategoryDict;
                // ==========================================
                // 4. 模型初始化
                // ==========================================
                
                // 实例化模型，传入配置。
                // 此时 DeploySharp 会根据配置加载 ONNX 模型，并初始化 DirectML 会话。
                Yolov26DetModel model = new Yolov26DetModel(config);
                
                // 使用 OpenCvSharp 读取图片到 Mat 对象中
                // Mat 是 OpenCV 中用于存储图像数据的核心矩阵结构
                Mat img = Cv2.ImRead(imagePath);
                // ==========================================
                // 5. 模型推理 (预热与测试)
                // ==========================================
                
                // 执行多次推理。
                // 第一次推理通常包含模型加载、内存分配等初始化开销，耗时较长。
                Result[] result = model.Predict(img);
                
                // 后续推理用于测试稳定的推理速度。
                result = model.Predict(img);
                result = model.Predict(img);
                result = model.Predict(img);
                
                // 打印性能分析记录。
                // 这将输出推理过程中各阶段（如预处理、推理执行、后处理）的耗时统计。
                model.ModelInferenceProfiler.PrintAllRecords();
                
                // 初始化列表，用于存储处理后的图像（本例主要用于演示）
                List<Mat> resultsMat = new List<Mat>();
                // ==========================================
                // 6. 结果可视化与显示
                // ==========================================
                
                // 调用可视化工具，将检测框（矩形框）和类别标签绘制在原图上。
                // VisualizeOptions(1.0f) 可能指定了缩放比例或字体大小等参数。
                var resultImg = Visualize.DrawDetResult(result, img, new VisualizeOptions(1.0f));
                
                // 将绘制好的图像加入列表
                resultsMat.Add(resultImg);
                
                // 使用 OpenCV 的窗口显示结果图像。
                // "image" 是窗口的标题。
                Cv2.ImShow("image", resultImg);
                
                // 等待按键输入。
                // 参数 0 表示无限期等待，直到用户按下键盘任意键。
                // 这是为了防止控制台程序执行完毕后窗口立即闪退。
                Cv2.WaitKey();
            }
        
        }
    }
    

#### （3）代码详解

上述代码与 3.1 节的代码结构基本相似，主要区别在于推理后端的配置：

1.  **设置推理后端为 ONNX Runtime**：
    
        config.SetTargetInferenceBackend(InferenceBackend.OnnxRuntime);
        
    
2.  **设置推理设备为 GPU**（此处使用独显设备）：
    
        config.SetTargetDeviceType(DeviceType.GPU0);
        
    
3.  **配置 DirectML 加速**：DirectML 是 Windows 上的高性能硬件加速接口，支持 AMD、NVIDIA 和 Intel 显卡，使用简单且无需复杂配置。
    
        config.SetTargetOnnxRuntimeDeviceType(OnnxRuntimeDeviceType.DML);
        
    

#### （4）结果展示

控制台输出如下。使用 DirectML 调用显卡加速，虽在速度上与 TensorRT 相比有所差距，但其配置简单、无需复杂设置的优势依然明显，适合快速开发验证。

### 3.3 使用 OpenCvSharp 作为图像处理库 + OpenVINO 推理后端

#### （1）NuGet 包安装

使用 OpenCvSharp 作为图像处理库、OpenVINO 作为推理后端时，需要安装以下核心包：

**DeploySharp 基础库及扩展库**：

    JYPPX.DeploySharp
    JYPPX.DeploySharp.OpenCvSharp
    

**Runtime 库**：

    OpenCvSharp4.runtime.win
    OpenVINO.runtime.win
    

#### （2）代码实现

推理代码如下所示，可直接复制运行：

    using OpenCvSharp;            // 引入 OpenCvSharp，用于图像的读取、显示和矩阵操作
    using DeploySharp.Model;      // 引入模型定义和配置类
    using DeploySharp.Data;       // 引入数据处理相关的类
    using DeploySharp.Engine;     // 引入推理引擎核心接口和枚举
    using DeploySharp;            // 引入 DeploySharp 主库和可视化工具
    namespace DeploySharp.OpenCvSharp.Demo
    {
        /// <summary>
        ///  YOLO26 目标检测演示 (基于OpenVINO  + OpenCvSharp)
        /// </summary>
        public class Yolov26DetDemo
        {
            public static void Run()
            {
                // ==========================================
                // 1. 路径配置
                // ==========================================
                
                // 模型下载提示：模型和测试图片可以前往QQ群(945057948)下载
                // 注意：此处加载的是标准的 .onnx 模型文件，而不是 TensorRT 的 .engine 文件。
                // ONNX 模型具有良好的跨平台特性。
                string modelPath = @"E:\Model\yolov28\yolo26s.onnx";
                
                // 设置待检测的图片路径
                string imagePath = @"E:\Data\image\bus.jpg";
                // ==========================================
                // 2. 模型配置
                // ==========================================
                
                // 创建 YOLO26Det 的配置对象，传入模型路径
                Yolov26DetConfig config = new Yolov26DetConfig(modelPath);
                
                // ==========================================
                // 3. 类别字典定义 (COCO 80类)
                // ==========================================
                
                // 定义 COCO 数据集的 80 个类别名称
                // 这些名称将用于在结果可视化时标注检测到的物体
                List<string> d = new List<string> { "person", "bicycle", "car", "motorcycle", "airplane", "bus",
                    "train", "truck", "boat", "traffic light", "fire hydrant", "stop sign", "parking meter", "bench",
                    "bird", "cat", "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack",
                    "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball", "kite",
                    "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", "wine glass",
                    "cup", "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", "broccoli", "carrot",
                    "hot dog", "pizza", "donut", "cake", "chair", "couch", "potted plant", "bed", "dining table", "toilet",
                    "tv", "laptop", "mouse", "remote", "keyboard", "cell phone", "microwave", "oven", "toaster", "sink",
                    "refrigerator", "book", "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush" };
                // 构建<索引, 类别名>字典
                Dictionary<int, string> CategoryDict = new Dictionary<int, string>();
                for (int i = 0; i < d.Count; i++)
                {
                    CategoryDict[i] = d[i];
                }
                
                // 将类别字典赋值给配置对象
                config.CategoryDict = CategoryDict;
                // ==========================================
                // 4. 模型初始化
                // ==========================================
                
                // 实例化模型，传入配置。
                // 此时 DeploySharp 会根据配置加载 ONNX 模型，并初始化 DirectML 会话。
                Yolov26DetModel model = new Yolov26DetModel(config);
                
                // 使用 OpenCvSharp 读取图片到 Mat 对象中
                // Mat 是 OpenCV 中用于存储图像数据的核心矩阵结构
                Mat img = Cv2.ImRead(imagePath);
                // ==========================================
                // 5. 模型推理 (预热与测试)
                // ==========================================
                
                // 执行多次推理。
                // 第一次推理通常包含模型加载、内存分配等初始化开销，耗时较长。
                Result[] result = model.Predict(img);
                
                // 后续推理用于测试稳定的推理速度。
                result = model.Predict(img);
                result = model.Predict(img);
                result = model.Predict(img);
                
                // 打印性能分析记录。
                // 这将输出推理过程中各阶段（如预处理、推理执行、后处理）的耗时统计。
                model.ModelInferenceProfiler.PrintAllRecords();
                
                // 初始化列表，用于存储处理后的图像（本例主要用于演示）
                List<Mat> resultsMat = new List<Mat>();
                // ==========================================
                // 6. 结果可视化与显示
                // ==========================================
                
                // 调用可视化工具，将检测框（矩形框）和类别标签绘制在原图上。
                // VisualizeOptions(1.0f) 可能指定了缩放比例或字体大小等参数。
                var resultImg = Visualize.DrawDetResult(result, img, new VisualizeOptions(1.0f));
                
                // 将绘制好的图像加入列表
                resultsMat.Add(resultImg);
                
                // 使用 OpenCV 的窗口显示结果图像。
                // "image" 是窗口的标题。
                Cv2.ImShow("image", resultImg);
                
                // 等待按键输入。
                // 参数 0 表示无限期等待，直到用户按下键盘任意键。
                // 这是为了防止控制台程序执行完毕后窗口立即闪退。
                Cv2.WaitKey();
            }
        
        }
    }
    

#### （3）代码详解

上述代码与 3.2 节的代码结构基本相似。使用 OpenVINO 作为推理后端时，通常无需额外设置，因为 DeploySharp 默认支持 OpenVINO。

若设备配备英特尔的集成显卡、独立显卡或 NPU，可通过以下代码指定推理设备以获得更好的性能：

    config.SetTargetInferenceBackend(InferenceBackend.OpenVINO);
    config.SetTargetDeviceType(DeviceType.GPU0);   // 设置设备为集显
    // 或
    config.SetTargetDeviceType(DeviceType.GPU1);  // 设置推理设备为独立显卡
    // 或
    config.SetTargetDeviceType(DeviceType.NPU);  // 设置推理设备为 NPU
    

#### （4）结果展示

控制台输出如下。使用 OpenVINO 在 CPU 上进行推理时，虽因设备限制推理速度有限，但 OpenVINO 已是 CPU 环境下推理速度最快的工具之一，且配置简单，全面支持英特尔全系设备，欢迎开发者使用。

四、YOLOv26 实例分割
--------------

### 4.1 代码使用示例

    using OpenCvSharp;            // 引入 OpenCvSharp，用于图像读取、显示及矩阵操作
    using DeploySharp.Model;      // 引入模型配置相关的类
    using DeploySharp.Data;       // 引入数据结果定义相关的类
    using DeploySharp.Engine;     // 引入推理引擎核心接口
    using DeploySharp;            // 引入 DeploySharp 主库及可视化工具
    
    namespace DeploySharp.OpenCvSharp.Demo
    {
        /// <summary>
        /// YOLO26Seg 实例分割演示类
        /// 本示例展示如何加载 TensorRT 引擎文件，对图像进行实例分割推理，并将掩码绘制在原图上。
        /// </summary>
        public class Yolov26SegDemo
        {
            public static void Run()
            {
                // ==========================================
                // 1. 路径配置
                // ==========================================
                
                // 模型下载提示：模型和测试图片可以前往QQ群(945057948)下载
                // 设置 TensorRT 引擎文件路径。
                // 注意：这里使用的是 .engine 文件，它是针对特定 GPU 和 TensorRT 版本编译的。
                // 文件名中的 '-seg' 表示这是一个带有分割头的实例分割模型。
                string modelPath = @"D:\Program Files\TensorRT-10.13.0.35-cu11\bin\yolo26s-seg.engine";
                
                // 设置待推理的图片路径
                string imagePath = @"E:\Data\image\bus.jpg";
    
    
                // ==========================================
                // 2. 模型配置与初始化
                // ==========================================
                
                // 创建 YOLO26Seg (实例分割) 的配置对象，传入模型路径
                Yolov26SegConfig config = new Yolov26SegConfig(modelPath);
                
                // [关键设置] 指定推理后端为 TensorRT。
                // 利用 TensorRT 可以在 NVIDIA GPU 上获得极高的推理速度。
                config.SetTargetInferenceBackend(InferenceBackend.TensorRT);
                
                // 实例化模型。
                // 此时会加载引擎文件，初始化 GPU 显存上下文。
                Yolov26SegModel model = new Yolov26SegModel(config);
    
    
                // ==========================================
                // 3. 图像加载
                // ==========================================
                
                // 使用 OpenCvSharp 读取图片。
                // img 是一个 Mat 对象，包含了图像的像素数据。
                Mat img = Cv2.ImRead(imagePath);
    
    
                // ==========================================
                // 4. 模型推理 (预热与性能测试)
                // ==========================================
                
                // 执行第一次推理。
                // 首次运行通常包含模型加载、显存分配等开销，耗时较长。
                var result = model.Predict(img);
                
                // 执行后续多次推理。
                // 这是为了排除初始化开销，测试模型在稳定状态下的推理速度。
                result = model.Predict(img);
                result = model.Predict(img);
                result = model.Predict(img);
                
                // 打印推理性能分析记录。
                // 这将输出预处理、推理计算、后处理（包括掩码生成）各阶段的耗时。
                model.ModelInferenceProfiler.PrintAllRecords();
    
    
                // ==========================================
                // 5. 结果可视化
                // ==========================================
                
                // 调用可视化工具，绘制分割结果。
                // 注意这里使用的是 DrawSegResult (绘制分割结果)，而不是 DrawDetResult (绘制检测框)。
                // 该函数会将检测到的物体框、类别标签以及彩色的半透明掩码绘制在原图上。
                var resultImg = Visualize.DrawSegResult(result, img, new VisualizeOptions(1.0f));
                
                // 使用 OpenCV 窗口显示渲染后的结果图像。
                Cv2.ImShow("image", resultImg);
                
                // 等待按键输入，防止窗口闪退。
                Cv2.WaitKey();
            }
        }
    }
    
    

### 4.2 代码详解

1.  **创建分割配置**：
    
        Yolov26SegConfig config = new Yolov26SegConfig(modelPath);
        config.SetTargetInferenceBackend(InferenceBackend.TensorRT);
        
    
    `Yolov26SegConfig` 是 YOLOv26 分割模型的配置类。
    
2.  **执行分割推理**：
    
        var result = model.Predict(img);
        
    
    分割推理返回 `SegResult[]` 数组，每个元素包含边界框、置信度、类别和分割掩码。
    
3.  **可视化分割结果**：
    
        var resultImg = Visualize.DrawSegResult(result, img, new VisualizeOptions(1.0f));
        
    
    `DrawSegResult` 会为每个检测到的对象绘制不同颜色的掩码，叠加在原图上。
    

### 4.3 分割结果展示

#### 控制台输出

以下三张截图分别展示了在 TensorRT GPU、ONNX Runtime(DirectML) GPU、OpenVINO CPU 设备下的推理性能。不同引擎各有优势，开发者可根据自身硬件环境选择最适合的方案。

**TensorRT GPU：**

**ONNX Runtime (DirectML) GPU：**

**OpenVINO CPU：**

#### 推理结果绘制

下图为官方预训练模型导出后的推理结果示例：

五、YOLOv26 人体姿态估计
----------------

### 5.1 功能介绍

YOLO26 Pose 模型用于检测人体关键点，通常支持 17 个关键点（头部、颈部、肩膀、手肘、手腕、臀部、膝盖、脚踝等）。

**关键点定义**（COCO 格式）：

关键点

名称

描述

0

nose

鼻子

1

left\_eye

左眼

2

right\_eye

右眼

3

left\_ear

左耳

4

right\_ear

右耳

5

left\_shoulder

左肩

6

right\_shoulder

右肩

7

left\_elbow

左肘

8

right\_elbow

右肘

9

left\_wrist

左腕

10

right\_wrist

右腕

11

left\_hip

左髋

12

right\_hip

右髋

13

left\_knee

左膝

14

right\_knee

右膝

15

left\_ankle

左踝

16

right\_ankle

右踝

### 5.2 代码使用示例

    using OpenCvSharp;            // 引入 OpenCvSharp，用于图像的读取、显示和矩阵操作
    using DeploySharp.Model;      // 引入模型定义和配置类
    using DeploySharp.Data;       // 引入数据结果相关的类
    using DeploySharp.Engine;     // 引入推理引擎核心接口
    using DeploySharp;            // 引入 DeploySharp 主库和可视化工具
    using System;                 // 引入 System 命名空间以使用 Console
    
    namespace DeploySharp.OpenCvSharp.Demo
    {
        /// <summary>
        /// YOLO26Pose 姿态估计演示类
        /// 本示例展示了如何加载 ONNX 模型进行人体关键点检测，并可视化骨骼连接。
        /// </summary>
        public class Yolov26PoseDemo
        {
            public static void Run()
            {
                // ==========================================
                // 1. 路径配置
                // ==========================================
                
                // 模型下载提示：模型和测试图片可以前往QQ群(945057948)下载
                // 设置 ONNX 模型文件路径。
                // '-pose' 后缀表示这是一个专门用于姿态估计（关键点检测）的模型。
                string modelPath = @"E:\Model\yolov28\yolo26s-pose.onnx";
                
                // 设置待推理的图片路径
                string imagePath = @"E:\Data\image\demo_9.jpg";
    
    
                // ==========================================
                // 2. 模型配置与初始化
                // ==========================================
                
                // 创建 YOLO26Pose (姿态估计) 的配置对象，传入模型路径
                Yolov26PoseConfig config = new Yolov26PoseConfig(modelPath);
                
                // [关键设置] 设置推理后端为 ONNX Runtime。
                // 这使得模型可以跨平台运行，不仅限于 NVIDIA GPU（取决于 ONNX Runtime 的安装提供程序）。
                config.SetTargetInferenceBackend(InferenceBackend.OnnxRuntime);
                
                // 实例化姿态估计模型。
                // 模型加载时会解析 ONNX 图结构，准备好输入输出节点。
                Yolov26PoseModel model = new Yolov26PoseModel(config);
    
    
                // ==========================================
                // 3. 图像加载
                // ==========================================
                
                // 使用 OpenCvSharp 读取图片。
                Mat img = Cv2.ImRead(imagePath);
    
    
                // ==========================================
                // 4. 模型推理与结果查看
                // ==========================================
                
                // 执行推理。
                // 第一次推理通常较慢，包含初始化开销。
                var result = model.Predict(img);
                
                // 执行多次推理以测试稳定状态下的性能。
                result = model.Predict(img);
                result = model.Predict(img);
                result = model.Predict(img);
                
                // 打印第一个结果的详细信息到控制台。
                // 姿态估计的 Result 对象通常包含检测框信息以及一个关键点数组。
                // 这一行有助于开发者调试，查看模型输出的原始数据结构。
                Console.WriteLine(result[0].ToString());
                
                // 打印性能分析记录，查看各阶段耗时。
                model.ModelInferenceProfiler.PrintAllRecords();
    
    
                // ==========================================
                // 5. 结果可视化
                // ==========================================
                
                // 调用可视化工具，绘制姿态估计结果。
                // 注意这里使用的是 DrawPoses，它会自动将识别出的关键点（如眼睛、肩膀、肘部等）
                // 用圆点标出，并根据人体结构连接成骨架。
                // VisualizeOptions(1.0f) 可能指定了绘制时的线条粗细或字体缩放比例。
                var resultImg = Visualize.DrawPoses(result, img, new VisualizeOptions(1.0f));
                
                // 显示结果图像。
                Cv2.ImShow("image", resultImg);
                
                // 等待按键，防止窗口闪退。
                Cv2.WaitKey();
            }
        }
    }
    
    

### 5.3 代码详解

1.  **创建姿态估计配置**：
    
        Yolov26PoseConfig config = new Yolov26PoseConfig(modelPath);
        config.SetTargetInferenceBackend(InferenceBackend.OnnxRuntime);
        
    
    `Yolov26PoseConfig` 是 YOLOv26 姿态估计模型的配置类。
    
2.  **执行姿态估计推理**：
    
        var result = model.Predict(img);
        
    
    姿态估计推理返回 `KeyPointResult[]` 数组，每个元素包含人体边界框、置信度和 17 个关键点坐标。
    
3.  **可视化姿态估计结果**：
    
        var resultImg = Visualize.DrawPoses(result, img, new VisualizeOptions(1.0f));
        
    
    `DrawPoses` 会绘制人体骨架（连接关键点）和关键点标记。
    

### 5.4 结果展示

#### 控制台输出

以下截图展示了在 ONNX Runtime CPU 设备下的推理性能：

#### 推理结果绘制

下图为官方预训练模型导出后的推理结果示例：

六、YOLOv26 旋转框检测
---------------

YOLOv26 OBB (Oriented Bounding Box) 模型用于检测旋转物体，生成带有旋转角度的边界框。这对于检测航空影像中的建筑物、遥感图像中的车辆等场景非常重要。

### 6.1 代码使用示例

以下代码演示如何使用 TensorRT 引擎进行旋转目标检测：

    using OpenCvSharp;            // 引入 OpenCvSharp，用于图像读取、显示及绘图
    using DeploySharp.Model;      // 引入模型配置相关的类
    using DeploySharp.Data;       // 引入数据结果定义相关的类
    using DeploySharp.Engine;     // 引入推理引擎核心接口
    using DeploySharp;            // 引入 DeploySharp 主库及可视化工具
    namespace DeploySharp.OpenCvSharp.Demo
    {
        /// <summary>
        /// YOLOv26 OBB 旋转目标检测演示类
        /// 本示例展示如何加载 TensorRT 引擎文件，对图像进行旋转目标检测，并绘制旋转框。
        /// </summary>
        public class Yolov26ObbDemo
        {
            public static void Run()
            {
                // ==========================================
                // 1. 路径配置
                // ==========================================
                
                // 模型下载提示：模型和测试图片可以前往 QQ 群（945057948）下载
                // '-obb' 表示该模型用于输出旋转边界框
                string modelPath = @"D:\Program Files\TensorRT-10.13.0.35-cu11\bin\yolo26s-obb.engine";
                
                // 设置待推理的图片路径
                // plane.png 是旋转目标检测的经典测试图（飞机停机坪通常包含各种角度的飞机）。
                string imagePath = @"E:\Data\image\plane.png";
                // ==========================================
                // 2. 模型配置与初始化
                // ==========================================
                
                // 创建 YOLOv26 OBB (旋转目标检测) 的配置对象，传入模型路径
                Yolov26ObbConfig config = new Yolov26ObbConfig(modelPath);
                
                // [关键设置] 指定推理后端为 TensorRT。
                // 这将调用 NVIDIA GPU 进行高性能计算。
                // 注意：因为使用的是 .engine 文件，所以必须选择 TensorRT 后端。
                config.SetTargetInferenceBackend(InferenceBackend.TensorRT);
                
                // 实例化旋转目标检测模型。
                Yolov26ObbModel model = new Yolov26ObbModel(config);
                // ==========================================
                // 3. 图像加载
                // ==========================================
                
                // 使用 OpenCvSharp 读取图片。
                Mat img = Cv2.ImRead(imagePath);
                // ==========================================
                // 4. 模型推理
                // ==========================================
                
                // 执行推理。
                var result = model.Predict(img);
                
         
                // 如果需要测试纯推理速度（排除初始化开销），可以取消注释进行多次循环。
                result = model.Predict(img);
                result = model.Predict(img);
                result = model.Predict(img);
                
                // 打印性能分析记录。
                // 这将显示预处理、TensorRT 推理、后处理（包含 OBB 解码）的耗时。
                model.ModelInferenceProfiler.PrintAllRecords();
                // ==========================================
                // 5. 结果可视化
                // ==========================================
                
                // 调用可视化工具，绘制旋转检测结果。
                // DrawObbResult 会根据检测到的 x, y, w, h 和 angle (角度) 绘制旋转矩形。
                var resultImg = Visualize.DrawObbResult(result, img, new VisualizeOptions(1.0f));
                
                // [可选] 调整图片大小以适应屏幕
                // 航拍图通常分辨率很大，可以缩小显示。
                //Cv2.Resize(resultImg, resultImg, new Size(resultImg.Width / 4, resultImg.Height / 4));
                
                // 显示结果图像。
                Cv2.ImShow("image", resultImg);
                
                // 等待按键，防止窗口闪退。
                Cv2.WaitKey();
            }
        }
    }
    

### 6.2 代码详解

1.  **创建旋转框检测配置**：
    
        Yolov26ObbConfig config = new Yolov26ObbConfig(modelPath);
        config.SetTargetInferenceBackend(InferenceBackend.TensorRT);
        
    
    `Yolov26ObbConfig` 是 YOLOv26 旋转框检测模型的配置类。
    
2.  **执行旋转框检测推理**：
    
        ObbResult[] result = model.Predict(img);
        
    
    旋转框检测推理返回 `ObbResult[]` 数组，每个元素包含中心点、宽度、高度、旋转角度和类别信息。
    
3.  **可视化旋转框检测结果**：
    
        var resultImg = Visualize.DrawObbResult(result, img, new VisualizeOptions(1.0f));
        
    
    `DrawObbResult` 会绘制旋转的边界框（四边形），而不是普通的轴对齐矩形。
    

### 6.3 旋转框检测结果展示

#### 控制台输出

以下截图展示了在 TensorRT GPU 设备下的推理性能：

#### 推理结果绘制

下图为官方预训练模型导出后的推理结果示例：

七、跨引擎支持
-------

DeploySharp 原生支持 OpenVINO、ONNX Runtime、TensorRT 三大主流推理引擎，为开发者在 CPU、GPU、NPU 等不同硬件设备上部署模型提供了最全面的解决方案。集成的 YOLOv26 系列默认支持所有推理引擎，开发者可根据实际硬件环境选择最优的推理方案。

### 7.1 引擎性能对比

引擎

优势

适用场景

性能特点

OpenVINO

Intel 硬件优化，支持多种设备（CPU、GPU0、GPU1、NPU）

Intel CPU、Intel GPU、NPU

Intel 硬件加速

ONNX Runtime

广泛支持，跨平台，兼容性好

CPU、GPU(CUDA/DML)、移动端

平衡性能与兼容性

TensorRT

NVIDIA GPU 极致性能，经过专门优化

NVIDIA GPU 高性能场景

最佳 GPU 性能

### 7.2 引擎选择建议

根据硬件环境和应用场景选择合适的推理引擎：

硬件环境

推荐引擎

说明

Intel CPU/GPU

OpenVINO

Intel 硬件优化，性能最佳

NVIDIA GPU

TensorRT

极致性能，适合高频推理

NVIDIA GPU (需要灵活性)

ONNX Runtime (CUDA)

兼容性好，易于切换

通用 CPU

ONNX Runtime

跨平台兼容性好

### 7.3 引擎切换示例

    // 切换到 OpenVINO
    config.SetTargetInferenceBackend(InferenceBackend.OpenVINO);
    config.TargetDeviceType = DeviceType.CPU;
    
    // 切换到 ONNX Runtime (CUDA)
    config.SetTargetInferenceBackend(InferenceBackend.OnnxRuntime);
    config.TargetDeviceType = DeviceType.GPU;
    
    // 切换到 TensorRT
    config.SetTargetInferenceBackend(InferenceBackend.TensorRT);
    config.TargetDeviceType = DeviceType.GPU;
    

**注意**：切换推理引擎可能需要重新加载模型，建议在应用启动时确定使用的引擎。

八、性能优化建议
--------

### 8.1 预热机制

首次推理通常较慢，因为需要加载模型、初始化推理引擎、编译计算图等。建议执行几次预热推理。

    // 预热模型（执行 3 次推理）
    for (int i = 0; i < 3; i++)
    {
        model.Predict(img);
    }
    
    // 实际推理
    var result = model.Predict(img);
    

### 8.2 批量推理

对于大量图像，使用批量推理可以提高吞吐量，前提是模型支持多 Batch Size。

    // 设置批量大小为 4
    config.InferBatch = 4;
    
    // 准备批量图像
    var imageList = new List<Image<Rgb24>>();
    imageList.Add(Image.Load<Rgb24>(@"path1.jpg"));
    imageList.Add(Image.Load<Rgb24>(@"path2.jpg"));
    imageList.Add(Image.Load<Rgb24>(@"path3.jpg"));
    imageList.Add(Image.Load<Rgb24>(@"path4.jpg"));
    
    // 执行批量推理
    var results = model.Predict(imageList);
    

### 8.3 设备选择

根据硬件选择最优设备：

    // Intel 环境：使用 OpenVINO
    config.SetTargetInferenceBackend(InferenceBackend.OpenVINO);
    
    // NVIDIA 环境：使用 TensorRT 或 ONNX Runtime (CUDA)
    config.SetTargetInferenceBackend(InferenceBackend.TensorRT);
    config.TargetDeviceType = DeviceType.GPU;
    

九、总结
----

DeploySharp 对 YOLOv26 系列提供了全面而深入的支持，包括：

1.  **四种任务类型全覆盖**：检测、分割、姿态估计、旋转框检测
2.  **双图像处理库支持**：ImageSharp 和 OpenCvSharp
3.  **三推理引擎兼容**：OpenVINO、ONNX Runtime、TensorRT
4.  **完善的配置系统**：灵活的参数设置
5.  **详细的性能分析**：内置性能分析器
6.  **丰富的可视化选项**：支持多种结果展示方式

YOLOv26 的简化的输出格式和优化的架构，结合 DeploySharp 的封装和优化，使得开发者可以轻松地将 YOLOv26 集成到各种 C# 应用中，构建高效、准确的计算机视觉解决方案。

随着 YOLO 系列的持续发展，DeploySharp 也将持续跟进，为开发者提供最新模型的支持。期待 YOLOv26 及未来版本的更多创新和突破。

技术支持
----

如有问题或建议，欢迎通过以下方式交流：

*   📧 **GitHub Issues**：在项目仓库提 Issue 或 Pull Request
*   💬 **QQ 交流群**：加入 **945057948**，回复更方便更快哦

* * *

_作者：Guojin Yan_  
_版本：0.0.6.1_  
_最后更新：2026年1月_

* * *

**【文章声明】**

本文主要内容基于作者的研究与实践，部分表述借助AI工具进行了辅助优化。由于技术局限性，文中可能存在错误或疏漏之处，恳请各位读者批评指正。如果内容无意中侵犯了您的权益，请及时通过公众号后台与我们联系，我们将第一时间核实并妥善处理。感谢您的理解与支持！