---
layout: post
title: '吴恩达深度学习课程四：计算机视觉  第二周：经典网络结构 （一）经典卷积网络'
date: "2025-12-16T00:45:06Z"
---
吴恩达深度学习课程四：计算机视觉 第二周：经典网络结构 （一）经典卷积网络
=====================================

此分类用于记录吴恩达深度学习课程的学习笔记。  
课程相关信息链接如下：

1.  原课程视频链接：[\[双语字幕\]吴恩达深度学习deeplearning.ai](https://www.bilibili.com/video/BV1FT4y1E74V?buvid=XU762317353676D786954061C192FE625463B&from_spmid=playlist.playlist-detail.0.0&is_story_h5=false&mid=zqernykrmpf7XfIorMR%2FnA%3D%3D&plat_id=116&share_from=ugc&share_medium=android&share_plat=android&share_session_id=ce0bc526-db69-428a-962e-c65ed8c267bc&share_source=COPY&share_tag=s_i&spmid=united.player-video-detail.0.0&timestamp=1713085655&unique_k=DfBgvFW&up_id=8654113&vd_source=e035e9878d32f414b4354b839a4c31a4)
2.  github课程资料，含课件与笔记:[吴恩达深度学习教学资料](https://github.com/robbertliu/deeplearning.ai-andrewNG)
3.  课程配套练习（中英）与答案：[吴恩达深度学习课后习题与答案](https://blog.csdn.net/u013733326/article/details/79827273)

本篇为第四课的第二周内容，[2.1](https://www.bilibili.com/video/BV1FT4y1E74V/?p=119&spm_id_from=333.1007.top_right_bar_window_history.content.click&vd_source=e035e9878d32f414b4354b839a4c31a4)到[2.2](https://www.bilibili.com/video/BV1FT4y1E74V?spm_id_from=333.788.videopod.episodes&vd_source=e035e9878d32f414b4354b839a4c31a4&p=120)的内容。

* * *

本周为第四课的第二周内容，这一课所有内容的中心只有一个：**计算机视觉**。应用在深度学习里，就是专门用来进行图学习的模型和技术，是在之前全连接基础上的“特化”，也是相关专业里的一个重要研究大类。  
**这一整节课都存在大量需要反复理解的内容和机器学习、数学基础。** 因此我会尽可能的补足基础，用比喻和实例来演示每个部分，从而帮助理解。  
第二周的内容是对一些经典网络模型结构和原理的介绍，自然会涉及到相应的**文献论文**。因此，我也会在相应的模型下附上提出该模型的论文链接。  
本篇的内容关于一些早期经典的卷积网络模型，虽然距离这些模型的提出已经有了很长的时间，但这些模型的**设计思想和原理逻辑仍有很强的学习和应用价值**。

1.LeNet-5
=========

首先，提出 LeNet-5 模型的这篇论文发布于 **1998** 年，距离现在已经很远了，所以网络的设计中也存在一些现在看来“不合理”的地方。  
但是，这篇论文在今天最重要的价值，并不在于具体的参数配置或层级细节，而在于它**系统性地提出并验证了卷积神经网络的基本建模范式**，即通过“**卷积-池化-全连接**”的层级结构，实现从**局部特征到全局语义**的逐级抽象逻辑。这一逻辑思想为后续卷积网络的发展奠基并产生了深远影响。  
现在来详细看看这个模型：  
![image.png](https://img2024.cnblogs.com/blog/3708248/202512/3708248-20251215201506122-829101829.png)  
这就是它的网络结构，在现在看来甚至有些简单，但在当时的意义显示是重大的，LeNet-5 的一个成功应用领域就是我们之前[演示多分类模型](https://www.cnblogs.com/Goblinscholar/p/19263775)时使用的**手写数字图像识别**。在本周的实践部分我会再次用它来进行演示。  
现在，再说说 LeNet-5 的建模逻辑。  
![20251215185309203](https://img2024.cnblogs.com/blog/3708248/202512/3708248-20251215202342147-1110846370.png)  
这就是 LeNet-5 的伟大之处所在，用一句偏学术的话来总结：**LeNet-5说明视觉理解可以通过层级化的特征组合来实现，并用神经网络提供了一种可学习的实现方式。**

最后，这是 LeNet-5 原论文的**期刊索引链接**：[Gradient-Based Learning Applied to Document Recognition 期刊索引](https://ieeexplore.ieee.org/document/726791),你可以通过 Zotero 等文献管理软件把论文抓取到你的软件进行管理。  
当然，如果你不想这么麻烦，也可以通过这个链接**直接查看PDF**:[Gradient-Based Learning Applied to Document Recognition](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)

2.AlexNet
=========

提出 **AlexNet** 模型的论文发布于 **2012** 年，当时的计算机视觉正面临**大规模图像分类**的挑战。相比 LeNet-5，AlexNet 的网络更深、更大，但仍受到当时算力和经验的限制，这些设计细节虽然有局限，却不妨碍它成为现代深度卷积网络的里程碑。  
在那之前，人们更倾向于使用解释性更强的传统机器学习算法来完成视觉任务，而 AlexNet 的出现让业界看到深度学习的巨大潜力。它**系统性地展示了深度卷积神经网络在大规模视觉任务中的可行性**，通过**更深的卷积-池化-全连接**结构，并结合 **ReLU 激活、Dropout、数据增强以及 GPU 并行训练** 等技术，有效解决了大规模分类训练难题，让人们更愿意尝试使用深度学习来解决实际任务。  
![image.png](https://img2024.cnblogs.com/blog/3708248/202512/3708248-20251215201506439-302508690.png)  
此外，AlexNet 还使用了一种技术叫做局部响应归一化，简单来说就是对每个通道上同一位置的数进行归一化，但是现在已经被**淘汰**了，所以就不多说了。  
其中一种代替它的技术就是我们之前说过的[batch归一化](https://www.cnblogs.com/Goblinscholar/p/19232083)。  
PyTorch 里提供了 AlexNet 模型，并去除了局部响应归一化，同样，我会在本周的实践部分演示这个模型的效果。

最后，这是 AlexNet 原论文的**会议索引链接**：[ImageNet Classification with Deep Convolutional Neural Networks 会议索引](https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html),你可以通过 Zotero 等文献管理软件把论文抓取到你的软件进行管理。  
当然，如果你不想这么麻烦，也可以通过这个链接**直接查看PDF**:[ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)

3.VGG-16
========

提出 **VGG16** 模型的论文发布于 **2015** 年，当时计算机视觉领域已经在深度卷积网络上取得了显著进展，但如何设计更深、更有效的网络仍是关键问题。相比 AlexNet，VGG16 的网络更加深层（共有 16 个权重层），通过**堆叠小卷积核（3×3）的方式取代大卷积核，实现更强的特征表达能力，同时保持了结构的简单性。**  
来看看它的结构：  
![20251215200951921](https://img2024.cnblogs.com/blog/3708248/202512/3708248-20251215202244207-1680503632.png)  
VGG16 让当时的业界第一次看到，**卷积网络可以比 AlexNet 更深、更强，但仍可训练。**  
并且，VGG16的深层小卷积结构使得提取的特征通用且强大，让他更适合作为迁移学习的迁移来源。  
PyTorch 里同样提供了 VGG16 模型，我也会在本周的实践部分演示这个模型的效果。

最后，这是 VGG16 原论文的**会议索引链接**：[Very Deep Convolutional Networks for Large-Scale Image Recognition 会议索引](https://arxiv.org/abs/1409.1556),你可以通过 Zotero 等文献管理软件把论文抓取到你的软件进行管理。  
当然，如果你不想这么麻烦，也可以通过这个链接**直接查看PDF**:[Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/pdf/1409.1556)