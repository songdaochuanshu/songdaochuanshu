---
layout: post
title: '李飞飞的50美金比肩DeepSeek把CEO忽悠瘸了，倒霉的却是程序员'
date: "2025-02-14T00:35:50Z"
---
李飞飞的50美金比肩DeepSeek把CEO忽悠瘸了，倒霉的却是程序员
===================================

> 关注公众号**回复1**
> 
> 获取**一线、总监、高管《管理秘籍》**

书接上文：[DeepSeek怎么突然就比肩GPT了？](https://mp.weixin.qq.com/s/_zBVmPwPpxZC-aYs10UB2Q)

如前所述，应用层AI开发压根不会去刻意关注大模型底层实现，多数时候也关注不了。

但我们一定会关注的是**各种技术选型最终的优劣与效果**，其中关系最大的一定是**模型训练成本到底是多少？**

这个问题搞不清楚，后续做实现时候可能栽大跟头，想象一下你信誓旦旦的告诉CEO要去做模型训练，**几百万RMB丢进去，放个屁就没了，你觉得他会不会想要打死你？**

而近期因为想要**抢占DeepSeek热度**，很多**“老演员”**都在抢占注意力，这其实搞得很多技术负责人很难受：**因为，老板对训练的成本预期被标题党们带偏了**，比如网上流传的一篇文章：

**李飞飞**等斯坦福大学和华盛顿大学的研究人员以**不到 50 美元**的云计算费用，成功训练出了一个名为 s1 的人工智能推理模型。

如果真的有CEO相信了50美元的训练成本，然后再让技术负责人去做，那会把团队搞爆的...

AI应用的核心：成本
----------

模型开发离不开三要素：**算力、算法、数据**。其中底层算法与应用层关系不大，数据与算力的需求要看实际的应用。

比如做AI律师、AI医生、AI教师这种复杂AI项目，是跳不出去的，我粗略整理了一下（复杂AI应用）成本结构，大概是这样的：

成本项目

需要程度

成本预估

项目说明

研发团队（含产品）

★★★

不低

主要完成需求细化与具体实现，是大模型项目的核心部分。

领域专家团队（如律师、医生、老师）

★★☆

适中

提供行业KnowHow、初始规则与数据，帮助研发团队实现高效开发。

数据成本

★★★

不可控

数据是AI项目的核心，通常包括领域专家提供的数据以及其他额外数据。

训练成本

★☆☆

不可控

训练过程中需要大量算力，尤其在未优化前，成本非常高。

推理成本

★★★

可控

推理服务器是必须的，推理阶段的成本较为可控，主要作为服务器费用的一部分。

合规与安全成本

★☆☆

适中

涉及敏感数据的合规与安全性，特别是在医疗、金融等领域，需保证隐私保护与数据安全。

就过往经验来说，人力成本虽高，但他是可控的，并且可随时动态调整，长期来说也是公司的财富。

所以，尤为不可控的就是**数据成本与训练成本！**

### 一、数据成本

大模型对数据的质量要求极高，尤其是医疗、法律等领域，获取优质数据不仅需要支付高昂费用，往往还要依赖付费数据库或第三方合作。

大模型的训练需要大量标注数据，特别是涉及领域专家时，标注费用不容小觑。

数据的清洗与预处理更是一个耗费巨大资源的过程，**数据蒸馏在这块可以帮助很大，但必要的真人介入依旧难以避免。**

### 二、训练成本

将通用模型调整到特定领域（如法律、医疗）时，需要额外的计算资源和领域数据，通常每次微调都伴随着高额开销。

为了找到最佳的超参数配置，进行大量实验和计算是必须的，这无疑会进一步提高训练的成本。

为了降低推理成本，通常需要对模型进行压缩（如剪枝、量化等），这些优化步骤虽然能提高效率，但也需要额外的研发投入。

从这个角度再看**李飞飞的50美元成本**，突然就有点摸不着头脑了，但他已经搞得很多人很蛋疼。

**因为CEO们可不会管是不是真的，只要对他们有利，就认为是真的。但技术负责人必须搞清楚她到底怎么做到的？**

打开50美元
------

根据论文数据来源于对Gemini Thinking Experimental 模型的蒸馏1000 个样本小型数据集。

而后使用阿里的 Qwen2.5-32B-Instruct 进行监督微调；使用 16 个英伟达 H100 GPU 进行了 26 分钟的训练，而后发布信息：**媲美 DeepSeek R1、OpenAI o1 的 AI 推理模型**。

这就让人非常疑惑了，如果只考虑单次微调训练成本，如此小的数据量还用不了50美元，但是从前面的文章我们可以看出来两个问题：

1.  第一，李飞飞团队在数据上投入很小，蒸馏数据也花不了几个钱，简单信息AI完全就搞定了，也不需要进一步验证；
2.  第二，不能忽视基座模型Qwen2.5-32B-Instruct的前期投入，天知道阿里在模型调优和数据准备上花了多少钱；

但，无所谓，我们核心关注的是**成本与效果**，成本说不清楚就说效果，那么他真的用1000数据超过了o1吗？**想多了！**

从对比数据来看，s1只是在1000测试集数据的边界内表现不错，跳出这个边界可能撒也不是...

但是这就让我们很Emo了，因为老板真的让技术负责人拿着**10倍溢出500美金**去复现GPT。说实话，我虽然经常标题党，但他这个标题党的确实过份了...

另外回到1000个数据集这件事本身，就算有人真的基于某开源模型媲美了最顶级的模型能力，**那也不能说明什么！**

因为参数量大的大模型，其训练数据量也奇大无比，其结果是数据之中甚至可能会有冲突的情况，并且大数据量训练过程中还会伴随遗忘、覆盖等复杂场景，这其中的成本，绝不是小数据集训练可比拟的！

相比之下，小数据集训练通常意味着更少的复杂性和更容易控制的模型行为，但也会面临**欠拟合**的问题：即模型在面临新的、未见过的情境时表现得不够稳健。

因此，虽然小数据集的训练可以产生一些在特定测试集上表现优异的模型，但它并不能代表模型的通用能力或真实表现。

综上，这50美元无论从什么角度来看，都是不合理的...

但是，这里有个问题依旧没有被很好的解答**现在训练一个领域模型，到底成本如何？**

模型训练成本
------

对于AI应用来说，在效果差距不大的情况下，第一考虑一定是**实现成本**，而现在主流实现只有两条：

1.  **不训练模型。**基于知识图谱+模型的提示词后置策略；
2.  **训练模型。**基于领域模型的数据前置训练，API调用策略；

第一条路径在2024年，很多公司已经用过了，但市面上真正的AI产品爆款依旧没有出现，只能说明两个问题：

1.  第一，**可能技术路径能达到的效果有限**；
2.  第二，**无论产品需要的数据或者工程打磨的预期没有掌握好**；

我更相信是第二种：

> 本质上说，基于**知识图谱+强大基座模型**的AI应用和基于**垂直领域模型+Prompt**最终都是依赖与强大的**行业knowHow与工程能力**，不应该有太大差距
> 
> 所以，**如果知识图谱+GPT没做出来好的AI应用，换个路径也没那么容易**

而基于知识图谱（知识库）的技术路径，至少被实践了一年，其成本已经被各个公司摸得比较清晰，其中**包括初始建立知识库，后续根据数据更新再调整程序的成本。**

但DeepSeek出现后，训练的成本与之前相比却产生了巨大的变化。

> 这里之前做垂直领域模型训练的公司可能会哭晕在厕所...

所以DeepSeek的训练成本为什么那么低，其他开源模型能不能**复制他的低成本模式**变得很关键了，这会进一步影响技术路径选择，甚至很多人会尝试**混合路径**。

> 这里的点是：**无论知识图谱还是私有领域模型，都是公司壁垒，但显然领域模型更有噱头**

**PS：这里有误请您指出**

而我这里做了很多阅读，最终得出DeepSeek训练成本低的原因是综合的因素：

### 一、MTP架构

MTP（Multi-Token Prediction）：**多token预测技术**。

一种并行优化机制，可以让模型在训练时，同时预测多个连续位置的token。从而提升整体性能和推理速度。

传统的自回归模型在每次预测时都需要依赖前一步的输出，这意味着每个token的生成都依赖于前面已经生成的token。

而MTP通过并行化这一过程，减少了计算时间和资源的消耗，这对于大规模模型的训练尤其重要。

通过这种方式，DeepSeek能够更高效地使用计算资源，从而降低整体训练成本。

MTP不仅能够提升训练效率，还能够在推理阶段带来性能提升。由于模型能够同时生成多个token而不是逐步生成，因此推理速度也会大大加快。

这对于需要快速响应的实际应用场景来说，是一个重要的优势，能够显著减少延迟。

### 二、MoE架构

如前所述，大模型的训练依赖于海量数据，数据量过大其处理的复杂度将急剧上升，但如果是领域小模型的训练难度及成本就会好很多了。

这可能是DeepSeek使用混合专家模型（MoE）的原因。其核心思路包含三点：

1.  **专家模型**，MoE架构包含很多小模型，不同模型回答不同领域的问题；
2.  **“全科医生”**，他包含一个能力稍强的**通用模型**做信息分拆、意图识别，所有信息通过“全科医生”去找到最接近的（3个）**“科室医生模型”**，最后通过他们的回复，再由“全科医生”对外作答；

这个架构我认为是一种**工程降熵**的策略，因为参数过大的模型训练起来太费劲，那就用多个小模型去抵消一个大模型，从而**降低工程实现难度**。

### 三、数据蒸馏

就过往经验启示做数据蒸馏的成本是要高于服务器训练成本的。

因为数据蒸馏需要领域专家，而且数据会存在各种往复，这就会导致多轮数据处理，其成本是极高的。

但数据蒸馏（知识蒸馏）技术可以很好的规避这一切，相当于借助巨人的肩膀，使用优秀模型使用过的数据，这里的成本优化是很吓人的。

数据蒸馏减少了对大量标注数据的需求，最后结合**GRPO技术**，模型在学习过程中能够更好地应对噪声和不确定性，避免过拟合、加速收敛。

GRPO通过持续的反馈机制调整模型权重，确保模型在动态任务和复杂环境下保持较好的推理能力，从而进一步提升了训练效率。

### 四、KVcache

KVcache通过在推理过程中缓存 Key 和 Value 矩阵，避免重复计算，显著减少了自注意力机制的计算开销。

在生成每个新 token 时，模型只需计算当前 token 的 Query，并与缓存的 Key 和 Value 矩阵进行注意力计算，从而大幅提升推理速度并降低计算资源消耗。

在训练阶段，KV Cache 的作用有限，因为训练通常以批量方式进行，且需要完整的梯度计算。然而，在长序列训练中，KV Cache 仍可通过缓存部分结果提升效率。

但是 KV Cache会显著降低推理成本，为大规模应用提供了高效支持。

以上，大概是DeepSeek为什么成本低的原因，但具体到什么程度，还得等一段时间后工程应用后的真实数据。

结语
--

其实，国内云服务平台在DeepSeek的训练集成上速度会很快的，所以大部分知识后续会被云平台包装变成不可见的部分，这里需要持续跟进。

但，很有可能，留给我们的部分只会包含两点：

1.  训练数据的入口；
2.  API测试效果的出口；

所以，对于AI应用的各位来说，真正有用的知识可能是如何使用好**知识蒸馏**技术以及深入了解下MoE架构中尤其是门控系统是如何设计的，如果能迁移至工程实现是最好的。

未来，AI应用开发将更加注重成本与效果平衡，技术路径选择更加灵活。

无论是基于知识图谱的提示词策略，还是领域模型的前置训练，开发者需根据需求和资源做出最优决策。

DeepSeek的低成本模式为行业设立了标杆，推动更多企业探索高效、经济的解决方案。随着技术进步，AI应用开发的门槛将降低，创新应用的落地速度将加快，推动AI技术在各行业的深度渗透。

因此，开发者需持续关注技术动态，**并且一定要做好老板的预期管理，近期标题党太多，很容易引起老板们的AI焦虑，到时候吃亏的还是我们自己，**所以，加油吧。

**最后，文章有一些错漏，希望各位多指正。**

![](https://files.mdnice.com/user/25507/dfbdbae0-7236-421c-bbb0-badae3db3d76.png)

![](https://img2022.cnblogs.com/blog/294743/202202/294743-20220216140902628-1163053035.png)