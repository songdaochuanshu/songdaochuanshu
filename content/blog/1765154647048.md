---
layout: post
title: 'Nano-vLLM-Ascend'
date: "2025-12-08T00:44:07Z"
---
Nano-vLLM-Ascend
================

å‚è€ƒ  
[https://github.com/linzm1007/nano-vllm-ascend](https://github.com/linzm1007/nano-vllm-ascend)

Nano-vLLM-Ascend
----------------

nano-vllmæ˜¯å¼€æºçš„ä¸€ä¸ªgpuæ¨ç†é¡¹ç›®ï¼ŒåŸºäºå¼€æºç‰ˆæœ¬å¼„çš„ä¸€ä¸ªascend npuç‰ˆæœ¬æ¨ç†å°demoï¼Œæ—¨åœ¨å¸®åŠ©åˆå­¦è€…äº†è§£æ¨ç†çš„æ•´ä½“æµç¨‹ï¼ŒåŒºåˆ«äºvllmï¼Œnano-vllmä½“é‡æ›´å°ï¼Œéº»é›€è™½å°äº”è„ä¿±å…¨ï¼Œæ›´æœ‰åŠ©äºåˆå­¦è€…å­¦ä¹ ã€‚

æ¡†æ¶å±‚æµç¨‹å›¾
------

æ¨¡å‹å±‚æµç¨‹å›¾
------

ç‰¹æ€§
--

*   ğŸ“– **å¯è¯»ä»£ç åº“** - çº¦1200è¡ŒPythonä»£ç çš„æ¸…æ™°å®ç°
*   âš¡ **ä¼˜åŒ–å¥—ä»¶** - å¼ é‡å¹¶è¡Œã€Torchç¼–è¯‘ç­‰

*    å¾…å®Œæˆï¼šç›®å‰åªæ”¯æŒå•ç®—å­, npuå›¾æ¨¡å¼å®ç°
*    dummyæ–¹å¼åœ¨cpuç¯å¢ƒè¿è¡Œ
*    æ€§èƒ½ä¼˜åŒ–
*    ç›®å‰åªæ”¯æŒQwen3-0.6Bï¼Œæ”¯æŒæ›´å¤šæ¨¡å‹

é•œåƒä¸‹è½½
----

    docker login xx
    docker pull xxx/nano-vllm/nano-vllm-ascend:v1_20251112
    

å®¹å™¨è¿è¡Œ
----

    #!/bin/bash
    
    CONTAINER_NAME="xxx"
    
    # åœæ­¢å¹¶åˆ é™¤ç°æœ‰å®¹å™¨
    docker stop $CONTAINER_NAME 2>/dev/null
    docker rm $CONTAINER_NAME 2>/dev/null
    
    echo "Starting SSH container..."
    
    docker run -it --name=$CONTAINER_NAME \
            --shm-size=20g \
            --net=host \
            --privileged=true \
            -u root \
            -w /data \
            --device=/dev/davinci_manager \
            --device=/dev/hisi_hdc \
            --device=/dev/devmm_svm \
            -v /data:/data \
            -v /tmp:/tmp \
            -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \
            -v /usr/local/dcmi:/usr/local/dcmi \
            -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \
            -v /etc/ascend_install.info:/etc/ascend_install.info \
            -v /usr/local/sbin:/usr/local/sbin \
            -v /etc/hccn.conf:/etc/hccn.conf \
            -v /usr/bin/hccn_tool:/usr/bin/hccn_tool \
            -v /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime \
    	xxx/nano-vllm/nano-vllm-ascend:v1_20251112 bash
    
    

å®‰è£…ä¾èµ–
----

    pip install .
    

sshå®‰è£…
-----

    #!/bin/bash
    set -ex
    
    # é…ç½®openEulerè½¯ä»¶æº
    echo "é…ç½®openEulerè½¯ä»¶æº..."
    cat > /etc/yum.repos.d/openeuler.repo << 'EOF'
    [openEuler-everything]
    name=openEuler-everything
    baseurl=http://mirrors.tools.xx.com/openeuler/openEuler-22.03-LTS-SP4/everything/aarch64/
    enabled=1
    gpgcheck=0
    gpgkey=http://mirrors.tools.xx.com/openeuler/openEuler-22.03-LTS-SP4/everything/aarch64/RPM-GPG-KEY-openEuler
    
    [openEuler-EPOL]
    name=openEuler-epol
    baseurl=http://mirrors.tools.xx.com/openeuler/openEuler-22.03-LTS-SP4/EPOL/main/aarch64/
    enabled=1
    gpgcheck=0
    
    [openEuler-update]
    name=openEuler-update
    baseurl=http://mirrors.tools.xx.com/openeuler/openEuler-22.03-LTS-SP4/update/aarch64/
    enabled=1
    gpgcheck=0
    EOF
    
    yum clean all
    yum makecache  
    
    yum install passwd -y
    
    # è®¾ç½®rootç”¨æˆ·å¯†ç 
    echo "è®¾ç½®rootç”¨æˆ·å¯†ç ..."
    echo "root:xxxx-" | chpasswd
    
    # é…ç½®SSHæœåŠ¡
    echo "é…ç½®SSHæœåŠ¡..."
    # å¯ç”¨TCPè½¬å‘
    sed -i 's/^#AllowTcpForwarding yes/AllowTcpForwarding yes/' /etc/ssh/sshd_config
    # å¯ç”¨GatewayPorts
    sed -i 's/^#GatewayPorts no/GatewayPorts yes/' /etc/ssh/sshd_config
    # æ·»åŠ ç«¯å£6068ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
    if ! grep -q "^Port 6068" /etc/ssh/sshd_config; then
        echo "Port 6068" >> /etc/ssh/sshd_config
    fi
    
    # ç”ŸæˆSSHå¯†é’¥å¹¶é‡å¯æœåŠ¡
    echo "åˆå§‹åŒ–SSHæœåŠ¡..."
    ssh-keygen -A
    /usr/sbin/sshd
    
    echo "æ‰€æœ‰é…ç½®å®Œæˆï¼rootå¯†ç å·²è®¾ç½®ï¼ŒSSHæœåŠ¡å·²å¯åŠ¨ï¼ˆç›‘å¬ç«¯å£6068ï¼‰"
    

å®¹å™¨èµ·æ¥ï¼Œsshä¹Ÿå®‰è£…å¥½ï¼Œå¯ä»¥è¿œç¨‹è¿æ¥å®¹å™¨è¿è¡Œexample.py

æ¨¡å‹ä¸‹è½½
----

    huggingface-cli download --resume-download Qwen/Qwen3-0.6B \
      --local-dir ~/huggingface/Qwen3-0.6B/ \
      --local-dir-use-symlinks False
    

å¿«é€Ÿå¼€å§‹
----

è¯·å‚è§ example.py äº†è§£ç”¨æ³•ã€‚è¯¥ API ä¸ vLLM çš„æ¥å£åŸºæœ¬ä¸€è‡´ï¼Œä»…åœ¨ LLM.generate æ–¹æ³•ä¸Šå­˜åœ¨ä¸€äº›ç»†å¾®å·®å¼‚ï¼š

    from nanovllm import LLM, SamplingParams
    llm = LLM("/YOUR/MODEL/PATH", enforce_eager=True, tensor_parallel_size=1)
    sampling_params = SamplingParams(temperature=0.6, max_tokens=256)
    prompts = ["Hello, Nano-vLLM."]
    outputs = llm.generate(prompts, sampling_params)
    outputs[0]["text"]
    

exampleè¿è¡Œç»“æœ
-----------

ç¯å¢ƒ
--

ä»…ä¾›å‚è€ƒ  
ascend-dmi -c #æŸ¥çœ‹

*   ç¡¬ä»¶ç¯å¢ƒâ€‹ï¼š
    *   1.æ˜¾å¡:A3 910C
    *   2.é©±åŠ¨ç‰ˆæœ¬:24.1.rc3.10
    *   3.å›ºä»¶ç‰ˆæœ¬:7.5.0.109.220
*   è½¯ä»¶ç¯å¢ƒâ€‹ï¼š
    *   1.CANNåŒ… 8.3.RC1
    *   2.PTAç‰ˆæœ¬ï¼štorch-npu 2.5.1.post2+gitd7a85f8ï¼Œtorch 2.5.1

Benchmark
---------

See `bench.py` for benchmark.

**Test Configuration:**

*   Model: Qwen3-0.6B
*   Total Requests: 256 sequences
*   Input Length: Randomly sampled between 100â€“1024 tokens
*   Output Length: Randomly sampled between 100â€“1024 tokens

**Performance Results:**  
Nano-vLLM-Ascend å®åœ¨å¤ªæ…¢äº†åªè·‘äº†10æ¡seq  
Nano-vLLM-Ascendå¯ä»¥å¿½ç•¥\[å“­è„¸\]

Inference Engine

Output Tokens

Time (s)

Throughput (tokens/s)

vLLM

133,966

98.37

1361.84

Nano-vLLM

133,966

93.41

1434.13

Nano-vLLM-Ascend

4805

257.49

18.66

qwen3-0.6B layers
-----------------

    ModuleList(
      (0-27): 28 x Qwen3DecoderLayer(
        (self_attn): Qwen3Attention(
          (qkv_proj): QKVParallelLinear()
          (o_proj): RowParallelLinear()
          (rotary_emb): RotaryEmbedding()
          (attn): Attention()
          (q_norm): RMSNorm()
          (k_norm): RMSNorm()
        )
        (mlp): Qwen3MLP(
          (gate_up_proj): MergedColumnParallelLinear()
          (down_proj): RowParallelLinear()
          (act_fn): SiluAndMul()
        )
        (input_layernorm): RMSNorm()
        (post_attention_layernorm): RMSNorm()
      )
    )
    
    

è“å¤©å’Œç™½äº‘æ˜¯æ ‡é…ã€‚