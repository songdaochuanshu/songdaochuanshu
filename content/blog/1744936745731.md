---
layout: post
title: '重生之我是操作系统(十)----I/O管理'
date: "2025-04-18T00:39:05Z"
---
重生之我是操作系统(十)----I/O管理
---------------------

简介
==

操作系统的I/O管理(input/output mannagment)是协调，控制计算机与外部设备(如磁盘，键盘，网络接口)等之间数据交换的核心功能。实现可靠高效且统一(隐藏设备差异，如磁盘、串口、网卡的硬件特性)的设备访问

> 前几章讲述的CPU管理，内存管理，文件管理。都是在计算机主机内部进行的操作。  
> 而I/O管理是对外部设备进行操作。这中间一定会有一层"抽象"层

I/O控制器
======

CPU`无法直接控制`I/O设备的机械部分(比如硬盘的磁臂，显示器的灯珠等)，因此I/O设备还要有一个电子设备作为"中转"，由I/O设备提供给CPU，实现CPU对I/O设备的控制。这个设备叫做`I/O控制器`

I/O控制器需要有如下几个功能

1.  接受和识别CPU发出的指令  
    解析CPU发送的I/O指令，转化为设备可识别的操作，比如磁盘的寻址，扇区读写。
    
2.  向CPU报告设备状态  
    I/O控制器中会有相应的状态寄存器，来表示设备状态。忙碌or空闲
    
3.  数据交互
    
4.  地址识别
    

![image](https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250417121450313-1303522774.png)

以CPU向I/O设备输出数据为例子：

1.  CPU通过控制线向I/O控制器发送指令，并在地址线上说明要操作哪一个设备。
2.  CPU通过数据总线，得出I/O控制器的状态，假定状态空闲。
3.  CPU通过数据总线，将指令的参数放入控制寄存器。随后从后者取值
4.  CPU通过数据总线，输出数据到数据寄存器。随后从后者取值。
5.  与设备进行交互。

I/O控制方式
-------

I/O控制方式主要有四种：

1.  程序直接控制方式（Programmed I/O, Polling）  
    原理：cpu通过`不断轮询`，查询状态寄存器。直到设备ready。  
    优点：无需硬件中断，实现简单。  
    缺点：性能浪费，CPU空转。

> 场景：单片机电路开关，LED指示灯。

![image](https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250417114506973-458634665.png)

2.  中断驱动 I/O 方式（Interrupt-Driven I/O）  
    原理：CPU发送I/O请求后执行其它任务，I/O设备就绪时主动向CPU发送`中断信号`，触发CPU暂停当前任务，转为处理I/O中断。  
    优点：提高CPU利用率，且提高响应(鼠标移动)  
    缺点：中断每次都需要保存/恢复上下文。高频中断会导致CPU效率降低。

> 场景：鼠标、键盘、打印机等设备运行

![image](https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250417114724005-1254529636.png)

3.  直接内存访问方式(Direct Memory Access,DMA)  
    原理：通过专用的`DMA控制器代替数据总线`，直接在设备与内存之间传输数据，无需CPU干预。CPU仅仅在传输开始前配置DMA参数，传输完成后处理中断。  
    优点：CPU利用率接近100%，仅处理启动和完成中断。  
    缺点：需要硬件支持(DMAC)，且多个设备可能有竞争。如果CPU要读写离散的多个数据，需要发出多条I/O指令，无法做到多路复用。

> 场景：磁盘、SSD、网卡（需传输大量数据，如 GB 级文件读写）。显卡通过 DMA 直接访问内存帧缓冲区，提升图像渲染效率  
> 与中断驱动相比，DMA的传输单位变为了"block"，不再是一个字一个字的传输  
> 数据直接与内存交互，不再需要CPU作为快递小哥传输

![image](https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250417120243891-1904109636.png)

4.  通道控制方式（Channel I/O）  
    原理：引入独立于CPU的I/O通道处理器，专门负责处理 I/O 指令和设备通信。通道可执行专用的 “通道程序”，控制多个设备的并发操作，相当于一个`弱鸡版的CPU`  
    优点：解放CPU，无需CPU处理。一次性处理多条数据，多路复用。  
    缺点：成本极高，需要专用硬件。生态欠缺，需要依赖硬件厂商编写驱动程序。

> 场景：大型机、数据中心服务器（同时处理磁盘I/O ，网络I/O）。

**特性**

**程序直接控制**

**中断驱动**

**DMA**

**通道控制**

**CPU参与度**

全程参与（轮询）

仅处理中断

仅配置/收尾

仅发起请求

**数据传输方式**

CPU直接读写

CPU通过控制器读写

DMA控制器直接读写内存

通道处理器独立控制

**适用设备**

低速简单设备

中速交互式设备

高速块设备（磁盘、网卡）

多设备高并发（大型机）

**CPU利用率**

极低

中等

高

接近100%

**典型场景**

嵌入式传感器

键盘、打印机

磁盘文件读写

大型机数据中心

**硬件依赖**

无

中断控制器

DMA控制器

专用通道处理器

**传输单位**

字

字

块

一组块

I/O软件的层次结构
==========

在操作系统中，I/O 软件层次结构通过分层设计将复杂的输入输出功能解耦，实现硬件无关性、模块化和高效管理。  
![image](https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250417132147432-266086351.png)

1.  硬件层  
    执行具体操作，比如磁盘寻道，数据读写；生产中断信号；处理设备与内存之间的数据传输(DMA)。
2.  中断处理程序  
    响应中断；保存/恢复现场；通知驱动设备，比如数据就绪or错误。
3.  设备驱动程序  
    设备初始化；命令转换；I/O请求调度；状态监控
4.  与设备无关的 I/O 层  
    提供设备无关接口，比如通过文件描述符将设备视为“文件”，比如VFS系统;设备分配与回收；错误处理；缓冲区管理；元数据管理；
5.  用户层 I/O 软件  
    将系统调用封装为库函数;假脱机，多任务环境下，将独占设备模拟为共享设备，比如通过磁盘缓冲区实现打印机的多任务排队。

> 假脱机技术，又称“SPOOling技术”，全程Simultaneous Peripheral Operations On-Line。是操作系统用于将`独占设备`虚拟为共享设备的核心技术，通过磁盘作为中间缓冲区，使得多个进程能并发访问独占设备，提高系统利用率。

设备的分配与回收
--------

根据设备的使用方式，设备分为3类：

1.  独占设备  
    同一时间只能被一个进程占用，采用 静态或动态分配，分配后独占直到释放。
2.  共享设备  
    允许多个进程并发访问（通过分时或调度），采用 动态分配，效率高但需调度算法
3.  虚拟设备  
    通过磁盘缓冲区将独占设备模拟为共享设备，分配的是缓冲区资源而非物理设备本身

为了安全，高效的使用这些设备，分配设备时，需要遵循如下几个目标：

1.  资源利用率最大化  
    减少设备空闲时间，避免CPU忙等或阻塞
2.  避免死锁
3.  公平性与优先级  
    平衡各个进程之间的需求，优先处理高优先级任务。比如同时发生鼠标移动事件与打印机打印事件，孰轻孰重要拎得清。

设备的数据结构
-------

![image](https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250417135225287-1278191049.png)

1.  设备控制表(DCT)  
    每个物理设备一张表，记录设备类型，状态，当前占用进程，阻塞进程队列。
2.  控制器控制表(COCT)  
    记录控制器状态，对应通道的指针，等待队列。
3.  通道控制表(CHCT)  
    记录通道状态及分配情况（通道是控制外设与内存数据传输的硬件部件，需与控制器、设备配合使用）
4.  系统设备表(SDT)  
    全局表，列出系统所有设备的基本信息（类型、标识符、驱动程序入口等）

设备的分配策略
-------

从分配方式来说，可以分为两种：

1.  静态分配  
    原理：在进程启动前分配所有所需设备及相关资源(比如控制器，通道)，进程结束后统一回收。  
    优点：简单，不会死锁。  
    缺点：利用率低，进程很有可能"占着茅坑不拉屎"。
    
2.  动态分配  
    原理：进程运行时按需申请设备，使用完毕后立即释放。  
    优点：提高设备利用率。  
    缺点：可能因资源竞争导致死锁。
    

> 演化与内存分配方式的演化是一个套路，因此对于分配算法不再介绍，先来先服务，优先级高有限等等。都是一个思路。

对于一个设备，他被调用时，分配流程如下。

1.  请求设备  
    进程通过系统调用（如open()）申请设备，指定设备类型或逻辑名（设备无关性）
2.  检索数据结构  
    操作系统根据`逻辑设备名/物理设备名`找到SDT，再根据SDT找到DCT，若设备忙则将PCB挂到`设备等待队列`中，不忙则将设备分配给进程。  
    然后根据DCT找到COCT，若控制器忙则将PCB挂到`控制器等待队列中`，不忙则将控制器分配给进程。  
    然后根据COCT找到CHCT，若通道忙则将PCB挂到`通道等待对流中`，不忙则将通道分配给进程。

> 只有设备，控制器，通道 三个都分配成功时，这次设备分配才算成功，之后才能对I/O设备进行操作。

缓冲区管理
=====

**为什么需要缓冲区？**

1.  主要是为了缓和CPU与I/O设备之间速度不匹配的矛盾  
    CPU 处理速度远快于磁盘 I/O，缓冲区暂存数据可减少 CPU 等待外设的时间
2.  减少中断次数  
    批量数据传输，将多个数据块积攒起来，一次性写入到磁盘，降低CPU处理中断的频率。  
    如果是字符型设备，每输出一个字符就要向CPU发送一次中断信号
3.  解决数据颗粒度不匹配的问题  
    外设以块为单位传输，CPU 以字节为单位处理，缓冲区作为数据转换的中间层  
    ![image](https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250417154025428-1600356686.png)

缓冲区类型
-----

1.  单缓冲  
    原理：仅在内存中开辟一个缓冲区，CPU与I/O共享此缓冲区。  
    缺点：因为共享的缘故，CPU与I/O设备需串行工作，效率比较低  
    ![image](https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250417155009078-1411902968.png)
    
2.  双缓冲  
    原理：两个缓冲区（缓冲区 A 和 B）。CPU与I/O各自独占。  
    优点：实现 CPU 与外设的双向并行，提升效率。  
    缺点：仅适用于双向数据传输且数据量均衡的场景，否则就会出现一方等待另一方的现象。  
    ![image](https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250417155314251-1659285864.png)
    
3.  循环缓冲区  
    原理：多个固定大小的缓冲区连城环形队列，通过in/out指针管理，写指针指向可用缓冲区，读指针指向待处理缓冲区  
    ![image](https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250417161153847-1342327970.png)
    

> 本质上就是环形数组

4.  缓冲池  
    原理：多个共享缓冲区组成的池，按用途分为不同队列（如空缓冲队列、装满输入数据的缓冲队列、装满输出数据的缓冲队列）。  
    ![image](https://img2024.cnblogs.com/blog/1084317/202504/1084317-20250417161436895-1835937269.png)

posted on 2025-04-17 16:19  [叫我安不理](https://www.cnblogs.com/lmy5215006)  阅读(102)  评论(0)    [收藏](javascript:void\(0\))  [举报](javascript:void\(0\))