---
layout: post
title: '大数据技术领域发展与Spark的性能优化'
date: "2026-01-19T00:50:08Z"
---
大数据技术领域发展与Spark的性能优化
====================

**一、大数据技术领域发展方向**

随着AI时代的到来，大数据技术领域逐渐退居二线，再也没有了前些年的重视程度。博主近期结合从业多年经验，对大数据技术领域的技术演进路线做下梳理。

当前大数据领域发展已经进入深水区，随着各种成熟大数据框架的应用普及，难点已经从存不下、算不出，变为了如何高质量、高效计算数据并增加数据与价值的转换率，这就涉及到针对价值变现场景的数据设计和全生命周期的管理。这部分根据具体业务场景的差异，设计实现千差万别，本文以Spark On Yarn经典大数据集群场景为例，讲一讲如何高效计算数据。

**二、Spark On Yarn性能优化思路**

**1、Spark调参**

Spark开放了众多过程参数，来控制集群运行过程中各个维度的设置。常用来参数调优的有：

spark.default.parallelism：并行度

spark.sql.shuffle.partitions：shuffle分区数（常为集群Executor核心数的2-3倍）

spark.executor.memoryOverhead：调节shuffle过程中内存溢出阈值

spark.dynamicAllocation.enabled=true：启用动态资源分配，任务负载高时可自行增加对资源的申请

spark.sql.adaptive.enabled=true：开启AQE，自动调节最优分区数，还可改善数据倾斜问题

上面只是例举其中一小部分，参数调参配合SparkUI使用，方便观测调整效果。

**2、代码端优化**

手段很多，包括但不限于：增加缓存、减少udf的使用、走dataframe或sparksql最大化利用spark原生的引擎优化、使用broadcast等，核心原则是多利用spark优化机制，做好数据缓存。

**3、数据端优化**

数据端优化主要是两部分：

第一是读取、存储时，采用高效存储格式，如parquet、ORC等，天然适配spark的分区计算模式，会减少很多无谓的操作。

第二是采用高效序列化方式，减少shuffle过程中的序列化耗时，这部分时间可在SparkUI的Stage处查看task的timeline中的对应耗时。

**4、架构层优化**

上述措施都做完之后，基本就进入了性能优化的深水区，当前业界成熟做法有两大类，均能进一步突破数据计算瓶颈可带来较大幅度提升。

**第一是利用向量化技术，大幅提升计算效率。**

向量化技术能有效果的基础，在于现代计算机对SIMD指令的支持。

SIMD指令，即单指令流多数据流 Single Instruction Multiple Data，在计算机中可以使用一条指令，传递多个数据进去（即向量），而后CPU仅需对这一个向量进行一次运算（比如当前要进行加法运算），即可得到结果，相比传统CPU一个加法调用一次指令的方式，快了N（N为向量的长度）倍。

所以向量化改造是一条理论上具备高效提效能力的技术方向。具体实操的话，开源组件推荐使用Gluten，小米技术团队去年做过实践分享，改造之后时间耗时平均降低30%。

**第二是在并行计算路上继续狂奔，引入异构的GPU**（注意不是NPU，NPU仅为支持AI训练推理加速，对通用数据计算增益效果并不好，且缺少配套）。

在GPU计算提效这块，英伟达专门为Spark无缝使用开发了RAPIDS加速器插件。它可以以插件的方式集成到spark客户端中，通过参数开关指定启用。在spark的物理计划生成之后，会被该加速器插件拦截，将其中的CPU算子替换为GPU算子（若评估加速效果不好还可退回成CPU算子），而后在Task执行阶段，RAPIDS会接过该任务进行执行。

大体，就这些了。单纯的大数据技术领域，可做的新技术演进已经不多了，后面更多的是如何精细化价值转换，给AI给行业赋能。

后续将沿着AI的方向，进行博文的更新和学习。