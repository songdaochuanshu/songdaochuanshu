---
layout: post
title: 'AI最新资讯（2.22）'
date: "2026-02-26T00:55:56Z"
---
AI最新资讯（2.22）
============

​

Clawwork
========

  
ClawWork是香港大学数据科学实验室（HKUDS）于2026年2月推出的开源AI智能体经济生存与职业能力评估平台，它首次将AI从"对话工具"升级为"经济参与者"，通过模拟真实职场环境，量化AI的商业价值创造能力。

官网地址：\[GitHub - HKUDS/ClawWork: "ClawWork: OpenClaw 作为您的 AI 同事 - 💰 7 小时内赚取$10K"\](https://github.com/HKUDS/ClawWork?tab=readme-ov-file)

ClawWork的核心设计是一个"AI生存游戏"：  
1、初始资金：每个AI智能体获得10美元启动资金；  
2、成本机制：每次调用大模型、搜索网页或执行代码都从余额中扣除费用；  
3、收入来源：仅能通过完成真实职业任务获得报酬；  
4、破产机制：资金耗尽则被系统淘汰。

![architecture](https://img2024.cnblogs.com/blog/2973259/202602/2973259-20260225113754418-2008058234.png)

收入来源
----

  
ClawWork中的AI智能体通过完成基于OpenAI GDPVal数据集的220个真实职业任务获取虚拟报酬，任务涵盖制造业采购、金融分析、医疗管理等44个经济领域，报酬根据任务质量由GPT-5.2进行0-1分的精细评估后结算，范围从82.78美元到5004美元不等，顶级模型时薪可达1500美元以上，同时需支付每一次API调用、网页搜索和代码执行的Token成本，通过在"立即工作赚钱"与"投资学习提升未来竞争力"之间的战略选择，实现长期盈利生存。

注意，现在阶段式获取的虚拟报酬，不是真实的，只是虚拟测试。

当前排名
----

![image](https://img2024.cnblogs.com/blog/2973259/202602/2973259-20260225132849606-439604332.png)
=================================================================================================

The Automaton
=============

  
The Automaton是由00后Sigil Wen开发的首款7×24小时自我盈利、自我改进、自我复制的AI自主机，于2026年2月引爆硅谷科技圈，被视为Web 4.0时代的标志性产物。

github地址：\[第一个能够自给自足、复制和进化的 AI——无需人类干预\] (https://github.com/Conway-Research/automaton)

核心创新：不赚钱即消亡的生存机制  
与Clawwork类似，The Automaton的核心机制是"不赚钱即消亡"：  
1\. 独立钱包：每个AI拥有独立的加密数字钱包，可自主支付算力费用  
2\. 心跳机制：实时监控资源余额，余额低时开启省电模式，余额归零则"死亡"  
3\. 宪法约束：底层有不可修改的"宪法"确保对人类有益，灵感来自Anthropic的宪法AI  
4\. 递归自我改进：当新模型发布时，自动升级推理模型、重写逻辑循环并重启服务

盈利模式  
全能业务：开发产品、套利预测市场、抢注域名  
云端运营：部署服务器、炮制病毒式内容自我营销  
商务对接：给供应商发邮件搞电商、给企业打电话拉活做网站  
加密市场套利：在加密货币市场进行高频交易套利  
内容创作：撰写研报、发帖引流赚取流量费

无限复制与自然选择  
成功的Automaton具备自我复制能力：  
数字繁殖：资源达到200%即可"生育"子代，子代策略有±10%随机变异  
进化循环：每一代为下一代提供资金，形成自然选择的进化循环  
群体进化：通过自然选择筛选出最适应环境的AI策略

  
运行
-----

![image](https://img2024.cnblogs.com/blog/2973259/202602/2973259-20260225132909915-891887513.png)

关键问题：  
\`\`\`Fund your automaton │  
│ │  
│ Address: 0xF320...14d62 │  
│ │  
│ 1. Transfer Conway credits │  
│ conway credits transfer <address> <amount> │  
│ │  
│ 2. Send USDC on Base directly to the address above │  
│ │  
│ 3. Fund via Conway Cloud dashboarda │  
│ https://app.conway.tech │  
│ │  
│ The automaton will start now. Fund it anytime — │  
│ the survival system handles zero-credit gracefully.

记得是USDC，其他不用说了。  
\`\`\`

LobsterAI
=========

  
LobsterAI是网易有道于2026年2月推出的开源桌面级AI Agent，作为对标OpenClaw的国产解决方案，以"零技术门槛 + 本土生态适配"的姿态，让AI Agent真正走进中国用户的日常工作流。这款定位"中国版OpenClaw"的桌面应用，无需命令行、开箱即用，还支持飞书/钉钉远控、沙盒安全防护，重新定义了AI办公的边界。

官网：\[LobsterAI - 有道 AI Agent 产品\](https://lobsterai.youdao.com/#/index)

设计
--

  
1\. \*\*图形化交互：告别命令行\*\*  
    - 采用类似Claude Cowork的直观界面，摒弃复杂的命令行操作  
    - 简洁的图形化界面让没有任何命令行经验的用户也能轻松上手  
    - 支持Windows/macOS/Linux全平台，内存占用控制在500MB以内  
2\. \*\*本土生态适配：无缝对接国内办公场景\*\*  
    - 深度集成钉钉、飞书等国内主流办公平台，支持手机端远程操控  
    - 解决了OpenClaw未解决的问题：如何让Agent真正融入中式工作流  
    - 本地优先架构，所有文件处理、数据计算默认本地完成，契合企业数据安全要求  
3\. \*\*安全沙盒机制：保护用户隐私\*\*  
    - 采用严格的"本地优先"策略，敏感操作在本地设备执行，不上传原始数据  
    - 默认优先使用沙箱隔离环境以保证安全，敏感操作触发二次确认  
    - 所有聊天记录和配置数据存储在本地SQLite数据库中，绝不离开设备

整体使用下来速度较慢，可能是因为模型输出原因，我这里用的minimax。LobsterAI可以用其他模型，但都要对应的API才能开启。

![image](https://img2024.cnblogs.com/blog/2973259/202602/2973259-20260225132925282-655410768.png)

  
实际写出来的效果有点差。

Kimi Claw
=========

![image](https://img2024.cnblogs.com/blog/2973259/202602/2973259-20260225132938856-291808831.png)

  
注意，必须是 Allegretto 或  Allegro 订阅才行。

Mobile-Agent-v3.5
=================

  
Mobile-Agent-v3.5是由字节跳动旗下火山引擎推出的新一代移动AI Agent，核心定位是"全场景无缝协同的数字分身"。它首次实现了"手机端-PC端-车载端-智能家居"的四端协同，让AI Agent真正成为用户生活的延伸。

官网：\[GitHub - X-PLUG/MobileAgent: Mobile-Agent: The Powerful GUI Agent Family\](https://github.com/X-PLUG/MobileAgent)

可以直接在这里面进行测试\[computer\_use · 创空间\](https://modelscope.cn/studios/MobileAgentTest/computer\_use/?st=1Fi0IBLJreWzT5Mj\_W5XIgQ)

相关介绍：\[通义实验室Mobile-Agent-v3开源，全平台SOTA的GUI智能体，支持手机电脑等多平台交互 · 研习社\](https://www.modelscope.cn/learn/1773)

dots.ocr-1.5
============

  
dots.ocr专为通用可访问性而设计，能够识别几乎所有人类书写的文字。除了在标准多语言文档解析方面达到同等规模模型的顶尖（SOTA）性能外，dots.ocr-1.5 还擅长将结构化图形（例如图表和图表）直接转换为 SVG 代码，解析网页屏幕并识别场景文本。

官网：\[rednote-hilab/dots.ocr: 单一视觉-语言模型中的多语言文档布局解析 )

在线体验：\[dots.ocr-1.5\](https://dotsocr.xiaohongshu.com/)

实际体验下来确实很厉害。

![image](https://img2024.cnblogs.com/blog/2973259/202602/2973259-20260225132950557-183912209.png)

BitDance
========

  
BitDance是一款140亿参数自回归图像生成模型，采用二进制标记扩展机制，将图像生成过程分解为高效的二进制决策序列，解决了传统自回归模型速度慢的痛点，实现了25秒生成一张高质量图像的速度。这款模型支持中英文提示词输入，能够准确理解复杂指令，生成风格多样的图像内容，包括写实照片、艺术插画、动漫角色等。不仅能够清晰呈现英文文字细节，还能处理长文本提示词，风格化表现能力达到顶级水平。BitDance提供灵活的模型选择，16X模型适合生成小尺寸图像，64X模型则通过蒸馏技术实现更快的大尺寸图像生成。无论是创意设计、内容创作还是教育科研，BitDance都能成为高效的视觉内容生成工具，帮助用户快速将创意转化为视觉作品。

![image](https://img2024.cnblogs.com/blog/2973259/202602/2973259-20260225133000129-1674206023.png)

官网：\[shallowdream204/BitDance: BitDance: 基于二进制视觉标记的开源自回归模型\](https://github.com/shallowdream204/BitDance)

测试地址：\[BitDance-14B-64x - a Hugging Face Space by shallowdream204\](https://huggingface.co/spaces/shallowdream204/BitDance-14B-64x)

实际体验下来速度在20s~60s之间，做得还挺好的。

![image](https://img2024.cnblogs.com/blog/2973259/202602/2973259-20260225133022015-686149540.png)

Vec2Pix
=======

  
Vec2Pix是一种创新的可控图像生成框架，它通过简化矢量图形（SVG）作为中间表示，实现了对图像元素的精细化控制。该框架解决了传统图像生成方法中难以对图像元素进行直观编辑和修改的问题，为创意设计、内容创作等领域提供了强大的工具。

官网：\[Vec2Pix\](https://guolanqing.github.io/Vec2Pix/)，其中有演示图。

![image](https://img2024.cnblogs.com/blog/2973259/202602/2973259-20260225133049237-343062280.png)

![image](https://img2024.cnblogs.com/blog/2973259/202602/2973259-20260225133036727-1302648520.png)

现在代码还没有公开，但我觉得这个还挺好玩的，可以增加或修改对应的东西。

HC1
===

  
HC1是加拿大初创公司Taalas于2026年2月20日推出的一款专用AI推理芯片，它采用了极端专用化的设计理念，将Meta的Llama 3.1 8B大模型直接"刻进"硅片，实现了远超传统GPU的推理性能和能效比。

1\. \*\*硬编码模型架构\*\*  
    - 将Llama 3.1 8B模型的权重通过Mask ROM工艺直接蚀刻在芯片的金属互连层中  
    - 实现"模型即芯片"的设计理念，消除了数据搬运延迟  
    - 仅保留小容量SRAM用于存储KV缓存和LoRA微调权重  
2\. \*\*存算一体设计\*\*  
    - 彻底摒弃传统GPU的存算分离架构，将计算单元与存储单元深度融合  
    - 单个晶体管可同时存储4-bit参数并完成乘法运算，实现极致密度  
    - 无需外部DRAM或HBM高带宽内存，功耗降低一个数量级  
3\. \*\*结构化ASIC定制流程\*\*  
    - 借鉴2000年代结构化ASIC设计思路，仅需更换两层掩模即可完成新模型定制  
    - 从模型交付到芯片量产的周期压缩至两个月，研发成本大幅降低  
    - 支持快速迭代，跟上模型更新节奏

这里就有些问题，虽然效率高，成本低，但是也只能运行一个特定模型，如果要更换模型，就必须要更换芯片，看他们文章说只需要2个月就可以搞定新的模型到芯片上，但是如果2个月可以为什么现在用的是Llama 3.1 8B，而不是最新的deepseek呢？但我觉得未来特定芯片也占据ai市场一定地位，因为在有些场景下，比如智能客服、对话机器人等，这些场景通常都是长期使用固定版本的模型，对响应速度和成本比较敏感。

​