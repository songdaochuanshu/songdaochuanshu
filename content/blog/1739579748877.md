---
layout: post
title: 'ä½¿ç”¨Ollamaå’ŒAnythingLLMæ­å»ºæœ¬åœ°AI'
date: "2025-02-15T00:35:48Z"
---
ä½¿ç”¨Ollamaå’ŒAnythingLLMæ­å»ºæœ¬åœ°AI
==========================

æ­å»ºæœ¬åœ°åšå®¢AI
--------

ç›®å½•

*   [æ­å»ºæœ¬åœ°åšå®¢AI](#æ­å»ºæœ¬åœ°åšå®¢ai)
    *   [ç¯å¢ƒ](#ç¯å¢ƒ)
    *   [ä¸‹è½½ollama](#ä¸‹è½½ollama)
    *   [é€‰æ‹©æ¨¡å‹](#é€‰æ‹©æ¨¡å‹)
        *   [é€‰æ‹©åµŒå…¥(embedder)æ¨¡å‹](#é€‰æ‹©åµŒå…¥embedderæ¨¡å‹)
            *   [æŸ¥çœ‹æ€§èƒ½æµ‹è¯•](#æŸ¥çœ‹æ€§èƒ½æµ‹è¯•)
            *   [ä¼°ç®—å†…å­˜](#ä¼°ç®—å†…å­˜)
            *   [é€‰æ‹©æ¨¡å‹](#é€‰æ‹©æ¨¡å‹-1)
            *   [é‡åŒ–ç±»å‹ä»‹ç»](#é‡åŒ–ç±»å‹ä»‹ç»)
                *   [**Q5\_0 vs Q5\_K**](#q5_0-vs--q5_k)
                *   [Q5\_K å˜ä½“(Q5\_K\_Sã€Q5\_K\_Mã€Q5\_K\_L)](#q5_k-å˜ä½“q5_k_sq5_k_mq5_k_l)
        *   [é€‰æ‹©LLMæ¨¡å‹](#é€‰æ‹©llmæ¨¡å‹)
    *   [ä¸‹è½½æ¨¡å‹](#ä¸‹è½½æ¨¡å‹)
        *   [ä¸‹è½½LLM](#ä¸‹è½½llm)
        *   [ä¸‹è½½Embedder](#ä¸‹è½½embedder)
    *   [ä¸‹è½½AnythingLLM](#ä¸‹è½½anythingllm)
        *   [é…ç½®å‘é‡æ•°æ®åº“](#é…ç½®å‘é‡æ•°æ®åº“)
    *   [æµ‹è¯•ä½¿ç”¨](#æµ‹è¯•ä½¿ç”¨)
    *   [Tips](#tips)
        *   [Resetå‘é‡æ•°æ®åº“](#resetå‘é‡æ•°æ®åº“)
        *   [LLMæ²¡æœ‰ä½¿ç”¨è‡ªå·±çš„æ–‡æ¡£](#llmæ²¡æœ‰ä½¿ç”¨è‡ªå·±çš„æ–‡æ¡£)
        *   [AIå›ç­”é€»è¾‘æ··ä¹±](#aiå›ç­”é€»è¾‘æ··ä¹±)
        *   [Ollama](#ollama)
            *   [æ—¥å¿—ä¸­å‡ºç°å‘Šè­¦æˆ–é”™è¯¯](#æ—¥å¿—ä¸­å‡ºç°å‘Šè­¦æˆ–é”™è¯¯)
            *   [å‘½ä»¤è¡Œ](#å‘½ä»¤è¡Œ)
            *   [Debug](#debug)
            *   [Ollama FAQ](#ollama-faq)
    *   [å‚è€ƒ](#å‚è€ƒ)
    *   [TODO](#todo)

### ç¯å¢ƒ

*   **Env**ï¼šMacBook Pro M2
*   **Total memory**ï¼š16GB

### ä¸‹è½½ollama

*   [ä¸‹è½½](https://ollama.com/)å¹¶æŒ‰ç…§æç¤ºå®‰è£…å¯åŠ¨ollamaã€‚
*   åœ¨æµè§ˆå™¨ä¸­è®¿é—®`http://localhost:11434`ï¼Œè‹¥è¿”å›"Ollama is running"ï¼Œåˆ™è¡¨ç¤ºå¯åŠ¨æˆåŠŸã€‚

### é€‰æ‹©æ¨¡å‹

#### é€‰æ‹©åµŒå…¥(embedder)æ¨¡å‹

##### æŸ¥çœ‹æ€§èƒ½æµ‹è¯•

[mteb](https://huggingface.co/spaces/mteb/leaderboard)å±•ç¤ºäº†æ–‡æœ¬åµŒå…¥æ¨¡å‹çš„æ€§èƒ½æµ‹è¯•ç»“æœã€‚ç”±äºåšå®¢ä»¥ä¸­è‹±æ–‡ä¸ºä¸»ï¼Œå› æ­¤åœ¨è¿‡æ»¤è¯­è¨€æ—¶åº”è¯¥åŒ…å«`cmn`ã€`zho`å’Œ`eng`(è¯­è¨€ä»£ç [ä½¿ç”¨](https://github.com/embeddings-benchmark/mteb/blob/main/docs/mmteb/readme.md#contribution-point-guideline)çš„æ˜¯[ISO 639-3](https://en.wikipedia.org/wiki/ISO_639-3)æ ‡å‡†)

![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250213150343270-1402600397.png)

è¿è¡Œç»“æœå¦‚ä¸‹ï¼š

![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250213150742640-107085415.png)

##### ä¼°ç®—å†…å­˜

åœ¨é€‰æ‹©æ¨¡å‹(ä¸ä»…é™åµŒå…¥æ¨¡å‹)æ—¶ï¼Œéœ€è¦è€ƒè™‘æ¨¡å‹å ç”¨çš„æ€§èƒ½ï¼Œé€šå¸¸å‚æ•°è¶Šå¤šï¼Œå ç”¨çš„å†…å­˜ä¹Ÿå°±è¶Šå¤§ã€‚æ¨¡å‹å ç”¨çš„å†…å­˜[ä¼°ç®—å…¬å¼](https://www.substratus.ai/blog/calculating-gpu-memory-for-llm)å¦‚ä¸‹ï¼š

\\\[M=\\frac{(P \* 4 B)}{(32 / Q)} \* 1.2 \\\]

Symbol

Description

M

ç”¨åƒå…†å­—èŠ‚ (GB) è¡¨ç¤ºçš„ GPU å†…å­˜

P

æ¨¡å‹ä¸­çš„å‚æ•°æ•°é‡ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ª 7B æ¨¡å‹æœ‰ 7 äº¿å‚æ•°ã€‚

4B

4 å­—èŠ‚ï¼Œè¡¨ç¤ºæ¯ä¸ªå‚æ•°ä½¿ç”¨çš„å­—èŠ‚æ•°

32

4 å­—èŠ‚ä¸­æœ‰ 32 ä½

Q

åŠ è½½æ¨¡å‹æ—¶åº”ä½¿ç”¨çš„æ¯”ç‰¹ä½æ•°ï¼Œä¾‹å¦‚ 16 ä½ã€8 ä½æˆ– 4 ä½ã€‚

1.2

è¡¨ç¤ºåœ¨ GPU å†…å­˜ä¸­åŠ è½½é¢å¤–å†…å®¹çš„ 20% å¼€é”€ã€‚

ä»¥ä¸Šå›¾ä¸­çš„ç¬¬2å`gte-Qwen2-1.5B-instruct`ä¸ºä¾‹ï¼Œå…¶å‚æ•°æ•°é‡(P)ä¸º1.78Bï¼Œå³17.8äº¿ä¸ªå‚æ•°ï¼Œå…¶æ¨¡å‹åº”ç”¨çš„æ¯”ç‰¹ä½æ•°(Q)ä¸ºF32ï¼Œå³32ä½ï¼Œé‚£ä¹ˆå®ƒå ç”¨çš„å†…å­˜çº¦ä¸º_M = (1.78 âˆ— 4) / (32 / 32) âˆ— 1.2 â‰ˆ 5.93GB_

![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250213185124710-744857088.png)

ç”±äº**é™¤åµŒå…¥æ¨¡å‹å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦è¿è¡Œå¤§æ¨¡å‹(LLM)**ï¼Œå› æ­¤åœ¨æ€»è®¡16GBçš„å†…å­˜ä¸Šè¿è¡Œè¿‘6GBçš„åµŒå…¥æ¨¡å‹æ˜¯æœ‰äº›åƒåŠ›çš„ã€‚é‚£ä¹ˆæ˜¯å¦æœ‰å…¶ä»–é™ä½æ¨¡å‹å†…å­˜çš„æ–¹å¼å‘¢ï¼Ÿ

ç­”æ¡ˆæ˜¯é€šè¿‡**é‡åŒ–**(Quantization)ã€‚

é‡åŒ–æ˜¯ä¸€ç§é™ä½å†…å­˜å ç”¨çš„æ–¹å¼ï¼Œé€šè¿‡å°†æ¨¡å‹å‚æ•°çš„ç²¾åº¦ä»æµ®ç‚¹æ•°é™ä½åˆ°æ›´ä½çš„è¡¨è¾¾æ–¹å¼(å¦‚ 8 ä½æ•´æ•°)ï¼Œæ˜¾è‘—é™ä½äº†å†…å­˜å’Œè®¡ç®—éœ€æ±‚ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´é«˜æ•ˆåœ°éƒ¨ç½²åœ¨èµ„æºæœ‰é™çš„è®¾å¤‡ã€‚ä½†é™ä½ç²¾åº¦å¯èƒ½ä¼šå½±å“è¾“å‡ºçš„å‡†ç¡®æ€§ã€‚é€šå¸¸æ¥è¯´ï¼Œ**8bitçš„é‡åŒ–å¯ä»¥è¾¾åˆ°16bitçš„æ€§èƒ½**ï¼Œä½†4bitçš„é‡åŒ–å¯èƒ½ä¼šæ˜¾è‘—å½±å“æ¨¡å‹æ€§èƒ½ã€‚

å¦‚æœæƒ³ç”¨**2GBå·¦å³**çš„å†…å­˜è¿è¡Œè¯¥æ¨¡å‹ï¼Œé‚£ä¹ˆé‡åŒ–åº”è¯¥è®¾ç½®ä¸ºå¤šå°‘ï¼Ÿ

è®¡ç®—_(1.78 âˆ— 4) / (32 / Q) âˆ— 1.2=2_ï¼Œæ±‚è§£`Q`çº¦ä¸º7.5ã€‚

è¿™é‡Œæä¾›äº†ä¸€ä¸ªæ¨¡å‹å†…å­˜è®¡ç®—[å·¥å…·](https://llm-calc.rayfernando.ai/?quant=8-bit&os=8&context=2000)ï¼Œæˆ‘ä»¬è®¾ç½®æ€»å†…å­˜(`Custom Ran(GB)`)ä¸º10GBï¼Œç³»ç»Ÿé¢„ç•™å†…å­˜(`OS Overhead(GB)`)ä¸º8GBï¼Œè¿™æ ·ç•™ç»™åµŒå…¥æ¨¡å‹çš„å°±åªæœ‰2GBå†…å­˜ã€‚é‡åŒ–çº§åˆ«(`Quantization Level`)ä¸º5-bitï¼Œä¸Šä¸‹æ–‡çª—å£(`Context Window(Tokens)`)ä¸º2048ï¼Œåˆ™è¯¥é…ç½®ä¸‹ï¼Œå¯ä»¥æ”¯æŒ1.6Bçš„æ¨¡å‹ï¼Œä¸é¢„æœŸå¤§è‡´ç›¸ç¬¦ï¼š

![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250213190542710-106143247.png)

##### é€‰æ‹©æ¨¡å‹

ä»ä¸Šé¢æˆªå›¾ä¸­å¯ä»¥çœ‹åˆ°`Alibaba-NLP/gte-Qwen2-7B-instruct`æ¨¡å‹æœ‰28ä¸ªé‡åŒ–ç‰ˆæœ¬ï¼Œç‚¹å‡»è¿›å…¥è¿™28ä¸ªé‡åŒ–ç‰ˆæœ¬çš„æµè§ˆé¡µé¢

![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250213162249465-1939654671.png)

ç‚¹å‡»è¿›å…¥ç¬¬ä¸€ä¸ªæ¨¡å‹`tensorblock/gte-Qwen2-7B-instruct-GGUF`(**ä¸‹è½½é‡æœ€å¤š**)ï¼Œåœ¨é¡µé¢å³ä¾§é€‰æ‹©`Use this model`\->`Ollama`:

![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250213163807138-489549065.png)

å¯ä»¥çœ‹åˆ°å®ƒæœ‰å¾ˆå¤šé‡åŒ–ç‰ˆæœ¬ï¼Œé‚£ä¹ˆè¯¥é€‰æ‹©å“ªä¸€ä¸ªï¼Ÿ

![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250213163846744-2017689464.png)

å¯ä»¥[å‚è€ƒ](https://github.com/ggerganov/llama.cpp/discussions/2094#discussioncomment-6351796)ä¸‹é¢æè¿°ï¼Œ**æ¨è`Q4_K_M`å’Œ`Q5_K_S`ï¼Œ`Q5_K_M`**ï¼Œé‰´äºæˆ‘ä»¬çš„é‡åŒ–çº§åˆ«ä¸èƒ½å¤§äº7ï¼Œå› æ­¤å¯ä»¥**é‡‡ç”¨æ¨èçš„`Q5_K_M`æ¨¡å‹**ã€‚

    Allowed quantization types:
       2  or  Q4_0   :  3.50G, +0.2499 ppl @ 7B - small, very high quality loss - legacy, prefer using Q3_K_M
       3  or  Q4_1   :  3.90G, +0.1846 ppl @ 7B - small, substantial quality loss - legacy, prefer using Q3_K_L
       8  or  Q5_0   :  4.30G, +0.0796 ppl @ 7B - medium, balanced quality - legacy, prefer using Q4_K_M
       9  or  Q5_1   :  4.70G, +0.0415 ppl @ 7B - medium, low quality loss - legacy, prefer using Q5_K_M
      10  or  Q2_K   :  2.67G, +0.8698 ppl @ 7B - smallest, extreme quality loss - not recommended
      12  or  Q3_K   : alias for Q3_K_M
      11  or  Q3_K_S :  2.75G, +0.5505 ppl @ 7B - very small, very high quality loss
      12  or  Q3_K_M :  3.06G, +0.2437 ppl @ 7B - very small, very high quality loss
      13  or  Q3_K_L :  3.35G, +0.1803 ppl @ 7B - small, substantial quality loss
      15  or  Q4_K   : alias for Q4_K_M
      14  or  Q4_K_S :  3.56G, +0.1149 ppl @ 7B - small, significant quality loss
      15  or  Q4_K_M :  3.80G, +0.0535 ppl @ 7B - medium, balanced quality - *recommended*
      17  or  Q5_K   : alias for Q5_K_M
      16  or  Q5_K_S :  4.33G, +0.0353 ppl @ 7B - large, low quality loss - *recommended*
      17  or  Q5_K_M :  4.45G, +0.0142 ppl @ 7B - large, very low quality loss - *recommended*
      18  or  Q6_K   :  5.15G, +0.0044 ppl @ 7B - very large, extremely low quality loss
       7  or  Q8_0   :  6.70G, +0.0004 ppl @ 7B - very large, extremely low quality loss - not recommended
       1  or  F16    : 13.00G              @ 7B - extremely large, virtually no quality loss - not recommended
       0  or  F32    : 26.00G              @ 7B - absolutely huge, lossless - not recommended
    

##### é‡åŒ–ç±»å‹ä»‹ç»

ä»ä¸Šé¢å¯ä»¥çœ‹å‡ºä¸åŒçš„åç¼€ï¼ˆ`0`ã€`K`ã€`K_S`ã€`K_M`ã€`K_L`ï¼‰ä»£è¡¨ **ä¸åŒçš„é‡åŒ–æŠ€æœ¯å’Œä¼˜åŒ–ç­–ç•¥**ã€‚ä»¥ä¸‹å†…å®¹æ¥è‡ªGPTï¼š

###### **Q5\_0 vs Q5\_K**

**Q5\_0**

*   Q5\_0 æ˜¯æœ€åŸºç¡€çš„ 5-bit é‡åŒ–æ–¹æ¡ˆï¼Œå®ƒä½¿ç”¨ å‡åŒ€é‡åŒ–ï¼ˆUniform Quantizationï¼‰ï¼Œä½†**ä¸åŒ…å«ä»»ä½•é¢å¤–çš„ä¼˜åŒ–**ã€‚
*   æ¯ä¸ª blockï¼ˆé€šå¸¸ 16 æˆ– 32 ä¸ªæƒé‡ï¼‰å…±äº«ç›¸åŒçš„ç¼©æ”¾å› å­ï¼ˆscaleï¼‰ã€‚
*   è¯¯å·®è¾ƒå¤§ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½å¯¼è‡´ æ¨¡å‹ç²¾åº¦ä¸‹é™ã€‚

**é€‚ç”¨åœºæ™¯**

*   é€‚ç”¨äºå¯¹**ç²¾åº¦è¦æ±‚ä¸é«˜**çš„ä»»åŠ¡ã€‚
*   å½“è®¾å¤‡è®¡ç®—**èµ„æºæœ‰é™ä½†ä»éœ€è¦è¾ƒå¥½çš„æ¨ç†é€Ÿåº¦**æ—¶ã€‚

* * *

**Q5\_K**

*   Q5\_Kï¼ˆK-Block Quantizationï¼‰æ˜¯ä¸€ç§æ›´å…ˆè¿›çš„ 5-bit é‡åŒ–æ–¹æ¡ˆï¼Œä½¿ç”¨ å—çº§ï¼ˆblock-wiseï¼‰éå‡åŒ€é‡åŒ–ï¼ˆNon-Uniform Quantizationï¼‰ ä»¥ é™ä½é‡åŒ–è¯¯å·®ã€‚
*   ç›¸æ¯” Q5\_0ï¼ŒQ5\_K åœ¨åŒæ ·çš„ 5-bit é‡åŒ–ä¸‹èƒ½æä¾›æ›´å¥½çš„æ•°å€¼ç²¾åº¦ï¼Œå› æ­¤æ¨¡å‹æ¨ç†è´¨é‡æ›´é«˜ã€‚
*   Q5\_K è¿›ä¸€æ­¥å¼•å…¥äº†ä¼˜åŒ–ç­–ç•¥ï¼Œå¦‚åŠ¨æ€ç¼©æ”¾ï¼ˆdynamic scalingï¼‰æˆ–éå‡åŒ€é‡åŒ–æ–¹æ³•ï¼Œ**ä½¿å¾—é‡åŒ–è¯¯å·®å°äº Q5\_0**ã€‚

**é€‚ç”¨åœºæ™¯**

*   é€‚ç”¨äº **å¯¹ç²¾åº¦æœ‰è¾ƒé«˜è¦æ±‚** çš„ LLM ä»»åŠ¡ï¼Œå¦‚ **èŠå¤©æœºå™¨äººã€ä»£ç ç”Ÿæˆã€ç¿»è¯‘** ç­‰ã€‚
*   é€‚ç”¨äº **å­˜å‚¨å—é™** ä½†ä»å¸Œæœ›ä¿æŒè¾ƒå¥½ç²¾åº¦çš„è®¾å¤‡ï¼Œå¦‚ **GPUã€CPUã€ç§»åŠ¨ç«¯**ã€‚

###### Q5\_K å˜ä½“(Q5\_K\_Sã€Q5\_K\_Mã€Q5\_K\_L)

æ–¹æ¡ˆ

è¯´æ˜

è®¡ç®—å¤æ‚åº¦

ç²¾åº¦

**Q5\_K\_S**

**"Small" ç‰ˆæœ¬**ï¼Œæ›´å¿«ä½†ç²¾åº¦ç¨ä½

âœ… æœ€ä½

âŒ è¾ƒä½

**Q5\_K\_M**

**"Medium" ç‰ˆæœ¬**ï¼ŒæŠ˜ä¸­æ–¹æ¡ˆ

ğŸ”„ é€‚ä¸­

ğŸ”„ é€‚ä¸­

**Q5\_K\_L**

**"Large" ç‰ˆæœ¬**ï¼Œè®¡ç®—ç¨æ…¢ä½†ç²¾åº¦é«˜

âŒ è¾ƒé«˜

âœ… æœ€ä½³

**é€‚ç”¨åœºæ™¯**

*   **Q5\_K\_S**ï¼šé€‚ç”¨äº **æ¨ç†é€Ÿåº¦ä¼˜å…ˆ** çš„åœºæ™¯ï¼Œä¾‹å¦‚ **å®æ—¶èŠå¤©æœºå™¨äºº** æˆ– **ä½ç«¯è®¾å¤‡**ã€‚
*   **Q5\_K\_M**ï¼šé€‚ç”¨äº **å¹³è¡¡ç²¾åº¦å’Œæ¨ç†é€Ÿåº¦** çš„åœºæ™¯ï¼Œæ˜¯ **æœ€å¸¸ç”¨çš„ Q5\_K ç‰ˆæœ¬**ã€‚
*   **Q5\_K\_L**ï¼šé€‚ç”¨äº **å¯¹ç²¾åº¦è¦æ±‚æé«˜çš„ LLM ä»»åŠ¡**ï¼Œå¦‚ **ç§‘å­¦è®¡ç®—ã€ä»£ç ç†è§£** ç­‰ã€‚

#### é€‰æ‹©LLMæ¨¡å‹

ä¸åµŒå…¥æ¨¡å‹ç±»ä¼¼ï¼ŒLLMæ¨¡å‹ä¹Ÿæœ‰è‡ªå·±çš„æ€§èƒ½æµ‹è¯•æ¿å—ï¼š[open-llm-leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/)ï¼Œä½†è¯¥æ’è¡Œæ¦œå¹¶æœªæä¾›è¯­è¨€è¿‡æ»¤åŠŸèƒ½ï¼Œå› æ­¤æ— æ³•ç›´æ¥é€‰æ‹©æŸä¸ªæ¨¡å‹ï¼Œè¿˜éœ€è¦åˆ¤æ–­è¯¥æ¨¡å‹æ˜¯å¦æ”¯æŒä¸­è‹±æ–‡ã€‚

å¯ä»¥å‚è€ƒ[Open Chinese LLM Leaderboard](https://huggingface.co/spaces/BAAI/open_cn_llm_leaderboard)ã€‚

ä¹Ÿå¯ä»¥å‚è€ƒ[chinese-llm-benchmark](https://github.com/jeinlee1991/chinese-llm-benchmark?tab=readme-ov-file#-%E6%8E%92%E8%A1%8C%E6%A6%9C)ï¼Œç»™å‡ºäº†ä¸­æ–‡å¤§æ¨¡å‹èƒ½åŠ›è¯„æµ‹æ¦œå•ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬æƒ³è¦æ‰¾5Bä»¥ä¸‹çš„å°æ¨¡å‹ï¼Œå¯ä»¥å‚è€ƒè¯¥[æ¦œå•](https://github.com/jeinlee1991/chinese-llm-benchmark/blob/main/leaderboard/opensource1.md)ï¼Œå‰3åä¸ºï¼š

1.  [qwen2.5-3b-instruct](https://huggingface.co/Qwen/Qwen2.5-3B-Instruct)
2.  [Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)
3.  [qwen2.5-1.5b-instruct](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct)

âš ï¸åœ¨é€‰æ‹©æ¨¡å‹æ—¶ï¼Œéœ€è¦åœ¨huggingfaceä¸Šå†æ¬¡ç¡®è®¤æ”¯æŒçš„è¯­è¨€ï¼Œå¦‚ä¸Šé¢çš„`Llama-3.2-3B-Instruct`æ¨¡å‹ï¼Œ[å®˜æ–¹](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)ä»…æ”¯æŒ8ç§è¯­è¨€_English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai are officially supported_ï¼Œå¹¶æ²¡æœ‰ä¸­æ–‡!

è¿™é‡Œæˆ‘ä»¬é€‰æ‹©çš„æ¨¡å‹ä¸º`qwen2.5-3b-instruct`ï¼Œæ ¹æ®å…¬å¼ï¼Œè¯¥æ¨¡å‹å¤§æ¦‚å ç”¨çš„å†…å­˜ä¸º2.55GBã€‚

### ä¸‹è½½æ¨¡å‹

â„¹ï¸ä¹Ÿå¯ä»¥ç›´æ¥åœ¨Ollamaçš„[æ¨¡å‹åº“](https://ollama.com/search?c=embedding&o=newest)ä¸­ç›´æ¥æŸ¥æ‰¾ä¸‹è½½ã€‚

#### ä¸‹è½½LLM

    ollama run hf.co/Qwen/Qwen2.5-3B-Instruct-GGUF:Q5_K_M
    

#### ä¸‹è½½Embedder

    ollama pull hf.co/second-state/gte-Qwen2-1.5B-instruct-GGUF:Q5_K_M
    

### ä¸‹è½½AnythingLLM

*   [ä¸‹è½½](https://anythingllm.com/)å¹¶å®‰è£…anythingLLM
    
*   è¿æ¥Ollamaï¼šåˆ†åˆ«åœ¨anythingLLMçš„`LLM`å’Œ`Embedder`ç§é€‰æ‹©Ollamaï¼Œå¹¶å°†è¿æ¥åœ°å€è®¾ç½®ä¸ºæ­£ç¡®çš„OllamaæœåŠ¡åœ°å€ï¼ŒOllamaçš„é»˜è®¤ç›‘å¬åœ°å€ä¸º`127.0.0.1:11434`(_è®¾ç½®ä¸º`http://localhost:11434`å¥½åƒæœ‰é—®é¢˜_)ã€‚è¿æ¥å¥½åå°±å¯ä»¥è‡ªåŠ¨åŠ è½½æ¨¡å‹ï¼š  
    ![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250214105537120-1149611445.png)
    
    âš ï¸ ä½¿ç”¨Ollamaæ—¶ï¼ŒanythingLLMæ— æ³•åŒºåˆ†æ¨¡å‹æ˜¯LLMè¿˜æ˜¯embedderï¼Œå› æ­¤éƒ½ä¼šè¿›è¡ŒåŠ è½½ï¼Œå³åœ¨`LLM`ä¸­å‡ºç°åµŒå…¥æ¨¡å‹ï¼Œè€Œåœ¨`Embedder`ä¸­å‡ºç°LLMï¼Œéœ€è¦æ‰‹åŠ¨é€‰æ‹©æ­£ç¡®çš„æ¨¡å‹ï¼Œå°†`LLM`è®¾ç½®ä¸º`hf.co/Qwen/Qwen2.5-3B-Instruct-GGUF:Q5_K_M`ï¼Œå°†`Embedder`è®¾ç½®ä¸º`hf.co/second-state/gte-Qwen2-1.5B-instruct-GGUF:Q5_K_M`ã€‚
    
    å®˜æ–¹æœ‰å¦‚ä¸‹[æè¿°](https://docs.useanything.com/setup/embedder-configuration/local/ollama)ï¼š
    
    > **Heads up!**
    > 
    > Ollama's `/models` endpoint will show both LLMs and Embedding models in the dropdown selection. **Please** ensure you are using an embedding model for embedding.
    > 
    > **llama2** for example, is an LLM. Not an embedder.
    

#### é…ç½®[å‘é‡æ•°æ®åº“](https://docs.anythingllm.com/features/vector-databases)

è¿™é‡Œå°±ç›´æ¥é‡‡ç”¨anythingLLMé»˜è®¤çš„æœ¬åœ°æ•°æ®åº“å³å¯ï¼š

![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250214111022713-909031879.png)

### æµ‹è¯•ä½¿ç”¨

ç®€å•æµ‹è¯•ä¸€ä¸‹æ¨¡å‹æ˜¯å¦ç”Ÿæ•ˆï¼š

![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250214125122571-2092548152.png)

ç°åœ¨åµŒå…¥ä¸€ä¸ªæ–‡æ¡£ï¼Œçœ‹æ˜¯å¦å¯ä»¥æ ¹æ®åµŒå…¥çš„æ–‡æ¡£è¿›è¡Œå›ç­”ã€‚å°†`Chat mode`è®¾ç½®ä¸ºQueryï¼Œè¿™æ ·æ¨¡å‹åªä¼šæ ¹æ®åµŒå…¥çš„æ–‡æ¡£è¿›è¡Œå›ç­”ï¼š

![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250214125314626-1846202931.png)

ä¸Šä¼ ä¸€ä¸ªæ–‡æ¡£ï¼Œæ–‡æ¡£é‡Œé¢åŒ…å«ä¸€ä¸ªè‡ªå®šä¹‰çš„æˆè¯­ï¼š"_ç©ºè®©å¼„é¥­æ˜¯ä¸€ä¸ªæˆè¯­ï¼Œæ„æ€æ˜¯æœ‰ç©ºä¸€èµ·åšé¥­ï¼Œå½¢å®¹ä¸€ä¸ªäººå¿ƒæƒ…å¥½_"ï¼š

![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250214125410578-154964474.png)

æµ‹è¯•ç»“æœå¦‚ä¸‹ï¼š  
![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250214141810021-1835797026.png)

å¦‚æœç”¨`Chat`æ¨¡å¼ï¼Œå…¶ç»“æœå¦‚ä¸‹ï¼š

![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250214141842889-216446065.png)

### Tips

#### Resetå‘é‡æ•°æ®åº“

![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250214115413636-587943269.png)

#### LLMæ²¡æœ‰ä½¿ç”¨è‡ªå·±çš„æ–‡æ¡£

å®˜æ–¹ç»™å‡ºäº†ä¸€äº›[è§£å†³æ–¹å¼](https://docs.anythingllm.com/llm-not-using-my-docs)

*   Vector Database Settings > Search Preferenceä¸­å°è¯•ä½¿ç”¨`Accuracy Optimized`,
    
    ![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250214144551626-293976461.png)
*   å°†Document similarity thresholdè®¾ç½®ä¸º`No Restriction`ã€‚è¯¥å±æ€§ç”¨äºè¿‡æ»¤æ‰å¯èƒ½ä¸æŸ¥è¯¢æ— å…³çš„ä½åˆ†å‘é‡æ•°æ®ï¼Œé»˜è®¤ä¸º20%ï¼š  
    ![image](https://img2024.cnblogs.com/blog/1334952/202502/1334952-20250214144624433-1740101294.png)
    

#### AIå›ç­”é€»è¾‘æ··ä¹±

å¯ä»¥é€‚å½“å°†ä½æ¨¡å‹çš„[temperatureå€¼](https://docs.useanything.com/llm-not-using-my-docs#chat-settings--llm-temperature)ï¼š`Chat Settings > LLM Temperature`

#### Ollama

##### æ—¥å¿—ä¸­å‡ºç°å‘Šè­¦æˆ–é”™è¯¯

**level=WARN source=runner.go:129 msg="truncating input prompt" limit=2048 prompt=2097 keep=0 new=2048**

åŸå› æ˜¯Ollamaé»˜è®¤ä½¿ç”¨2048çš„context windowï¼Œ[è§£å†³æ–¹å¼](https://github.com/ollama/ollama/issues/8099#issuecomment-2543316682)æ˜¯å¢åŠ æ¨¡å‹çš„`num_ctx`å€¼ï¼Œä½†è¿™ç§æ–¹å¼æ¯”è¾ƒè€—æ—¶ã€‚

å¦ä¸€ç§[æ–¹å¼](https://blog.driftingruby.com/ollama-context-window/)æ˜¯ä½¿ç”¨`Modefile`ï¼Œä¸‹é¢ä¿®æ”¹åµŒå…¥æ¨¡å‹`hf.co/second-state/gte-Qwen2-1.5B-instruct-GGUF:Q5_K_M`çš„`num_ctx`ä¸º8192:

    cat Modelfile
    # Modelfile
    FROM hf.co/second-state/gte-Qwen2-1.5B-instruct-GGUF:Q5_K_M
    PARAMETER num_ctx 8196
    

æ‰§è¡Œ`ollama create -f Modelfile gte-Qwen2-1.5B-instruct-GGUF:Q5_K_M`å°†åˆ›å»ºä¸€ä¸ªæ–°çš„åµŒå…¥æ¨¡å‹ï¼Œåœ¨AnythingLLMä¸­åŠ è½½è¯¥æ¨¡å‹å³å¯ã€‚  
âš ï¸é‡æ–°åŠ è½½æ¨¡å‹ä¹‹å‰éœ€è¦åˆ é™¤åµŒå…¥çš„æ–‡æ¡£ï¼Œå¹¶reset å‘é‡æ•°æ®åº“ã€‚

##### å‘½ä»¤è¡Œ

Ollamaçš„å‘½ä»¤è¡Œæœ‰ç‚¹åƒdockerï¼Œå¸¸ç”¨çš„å‘½ä»¤å¦‚ä¸‹ï¼š

*   ollama serverï¼šå¯åŠ¨ä¸€ä¸ªollamaæœåŠ¡
    
*   ollama runï¼šå¯åŠ¨ä¸€ä¸ªæ¨¡å‹
    
*   ollama stopï¼šåœæ­¢ä¸€ä¸ªæ¨¡å‹
    
*   ollama psï¼šæŸ¥çœ‹è¿è¡Œçš„æ¨¡å‹
    
*   ollama pullï¼šä¸‹è½½ä¸€ä¸ªæ¨¡å‹
    
*   ollama pushï¼šä¸Šä¼ ä¸€ä¸ªæ¨¡å‹
    
*   ollama rmï¼šåˆ é™¤ä¸€ä¸ªæ¨¡å‹
    
*   ollama listï¼šæŸ¥çœ‹ä¸‹è½½çš„æ¨¡å‹
    
*   ollama showï¼šæŸ¥çœ‹ä¸€ä¸ªæ¨¡å‹çš„ä¿¡æ¯
    

##### [Debug](https://github.com/ollama/ollama/blob/main/docs/troubleshooting.md)

æŸ¥çœ‹Ollamaæ—¥å¿—ï¼š`cat ~/.ollama/logs/server.log`

##### [Ollama FAQ](https://github.com/ollama/ollama/blob/main/docs/faq.md)

### å‚è€ƒ

*   [Calculating GPU memory for serving LLMs](https://www.substratus.ai/blog/calculating-gpu-memory-for-llm)
*   [å…¨æ°‘AIæ—¶ä»£ï¼šæ‰‹æŠŠæ‰‹æ•™ä½ ç”¨Ollama & AnythingLLMæ­å»ºAIçŸ¥è¯†åº“ï¼Œæ— éœ€ç¼–ç¨‹ï¼Œè·Ÿç€åšå°±è¡Œï¼](https://www.53ai.com/news/qianyanjishu/1427.html)
*   ollamaæ”¯æŒçš„[æ¨¡å‹åº“](https://github.com/ollama/ollama?tab=readme-ov-file#model-library)

### TODO

å°è¯•ä¸€ä¸‹å…¶ä»–å¤§æ¨¡å‹

æœ¬æ–‡æ¥è‡ªåšå®¢å›­ï¼Œä½œè€…ï¼š[charlieroro](https://www.cnblogs.com/charlieroro/)ï¼Œè½¬è½½è¯·æ³¨æ˜åŸæ–‡é“¾æ¥ï¼š[https://www.cnblogs.com/charlieroro/p/18709638](https://www.cnblogs.com/charlieroro/p/18709638)