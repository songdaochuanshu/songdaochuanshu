---
layout: post
title: '短视频 / 图片不够清？SeedVR2.5 超分操作指南，一键拉满画质'
date: "2025-12-13T00:42:03Z"
---
短视频 / 图片不够清？SeedVR2.5 超分操作指南，一键拉满画质
===================================

短视频 / 图片不够清？SeedVR2.5 超分操作指南，一键拉满画质
===================================

> Excerpt
> -------
> 
> 小编尝试过Flash VSR、video2x、Tapaz Video等图像视频高清大模型，认为目前还是SeedVR2.5效果最好，因此本文带大家一起来进行实践操作。

* * *

01

SeedVR2介绍

SeedVR2 2.5.10于2025年11月13日正式发布，适用于 ComfyUI，支持高质量视频和图像放大。其主要特点如下：

（一）核心能力

*   高质量基于扩散的放大 ：视频和图像增强的一步扩散模型
    
*   时间一致性 ：通过可配置的批处理保持视频帧间的一致性
    
*   多格式支持 ：支持视频和图像的 RGB 和 RGBA（alpha 通道）
    
*   任何视频长度 ：适合任何视频长度
    

（二）模型支持

*   多种模型变体 ：3B 和 7B 参数模型，具有不同精度选项
    
*   FP16、FP8 和 GGUF 量化 ：根据不同显存需求，选择全精度（FP16）、混合精度（FP8）或重量化 GGUF 模型
    
*   自动模型下载 ：模型首次使用时会自动从 HuggingFace 下载
    

（三）内存优化

*   区块交换技术 ：动态交换 GPU 和 CPU 内存之间的变压器块，以在有限显存上运行大型模型
    
*   VAE 平铺： 通过平铺编码/解码处理大分辨率，以减少显存使用率
    
*   智能卸载 ：在处理阶段之间将模型和中间张量卸载到 CPU 或次级 GPU
    
*   GGUF 量化支持 ：运行 4 位或 8 位量化的型号，极大节省显存
    

（四）性能特点

*   torch.compile 集成 ：可选 20-40% DiT 加速和 15-25% VAE 加速，配合 PyTorch 2.0+ 编译
    
*   多 GPU 光环链接 ：通过自动时间重叠混合，将工作负载分配到多个 GPU。
    
*   模型缓存 ：将模型加载在内存中以加快批量处理速度
    
*   灵活的注意力后端 ：在 PyTorch SDPA（稳定且始终可用）或 Flash Attention 2（支持硬件上更快）之间选择
    

（五）质量管理

*   高级色彩校正 ：五种方法，包括 LAB（推荐以实现最高保真度）、小波、小波自适应、HSV 和 AdaIN
    
*   噪声注入控制 ：微调输入和潜在噪声尺度，以降低高分辨率的伪影
    
*   可配置分辨率限制：设置目标分辨率和最大分辨率，并自动保持宽高比
    

（六）工作流程功能

*   ComfyUI 集成 ：四个专用节点，实现对升频流水线的完全控制
    
*   独立 CLI：批处理和自动化的命令行界面
    
*   调试日志 ：全面的调试模式，包含内存跟踪、时序信息和处理细节
    
*   进展报告 ：处理过程中实时更新进展
    

官方效果示例：

网友们的实践效果：

02

ComfyUI-SeedVR2\_VideoUpscaler部署

（一）安装ComfyUI

ComfyUI 是一个基于 Python 的图像生成工具，它使用类似于节点和连线的方式来创建图像生成的工作流。如果你想在 Linux 系统上安装 ComfyUI，你可以按照以下步骤进行：

1.安装 Python

首先，确保你的 Linux 系统上安装了 Python。ComfyUI 需要 Python 3.8 或更高版本。你可以通过以下命令安装 Python：

    sudo apt updatesudo apt install python3 python3-pip
    

2.安装 Git

安装 Git，以便你可以从 GitHub 克隆 ComfyUI 的源代码：

    sudo apt install git
    

3.克隆 ComfyUI 仓库

使用 Git 克隆 ComfyUI 的 GitHub 仓库到你的系统中

    git clone https://github.com/comfyanonymous/ComfyUI.gitcd ComfyUI
    

4.安装依赖项

在 ComfyUI 的目录中，你需要安装一些依赖项。运行以下命令来安装它们：

    pip install -r requirements.txt
    

5.安装额外的依赖（可选）

根据你的需求，ComfyUI 可能还需要额外的依赖项，如 CUDA（如果你想要使用 GPU 加速）。根据你的硬件配置和需求，你可能需要安装这些依赖项。例如，如果你想要使用 NVIDIA GPU，你可以安装 CUDA Toolkit 和 cuDNN。

对于 CUDA Toolkit 和 cuDNN 的安装，你可以参考 NVIDIA 的官方文档进行安装：

    CUDA Toolkit：https://developer.nvidia.com/cuda-downloads
    

6.运行 ComfyUI

一旦所有依赖项都安装完成，你可以通过以下命令启动 ComfyUI：

python main.py

这将会启动 ComfyUI 的 Web 界面，你可以在浏览器中访问 [http://localhost:8188](http://localhost:8188) 来使用它。

使用 Docker（可选）

如果你不想在你的系统上直接安装所有依赖项，你也可以选择使用 Docker 来运行 ComfyUI。首先，你需要安装 Docker：

    sudo apt install docker.io
    

然后，你可以从 Docker Hub 上拉取一个预配置的 ComfyUI Docker 镜像：

    docker pull abdelrahmanm/comfyui:latestdocker run -it -p 8188:8188 abdelrahmanm/comfyui:latest
    

这样，ComfyUI 将会在 Docker 容器中运行，并且可以通过 [http://localhost:8188](http://localhost:8188) 访问。

以上就是在 Linux 上安装和运行 ComfyUI 的步骤。希望这对你有所帮助！如果你在安装过程中遇到任何问题，可以查看 ComfyUI 的 GitHub 仓库或社区论坛获取更多帮助。

（二）安装ComfyUI Manager

ComfyUI Manager 是 ComfyUI 最常用的插件管理工具，支持一键安装 / 更新插件、模型、自定义节点，V3.37 是稳定版本，安装方式分为「自动安装（推荐）」和「手动安装」，以下介绍手动安装方法（Linux 环境）：

    # 进入 ComfyUI 的 custom_nodes 目录
    cd /root/userdata/ComfyUI/ComfyUI/custom_nodes# 克隆 ComfyUI Manager 仓库（自动拉取最新版，包含 V3.37+）
    git clone https://github.com/ltdrdata/ComfyUI-Manager.git# 安装 Manager 依赖（部分环境需要）cd ComfyUI-Managerpip install -r requirements.txt
    

（三）安装部署SeedVR2节点

此部分操作只需在CPU CCI中操作，后续执行在GPU CCI中操作。

1、Git代码与模型文件下载

项目站点：

    https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler/tree/main
    

模型地址：

    https://modelscope.cn/models/numz/SeedVR2_comfyUI/files
    

2、安装部署环境软件硬件要求

硬件：

通过当前的优化（铺砖、区块交换、GGUF 量化），SeedVR2 可以在多种硬件上运行：

最低显存 （8GB 或以下）：使用启用 BlockSwap 和 VAE 平铺的 GGUF Q4\_K\_M 型号

中等显存 （12-16GB）：根据需要使用带有 BlockSwap 或 VAE 平铺的 FP8 型号

高显存 （24GB+）：使用 FP16 型号以获得最佳质量和速度，无需内存优化

软件：

ComfyUI： 推荐最新版本

Python：3.12+（测试并推荐使用 Python 3.12 和 3.13），我用的3.10.12也没碰到啥问题。

PyTorch：2.0+ 支持 torch.compile（可选但推荐）

Triton：带电感后端的 torch.compile 必修（可选）

Flash Attention 2：在支持的硬件上提供更快的注意力计算（可选，退回 PyTorch SDPA）

3、安装方法一：通过ComfyUI 管理器安装

在你的 ComfyUI 界面中打开 ComfyUI 管理器

点击“自定义节点管理器”

搜索“ComfyUI-SeedVR2\_VideoUpscaler”

点击“安装”并重启 ComfyUI

注册表链接 ：ComfyUI 注册表 - SeedVR2 视频升频器

4、安装方法二：手动安装

（1）下载git代码并安装依赖包

（a）下载git代码

将https://github.com/numz/ComfyUI-SeedVR2\_VideoUpscaler/tree/main代码下载至ComfyUI的custom nodes目录下（其它大模型也是这样的）。

    cd  /root/userdata/ComfyUI/ComfyUI/custom_nodesgit clone https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler.git
    

（b）安装SeedVR2依赖包

将ComfyUI-SeedVR2\_VideoUpscaler所需要pip包安装到ComfyUI的Python虚拟环境中，之前有点担心不兼容，毕竟这么多大模型，ComfyUI都能兼容吗，会不会有包冲突，后来了解到大模型要适配ComfyUI是要确保不与ComfyUI有包冲突的。

安装命令如下：

    cd /root/userdata/ComfyUI/ComfyUI/custom_nodes/ComfyUI-SeedVR2_VideoUpscalerpip install -r requirements.txt
    

（2）下载模型文件

下载模型文件至ComfyUI/models/SEEDVR2

点击下载模型按钮查看下载命令：

下载VAE模型：

    cd models/SEEDVR2/modelscope download --model numz/SeedVR2_comfyUI ema_vae_fp16.safetensors --local_dir .
    

下载DIT模型：

    modelscope download --model numz/SeedVR2_comfyUI seedvr2_ema_3b_fp8_e4m3fn.safetensors --local_dir .
    

其它模型方法类似，可以结合ComfyUI上边运行工作流时的报错提示来下载模型。

03

运行ComfyUI

（一）切换到GPU CCI

因为启动ComfyUI是需要GPU的，当然大模型推理更需求GPU，因此需切换到GPU CCI。

此部分如何切换CCI及CCI的完整操作视频可私信小编。

每次切换CCI需要手动切换一下Python的虚拟环境。

（二）启动ComfyUI

1.配置外网访问端口

如果需指定IP和端口，请直接在命令后边增加参数。提前配置好CCI对外的端口映射：

2.切换Python虚拟环境并执行main.py

切到ComfyUI的Python虚拟环境后，执行以下命令：

    cd ~/userdata/ComfyUI/ComfyUIsource /root/userdata/ComfyUI/comfyUI_env_py3.10/bin/activatepython main.py --listen 0.0.0.0 --port 8188
    

解释：ComfyUI默认端口是8188，启动时指定0.0.0.0IP。

ComfyUI启动成功：

访问ComfyUI:

用我们在外网映射的IP及端口访问：[http://60.171.65.125:30580/](http://60.171.65.125:30580/)

04

制作SeedVR2工作流并运行

（一）图像转高清工作流示例

随便找了一张我们小九的照片，用加载图像节点来上传我们的照片。

再分别拖拽SEEDVR2节点下边的DIT、VAE模型、SeedVR2 Video Upscaler。

将各节点进行连线，最终再加一个预览图像的节点，并进行连线，如下图所示：

点击右上角（或者有时跑到下边来了）人蓝色运行按钮，执行成功，生成的图像

生成图像的分辨率是我设置的分辨率(1080\*1480)，我这里保守了，你可以大胆一点，弄个2倍、4倍放大都可以：

其它补充：

ComfyUI的管理界面

主菜单：包括工作流、文件、编辑、视图、主题、设置等功能，还可以在扩展中安装插件，这个非常好。

底部面版可以打开或关闭日志，这个跟在Vscode后台是一样的：

（二）视频转高清工作流示例

点击左上方加号创建新的工作流，点左上角菜单-文件，随便命个名保存一下。

按官网示例拖拽工作流：

运行中：

运行完成：

运行结果：

05

ComfyUI Manager的使用

可以在安装ComfyUI的时候安装ComfyUI Manager，也可以在后边随时安装，安装后，界面右上角会出现Manager的蓝色按钮：

由于篇幅限制，后边再专门介绍ComfyUI Manager的使用。

06

总结

可以看出来，SeedVR2.5单张图片高清都是秒级（几秒到几十秒不等，看GPU配置），视频比较慢，一个5秒的视频从分辨率1248\_704变为1914\_1080。用了1张h100GPU\*80G显存），共花了10分钟，比Flash VSR要慢许多，但效果比Flash VSR要好很多。

SeedVR2.5有3B和7B的模型，3B感觉主要在磨皮，7B细节更多，当然可以用不同视频以及不同模型来测试效果，获得一个合适的方案。

当然，再好的模型都有不足的地方，现在为什么模型这么多呢，还是专业的模型干专业的活，SeedVR2.5对文字不是特别友好，如果原图片有文字，大概率文字变高清后就会变形，希望下一个版本能改善。