---
layout: post
title: 'Claude Opus 4.6 真的用不起了！我换成了国产 M2.5，实测真香！！'
date: "2026-02-28T00:50:09Z"
---
Claude Opus 4.6 真的用不起了！我换成了国产 M2.5，实测真香！！
-----------------------------------------

春节前后，大模型市场神仙打架：MiniMax M2.5、GPT-5.3-Codex、GLM-5、Opus 4.6、Qwen3.5-Plus 轮番登场。**但作为每天跑 Agent 的重度用户，我的体感却很复杂——尤其是面对 Opus 4.6 的账单时。**"

说实话，Opus 4.6 的能力确实强，但那个价格也真的是"贵到离谱"。对于我们这种每天深度依赖 AI 写代码、跑 Agent 的开发者来说，每次跑一个长上下文的重构任务，看着后台蹭蹭上涨的账单，心里都在滴血——**真的用不起！**

于是，我把目光投向了最近低调上线、主打“1 美元/小时”的 **MiniMax M2.5**。

我目前的策略是：日常 80-90% 的任务用 M2.5 就能搞定，剩下少数极难的任务再切换到 Opus 4.6。这样既能保证效果，又能大幅降低成本。

MiniMax 官方给出的 M2.5 数据很漂亮：SWE-Bench Verified 直接干到了 **80.2%** ，任务完成速度比上一代快了 **37%** ——这意味着原本 30 分钟的重构任务，现在 19 分钟就能跑完。

但作为一个 AI 编程老用户来说，我最开始是持怀疑态度的。毕竟国产模型在编程这块，以前总给我一种“写 Demo 挺顺，进生产环境就拉胯”的刻板印象。

于是，我专门花了一个深夜，用它做了两个极其有代表性的实测：

1.  **现有项目的深度重构**：在我的[AI 智能面试平台](https://javaguide.cn/zhuanlan/interview-guide.html)里，新增一个完整的"错题复盘"模块。
2.  **全栈项目开发**：从 0 到 1 手搓一个**带拖拽功能的 Web 任务看板**。

**实测下来的结果，只能用“杀疯了”来形容。**

最让我惊艳的不是它比 Opus 快 3 倍的推理速度，而是那股**“老架构师”的味道**。它不仅帮我省下了 90% 的 Token 费用，最重要的是，它让我第一次感觉到：**无限运行复杂 Agent，在经济上终于可行了。**

Claude Code 中接入 MiniMax M2.5
----------------------------

Claude Code 强在它的工具链和执行力，但如果你觉得 Claude 官方模型太贵，或者受够了那挤牙膏一样的响应速度，完全可以把 M2.5 作为它的底层大模型。

M2.5 目前已经是 OpenRouter 调用量的榜一了：

![](https://mmbiz.qpic.cn/mmbiz_png/icJuV9QZRqg5duevBaMlh5t7UfyI1j6eyUA9tAEmicEIUstnzLOKsIibgoxZqeGFKz5xvdmpj4uzOdXdr7W4GJQI7bXhHSUch9pPB6AEyTPfkU/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=0)

Claude Code 强在它的工具链和执行力，但如果你觉得 Claude 官方模型太贵，或者受够了那挤牙膏一样的响应速度，完全可以把 M2.5 作为它的底层大模型。

由于 M2.5 采用了标准的 **OpenAI 兼容接口**，接入过程非常丝滑。

如果你本机没有安装 Claude Code 的话，只需要运行下面这行命令安装即可（Node.js 18+）：

    npm install -g @anthropic-ai/claude-code
    

**1.获取 API Key**

先去 MiniMax 开放平台获取 Key：**[https://platform.minimaxi.com/user-center/basic-information/interface-key](https://platform.minimaxi.com/user-center/basic-information/interface-key)**

![](https://mmbiz.qpic.cn/mmbiz_png/iaIdQfEric9TxCdV1ib8d8TCX96ica9zvoFiaSwicLFx4TnNBE7xGVib42fOPc1am016rooiaOkv02n6xicXsFsjEY7dwhw/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=8)

**2\. 神器推荐**

强烈推荐安装 **CC Switch**，这是一个专门管理 Claude Code 模型切换的小工具，能让你在不同 Provider 之间一键横跳。并且，还支持管理 Skills、MCP 和提示词。

![](https://oss.javaguide.cn/temp/m2.5/image-20260227085048810.png)

启动 CC Switch，点击右上角 **”+”** ，选择预设的 MiniMax 供应商，并填写你的 MiniMax API Key。

![](https://oss.javaguide.cn/temp/m2.5/0acbfee9-8871-4171-af19-e318476456a4.png)

将模型名称全部改为 MiniMax-M2.5，完成后点击右下角的 “添加”。

![](https://oss.javaguide.cn/temp/m2.5/949bc0f3-2cb3-48df-ad40-15da8388092a.png)

项目地址：**[https://github.com/farion1231/cc-switch](https://github.com/farion1231/cc-switch)** 。

**3.手动编辑配置文件**

除了上面这种可视化配置方式之外，你也可以手动编辑配置文件。

    # Stpe1: 编辑或创建 Claude Code 的配置文件
    # MacOS & Linux 为 `~/.claude/settings.json`
    # Windows 为`用户目录/.claude/settings.json`
    # `MINIMAX_API_KEY` 需替换为你的 MiniMax API Key
    {
      "env": {
        "ANTHROPIC_BASE_URL": "https://api.minimaxi.com/anthropic",
        "ANTHROPIC_AUTH_TOKEN": "MINIMAX_API_KEY",
        "API_TIMEOUT_MS": "3000000",
        "CLAUDE_CODE_DISABLE_NONESSENTIAL_TRAFFIC": 1,
        "ANTHROPIC_MODEL": "MiniMax-M2.5",
        "ANTHROPIC_SMALL_FAST_MODEL": "MiniMax-M2.5",
        "ANTHROPIC_DEFAULT_SONNET_MODEL": "MiniMax-M2.5",
        "ANTHROPIC_DEFAULT_OPUS_MODEL": "MiniMax-M2.5",
        "ANTHROPIC_DEFAULT_HAIKU_MODEL": "MiniMax-M2.5"
      }
    }
    # Step2: 编辑或新增 `.claude.json` 文件
    # MacOS & Linux 为 `~/.claude.json`
    # Windows 为`用户目录/.claude.json`
    # 新增 `hasCompletedOnboarding` 参数
    {
      "hasCompletedOnboarding": true
    }
    

**4.测试是否生效**

在任意目录下输入 `claude` 命令即可启动 Claude Code，选择 信任此文件夹 (Trust This Folder)。

![](https://oss.javaguide.cn/temp/m2.5/image-20260227133041251.png)

多场景实测
-----

### Case1：AI 智能面试平台新增错题本功能

春节后，我一直想为我的 [AI 智能面试平台](https://javaguide.cn/zhuanlan/interview-guide.html)项目新增一个错题本的功能。

这个需求看似简单，实则涉及**数据库 schema 变更、RESTful API 设计、前端状态管理、路由配置**等多个环节，是检验 AI 编程能力的典型场景。

**需求描述：**

> 目前用户做完模拟面试后，只能看历史记录。用户无法标记自己回答得不好的题目进行重点复习。我想要实现一个"错题收藏与复习"模块。在面试详情页的每个 Q&A 旁增加一个"收藏/加入复盘"按钮；新增一个"复盘本"页面，列表展示收藏的题目。

**第一阶段：需求拆解**

输入需求后，M2.5 没有直接开始写代码，而是先进入分析模式，读取项目结构、技术栈和现有代码规范。

![](https://oss.javaguide.cn/temp/m2.5/image-20260226225208189.png)

![](https://oss.javaguide.cn/temp/m2.5/image-20260227111702043.png)

这就是原生 Spec 行为的魅力，在动手写代码前，先以架构师视角主动拆解功能、结构和 UI 设计，输出一份完整的实现计划。计划包含：

*   **需求拆解**：明确了需求边界，将"错题收藏与复习"拆分为两个核心用户场景。
*   **数据模型设计**：它没有简单粗暴地新建表，而是选择在现有的 `InterviewAnswerEntity` 中优雅地扩展字段。复用已有实体，避免过度设计，同时通过 `favoritedAt` 为后续的"按时间排序"预留了扩展空间。
*   **RESTful API 设计**：RESTful 接口路径、请求/响应参数、状态码规范。
*   **前后端文件映射**：不仅列出了要改哪些文件，还明确了操作类型（修改/新建）和职责分工。
*   **验证方案**：Plan 的最后，甚至给出了 5 步验证清单，从 API 可用性到前端交互，覆盖完整的功能路径。

**第二阶段：丝滑的执行与容错**

![](https://oss.javaguide.cn/temp/m2.5/image-20260226225323041.png)

确认 Plan 后，我选择 **Option 2：auto-accept edits**（自动接受修改）。

> 💡 **建议**：执行复杂任务时，前期建议选择 **Option 3：manually approve edits**（手动接受修改）。通过手动 Review Diff，你可以清晰看到它的实现思路。等确认逻辑稳健后，再切换到 Option 2 提升效率。

![](https://oss.javaguide.cn/temp/m2.5/image-20260226225532936.png)

执行过程中，M2.5 展现了**极强的上下文感知能力**：

*   **后端**：自动识别项目使用的 Spring Boot + JPA 技术栈，生成的 `InterviewFavoriteService` 正确使用 `@Transactional` 事务注解，并遵循**贫血模型**设计（业务逻辑在 Service，Entity 只负责数据）。
*   **前端**：检测到项目使用 **React + TypeScript** ，自动复用现有组件并和现有项目样式保持一致。

中途遇到一个小插曲：写到一半，突然主动给我道歉，特别有意思。

![](https://oss.javaguide.cn/temp/m2.5/image-20260226231535098.png)

更让我意外的是它的**错误自愈能力**。由于修改了数据类型，遇到了 MapStruct 匹配不上的错误。它会自己分析修复，然后继续测试运行。

![](https://oss.javaguide.cn/temp/m2.5/image-20260227112431147.png)

**第三阶段：代码交付**

在完成所有的 Task 之后，它会清晰告知用户自己做了哪些修改并且已经验证了前后端可以正常启动。

最贴心的是它还会告诉用户如何去验证功能是否生效。

![](https://oss.javaguide.cn/temp/m2.5/image-20260226232205949.png)

代码完全写完之后，我本地实际启动后端和前端进行验证。功能写的完全没问题，且前端样式和我当前项目保持的比较统一。

![](https://img2024.cnblogs.com/blog/1843652/202602/1843652-20260227161026544-1810970668.jpg)

![](https://img2024.cnblogs.com/blog/1843652/202602/1843652-20260227161040328-28055314.jpg)

看一下代码，和原项目整体是保持的比较一致的，例如遵循项目现有的 `Result<T>` 统一响应格式和 JPA 规范。

![](https://oss.javaguide.cn/temp/m2.5/image-20260226233421983.png)

![](https://oss.javaguide.cn/temp/m2.5/image-20260227104321799.png)

### Case2：Web 版任务看板

这个场景比较简单，就是让 AI 快速做一个前后端分离的 Web 版任务看板。

**需求描述：**

> 我要做一个 Web 版的简易任务看板。核心功能是：有多列（To Do, In Progress, Done），可以在列之间拖拽卡片，需要包含完整的前后端。

M2.5 同样没有直接写代码，自动开启了规划模式，让我们根据自己的需要选择到底是使用什么技术栈。

这是因为当前项目都还没有创建，所以 M2.5 会寻求我们的意见去定技术栈，这是非常合理的行为。

![](https://oss.javaguide.cn/temp/m2.5/image-20260226221052651.png)

我这里前端选择了 Vue 3 + Vite，后端选择了 Spring Boot + SQLite。

然后，它进入了"Plan Mode"。它输出了一份极其详细的实现计划，包含技术栈、功能需求、项目结构、API 和数据库设计、实现步骤等内容。

![](https://oss.javaguide.cn/temp/m2.5/image-20260226222842114.png)

这里我们还是直接选择 **Option 2：auto-accept edits**。

速度真的飞快，15 分钟左右的时间，前后端都已经搞定了。

![](https://img2024.cnblogs.com/blog/1843652/202602/1843652-20260227160741829-148630988.png)  
![image](https://img2024.cnblogs.com/blog/1843652/202602/1843652-20260227160805035-491265685.png)

我用 DataGrip 连接 SQLite 文件验证数据持久化，可以看到，任务数据也是成功保存在了数据库中。

![](https://oss.javaguide.cn/temp/m2.5/image-20260227102821476.png)

M2.5 的核心优势
----------

M2.5 发布 12 小时内登顶 OpenRouter 热度榜，一周内周调用量达 3.07T tokens，超过 Kimi、GLM、DeepSeek 三家总和——这不仅仅是数据的胜利，更是市场对其实际能力的认可。

### 极致性价比

M2.5 提供两个效果一样，但速度和价格不同的版本：

*   **快速版本（100 TPS）**：处理每百万 token 输入需要 0.3 美金，输出需要 2.4 美金。
*   **经济版本（50 TPS）**：输出价格比快速版本低一倍。

在以每秒输出 100 个 token 的情况下，连续工作一小时只需要 1 美金；而在每秒输出 50 个 token 的情况下，只需要 0.3 美金。按照输出价格参考，50 TPS 版本的价格是 Claude Opus、Gemini 3 Pro 以及 GPT-5 这些模型的 1/10~1/20。

这意味着：1 万美金可以让 4 个 Agent 连续工作一年。

### 原生 Spec 行为

这是我觉得最实用的！M2.5 具备了「像架构师一样思考和构建」的能力，演化出了原生 Spec 行为：在动手写代码前，以架构师视角主动拆解功能、结构和 UI 设计，实现完整的前期规划。

Vibe Coding 适合快速验证想法，而 Spec Coding 才是构建企业级、高可维护性软件的正确姿势。

我们可以将 Spec Coding 拆解为四个标准化的“流水线”步骤，通过文档驱动 AI 自主完成任务：

1.  **Specify（产品定义）：** 充当产品经理，编写类 PRD 文档。明确产品功能、目标用户以及要解决的核心痛点。这一步决定了“做什么”。
2.  **Plan（技术规划）：** 进入技术方案阶段。确定技术栈（如 Java 21 + Spring Boot 3）、系统架构、代码规范及核心契约。这一步决定了“怎么做”。
3.  **Tasks（任务拆解）：** 将技术计划拆解为一个个原子化的 Task，并为每个 Task 设定明确的**验收标准（Acceptance Criteria）**。
4.  **Implement（AI 执行）：** 将前面的 Spec（`requirements.md`, `design.md`, `tasks.md`）一并丢给 AI 编程工具。此时 AI 会基于这些“前置共识”独立工作，开发者不再需要盯着它看，直接等待验收即可。

![](https://oss.javaguide.cn/temp/m2.5/image-20260227104601109.png)

### 原生 Agent 架构

M2.5 专为智能体生态深度优化，具备极强的任务规划与长链路执行能力。其核心技术包括：

*   **原生 Agent RL 框架**：通过中间层 inference server 解耦训推 engine 与 Agent，保证推理和训练的 token 一致性。
*   **Agent RL 算法与 Reward 设计**：沿用 CISPO 算法保障 MoE 模型在大规模训练中的稳定性，引入过程奖励机制（Process Reward）对生成质量进行全链路监控。
*   **工程优化**：引入 Windowed FIFO 调度策略和树状合并训练样本，实现约 40 倍的训练加速。

### 私有化部署

M2.5 的激活参数量仅为 10B，是第一梯队中参数规模最小的旗舰模型。这意味着在私有化部署、显存占用及推理能效比上具有压倒性优势。

值得一提的是，**官方确认该模型会开源**。

总结
--

实测下来，M2.5 给我的感觉非常明确：它不是在模仿人说话，而是在模仿人工作。尤其是那种"先谋后动"的 Spec 拆解能力，非常有大厂老架构师的味道。

最后给大家 5 个核心建议：

1.  **不要迷信旗舰模型**：日常 80-90% 的任务，M2.5 足够应对。只有极少数高难度场景才需要切到 Opus 4.6，混合使用才是最优解。
2.  **先规划，再执行**：M2.5 的原生 Spec 行为是其最大亮点。做复杂任务前，让它先出一份完整的技术方案，比直接写代码效果好太多。
3.  **成本不是唯一考量**：虽然 M2.5 价格只有 Opus 的 1/10，但更重要的是它的"让无限运行 Agent 在经济上可行"这个突破点。
4.  **私有化部署值得关注**：10B 激活参数 + 官方开源承诺，对于有私有化部署需求的企业来说，M2.5 是一个值得跟进的选项。
5.  **趁早尝鲜 Coding Plan**：目前官方的 Coding Plan 活动非常给力，价格不变但已全面支持 M2.5。用我向官方申请的专属福利链接，享 88 折优惠：[https://platform.minimaxi.com/subscribe/coding-plan?code=7UNnWZ3ypY&source=link](https://platform.minimaxi.com/subscribe/coding-plan?code=7UNnWZ3ypY&source=link) 。

**一句话建议**：如果你最近有复杂的全栈项目要跑，别犹豫，切到 M2.5 试试它的 Spec 拆解能力。这种"先谋后动"的编程体验，才是 AI 编程的最佳实践。

posted on 2026-02-27 16:11  [JavaGuide](https://www.cnblogs.com/javaguide)  阅读(333)  评论(0)    [收藏](javascript:void\(0\))  [举报](javascript:void\(0\))