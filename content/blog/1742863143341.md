---
layout: post
title: 'åœ¨ Hugging Face Spaces ä¸Šä½¿ç”¨ Gradio å…è´¹è¿è¡Œ ComfyUI å·¥ä½œæµ'
date: "2025-03-25T00:39:03Z"
---
åœ¨ Hugging Face Spaces ä¸Šä½¿ç”¨ Gradio å…è´¹è¿è¡Œ ComfyUI å·¥ä½œæµ
=================================================

ç®€ä»‹
--

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘å°†é€æ­¥æŒ‡å¯¼å¦‚ä½•å°†ä¸€ä¸ªå¤æ‚çš„ ComfyUI å·¥ä½œæµè½¬æ¢ä¸ºä¸€ä¸ªç®€å•çš„ Gradio åº”ç”¨ç¨‹åºï¼Œå¹¶è®²è§£å¦‚ä½•å°†å…¶éƒ¨ç½²åœ¨ Hugging Face Spaces çš„ ZeroGPU æ— æœåŠ¡å™¨æž¶æž„ä¸Šï¼Œè¿™æ ·å¯ä»¥è®©å®ƒä»¥æ— æœåŠ¡å™¨çš„æ–¹å¼å…è´¹éƒ¨ç½²å’Œè¿è¡Œã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [Nathan Shipley çš„ Flux\[dev\] Redux + Flux\[dev\] Depth ComfyUI å·¥ä½œæµ](https://gist.github.com/nathanshipley/7a9ac1901adde76feebe58d558026f68)ï¼Œä½†ä½ å¯ä»¥æŒ‰ç…§æ•™ç¨‹çš„æ­¥éª¤æ“ä½œä»»ä½•ä½ æƒ³è¦çš„å·¥ä½œæµã€‚

![comfy-to-gradio](https://img-s2.andfun.cn/devrel/posts/2025/03/d96a742f9e392.png)

ä»¥ä¸‹æ˜¯æœ¬æ•™ç¨‹å†…å®¹çš„ç®€è¦æ¦‚è¿°:

1.  ä½¿ç”¨ [`ComfyUI-to-Python-Extension`](https://github.com/pydn/ComfyUI-to-Python-Extension) å¯¼å‡ºä½ çš„ ComfyUI å·¥ä½œæµ;
2.  ä¸ºå¯¼å‡ºçš„ Python ä»£ç åˆ›å»ºä¸€ä¸ª Gradio åº”ç”¨ç¨‹åº;
3.  å°†å…¶éƒ¨ç½²åœ¨ Hugging Face Spaces çš„ ZeroGPU ä¸Š;
4.  å³å°†æŽ¨å‡º: æ•´ä¸ªè¿‡ç¨‹å°†å®žçŽ°è‡ªåŠ¨åŒ–ã€‚

### å‰ææ¡ä»¶:

*   **äº†è§£å¦‚ä½•è¿è¡Œ ComfyUI**:  
    æœ¬æ•™ç¨‹éœ€è¦ä½ èƒ½å¤ŸèŽ·å– ComfyUI å·¥ä½œæµå¹¶åœ¨æœ¬åœ°æœºå™¨ä¸Šè¿è¡Œå®ƒï¼ŒåŒ…æ‹¬å®‰è£…ç¼ºå¤±çš„èŠ‚ç‚¹å’Œæ‰¾åˆ°ç¼ºå¤±çš„æ¨¡åž‹ (ä¸è¿‡æˆ‘ä»¬è®¡åˆ’å¾ˆå¿«è‡ªåŠ¨åŒ–è¿™ä¸€æ­¥)ã€‚
*   **å‡†å¤‡å¥½è¦å¯¼å‡ºçš„å·¥ä½œæµ**:  
    å¦‚æžœä½ è¿˜æ²¡æœ‰æ˜Žç¡®çš„å·¥ä½œæµï¼Œå¯ä»¥å°è¯•è¿è¡Œ [Nathan Shipley çš„ Flux\[dev\] Redux + Flux\[dev\] Depth ComfyUI å·¥ä½œæµ](https://gist.github.com/nathanshipley/7a9ac1901adde76feebe58d558026f68) ä½œä¸ºå­¦ä¹ ç¤ºä¾‹ã€‚
*   **ä¸€ç‚¹ç‚¹ç¼–ç¨‹çŸ¥è¯†**:  
    è™½ç„¶éœ€è¦ä¸€äº›åŸºç¡€çš„ç¼–ç¨‹çŸ¥è¯†ï¼Œä½†æˆ‘é¼“åŠ±åˆå­¦è€…å°è¯•è·Ÿéšæœ¬æ•™ç¨‹ï¼Œå› ä¸ºå®ƒå¯ä»¥ä½œä¸ºä¸€ä¸ªå¾ˆå¥½çš„ Pythonã€Gradio å’Œ Hugging Face Spaces çš„å…¥é—¨æŒ‡å—ï¼Œä¸éœ€è¦å¤ªå¤šçš„ç¼–ç¨‹ç»éªŒã€‚

å¦‚æžœä½ æ­£åœ¨å¯»æ‰¾ä¸€ç§ç«¯åˆ°ç«¯çš„â€œå·¥ä½œæµåˆ°åº”ç”¨â€çš„è§£å†³æ–¹æ¡ˆï¼Œ **æ— éœ€è®¾ç½®å’Œè¿è¡Œ ComfyUI æˆ–å…·å¤‡ç¼–ç¨‹çŸ¥è¯†**ï¼Œè¯·å…³æ³¨æˆ‘çš„ [Hugging Face ä¸»é¡µ](https://huggingface.co/multimodalart/) æˆ– [Twitter/X](https://twitter.com/multimodalart)ï¼Œæˆ‘ä»¬è®¡åˆ’åœ¨ 2025 å¹´åˆå®žçŽ°è¿™ä¸€ç›®æ ‡ï¼

1\. å°† ComfyUI å·¥ä½œæµå¯¼å‡ºä¸ºçº¯ Python ä»£ç è¿è¡Œ
---------------------------------

ComfyUI éžå¸¸å¼ºå¤§ï¼Œæ­£å¦‚å…¶åç§°æ‰€ç¤ºï¼Œå®ƒåŒ…å«ä¸€ä¸ªç”¨æˆ·ç•Œé¢ (UI)ï¼Œä½† ComfyUI ä¸ä»…ä»…æ˜¯ä¸€ä¸ª UIï¼Œå®ƒè¿˜åŒ…å«ä¸€ä¸ªåŸºäºŽ Python çš„åŽç«¯ã€‚ç”±äºŽåœ¨æœ¬æ•™ç¨‹ä¸­æˆ‘ä»¬ä¸æ‰“ç®—ä½¿ç”¨ ComfyUI çš„åŸºäºŽèŠ‚ç‚¹çš„ UIï¼Œå› æ­¤éœ€è¦å°†ä»£ç å¯¼å‡ºä¸ºçº¯ Python è„šæœ¬æ¥è¿è¡Œã€‚

å¹¸è¿çš„æ˜¯ï¼Œ[Peyton DeNiro](https://github.com/pydn) åˆ›å»ºäº†ä¸€ä¸ªéžå¸¸æ£’çš„ [ComfyUI-to-Python-Extension](https://github.com/pydn/ComfyUI-to-Python-Extension) å·¥å…·ï¼Œå®ƒå¯ä»¥å°†ä»»ä½• ComfyUI å·¥ä½œæµå¯¼å‡ºä¸º Python è„šæœ¬ï¼Œä»Žè€Œè®©ä½ æ— éœ€å¯åŠ¨ UI å³å¯è¿è¡Œå·¥ä½œæµã€‚

![comfy-to-gradio](https://img-s2.andfun.cn/devrel/posts/2025/03/388d776712e82.png)

å®‰è£…è¯¥æ‰©å±•çš„æœ€ç®€å•æ–¹æ³•æ˜¯:

(1) åœ¨ ComfyUI Manager æ‰©å±•çš„ Custom Nodes Manager èœå•ä¸­æœç´¢ `ComfyUI to Python Extension` å¹¶å®‰è£…ã€‚

(2) å‰å¾€ UI å³ä¸‹è§’çš„è®¾ç½®ç¦ç”¨æ–°èœå•ã€‚

(3) ç‚¹å‡» `Save as Script` ã€‚

è¿™æ ·ï¼Œä½ å°†å¾—åˆ°ä¸€ä¸ª Python è„šæœ¬ã€‚

2\. å‡†å¤‡åœ¨ Hugging Face Spaces ä¸Šè¿è¡Œ
-------------------------------

çŽ°åœ¨æˆ‘ä»¬æœ‰äº† Python è„šæœ¬ï¼ŒæŽ¥ä¸‹æ¥æ˜¯åˆ›å»ºä¸€ä¸ª Gradio åº”ç”¨ç¨‹åºæ¥è¿è¡Œå®ƒã€‚Gradio æ˜¯ä¸€ä¸ªåŸºäºŽ Python çš„ Web UI æž„å»ºå·¥å…·ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬å¿«é€Ÿåˆ›å»ºç®€æ´çš„åº”ç”¨ç¨‹åºã€‚å¦‚æžœä½ è¿˜æ²¡æœ‰å®‰è£… Gradioï¼Œå¯ä»¥é€šè¿‡ `pip install gradio` å‘½ä»¤åœ¨ä½ çš„ Python çŽ¯å¢ƒä¸­å®‰è£…å®ƒã€‚

æŽ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦ç¨å¾®è°ƒæ•´ä¸€ä¸‹ Python è„šæœ¬ï¼Œä»¥ä¾¿ä¸ºå…¶åˆ›å»ºä¸€ä¸ªç”¨æˆ·ç•Œé¢ (UI)ã€‚

> **å°æç¤º**: åƒ ChatGPTã€Claudeã€Qwenã€Geminiã€LLama 3 ç­‰å¤§åž‹è¯­è¨€æ¨¡åž‹ (LLMs) éƒ½çŸ¥é“å¦‚ä½•åˆ›å»º Gradio åº”ç”¨ç¨‹åºã€‚ä½ å¯ä»¥å°†å¯¼å‡ºçš„ Python è„šæœ¬ç²˜è´´ç»™å®ƒä»¬ï¼Œå¹¶è¦æ±‚å®ƒä»¬å¸®ä½ åˆ›å»ºä¸€ä¸ª Gradio åº”ç”¨ï¼Œè¿™åœ¨åŸºç¡€å±‚é¢ä¸Šæ˜¯å¯è¡Œçš„ã€‚ä¸è¿‡ï¼Œä½ å¯èƒ½éœ€è¦æ ¹æ®æœ¬æ•™ç¨‹ä¸­å­¦åˆ°çš„çŸ¥è¯†è¿›è¡Œä¸€äº›ä¿®æ­£ã€‚ä¸ºäº†æœ¬æ•™ç¨‹çš„ç›®çš„ï¼Œæˆ‘ä»¬å°†è‡ªå·±åŠ¨æ‰‹åˆ›å»ºè¿™ä¸ªåº”ç”¨ç¨‹åºã€‚

æ‰“å¼€å¯¼å‡ºçš„ Python è„šæœ¬ï¼Œå¹¶åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ  Gradio çš„å¯¼å…¥è¯­å¥:

    import os
    import random
    import sys
    from typing import Sequence, Mapping, Any, Union
    import torch
    + import gradio as gr
    

çŽ°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘ UI çš„è®¾è®¡â€”â€” **ä»Žå¤æ‚çš„ ComfyUI å·¥ä½œæµä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨ UI ä¸­æš´éœ²å“ªäº›å‚æ•°ï¼Ÿ** å¯¹äºŽ `Flux[dev] Redux + Flux[dev] Depth ComfyUI å·¥ä½œæµ` ï¼Œæˆ‘å¸Œæœ›æš´éœ²ä»¥ä¸‹å‚æ•°: æç¤ºè¯ (prompt) ã€ç»“æž„å›¾åƒ (structure image) ã€é£Žæ ¼å›¾åƒ (style image) ã€æ·±åº¦å¼ºåº¦ (depth strengthï¼Œç”¨äºŽç»“æž„) å’Œé£Žæ ¼å¼ºåº¦ (style strength)ã€‚

![](https://img-s2.andfun.cn/devrel/posts/2025/03/cb0d0178a9605.gif)

_è§†é¢‘è¯´æ˜Žå“ªäº›èŠ‚ç‚¹å°†æš´éœ²ç»™æœ€ç»ˆç”¨æˆ·_

å› æ­¤ä¸€ä¸ªæœ€ç®€å•çš„ Gradio åº”ç”¨å¯ä»¥å¦‚ä¸‹æ‰€ç¤º:

    if __name__ == "__main__":
        # åœ¨å¯¼å‡ºçš„ Python ä»£ç ä¸­æ³¨é‡ŠæŽ‰å¯¹ main() å‡½æ•°çš„è°ƒç”¨
        
        # å¼€å¯ Gradio ç¨‹åº
        with gr.Blocks() as app:
            # æ·»åŠ æ ‡é¢˜
            gr.Markdown("# FLUX Style Shaping")
    
            with gr.Row():
                with gr.Column():
                    # æ·»åŠ è¾“å…¥
                    prompt_input = gr.Textbox(label="Prompt", placeholder="Enter your prompt here...")
                    # æ·»åŠ ä¸€ä¸ªâ€œRowâ€ä»¥å°†ç»„å¹¶æŽ’æ˜¾ç¤º
                    with gr.Row():
                        # ç¬¬ä¸€ç»„åŒ…æ‹¬ç»“æž„å›¾åƒå’Œæ·±åº¦å¼ºåº¦
                        with gr.Group():
                            structure_image = gr.Image(label="Structure Image", type="filepath")
                            depth_strength = gr.Slider(minimum=0, maximum=50, value=15, label="Depth Strength")
                        # ç¬¬äºŒç»„åŒ…æ‹¬é£Žæ ¼å›¾åƒå’Œé£Žæ ¼å¼ºåº¦
                        with gr.Group():
                            style_image = gr.Image(label="Style Image", type="filepath")
                            style_strength = gr.Slider(minimum=0, maximum=1, value=0.5, label="Style Strength")
                    
                    # ç”ŸæˆæŒ‰é’®
                    generate_btn = gr.Button("Generate")
                
                with gr.Column():
                    # è¾“å‡ºå›¾åƒ
                    output_image = gr.Image(label="Generated Image")
    
                # å½“ç‚¹å‡»æŒ‰é’®æ—¶ï¼Œå®ƒå°†è§¦å‘â€œgenerate_imageâ€å‡½æ•°ï¼Œè¯¥å‡½æ•°å¸¦æœ‰ç›¸åº”çš„è¾“å…¥
                # å¹¶ä¸”è¾“å‡ºæ˜¯ä¸€å¼ å›¾åƒ
                generate_btn.click(
                    fn=generate_image,
                    inputs=[prompt_input, structure_image, style_image, depth_strength, style_strength],
                    outputs=[output_image]
                )
            app.launch(share=True)
    

è¿™æ˜¯åº”ç”¨ç¨‹åºæ¸²æŸ“åŽçš„æ ·å­

![Comfy-UI-to-Gradio](https://img-s2.andfun.cn/devrel/posts/2025/03/1b4ec99826231.png)

ä½†æ˜¯ï¼Œå¦‚æžœä½ å°è¯•è¿è¡Œå®ƒï¼Œå®ƒè¿˜æ— æ³•å·¥ä½œï¼Œå› ä¸ºçŽ°åœ¨æˆ‘ä»¬éœ€è¦é€šè¿‡ä¿®æ”¹æˆ‘ä»¬å¯¼å‡ºçš„ Python è„šæœ¬ä¸­çš„ `def main()` å‡½æ•°æ¥è®¾ç½®è¿™ä¸ª `generate_image` å‡½æ•°ã€‚

è„šæœ¬:

    - def main():
    + def generate_image(prompt, structure_image, style_image, depth_strength, style_strength)
    

åœ¨å‡½æ•°å†…éƒ¨ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°æˆ‘ä»¬æƒ³è¦çš„èŠ‚ç‚¹çš„ç¡¬ç¼–ç å€¼ï¼Œå¹¶å°†å…¶æ›¿æ¢ä¸ºæˆ‘ä»¬æƒ³è¦æŽ§åˆ¶çš„å˜é‡ï¼Œä¾‹å¦‚:

    loadimage_429 = loadimage.load_image(
    -    image="7038548d-d204-4810-bb74-d1dea277200a.png"
    +    image=structure_image
    )
    # ...
    loadimage_440 = loadimage.load_image(
    -    image="2013_CKS_01180_0005_000(the_court_of_pir_budaq_shiraz_iran_circa_1455-60074106).jpg"
    +    image=style_image
    )
    # ...
    fluxguidance_430 = fluxguidance.append(
    -   guidance=15,
    +   guidance=depth_strength,
        conditioning=get_value_at_index(cliptextencode_174, 0)
    )
    # ...
    stylemodelapplyadvanced_442 = stylemodelapplyadvanced.apply_stylemodel(
    -   strength=0.5,
    +   strength=style_strength,
        conditioning=get_value_at_index(instructpixtopixconditioning_431, 0),
        style_model=get_value_at_index(stylemodelloader_441, 0),
        clip_vision_output=get_value_at_index(clipvisionencode_439, 0),
    )
    # ...
    cliptextencode_174 = cliptextencode.encode(
    -   text="a girl looking at a house on fire",
    +   text=prompt,   
        clip=get_value_at_index(cr_clip_input_switch_319, 0),
    )
    

å¯¹äºŽæˆ‘ä»¬çš„è¾“å‡ºï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¿å­˜å›¾åƒè¾“å‡ºèŠ‚ç‚¹ï¼Œå¹¶å¯¼å‡ºå…¶è·¯å¾„ï¼Œä¾‹å¦‚:

    saveimage_327 = saveimage.save_images(
        filename_prefix=get_value_at_index(cr_text_456, 0),
        images=get_value_at_index(vaedecode_321, 0),
    )
    + saved_path = f"output/{saveimage_327['ui']['images'][0]['filename']}"
    + return saved_path
    

æŸ¥çœ‹è¿™äº›ä¿®æ”¹çš„è§†é¢‘æ¦‚è¿°:

![](https://img-s2.andfun.cn/devrel/posts/2025/03/7a6f20a1fe5c4.gif)

çŽ°åœ¨ï¼Œæˆ‘ä»¬åº”è¯¥å‡†å¤‡å¥½è¿è¡Œä»£ç äº†ï¼å°†ä½ çš„ Python æ–‡ä»¶ä¿å­˜ä¸º app.pyï¼Œå°†å…¶æ·»åŠ åˆ° ComfyUI æ–‡ä»¶å¤¹çš„æ ¹ç›®å½•ä¸­ï¼Œå¹¶ä»¥â€œpython app.pyâ€çš„æ–¹å¼è¿è¡Œå®ƒã€‚

    python app.py
    

è¿™æ ·ä½ åº”è¯¥èƒ½å¤Ÿåœ¨ [http://0.0.0.0:7860](http://0.0.0.0:7860) ä¸Šè¿è¡Œä½ çš„ Gradio åº”ç”¨ç¨‹åºã€‚

    * Running on local URL: http://127.0.0.1:7860
    * Running on public URL: https://366fdd17b8a9072899.gradio.live
    

![](https://img-s2.andfun.cn/devrel/posts/2025/03/9e88d893b2158.gif)

ä¸ºäº†è°ƒè¯•è¿™ä¸ªè¿‡ç¨‹ï¼Œè¯·æŸ¥çœ‹ [è¿™é‡Œ](https://gist.github.com/apolinario/47a8503c007c5ae8494324bed9e158ce/revisions?diff=unified&w=47a8503c007c5ae8494324bed9e158ce#diff-faf377dc15b3371a15d2c4a03b4d012825533bd2fb2297852cb2244d07fe36eeL1) çš„å·®å¼‚å¯¹æ¯”ï¼Œè¿™æ˜¯ç”± `ComfyUI-to-Python-Extension` å¯¼å‡ºçš„åŽŸå§‹ Python æ–‡ä»¶ä¸Ž Gradio åº”ç”¨ä¹‹é—´çš„å·®å¼‚ã€‚ä½ ä¹Ÿå¯ä»¥åœ¨è¯¥ URL ä¸‹è½½è¿™ä¸¤ä¸ªæ–‡ä»¶ï¼Œä»¥ä¾¿æ£€æŸ¥å’Œä¸Žä½ è‡ªå·±çš„å·¥ä½œæµè¿›è¡Œæ¯”è¾ƒã€‚

å°±æ˜¯è¿™æ ·ï¼Œæ­å–œä½ ï¼ä½ å·²ç»æˆåŠŸå°† ComfyUI å·¥ä½œæµè½¬æ¢ä¸º Gradio åº”ç”¨ï¼Œä½ å¯ä»¥åœ¨æœ¬åœ°è¿è¡Œå®ƒï¼Œç”šè‡³å¯ä»¥å°† URL å‘é€ç»™å®¢æˆ·æˆ–æœ‹å‹ã€‚ç„¶è€Œï¼Œå¦‚æžœä½ å…³é—­ç”µè„‘æˆ–è¶…è¿‡ 72 å°æ—¶ï¼Œä¸´æ—¶çš„ Gradio é“¾æŽ¥å°†ä¼šå¤±æ•ˆã€‚ä¸ºäº†èŽ·å¾—ä¸€ä¸ªæŒä¹…çš„æ‰˜ç®¡åº”ç”¨çš„ç»“æž„â€”â€”åŒ…æ‹¬å…è®¸äººä»¬ä»¥æ— æœåŠ¡å™¨çš„æ–¹å¼å…è´¹è¿è¡Œå®ƒï¼Œä½ å¯ä»¥ä½¿ç”¨ Hugging Face Spacesã€‚

3\. ä¸ºå¯¼å‡ºçš„ Python ä»£ç åˆ›å»º Gradio åº”ç”¨
------------------------------

çŽ°åœ¨ï¼Œæˆ‘ä»¬çš„ Gradio æ¼”ç¤ºå·²ç»å¯ä»¥è¿è¡Œäº†ï¼Œä½ å¯èƒ½ä¼šæƒ³ç›´æŽ¥å°†æ‰€æœ‰å†…å®¹ä¸Šä¼ åˆ° Hugging Face Spacesã€‚ç„¶è€Œï¼Œè¿™å°†éœ€è¦ä¸Šä¼ æ•°å GB çš„æ¨¡åž‹åˆ° Hugging Faceï¼Œè¿™ä¸ä»…é€Ÿåº¦æ…¢ï¼Œè€Œä¸”æ²¡æœ‰å¿…è¦ï¼Œå› ä¸ºè¿™äº›æ¨¡åž‹å·²ç»å­˜åœ¨äºŽ Hugging Face ä¸Šäº†ï¼

ç›¸åï¼Œå¦‚æžœæˆ‘ä»¬è¿˜æ²¡æœ‰å®‰è£… `huggingface_hub` ï¼Œé¦–å…ˆéœ€è¦å®‰è£…å®ƒ:

    from huggingface_hub import hf_hub_download
    
    hf_hub_download(repo_id="black-forest-labs/FLUX.1-Redux-dev", filename="flux1-redux-dev.safetensors", local_dir="models/style_models")
    hf_hub_download(repo_id="black-forest-labs/FLUX.1-Depth-dev", filename="flux1-depth-dev.safetensors", local_dir="models/diffusion_models")
    hf_hub_download(repo_id="Comfy-Org/sigclip_vision_384", filename="sigclip_vision_patch14_384.safetensors", local_dir="models/clip_vision")
    hf_hub_download(repo_id="Kijai/DepthAnythingV2-safetensors", filename="depth_anything_v2_vitl_fp32.safetensors", local_dir="models/depthanything")
    hf_hub_download(repo_id="black-forest-labs/FLUX.1-dev", filename="ae.safetensors", local_dir="models/vae/FLUX1")
    hf_hub_download(repo_id="comfyanonymous/flux_text_encoders", filename="clip_l.safetensors", local_dir="models/text_encoders")
    hf_hub_download(repo_id="comfyanonymous/flux_text_encoders", filename="t5xxl_fp16.safetensors", local_dir="models/text_encoders/t5")
    

è¿™å°†æŠŠæ‰€æœ‰ ComfyUI ä¸­çš„æœ¬åœ°æ¨¡åž‹æ˜ å°„åˆ°å®ƒä»¬åœ¨ Hugging Face ä¸Šçš„ç‰ˆæœ¬ã€‚é—æ†¾çš„æ˜¯ï¼Œç›®å‰è¿˜æ²¡æœ‰åŠžæ³•è‡ªåŠ¨åŒ–è¿™ä¸€è¿‡ç¨‹ï¼Œä½ éœ€è¦ **æ‰‹åŠ¨** æ‰¾åˆ°å·¥ä½œæµä¸­ä½¿ç”¨çš„æ¨¡åž‹åœ¨ Hugging Face ä¸Šçš„å¯¹åº”ç‰ˆæœ¬ï¼Œå¹¶å°†å®ƒä»¬æ˜ å°„åˆ° ComfyUI çš„ç›¸åŒæ–‡ä»¶å¤¹ä¸­ã€‚

å¦‚æžœä½ è¿è¡Œçš„æ¨¡åž‹ä¸åœ¨ Hugging Face ä¸Šï¼Œä½ éœ€è¦æ‰¾åˆ°ä¸€ç§æ–¹æ³•ï¼Œé€šè¿‡ Python ä»£ç å°†å®ƒä»¬ä¸‹è½½åˆ°æ­£ç¡®çš„æ–‡ä»¶å¤¹ä¸­ã€‚è¿™æ®µä»£ç åªä¼šåœ¨ Hugging Face Space å¯åŠ¨æ—¶è¿è¡Œä¸€æ¬¡ã€‚

çŽ°åœ¨ï¼Œæˆ‘ä»¬å°†å¯¹ `app.py` æ–‡ä»¶è¿›è¡Œæœ€åŽä¸€æ¬¡ä¿®æ”¹ï¼Œå³æ·»åŠ  ZeroGPU çš„å‡½æ•°è£…é¥°å™¨ï¼Œè¿™å°†è®©æˆ‘ä»¬èƒ½å¤Ÿå…è´¹è¿›è¡ŒæŽ¨ç†ï¼

    import gradio as gr
    from huggingface_hub import hf_hub_download
    + import spaces
    # ...
    + @spaces.GPU(duration=60) #modify the duration for the average it takes for your worflow to run, in seconds
    def generate_image(prompt, structure_image, style_image, depth_strength, style_strength):
    

è¯·æŸ¥çœ‹ [è¿™é‡Œ](https://gist.github.com/apolinario/47a8503c007c5ae8494324bed9e158ce/revisions?diff=unified&w=47a8503c007c5ae8494324bed9e158ce#diff-faf377dc15b3371a15d2c4a03b4d012825533bd2fb2297852cb2244d07fe36eeL4) çš„å·®å¼‚å¯¹æ¯”ï¼Œè¿™æ˜¯ä¹‹å‰çš„ Gradio æ¼”ç¤ºä¸Žä¸º Hugging Face Spaces å‡†å¤‡çš„å˜åŒ–ä¹‹é—´çš„å·®å¼‚ã€‚

4\. å¯¼å‡ºåˆ° Spaces å¹¶åœ¨ ZeroGPU ä¸Šè¿è¡Œ
-----------------------------

ä»£ç å·²å‡†å¤‡å¦¥å½“ã€‚ä½ æ—¢å¯ä»¥åœ¨æœ¬åœ°è¿è¡Œï¼Œä¹Ÿå¯é€‰æ‹©ä»»æ„å¿ƒä»ªçš„äº‘æœåŠ¡ï¼Œå¦‚ Hugging Face Spaces çš„ä¸“ç”¨ GPUã€‚è‹¥è¦åœ¨æ— æœåŠ¡å™¨çš„ ZeroGPU ä¸Šè¿è¡Œï¼Œè¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ã€‚

### ä¿®å¤ä¾èµ–é¡¹

é¦–å…ˆï¼Œä½ éœ€è¦ä¿®æ”¹ `requirements.txt` æ–‡ä»¶ï¼Œä»¥åŒ…å« `custom_nodes` æ–‡ä»¶å¤¹ä¸­çš„ä¾èµ–é¡¹ã€‚ç”±äºŽ Hugging Face Spaces è¦æ±‚åªæœ‰ä¸€ä¸ª `requirements.txt` æ–‡ä»¶ï¼Œå› æ­¤è¯·ç¡®ä¿å°†æ­¤å·¥ä½œæµæ‰€éœ€çš„èŠ‚ç‚¹ä¾èµ–é¡¹æ·»åŠ åˆ°æ ¹ç›®å½•çš„ `requirements.txt` æ–‡ä»¶ä¸­ã€‚

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œéœ€è¦å¯¹æ‰€æœ‰ `custom_nodes` é‡å¤æ­¤è¿‡ç¨‹:

![](https://img-s2.andfun.cn/devrel/posts/2025/03/5243511214631.gif)

çŽ°åœ¨æˆ‘ä»¬å‡†å¤‡å¥½äº†ï¼

![create-space](https://img-s2.andfun.cn/devrel/posts/2025/03/4be4e9fd8493b.png)

1.  è®¿é—® [Hugging Face](https://huggingface.co/) å¹¶åˆ›å»ºä¸€ä¸ªæ–°çš„ Spaceã€‚
2.  å°†å…¶ç¡¬ä»¶è®¾ç½®ä¸º ZeroGPU (å¦‚æžœä½ æ˜¯ Hugging Face PRO è®¢é˜…ç”¨æˆ·)ï¼Œæˆ–è€…å¦‚æžœä½ ä¸æ˜¯ PRO ç”¨æˆ·ï¼Œåˆ™è®¾ç½®ä¸º CPU Basic (å¦‚æžœä½ ä¸æ˜¯ PRO ç”¨æˆ·ï¼Œæœ€åŽå¯èƒ½éœ€è¦ä¸€ä¸ªé¢å¤–çš„æ­¥éª¤)ã€‚  
    2.1. (å¦‚æžœä½ æ›´å–œæ¬¢ä½¿ç”¨ä»˜è´¹çš„ä¸“ç”¨ GPUï¼Œå¯ä»¥é€‰æ‹© L4ã€L40S æˆ– A100ï¼Œè€Œä¸æ˜¯ ZeroGPUï¼Œè¿™æ˜¯ä¸€ä¸ªä»˜è´¹é€‰é¡¹)ã€‚
3.  ç‚¹å‡» â€œFilesâ€ é€‰é¡¹å¡ï¼Œé€‰æ‹© `File > Upload Files` ã€‚æ‹–åŠ¨ä½ çš„ ComfyUI æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶ **é™¤äº†** `models` æ–‡ä»¶å¤¹ (å¦‚æžœä½ å°è¯•ä¸Šä¼  `models` æ–‡ä»¶å¤¹ï¼Œä¸Šä¼ ä¼šå¤±è´¥)ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ç¬¬ 3 éƒ¨åˆ†çš„åŽŸå› ã€‚
4.  ç‚¹å‡»é¡µé¢åº•éƒ¨çš„ `Commit changes to main` æŒ‰é’®ï¼Œç­‰å¾…æ‰€æœ‰å†…å®¹ä¸Šä¼ å®Œæˆã€‚
5.  å¦‚æžœä½ ä½¿ç”¨çš„æ˜¯å—é™æ¨¡åž‹ (å¦‚ FLUX)ï¼Œä½ éœ€è¦åœ¨è®¾ç½®ä¸­æ·»åŠ ä¸€ä¸ª Hugging Face ä»¤ç‰Œã€‚é¦–å…ˆï¼Œåœ¨ [è¿™é‡Œ](https://huggingface.co/settings/tokens) åˆ›å»ºä¸€ä¸ªå…·æœ‰ `read` æƒé™çš„ä»¤ç‰Œï¼Œç”¨äºŽè®¿é—®ä½ éœ€è¦çš„æ‰€æœ‰å—é™æ¨¡åž‹ï¼Œç„¶åŽè¿›å…¥ä½ çš„ Space çš„ `Settings` é¡µé¢ï¼Œåˆ›å»ºä¸€ä¸ªåä¸º `HF_TOKEN` çš„æ–°å¯†é’¥ï¼Œå¹¶å°†ä½ åˆšåˆšåˆ›å»ºçš„ä»¤ç‰Œå€¼å¡«å…¥ã€‚

![variables-and-secrets](https://img-s2.andfun.cn/devrel/posts/2025/03/d91273baa91a3.png)

### å°†æ¨¡åž‹ç§»å‡ºè£…é¥°å‡½æ•° (ä»…é€‚ç”¨äºŽ ZeroGPU)

ä½ çš„æ¼”ç¤ºåº”è¯¥å·²ç»å¯ä»¥è¿è¡Œäº†ï¼Œä½†åœ¨å½“å‰çš„è®¾ç½®ä¸­ï¼Œæ¯æ¬¡è¿è¡Œæ—¶æ¨¡åž‹éƒ½ä¼šä»Žç£ç›˜å®Œå…¨åŠ è½½åˆ° GPU ä¸­ã€‚ä¸ºäº†åˆ©ç”¨æ— æœåŠ¡å™¨ ZeroGPU çš„æ•ˆçŽ‡ï¼Œæˆ‘ä»¬éœ€è¦å°†æ‰€æœ‰æ¨¡åž‹å£°æ˜Žç§»åˆ°è£…é¥°å‡½æ•°ä¹‹å¤–ï¼Œæ”¾åˆ° Python çš„å…¨å±€ä¸Šä¸‹æ–‡ä¸­ï¼Œæˆ‘ä»¬ç¼–è¾‘ `app.py` æ–‡ä»¶æ¥å®žçŽ°è¿™ä¸€ç‚¹ã€‚

    @@ -4,6 +4,7 @@
    from typing import Sequence, Mapping, Any, Union
    import torch
    import gradio as gr
    from huggingface_hub import hf_hub_download
    +from comfy import model_management
    import spaces
    
    hf_hub_download(repo_id="black-forest-labs/FLUX.1-Redux-dev", filename="flux1-redux-dev.safetensors", local_dir="models/style_models")
    @@ -109,6 +110,62 @@
    
    from nodes import NODE_CLASS_MAPPINGS
    
    +intconstant = NODE_CLASS_MAPPINGS["INTConstant"]()
    +dualcliploader = NODE_CLASS_MAPPINGS["DualCLIPLoader"]()
    +dualcliploader_357 = dualcliploader.load_clip(
    +    clip_name1="t5/t5xxl_fp16.safetensors",
    +    clip_name2="clip_l.safetensors",
    +    type="flux",
    +)
    +cr_clip_input_switch = NODE_CLASS_MAPPINGS["CR Clip Input Switch"]()
    +cliptextencode = NODE_CLASS_MAPPINGS["CLIPTextEncode"]()
    +loadimage = NODE_CLASS_MAPPINGS["LoadImage"]()
    +imageresize = NODE_CLASS_MAPPINGS["ImageResize+"]()
    +getimagesizeandcount = NODE_CLASS_MAPPINGS["GetImageSizeAndCount"]()
    +vaeloader = NODE_CLASS_MAPPINGS["VAELoader"]()
    +vaeloader_359 = vaeloader.load_vae(vae_name="FLUX1/ae.safetensors")
    +vaeencode = NODE_CLASS_MAPPINGS["VAEEncode"]()
    +unetloader = NODE_CLASS_MAPPINGS["UNETLoader"]()
    +unetloader_358 = unetloader.load_unet(
    +    unet_name="flux1-depth-dev.safetensors", weight_dtype="default"
    +)
    +ksamplerselect = NODE_CLASS_MAPPINGS["KSamplerSelect"]()
    +randomnoise = NODE_CLASS_MAPPINGS["RandomNoise"]()
    +fluxguidance = NODE_CLASS_MAPPINGS["FluxGuidance"]()
    +depthanything_v2 = NODE_CLASS_MAPPINGS["DepthAnything_V2"]()
    +downloadandloaddepthanythingv2model = NODE_CLASS_MAPPINGS[
    +    "DownloadAndLoadDepthAnythingV2Model"
    +]()
    +downloadandloaddepthanythingv2model_437 = (
    +    downloadandloaddepthanythingv2model.loadmodel(
    +        model="depth_anything_v2_vitl_fp32.safetensors"
    +    )
    +)
    +instructpixtopixconditioning = NODE_CLASS_MAPPINGS[
    +    "InstructPixToPixConditioning"
    +]()
    +text_multiline_454 = text_multiline.text_multiline(text="FLUX_Redux")
    +clipvisionloader = NODE_CLASS_MAPPINGS["CLIPVisionLoader"]()
    +clipvisionloader_438 = clipvisionloader.load_clip(
    +    clip_name="sigclip_vision_patch14_384.safetensors"
    +)
    +clipvisionencode = NODE_CLASS_MAPPINGS["CLIPVisionEncode"]()
    +stylemodelloader = NODE_CLASS_MAPPINGS["StyleModelLoader"]()
    +stylemodelloader_441 = stylemodelloader.load_style_model(
    +    style_model_name="flux1-redux-dev.safetensors"
    +)
    +text_multiline = NODE_CLASS_MAPPINGS["Text Multiline"]()
    +emptylatentimage = NODE_CLASS_MAPPINGS["EmptyLatentImage"]()
    +cr_conditioning_input_switch = NODE_CLASS_MAPPINGS[
    +    "CR Conditioning Input Switch"
    +]()
    +cr_model_input_switch = NODE_CLASS_MAPPINGS["CR Model Input Switch"]()
    +stylemodelapplyadvanced = NODE_CLASS_MAPPINGS["StyleModelApplyAdvanced"]()
    +basicguider = NODE_CLASS_MAPPINGS["BasicGuider"]()
    +basicscheduler = NODE_CLASS_MAPPINGS["BasicScheduler"]()
    +samplercustomadvanced = NODE_CLASS_MAPPINGS["SamplerCustomAdvanced"]()
    +vaedecode = NODE_CLASS_MAPPINGS["VAEDecode"]()
    +saveimage = NODE_CLASS_MAPPINGS["SaveImage"]()
    +imagecrop = NODE_CLASS_MAPPINGS["ImageCrop+"]()
    
    @@ -117,75 +174,6 @@
    def generate_image(prompt, structure_image, style_image, depth_strength, style_strength):
        import_custom_nodes()
        with torch.inference_mode():
    -        intconstant = NODE_CLASS_MAPPINGS["INTConstant"]()
             intconstant_83 = intconstant.get_value(value=1024)
    
             intconstant_84 = intconstant.get_value(value=1024)
    
    -        dualcliploader = NODE_CLASS_MAPPINGS["DualCLIPLoader"]()
    -        dualcliploader_357 = dualcliploader.load_clip(
    -            clip_name1="t5/t5xxl_fp16.safetensors",
    -            clip_name2="clip_l.safetensors",
    -            type="flux",
    -        )
    -
    -        cr_clip_input_switch = NODE_CLASS_MAPPINGS["CR Clip Input Switch"]()
             cr_clip_input_switch_319 = cr_clip_input_switch.switch(
                 Input=1,
                 clip1=get_value_at_index(dualcliploader_357, 0),
                 clip2=get_value_at_index(dualcliploader_357, 0),
             )
    
    -        cliptextencode = NODE_CLASS_MAPPINGS["CLIPTextEncode"]()
             cliptextencode_174 = cliptextencode.encode(
                 text=prompt,
                 clip=get_value_at_index(cr_clip_input_switch_319, 0),
             )
    
             cliptextencode_175 = cliptextencode.encode(
                 text="purple", clip=get_value_at_index(cr_clip_input_switch_319, 0)
             )
    
    -        loadimage = NODE_CLASS_MAPPINGS["LoadImage"]()
             loadimage_429 = loadimage.load_image(image=structure_image)
    
    -        imageresize = NODE_CLASS_MAPPINGS["ImageResize+"]()
             imageresize_72 = imageresize.execute(
                 width=get_value_at_index(intconstant_83, 0),
                 height=get_value_at_index(intconstant_84, 0),
                 interpolation="bicubic",
                 method="keep proportion",
                 condition="always",
                 multiple_of=16,
                 image=get_value_at_index(loadimage_429, 0),
             )
    
    -        getimagesizeandcount = NODE_CLASS_MAPPINGS["GetImageSizeAndCount"]()
             getimagesizeandcount_360 = getimagesizeandcount.getsize(
                 image=get_value_at_index(imageresize_72, 0)
             )
    
    -        vaeloader = NODE_CLASS_MAPPINGS["VAELoader"]()
    -        vaeloader_359 = vaeloader.load_vae(vae_name="FLUX1/ae.safetensors")
    
    -        vaeencode = NODE_CLASS_MAPPINGS["VAEEncode"]()
             vaeencode_197 = vaeencode.encode(
                 pixels=get_value_at_index(getimagesizeandcount_360, 0),
                 vae=get_value_at_index(vaeloader_359, 0),
             )
    
    -        unetloader = NODE_CLASS_MAPPINGS["UNETLoader"]()
    -        unetloader_358 = unetloader.load_unet(
    -            unet_name="flux1-depth-dev.safetensors", weight_dtype="default"
    -        )
    
    -        ksamplerselect = NODE_CLASS_MAPPINGS["KSamplerSelect"]()
             ksamplerselect_363 = ksamplerselect.get_sampler(sampler_name="euler")
    
    -        randomnoise = NODE_CLASS_MAPPINGS["RandomNoise"]()
             randomnoise_365 = randomnoise.get_noise(noise_seed=random.randint(1, 2**64))
    
    -        fluxguidance = NODE_CLASS_MAPPINGS["FluxGuidance"]()
             fluxguidance_430 = fluxguidance.append(
                 guidance=15, conditioning=get_value_at_index(cliptextencode_174, 0)
             )
    
    -        downloadandloaddepthanythingv2model = NODE_CLASS_MAPPINGS[
    -            "DownloadAndLoadDepthAnythingV2Model"
    -        ]()
    -        downloadandloaddepthanythingv2model_437 = (
    -            downloadandloaddepthanythingv2model.loadmodel(
    -                model="depth_anything_v2_vitl_fp32.safetensors"
    -            )
    -        )
    
    -        depthanything_v2 = NODE_CLASS_MAPPINGS["DepthAnything_V2"]()
             depthanything_v2_436 = depthanything_v2.process(
                 da_model=get_value_at_index(downloadandloaddepthanythingv2model_437, 0),
                 images=get_value_at_index(getimagesizeandcount_360, 0),
             )
    
    -        instructpixtopixconditioning = NODE_CLASS_MAPPINGS[
    -            "InstructPixToPixConditioning"
    -        ]()
             instructpixtopixconditioning_431 = instructpixtopixconditioning.encode(
                 positive=get_value_at_index(fluxguidance_430, 0),
                 negative=get_value_at_index(cliptextencode_175, 0),
                 vae=get_value_at_index(vaeloader_359, 0),
                 pixels=get_value_at_index(depthanything_v2_436, 0),
             )
    
    -        clipvisionloader = NODE_CLASS_MAPPINGS["CLIPVisionLoader"]()
    -        clipvisionloader_438 = clipvisionloader.load_clip(
    -            clip_name="sigclip_vision_patch14_384.safetensors"
    -        )
    
             loadimage_440 = loadimage.load_image(image=style_image)
    
    -        clipvisionencode = NODE_CLASS_MAPPINGS["CLIPVisionEncode"]()
             clipvisionencode_439 = clipvisionencode.encode(
                 crop="center",
                 clip_vision=get_value_at_index(clipvisionloader_438, 0),
                 image=get_value_at_index(loadimage_440, 0),
             )
    
    -        stylemodelloader = NODE_CLASS_MAPPINGS["StyleModelLoader"]()
    -        stylemodelloader_441 = stylemodelloader.load_style_model(
    -            style_model_name="flux1-redux-dev.safetensors"
    -        )
    -
    -        text_multiline = NODE_CLASS_MAPPINGS["Text Multiline"]()
             text_multiline_454 = text_multiline.text_multiline(text="FLUX_Redux")
    
    -        emptylatentimage = NODE_CLASS_MAPPINGS["EmptyLatentImage"]()
    -        cr_conditioning_input_switch = NODE_CLASS_MAPPINGS[
    -            "CR Conditioning Input Switch"
    -        ]()
    -        cr_model_input_switch = NODE_CLASS_MAPPINGS["CR Model Input Switch"]()
    -        stylemodelapplyadvanced = NODE_CLASS_MAPPINGS["StyleModelApplyAdvanced"]()
    -        basicguider = NODE_CLASS_MAPPINGS["BasicGuider"]()
    -        basicscheduler = NODE_CLASS_MAPPINGS["BasicScheduler"]()
    -        samplercustomadvanced = NODE_CLASS_MAPPINGS["SamplerCustomAdvanced"]()
    -        vaedecode = NODE_CLASS_MAPPINGS["VAEDecode"]()
    -        saveimage = NODE_CLASS_MAPPINGS["SaveImage"]()
    -        imagecrop = NODE_CLASS_MAPPINGS["ImageCrop+"]()
    
             emptylatentimage_10 = emptylatentimage.generate(
                 width=get_value_at_index(imageresize_72, 1),
                 height=get_value_at_index(imageresize_72, 2),
                 batch_size=1,
             )
    

æ­¤å¤–ï¼Œä¸ºäº†é¢„åŠ è½½æ¨¡åž‹ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ ComfyUI çš„ `load_models_gpu` å‡½æ•°ï¼Œè¯¥å‡½æ•°ä¼šå°†ä¸Šè¿°é¢„åŠ è½½çš„æ¨¡åž‹ä¸­æ‰€æœ‰å·²åŠ è½½çš„æ¨¡åž‹åŒ…å«è¿›æ¥ (ä¸€ä¸ªç»éªŒæ³•åˆ™æ˜¯æ£€æŸ¥å“ªäº›æ¨¡åž‹åŠ è½½äº† `*.safetensors` æ–‡ä»¶)ã€‚

    from comfy import model_management
    
    # æ·»åŠ æ‰€æœ‰åŠ è½½ safetensors æ–‡ä»¶çš„æ¨¡åž‹
    model_loaders = [dualcliploader_357, vaeloader_359, unetloader_358, clipvisionloader_438, stylemodelloader_441, downloadandloaddepthanythingv2model_437]
    
    # æ£€æŸ¥å“ªäº›æ¨¡åž‹æ˜¯æœ‰æ•ˆçš„ï¼Œå¹¶ç¡®å®šæœ€ä½³åŠ è½½æ–¹å¼
    valid_models = [
        getattr(loader[0], 'patcher', loader[0])
        for loader in model_loaders
        if not isinstance(loader[0], dict) and not isinstance(getattr(loader[0], 'patcher', None), dict)
    ]
    
    # æœ€ç»ˆåŠ è½½æ¨¡åž‹
    model_management.load_models_gpu(valid_models)
    

åœ¨ GitHub ä¸­ [æŸ¥çœ‹ diff](https://gist.github.com/apolinario/47a8503c007c5ae8494324bed9e158ce/revisions#diff-faf377dc15b3371a15d2c4a03b4d012825533bd2fb2297852cb2244d07fe36eeL6) ä»¥ç¡®åˆ‡äº†è§£å‘ç”Ÿäº†å“ªäº›å˜åŒ–ã€‚

### éžä¸“ä¸šç‰ˆè®¢é˜…ç”¨æˆ·è¯·ç•™æ„ (ä¸“ä¸šç‰ˆç”¨æˆ·å¯è·³è¿‡æ­¤æ­¥éª¤)

è‹¥ä½ å¹¶éž Hugging Face ä¸“ä¸šç‰ˆè®¢é˜…ç”¨æˆ·ï¼Œåˆ™éœ€ç”³è¯· ZeroGPU æŽˆæƒã€‚ä½ åªéœ€è¿›å…¥è‡ªå·±çš„ Space è®¾ç½®é¡µé¢ï¼Œæäº¤ ZeroGPU æŽˆæƒè¯·æ±‚å³å¯ï¼Œæ“ä½œååˆ†ç®€ä¾¿ã€‚æ‰€æœ‰é‡‡ç”¨ ComfyUI åŽç«¯çš„ Spaces çš„ ZeroGPU æŽˆæƒè¯·æ±‚éƒ½å°†èŽ·æ‰¹ã€‚ðŸŽ‰

### æ¼”ç¤ºæ­£åœ¨è¿è¡Œ

æœ¬æ•™ç¨‹ä¸­æˆ‘ä»¬æž„å»ºçš„æ¼”ç¤ºç¤ºä¾‹å·²ç»å‘å¸ƒåˆ° Hugging Face Spaces ä¸Šå•¦ï¼Œç‚¹å‡»è¿™é‡Œä½“éªŒ: [https://huggingface.co/spaces/multimodalart/flux-style-shaping](https://huggingface.co/spaces/multimodalart/flux-style-shaping)

5\. ç»“è®º
------

ðŸ˜®â€ðŸ’¨ï¼Œå°±è¿™äº›äº†ï¼ æˆ‘çŸ¥é“è¿™éœ€è¦èŠ±è´¹ä¸€äº›ç²¾åŠ›ï¼Œä½†ä½œä¸ºå›žæŠ¥ï¼Œä½ å¯ä»¥è½»æ¾çš„ä½¿ç”¨ä¸€ä¸ªç®€æ´çš„ç”¨æˆ·ç•Œé¢å’Œå…è´¹æŽ¨ç†å°†ä½ çš„å·¥ä½œæµåˆ†äº«ç»™æ‰€æœ‰äººï¼ æ­£å¦‚ä¹‹å‰æ‰€è¿°ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯åœ¨ 2025 å¹´åˆå°½å¯èƒ½åœ°è‡ªåŠ¨åŒ–å’Œç®€åŒ–è¿™ä¸€è¿‡ç¨‹ï¼ èŠ‚æ—¥å¿«ä¹ï½ž ðŸŽ…âœ¨

* * *

> åŽŸæ–‡é“¾æŽ¥: [https://hf.co/blog/run-comfyui-workflows-on-spaces](https://hf.co/blog/run-comfyui-workflows-on-spaces)
> 
> åŽŸæ–‡ä½œè€…: ApolinÃ¡rio from multimodal AI art, Charles Bensimon
> 
> è¯‘è€…: evinci