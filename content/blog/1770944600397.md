---
layout: post
title: 'AiReader：一个不联网的 AI 阅读助手，让你的算力为你服务'
date: "2026-02-13T01:03:20Z"
---
AiReader：一个不联网的 AI 阅读助手，让你的算力为你服务
=================================

![AiReader：一个不联网的 AI 阅读助手，让你的算力为你服务](https://img2024.cnblogs.com/blog/3618712/202602/3618712-20260212155315495-120542706.png) AiReader ：一个内置 AI 的桌面阅读器，所有 AI 推理都在你本地的 CPU/GPU 上运行。 不需要联网，不需要注册，不需要 API Key。安装后首次配置下载一个 AI 模型（几百 MB 到几 GB），之后拔掉网线也能用。

你的文档，正在被谁阅读？
------------

每次你把一篇论文扔进在线翻译工具，每次你让 AI 帮你解读一份合同——你的文档都被上传到了某家公司的服务器上。

也许你觉得无所谓。但如果有一种方式，**AI 一样好用，但文档永远不离开你的电脑呢？**

这就是 AiReader 在做的事。

* * *

AiReader 是什么
------------

一句话：**一个内置 AI 的桌面阅读器，所有 AI 推理都在你本地的 CPU/GPU 上运行。**

不需要联网，不需要注册，不需要 API Key。安装后首次配置下载一个 AI 模型（几百 MB 到几 GB），之后拔掉网线也能用。

它支持阅读 **PDF、EPUB、Markdown、TXT** 四种格式，内置以下 AI 能力：

* * *

### 📖 选中即译

在文档中选中任意文字，AI 立即翻译。支持三种模式：

*   **直译**：保留原文结构
*   **意译**：更自然的目标语言表达
*   **白话**：用最简单的话解释

自动识别中英文方向。不是逐词机翻，是理解上下文后的翻译。

### 🔍 文法解释

选中一个复杂句子，AI 拆解句子结构：主谓宾、从句关系、关键词汇用法。

比起翻译，这才是真正帮你「读懂」一门语言的工具。

### 💬 上下文对话

选中一段内容，然后像和 ChatGPT 一样追问。可以锁定上下文反复深入，对话历史按文档自动保存。

### 📝 智能笔记

翻译、解释、对话内容都可以一键保存为笔记。笔记关联文档，支持 Markdown 导出。

### 📚 离线词典

内置 ECDICT（英汉）+ CC-CEDICT（汉英），双击任意单词弹窗查词，无需联网。

* * *

它凭什么能在本地跑 AI？
-------------

底层用的是 **llama.cpp** —— 目前最成熟的开源本地大模型推理引擎，被全球数百万开发者使用。内置的模型是 **Qwen3 系列**（通义千问），从 0.6B 到 32B 参数量都有。

在不同硬件上的表现：

你的硬件

能跑什么

体验

游戏笔记本（RTX 3060+）

8B 模型

和 ChatGPT 一样流畅

普通笔记本（无独显）

1.7B-4B 模型

流畅，翻译质量够用

办公电脑

0.6B 模型

可用，简单翻译没问题

Mac M 系列芯片

4B-8B 模型

Metal 加速，非常流畅

**你不需要了解这些细节。** 首次启动时，应用会自动检测你的硬件、跑基准测试、推荐最合适的模型，全程一键完成。

* * *

三个平台都能用
-------

平台

GPU 加速

安装包

**Windows** x64

NVIDIA (CUDA) · AMD/Intel (Vulkan)

`.exe` 安装包

**macOS** ARM / Intel

Metal

`.dmg`

**Linux** x64

Vulkan

`.AppImage` / `.deb`

* * *

完全免费，完全开源
---------

*   **MIT 协议**：你可以自由使用、修改、分发
*   **无付费版**：所有功能免费
*   **无广告**：没有任何广告和推广
*   **无数据收集**：不收集任何用户数据
*   **代码公开**：每一行代码都在 GitHub 上，欢迎审查

* * *

谁适合用
----

*   📄 经常阅读英文论文、技术文档、外文书籍的人
*   🔒 处理敏感文件（商业合同、内部报告、未发表研究）不想上传云端的人
*   🎓 正在学外语，需要文法拆解而不只是翻译的学生
*   🖥️ 想体验本地大模型但不知道从哪里开始的技术爱好者
*   💡 信奉"我的数据我做主"的人

* * *

怎么获取
----

### 下载

GitHub Releases 页面下载对应平台安装包：

🔗 **[https://github.com/LissajousX/aireader/releases](https://github.com/LissajousX/aireader/releases)**

### 安装

*   **Windows**：双击 `.exe` 安装包，一路下一步
*   **macOS**：打开 `.dmg`，拖入应用程序文件夹
    
    > ⚠️ macOS 版本暂未完成 Apple 签名认证，首次打开需要：右键点击 App → 选择「打开」→ 确认。或在终端执行 `xattr -cr /Applications/Aireader.app`
    
*   **Linux**：运行 `.AppImage` 或安装 `.deb` 包

### 首次使用

启动后跟随引导向导：选择语言 → 设置存储路径 → 一键配置 AI → 开始阅读。

整个过程 3-5 分钟（主要是下载模型的时间）。

* * *

一些你可能会问的问题
----------

**Q: 翻译质量和在线工具比怎么样？**  
A: 4B 以上的模型，日常翻译质量接近 GPT-3.5 水平。8B 模型在大多数场景下和 GPT-4 差距不大。专业术语密集的场景（如医学、法律），建议用更大的模型或接入云端 API。

**Q: 只能用内置模型吗？**  
A: 不是。你也可以连接 Ollama（本地跑更大的模型）或任何 OpenAI 兼容的 API（如 DeepSeek）。

**Q: 电脑配置不够怎么办？**  
A: 最低 4GB 内存 + 任意 CPU 就能跑 0.6B 模型。如果觉得质量不够，可以接 Ollama 或云端 API 作为补充。

**Q: 支持中文文档吗？**  
A: 支持。Qwen3 模型本身就擅长中英双语。界面也支持中英文切换。

**Q: 安全吗？代码可信吗？**  
A: MIT 开源，全部代码公开。你可以自己审查，也可以自己编译。没有混淆，没有后门。

* * *

让你的算力为你服务
---------

你的电脑里有一颗强大的处理器，可能还有一块不便宜的显卡。大多数时候，它们都在闲着。

AiReader 让这些算力做它们最擅长的事：**帮你阅读、翻译、理解、思考。**

而且，完全在你自己的电脑上。

* * *

**🔗 GitHub: [https://github.com/LissajousX/aireader](https://github.com/LissajousX/aireader)**

如果觉得有用，一个 ⭐ Star 就是最好的支持。