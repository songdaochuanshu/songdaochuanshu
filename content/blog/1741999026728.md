---
layout: post
title: 'Ollama——大语言模型本地部署的极速利器'
date: "2025-03-15T00:37:06Z"
---
Ollama——大语言模型本地部署的极速利器
======================

1、概述
====

　　Ollama 是一款开源跨平台大模型工具，**主要用于在本地便捷部署和运行大型语言模型（LLM），核心目标是降低用户使用大模型的门槛，同时保障数据隐私。**核心功能与特点如下：

**（1）本地部署，隐私保护**

1.  支持在 Windows、MacOS、Linux 等系统本地运行模型，无需依赖云端，数据交互全程在本地完成，避免隐私泄露。
2.  适合对数据敏感的场景（如企业内部、科研）。

**（2）丰富模型库，开箱即用**

1.  **预集成主流开源模型**，如 Llama 3、DeepSeek-R1、Qwen、Mistral 等（可以在 [http://ollama.com/library](https://link.zhihu.com/?target=http%3A//ollama.com/library) 上找到），覆盖文本生成、代码开发、多语言翻译等场景。
2.  支持模型量化（如 7B/13B 参数模型），降低显存需求，普通电脑（8GB + 内存）即可运行轻量模型。

**（3）极简交互，命令行与 API 双支持**

1.  命令行： 通过 ollama run \[模型名\] 一键下载并启动模型，支持流式对话（如 ollama run yi:6b-chat）。
2.  API 接口：默认开放 11434 端口，兼容 OpenAI API 格式，可无缝对接 LangChain 等工具，方便开发集成。

**（4）自定义模型** 

1.  通过 Modelfile 配置参数（温度、上下文长度、系统提示等），创建个性化模型（如 FROM llama2 PARAMETER temperature 0.7）。

2、安装与基础命令
=========

**（1）安装（Github：[https://github.com/ollama/ollam](https://link.zhihu.com/?target=https%3A//github.com/ollama/ollama)）**

*   官网下载：[ollama.com](https://ollama.com/)（Windows、Mac支持一键安装包）。
*   命令行安装（Linux）：curl -fsSL https://ollama.com/install.sh | sh。
*   Docker安装：直接docker run ollama。

**（2）常用命令**

拉取模型：ollama pull llama3:13b
运行对话：ollama run llama3:13b（首次自动下载）
列出模型：ollama list
停止服务：ollama stop
查看帮助：ollama --help

> 注意： 详细命令使用参见《[大模型-ollama（运行框架）](https://zhuanlan.zhihu.com/p/720546185)》这篇博文。

3、本地部署大语言模型和云端部署大语言模型对比
=======================

![](https://img2024.cnblogs.com/blog/624219/202503/624219-20250314142447924-465970463.png)

4、典型使用场景
========

*   开发者测试：快速验证模型性能，无需申请云端 API 权限。
*   本地化应用：离线聊天机器人、内部文档问答系统（如医疗、法律领域）。
*   科研与教学：自定义模型训练，分析模型行为（如参数窃取实验）。
*   隐私优先场景：避免敏感数据上传云端（如企业代码、用户对话）。

5、安全风险与加固建议
===========

**（1）安全风险**

　　2025 年 3 月，国家网络安全通报中心指出 Ollama 默认配置存在三大风险：

1.  未授权访问：11434 端口默认开放且无认证，攻击者可直接调用模型、删除文件。
2.  数据泄露：通过 /api/show 接口获取模型敏感信息（如 License）。
3.  历史漏洞：可利用 CVE-2024 系列漏洞执行恶意操作（如数据投毒）。

**（2）加固建议**

*   限制端口监听：修改配置仅允许本地访问（ollama serve --listen localhost:11434）。
*   配置防火墙：禁止公网访问 11434 端口。
*   启用 API 密钥：通过环境变量 OLLAMA\_API\_KEY 认证（需版本 ≥0.5.12）。
*   及时更新：修复漏洞，避免使用默认配置暴露公网。

6、优缺点总结
=======

*   优点：轻量易用、模型丰富、隐私性强，适合快速原型开发。
*   缺点：默认配置不安全（需手动加固），多模型并行依赖 GPU 显存，复杂场景需结合 vLLM 等框架优化。

7、总结
====

　　Ollama 是本地大模型的 “瑞士军刀”，用一行命令即可开启私有化 AI 体验，但需注意安全配置，适合追求便捷与隐私的开发者和企业。

8、参考文章
======

    [大模型-ollama（运行框架）](https://zhuanlan.zhihu.com/p/720546185) 、 [Ollama使用指南【超全版】](https://zhuanlan.zhihu.com/p/704951717)