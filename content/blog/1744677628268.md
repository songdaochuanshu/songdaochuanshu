---
layout: post
title: '垂直模型和AI Workflow是开AGI的历史倒车'
date: "2025-04-15T00:40:28Z"
---
垂直模型和AI Workflow是开AGI的历史倒车
==========================

> 提供**AI咨询**+**AI项目陪跑**服务，有需要回复1

**RL 之父 Rich Sutton**在 2019 年的文章《苦涩的教训》中指出：

> 70 年的 AI 研究历史告诉我们一个最重要的道理：依靠纯粹算力的通用方法，最终总能以压倒性优势胜出

怎么说呢？他认为试图将人类知识编码到AI中（如专家系统、手工设计特征）短期有效，但长期会限制发展。

比如AlphaGo/GPT-3的成功并非源于复杂规则，而是大规模算力支撑的简单算法（神经网络+海量数据）。

而后又有一些案例：最近 Gemini 和 4o 更新的图片功能，可能直接取代了很多图片工作流：用自然语言对话完成现在复杂的 SD 图像生成工作流。

于是很多人会认为：**模型的通用能力，正在取代现在那些复杂的 Workflow。**

> 但我认为**这是不对的**，至少说在这几年是不对的，因为GPT是基于统计学的逻辑，他并不具备真正的思考能力

知识的有损性
------

我们知道，知识/数据是对**真实世界的描述**，就简单一个事物，事实上我们平时只会关注他不到1/10的部分，以糖尿病为例：

![](https://files.mdnice.com/user/25507/c09ff275-d992-4646-92eb-5a710fda2a9a.png)

我们讨论的最多的是其症状和药物，文化经济模块很少会涉及，这里造成的结果就是**数据残缺性与知识表征瓶颈**。

比如医生在实际诊断过程中，不仅依赖临床指南，还有大量的内化知识，包括：

1.  患者微表情解读（疼痛忍耐度）；
2.  社会经济因素权衡（治疗方案可行性）；
3.  伦理判断（生命质量 vs 延长寿命）；

这是当前AI难以跨越的困局：**隐性知识难以结构化，导致训练数据本质残缺。**

GPT-4的医学考试高分≠临床能力，恰如通过飞行理论考试≠能处理空中特情，一个道理。

AlphaGo的成功建立在围棋**规则完全透明、状态空间有限的基础上。**而真实医疗场景存在：

1.  模糊边界（症状相似的不同疾病）；
2.  动态演化（患者病情突变）；
3.  价值冲突（不同科室意见相左）；

这类开放性问题需要**元认知能力（反思自身决策局限）**，而当前AI仍停留在**“统计拟合”**层面。

综上，**RL 之父所谓的算力碾压需要一个大前提**：**算力需作用于正确架构**。

若基础模型无法表征某类知识（如医学伦理），单纯堆算力可能陷入**“自以为是又严密而精准的错误”**。

而GPT的预训练是基于词序列的条件概率建模，其核心是通过海量文本学习**在特定上下文中，下一个词的概率分布**。

确实不能否定其可能出现**涌现**的可能，但那也要建立在对世界全量知识的输入，显然现在是做不到的，毕竟文字可不能完全描述真实世界。

现有研究表明，语言文字至多能描述真实世界的30-40%（以可编码信息量计算），根据描述对象的不同，语言的有效性差异显著：

![](https://files.mdnice.com/user/25507/8c0f24bc-e93a-4ed0-816d-25cc92cbd3e6.png)

这里很多多模态设备需要进一步发展才行，所以这个窗口期早着呢！

综上，现在鼓吹**零Workflow**的人都**“其心可诛”**，没准他们在释放错误的技术路径，自己晚上偷偷的组装各种Workflow做训练呢！

“偏向性”公平不可取
----------

其实，**零Workflow**是完全适应于OpenAI的Agent发展预测的（山姆·奥特曼提出）：

**L1级别（聊天机器人）。**AI系统能够进行基本的对话和交流，显示出对自然语言的基本理解能力，并能对各种提示和问题作出响应。

**L2：推理者（Reasoners）。**AI系统能够以人类专家的熟练程度解决复杂问题，标志着其从单纯模仿人类行为升级到展现真实的智能水平。这些AI不仅擅长对话，更具备了解决问题的能力，其推理和决策能力已接近人类水平。

**L3：智能体（Agents）。**AI系统能够承担复杂的任务、作出决策和适应不断变化的环境，并在无须持续人类监督的情况下自主行动。这一阶段的AI不仅具备推理能力，更能自主执行各类复杂的操作任务。

**L4：创新者（Innovators）。**AI系统具有创造性和独创性，能够提出突破性的想法和解决方案。它们不仅能模仿人类的创造力，更能突破思维的局限，提出令人耳目一新的创新理念。

**L5：组织者（Organizations）。**AI系统不仅具备战略思维，还拥有实现组织目标所需的高效率和强适应性，能够管理复杂的系统。它们能够灵活协调多个智能体，合理分配任务，实时监控进度，并依据实际情况作出迅速调整。

当前正处于L2到L3的分界线，L3-L5全是**脏活累活，在LLM的基础上不断叠加各种能力，说人话一点就是开放API/开放知识/开放能力给大模型**。

L1是是否问题，L2是增强问题，L3-L5其实是数据和能力组织问题。他包括了**多模态、环境感知、具身智能、AR/VR甚至脑机接口**撒的。

这本事没什么问题，慢慢发展即可，**但很多人为了吹嘘所谓尚不成熟的Agent框架**，在一再贬低基于Workflow（或者说SOP）的AI应用：

![](https://files.mdnice.com/user/25507/4a6b89c9-8005-4012-8cf7-2bc82266ffdb.png)

比如，这里说SOP AI应用只能靠**指令主动触发**或者只能做到**单次请求响应**，完全就是YY；

然后他们所谓的AI Agent可以自动感知环境主动触发，其实严格意义上也需要触发器的，这样带着**偏见**去叙事，抬高一个打压一个是很神奇的，**瞒者瞒不识，识者不能瞒**。

在看AI Agent框架的定义：

![](https://files.mdnice.com/user/25507/1dc8f79c-c1ca-470e-a6e5-0b4ea85f747e.jpg)

所谓的记忆与工具且早着呢，单记忆好多公司就搞不定，每个行业各种黑科学、黑话，**坐着等待大模型慢慢发展，其实约等于等待大模型将各行各业的SOP内部封装做完**。

> 醒醒吧，这是一场入口之争，是你想入口在哪的问题！

其实，仅仅是**鼓吹零Workflow**也就算了，但是当前有些信号正在逐渐打压垂直领域的模型，会认为垂直模型是开倒车，这真的是胡说八道了...

垂直模型开倒车
-------

首先，AI产品的实现在于两极：**模型与工程**，基座模型能力越强那么对应工程实现就可以越简单，只不过这又该临界点。比如，这个临界点是：

1.  **模型可以不必做规划，但他真的能精准抽取关键词，这是是否问题**；
2.  **工程能切实补足大模型的天生缺陷，比如幻觉、比如记忆问题**；

就我去年到今年看到的20家企业，在AI产品实现全部是基于Workflow在做设计，他们对于模型是否会完全颠覆自己的提示词工程表现出了**几无所谓**的态度，原因是：

1.  浅尝则止的公司，提示词工程本来成本就很低，10多20万就搞定了，模型要取代就取代呗，他们**毫无所谓**；
2.  **行业深度**运用的公司，已经是领域非常资深的玩家，他们的提示词工程依赖于大量KnowHow，偶尔他们自己都玩不明白，所以对于模型马上会具备超越他们行业认知的事情，是**毫不担心**的；

这里要注意的是，这里所谓的行业深度并不是只程序员行业、图像行业这种规则性完善的公司，而是指医疗、金融、法律等领域。

所以，真实生产在用的技术路径，和某些公司在鬼扯的路径完全不是一套，这是什么原因呢？

入口之争
----

其实前面已经说过了，垂直领域的玩家当前只能基于Workflow自己玩，而类似DeepResearch、Genspark、Agent、Manus甚至门槛更高的Coze这种玩家当然是希望：**你们什么都别做，等我好了，就用我的！**

以Genspark为例，他们就发现直接抓取网络或者完全依赖大模型只能解决简单问题时，就有一系列改进策略了，包括：

1.  **加入专业数据源（如学术、财经、旅游等）**；
2.  并行搜索处理复杂问题；
3.  多代理交叉验证信息避免幻觉；
4.  引入专门的深度调研 Agent；

特别是这点需要特别引人注意：  
**使用高质量数据源、专家审核内容；数据由离线 Agent 审核，确保准确性，避免信息冗杂和虚假**。

虽然鼓吹的是更少的控制，更多的工具，只不过什么是工具就需要仔细揣摩了。

举个例子，如果我现在要做医疗场景的Agent，那么我完全可以基于Workflow做基础实现，然后开启用户验证。

而当我验证的差不多后，立马宣传大家都不要使用Workflow，并且马上用DeepSeek包装出一套Agent框架，将我的Workflow、数据全部**以知识的形式内置进模型**。

> 那么，此时这个所谓Agent框架，他到底是框架还是垂直模型呢？

再比如，我野心再大点，已经不满足于一个医疗领域。于是去收购了一家特别优秀的教育做AI Workflow的公司，然后用同样的方法论将知识内置，并开始鼓吹**专家模型**...

如果体验较好，也不知道最后会怎么样。

结语
--

在Agent与Workflow的博弈中，技术演进的本质是效率与**安全稳定性**的动态平衡。

当前的讨论焦点并非“谁取代谁”，而是如何在不断变化的应用场景中找到最优解。通过深入分析行业实践，可以归纳出以下三个关键结论：

**一、通用性需以基础模型突破为前提**

GPT的崛起证明了，当底层架构足够强大时，统一的框架可以打破细分领域的“专家系统”垄断。然而，要实现Agent的类似颠覆，我们面临两大障碍：

1.  **长程规划的可靠性：**当前，模型在超过50步的任务中错误率呈指数级上升（0.95^50≈0.07），难以满足生产环境中对稳定性的高要求；
2.  **工具调用的完备性：**现有的Function Calling功能主要支持基础操作（如浏览器、文件读取等），而对垂直领域的专业工具链支持则明显不足；

没有强大的基础模型与多模态工具支撑，Agent无法实现从一般任务到专业任务的跨越。

**二、垂直Workflow仍是产业落地的现实选择**

尽管通用Agent充满潜力，但在金融、医疗等高要求行业，Workflow依然在多个维度上具备不可替代的优势：

1.  **确定性交付：**通过预设规则和标准化流程，能够有效规避模型幻觉的风险。以医疗诊断为例，强制嵌入临床指南的校验模块，确保输出的可靠性；
2.  **成本效率：**与其让Agent进行冗长的推理，不如直接调用已预设的流程来完成任务，这不仅能降低错误率，还能节省大量计算资源，减少90%的Token消耗；
3.  **数据反哺：**通过执行Workflow生成的日志数据，可以为基础模型训练提供高质量的轨迹数据，进一步提升模型在特定领域的能力。

这正是吕老师所说的**Workflow是模型能力边界的缓冲层**的意思，它实际上是人类经验的结构化封装，为AI的实际应用提供稳定的基础。

**三、融合架构将成为中期主流**

随着技术的不断进步，我们看到行业中逐渐形成新的技术范式：**通用模型作协调层，垂直Workflow作执行层。**

这一架构能够在避免纯Agent的失控风险的同时，突破传统Workflow的僵化局限，成为一种灵活且高效的解决方案。典型的案例包括：

1.  **Coze的“混合编排”模式：**用户自定义的Workflow节点中，嵌入了Agent的决策点，在关键环节留有人工干预入口，从而平衡了灵活性与可控性；
2.  **Deepseek的“能力蒸馏”路径：**通过将垂直场景中的Workflow执行数据反向训练基座模型，逐步内化领域知识，最终实现高效的自主决策；

这种架构的核心在于，它将工具链的标准化视为Agent落地的必经之路，而工具本身的设计，往往源自于既有Workflow的抽象。

这不仅提高了模型的自主性，还保持了在复杂场景中的高效执行。

**未来五年的关键命题**

行业发展正在向着更加成熟的方向前进，但在这一过程中，我们也需警惕两类极端倾向：

第一，**盲目追求“零Workflow”：**

在模型尚未成熟时，急于推向通用Agent，可能会让产品陷入**“高概念、低可用”**的陷阱。

真正的技术进步应当是在能力达到临界点后，再让Agent承担更多任务；

第二，**固守手工规则：**

拒绝拥抱基础模型的进化，可能会错失自动生成Workflow的技术浪潮，导致技术逐步落后。

> 真正的机会并不在于简单的“零Workflow”或“手工规则”的选择，而在于建立动态适配体系。

通过实时监控模型的能力边界，将可预测的任务交给Agent自主规划，而对于不确定的环节，依然需要保留Workflow的硬性约束。

这种方法才是真正的**“More Intelligence, Less Structure”**的务实解读：不是消除结构，而是让人工智能学会在规则与自由之间找到最佳平衡，动态适应不同场景的需求。

最后，未来的AI产品将不再是简单的“工具”或“执行系统”，而是能够在动态变化的环境中自主学习、进化，并根据实际需求切换工作模式的智能体。

从应用角度看，真正的挑战在于如何平衡技术创新与可控性，如何让AI技术服务于特定行业的需求，而不仅仅是追逐“通用智能”的梦想。

**短期内，Workflow仍将在很多行业中扮演关键角色，而长远来看，随着基础模型的不断完善，AI将逐步迈向更加灵活与自主的阶段，助力各行各业的智能化转型。**

![](https://files.mdnice.com/user/25507/2de720b0-1cd9-48e6-b009-5f1ce49f7eed.png)

![](https://img2022.cnblogs.com/blog/294743/202202/294743-20220216140902628-1163053035.png)