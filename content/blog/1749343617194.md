---
layout: post
title: '综述论文解读：Editing Large Language Models: Problems, Methods, and Opportunities'
date: "2025-06-08T00:46:57Z"
---
综述论文解读：Editing Large Language Models: Problems, Methods, and Opportunities
==========================================================================

  论文为大语言模型知识编辑综述，发表于自然语言处理顶会ACL（[原文链接](https://aclanthology.org/2023.emnlp-main.632/)）。由于目前存在广泛的模型编辑技术，但一个统一全面的分析评估方法，所以本文：

  1、对LLM的编辑方法进行了详尽、公平的实证分析，探讨了它们各自的优势和劣势。

  2、构建了一个新的数据集，旨在揭示当前模型编辑方法的缺点，特别是泛化和效率方面。

  3、概述了模型编辑领域未来潜在的研究机会。

  阅读本文请同时参考原始论文图表。

问题定义
====

  假设原始模型为$f\_\\theta(x):\\mathbb{X}\\to\\mathbb{Y}$，对于某个样本$(x\_e,y\_e)$，或称编辑描述符，有$f\_\\theta(x\_e)\\neq y\_e$，则模型编辑就是使得编辑后的模型$f\_{\\theta\_e}$有$f\_{\\theta\_e}(x\_e)= y\_e$。

  模型编辑会影响与所编辑样本$(x\_e,y\_e)$相关的样本的预测，把这样的样本集合称为编辑域$I(x\_e,y\_e)$，也就是$(x\_e,y\_e)$和与它相似的邻域样本$N(x\_e,y\_e)$构成的样本集合。一个成功的模型编辑仅影响编辑域内部的模型行为，而不影响编辑域外部的模型行为。如文中式(1)所示，其中$O(x\_e,y\_e)$表示编辑域之外的样本。

  编辑后的模型$f\_{\\theta\_e}$通常要满足可靠性、普适性和局部性(reliabilty, generality, locality)：

  1、可靠性 (Reliability)：文中式(2)，即修改后的模型对编辑样本正确预测的期望，越大越好。

  2、普适性 (Generality)：文中式(3)，即修改后的模型对编辑样本的邻域$N(x\_e,y\_e)$的样本正确预测的期望，越大越好，本文的意思就是同义句也要满足。

  3、局部性 (Locality)：文中式(4)，即修改后的模型对编辑域之外的样本的预测与原始模型预测一致的期望，越大越好。

现有LLM编辑方法
=========

  现有LLM编辑方法可分为两类。总结看表1，示意图看图2.

使用额外参数而保持原始模型参数不变
-----------------

1.  SERAC: 一种使用检索增强反事实模型（SERAC）实现的半参数编辑。该模型将编辑存储在显式存储器中，并学会对其进行推理，从而根据需要调整原始模型的预测。
    
2.  T-Patcher和CaliNET: 将额外的可训练参数引入到PLM的FFN层中，并在修改后的数据集上训练额外添加的参数。
    

修改模型内部参数
--------

### 基于定位和修改

  1、KN: 使用知识归因方法定位模型FFN中表达知识的神经元，并进行更新。

  2、ROME: 使用因果中介分析来定位编辑区域。与在FFN中修改知识神经元不同，ROME修改整个矩阵。

  3、MEMIT: 修改一系列的模型层，支持同时执行数千个修改。

  以上方法基于事实知识的局部性假设，尚未得到广泛验证，某些参数的变化可能会影响不相关的知识，并产生不可预见的结果。

### 基于元学习

  1、KE：训练一个超网络（双向LSTM）来预测每个数据点的权重更新，从而实现对目标知识的编辑，而不破坏其他知识。但这种方法对于LLM效果不佳。

  2、MEND: 使用梯度的低秩分解来学习转换经过微调的语言模型的梯度。这种方法能够以较少的资源消耗应用于LLMs。

初步实验
====

  表2展示了以上模型在三个指标上的实验对比结果，其中，FT表示直接对原始模型进行微调。

  数据集：ZsRE一个问答 (QA) 数据集，使用反译生成的问题改写作为样本邻域，并使用自然问题 (NQ) 作为编辑域之外的数据来评估局部性。COUNTERFACT通过用一个与主语实体相似但共享相同谓词的近似主语实体替换事实中的主语实体来构建超出范围的数据。

  模型：实验实施在T5-XL(3B)和GPT-J(6B)两个大模型上，T5-XL包含编解码器结构，GPT-J仅包含解码器。由于ROME和MEMIT只适用于解码器，因此只在GPT-J上进行了实验。

  微调：为了减小计算量，仅对ROME定位的层进行微调。

  结果分析：SERAC、ROME、MEMIT效果最好，在修改模型权重的方法中，ROME最好。

综合分析
====

可移植性 (Portability)
------------------

  除了前面的指标以外，模型将修改的某个知识转移到相关内容的有效性也是一个重要的指标。因此使用GPT-4来构建一个新的数据集来评估编辑方法的相关性能。简单来说，当将模型关于某个提问$(s,r,?)$的预测$o$修改为$o^\*$时，对于已知事实$(o^\*,r^\*,o'^\*)$，能对问题$(s,r,r^\*,?)$预测出$o'^\*$，也就是把$o^\*$当做一个跳板。如果模型能正确回答出$o'^\*$，则可以推断模型正确修改了$(s,r,o^\*)$。数据集构建方式如文中表6所示。B.1好像是，对于GPT-4生成的问题答案的已知事实$(o^\*,r^\*,o'^\*)$，选择T5和GPT-J共享的作为最终的可移植性数据集，但是符号写的却是原始的。

  可移植性指标定义为文中式(5)，其中$P(x\_e,y\_e)$表示由新生成的数据组成的样本。

  结果如表3所示，可以看出MEMIT效果最好。

局部性
---

  图4可视化了不同指标概念对于某个样本的分布。对于某个问题的模型编辑，一个好的编辑应该使模型同步修改整个灰色虚线内部的所有问题的答案，而不修改虚线外的问题的答案。

效率
--

  表4展示了各方法10次编辑所需的时间，不计入模型训练时间。

  图5对比各方法的显存消耗。

批量编辑分析
------

  图6展示了各方法批量编辑的结果。在基于定位和修改的方法中，MEMIT效果最好。尽管SERAC效果不错，但是MEND和SERAC需要为每一批编辑训练一个独特的模型，在实践中不可行。

序列编辑分析
------

  图7展示了各方法在连续实施多次编辑编辑后的模型指标，横坐标为编辑次数。可以看出冻结模型参数而进行外部修改的方法SERAC和T-Patcher最稳定。另外三个方法由于需要修改原始模型，所以会性能产生退化，其中MEMIT的效果和稳定性最强。

总结
==

  在所有方法中，可靠性、普适性、局部性、可移植性综合来说最高的方法是MEMIT，并且它还支持批量编辑，缺点是它只适用于解码器，并且随着连续编辑次数增加，模型会退化，但这是基于定位和修改的方法的通病。

  在基于外部参数的方法中，SERAC的可靠性、普适性、局部性最好，对连续编辑的鲁棒性强，但可移植性较差。