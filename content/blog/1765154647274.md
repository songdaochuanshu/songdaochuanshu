---
layout: post
title: '小白必看：零花销开启微调模型之旅'
date: "2025-12-08T00:44:07Z"
---
小白必看：零花销开启微调模型之旅
================

今天我特地花时间全流程熟悉了一下魔搭社区，很多人都说它是国内版的 Hugging Face，想跟大家分享一下我的一些总体感受。首先，的确像大家说的那样，它提供了很多免费的额度。比如，CPU 机器是完全免费的，而且没有时长限制；GPU 机器的免费时长是 36 小时，我注册得比较早，看到现在新用户是 100 小时。其实当初我注册的时候挺犹豫的，因为完全没接触过这个领域，怕搞不懂。但现在看来，总体体验还是挺不错的。

不过，毕竟它是一个偏向开发者的社区类型，遇到报错什么的，有时候真的很难快速找到解决办法。今天我在操作过程中就遇到了好几个问题，几乎都是自己摸索着解决的，找不到人帮忙。而且，社区里面的相关文章也比较少，几乎没法直接找到很有用的资料。唯一能依赖的就是提 issue，虽然感觉这不是最快的解决方案。

我之前按照 GitHub 上的教程，用代码微调了下 Qwen-7B，虽然效果是有出来的，但中间的流程我完全搞不懂，尤其是那些一堆密密麻麻的参数，真的是看得头大。后来发现魔搭提供了一个叫哥Swift的轻量级框架，它有可视化界面，这才让我有了兴趣去试一试。整体来说，用起来确实挺方便的，我根本不用去管那些复杂的参数设置，就算偶尔想调一下，也只是点点页面上的选项就行了。毕竟我是个小白，能有个简单直观的工具帮我入门，感觉挺适合像我这种初学者的。

![f2fdd2e46fbf88ed74da05c72c8b6133](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164413298-34500289.png)

好的，废话不多说，今天我就带大家一起看看，怎么利用魔搭社区零花销快速训练和微调一个模型，然后发布到社区里，让其他人也能用到它。

创建实例
====

魔搭社区的网址是：[https://www.modelscope.cn](https://www.modelscope.cn)。

对于还不太熟悉的小伙伴们，建议可以先去社区里逛一逛，了解一下它都提供了哪些功能。其实我们最常用的两个功能就是模型库和数据集，当然啦，如果能用到免费的机器那就更好了，要不然还得自己去租台机器来用。

逛完之后，我在模型库里找到了一个下载量超高的模型——qwen-32b。为了不花钱、先熟悉一下操作，我决定先看看它能不能直接部署在机器上。然后，我选择了CPU环境来部署，因为GPU环境的使用时长是有限制的。你们可以参考下图：

![23a12e9faf9e7a6bad33afdd2538c3fc](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164419218-184144289.png)

CPU实例
-----

### 试水Qwen3-32B

进去之后，你会看到一个跟常见的 VS Code 很像的编辑器，界面挺熟悉的。不同的是，它还会显示当前机器的一些配置信息，比如 CPU、GPU、存储空间等，方便你随时了解系统的资源状态。

![c7bb2be0957887ef86b4059adb871167](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164430430-1752036292.png)

里面啥也没有，只有一个我当时选的模型——Qwen3-32B的入门notebook。这个notebook挺基础的，内容都比较简单，但是也很友好，特别适合刚开始接触的朋友。

![629751b01a40641d0eb383c023c0f83b](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164434677-1183480122.png)

我找到了一个代码片段，先不管啥，直接跑了一下，结果一上来就报错了。原来是它试图从 Hugging Face 社区下载模型，但因为网络问题没法连上。我去他们的问答区查了一下，简单修改了几下，像图中这样：

![e3a4fe5a9a23181fec8a2fb8040468b7](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164438956-1786922243.png)

他现在可以直接从国内的魔搭社区下载了。等了好一阵，结果没想到32B模型竟然占了几十个G的存储，直接就把一半硬盘空间给占满了。如果还要调试什么的，100G的存储基本就不够用了。

![927cccfc57b93101d9a4fc39921ea101](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164442889-2025295672.png)

因为下载的时间实在是太长了，我就先放那儿不管了。结果过了大概一个小时，实例就直接被关掉了，真是尴尬。赶紧搜了一下，发现首页有个入口可以重新启动实例环境，赶紧点开启动了。

![7747713b10e42ad66eb1637760a85e82](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164447026-441689960.png)

启动之后，页面上会出现一个“查看notebook”按钮，但不要急着点那个按钮哦。因为浏览器有时候可能会显示一个“no health upstream”的错误提示，我之前就碰到过。这个问题其实不用担心，只要稍微等一下就好。等了一会儿之后，页面就正常加载了，最后确认我们的模型确实已经成功下载了。

### SWIFT可视化操作

因为我当时的目标很明确，就是简单地训练模型并发布它，毕竟这是我第一个要跑通的案例。所以，我就按照官方文档一步步操作。翻了一下文档后，发现有个叫SWIFT的框架，看起来很合适，而且界面超级友好，一看就能上手。

于是，我直接在终端控制台里输入了下面两条命令，快速启动。

> pip install 'ms-swift'
> 
> swift web-ui --lang zh

对了，有一点很重要，启动CPU实例和GPU实例其实没有太大区别，机器里的内容是完全一样的。所以你不用担心它们之间不能互通的问题。如果某些操作只需要CPU就能搞定，那就启动CPU实例就好；但如果你需要进行一些更复杂的训练，想要用到GPU加速，那就再启动GPU实例。

简单来说，根据需求切换就行，完全不用担心其他的。

![c6ad74e22bf7e9a24f03b86e12cf666c](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164454113-997483627.png)

命令执行完毕之后，如果启动时没有提醒你去打开浏览器页面，没关系，你可以去‘port’标签下找一下 Swift 的端口，直接点击那个地址就能进入浏览器查看了。

![ccd205cc04be2d0ebf11058837a82c96](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164457849-1015147408.png)

你一打开就会看到一个简洁明了的首页界面，如图所示：

![66858d968e52833da4753956d2886892](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164502336-579252320.png)

因为我知道32B模型训练起来可能会挺耗时间和计算资源的，所以我就直接选择了8B的相对小一些的模型，先试试效果如何。直接选择就行了，像图中这样操作就可以了：

![f5bc5f3731f69584e687f007c754513b](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164506043-435061077.png)

页面一报错，我本来想看个具体信息，结果什么都没显示。于是我就直接切回notebook后台看了看。如图所示：

![4ef3c73475ee84b2a13f798d069aa0af](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164510369-2069580608.png)

我也在页面上看到了这个参数。大概理解是，因为我没有GPU，所以CPU不能使用bf16这个功能吧。

![d6c693789229ffbe8b7190dfc8ccc0c3](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164516328-1254633295.png)

我就改成了float16.结果还是报错：

> ImportError: FlashAttention2 has been toggled on, but it cannot be used due to the following error: the package flash\_attn seems to be not installed. Please refer to the documentation of [https://huggingface.co/docs/transformers/perf\_infer\_gpu\_one#flashattention-2](https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2) to install Flash Attention 2.

GPU实例
-----

好嘛，既然都知道是怎么回事了，我干脆放弃用CPU，直接切换到GPU启动。反正也没啥大不了的。不过，启动之前还是得先授权一下，如图所示：

![acd49992631b7f95d666caa170f94100](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164522326-923741834.png)

注意啊，其实我们不需要一步一步全做完。这里面显示了三步，但第三步其实是收费的步骤，我们并不需要去创建那个实例。说实话，那不是我们需要的东西，而且一小时大概要10块钱左右，所以不用去做。

![13683976cd7fb0949fbf9c61c1c9d680](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164527704-1116950837.png)

好的，那我们接着来说一下魔搭平台的免费实例。你可以直接选择一个GPU环境的实例，操作非常简单，选好后就可以直接启动了。这样你就可以开始使用了，十分方便。

![76c27a913eaa3f3f6e3b3e4cfcd7cd4a](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164533018-700300782.png)

模型训练
====

你看，虽然启动方式不太一样，但我们内部的应用信息都还是保留着的，命令一打就能直接启动，因为Swift已经在我们的CPU环境中安装好了。

![0b2d4ce82a61cc5229c6e9c37feb000c](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164537271-836328977.png)

启动之后，我直接就开始训练了。我用的是文档里提供的数据集（链接：[https://modelscope.cn/datasets/swift/self-cognition）](https://modelscope.cn/datasets/swift/self-cognition%EF%BC%89)

直接在数据集选项框里复制粘贴进去就行，选不到的话也不用担心，系统会自动帮你下载好。训练过程中，你也能随时在页面上查看相关的训练记录。我这里的过程非常顺利，没有遇到任何报错。

![b070cfa1616d3fca0b02ca403d3c1c85](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164541789-1781537465.png)

训练成功后，模型会自动生成在 `output` 目录下。我们接下来只需要复制一下 `checkpoint` 这个目录的路径，因为稍后我们会用到它。具体操作可以参考下图：

![a24162dddcfc581eced7f51e5f447189](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164546103-1602743680.png)

模型推理
====

因为我们的训练已经完成了，所以接下来直接去LLM推理那一页，找到“model”参数输入框。在这里，我们不需要选什么现成的模型，而是直接把刚刚训练好的checkpoint粘贴进去就行了。具体操作可以参考下面的图示。

> output/Qwen3-8B/v1-20250918-223553/checkpoint-21

![4b697c71f8f98fe25b20bd3d8d2a9bbd](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164550931-87801712.png)

部署模型
----

然后我们需要先部署才能对话。稍等片刻，如图所示：

![e5b67c5a86eef2b2fa479867c001bf3e](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164555117-1695913790.png)

在这个时候，页面上也会显示部署的状态日志。如果你发现页面的 WebUI 没有显示任何运行日志，不用担心，我也遇到过这种情况。其实日志会在 output 中生成，像图中展示的那样。

![db7b9c7cb83aafe34284bdef520a014e](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164559653-1800771669.png)

双击后，就能看到实时日志了，不用刷新文件，他会自动刷新。

![9380e24948ee42964ed19b9791ec5ab3](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164603444-856068346.png)

在正常情况下，部署完成后，这里会显示绑定8000端口成功。也就是说，我们就可以开始进行模型对话了

![a1868ec73759950029cec073833434bb](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164608597-1558787181.png)

### topk：invalid value

有时候呢，你在选完模型之后，界面会自动把某些参数给转换成float类型，就像我遇到的情况一样。表面上看界面一点问题都没有，也不会报错，感觉一切都挺正常的。可等你真正去部署的时候，才发现跑不起来，然后才报错，特别尴尬。下面就是我遇到的具体情况，给你参考一下。

![6f0668f688d8d6506c05f862a13993d8](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164613422-1265735935.png)

自己去改一下就行，去掉小数点，再去点击部署就没毛病了。

![5cd16df8d2adde115a66d33b0004a8b5](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164616881-32646551.png)

对话
--

部署成功后，我们直接在最下方与微调后的模型进行对话。

![2fd94a22fa8b31dd2316237051f89733](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164621529-963286651.png)

### TypeError

果不其然还是报错了。我去后台看了下是数值问题。

> TypeError: '<' not supported between instances of 'str' and 'float'

这种问题不好找，我直接去我使用的模型库里提了一个issue，如图示：

![62ca1ac600b8bdaa3f8315fd63bfcfa8](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164627223-606841149.png)

当然，这种问题反馈的进度通常会特别慢，可能要等很久才能有结果。所以我干脆自己先去搞定了。毕竟，Web-IDE界面里有个通义千问助手，我就直接去问它怎么解决这个问题。

![2399e13cca2ef8383d3013886b11680c](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164635061-1535714698.png)

行，让我去改代码，我一点击那个位置，发现真的能编辑，确实是能操作。然后我就按照助手说的步骤试了一下，感觉挺顺利的。

![7deb2171a7a5ed61d716d9a5a9aa4fff](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164639216-340601376.png)

我重启了一下 Swift，然后再次进入对话界面，终于成功了。其实中间试过了好多方法，只有这个有效。希望这个方法能帮到你！

![1c34221180bcc66f7b9f8e5ff9ffaeed](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164644207-852281906.png)

最后一对话，这啥啊这是，我是不是训练的数据集出了问题？赶紧去看了一下数据预览，结果果然是这样。那就不是什么大问题了，以后选个更靠谱的数据集就行了。这个数据集其实还挺不错的，至少提供了可以替换的变量值，只是我之前没提前注意到。以后得多留意一下这些细节。

![7a92ae3e399ba9f6d689fe6f8f4b2b5e](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164649741-1146596568.png)

模型导出
====

类似的操作，首先选择“LLM导出”这个标签页，然后把我们刚才复制的 checkpoint 粘贴进去，再加上输出目录就可以了。

![4dd6cbb511b12c0e66add2b716a058a2](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164654972-1758981679.png)

稍等片刻后，我们的模型就导出成功了。如图所示：

![266a0ffa8ec04824416cacca0bd34800](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164659353-632687444.png)

不过他好像没能导出到魔搭社区，估计是页面不支持这个功能。看起来我们只能通过命令行来操作了。官方提供的方式是这样的：

> swift export  
> \--model output/Qwen3-8B/v1-20250918-223553/checkpoint-21  
> \--push\_to\_hub true  
> \--hub\_model\_id ''  
> \--hub\_token ''  
> \--use\_hf false

申请token
-------

这里其他的都没问题，不过token需要我们单独申请一下，去首页就能看到，如图所示：

![8ff7c5bc3955a502b09adb1d1c9eaf8e](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164718420-260792059.png)

### ValueError: Please set --model <model\_id\_or\_path>\`, model: None

执行后，果然还是报错了。

> Please set --model <model\_id\_or\_path>\`, model: None
> 
> ValueError: Please set --model <model\_id\_or\_path>\`, model: None  
> bash: --model: 未找到命令  
> bash: --push\_to\_hub: 未找到命令  
> bash: --hub\_model\_id: 未找到命令  
> bash: --hub\_token: 未找到命令  
> bash: --use\_hf: 未找到命令

找到了github的issue：[https://github.com/modelscope/ms-swift/issues/2770，说是版本问题，最后发现我的版本挺高的，我通过报错看出来，他应该是没识别换行符。那我直接弄成一行，直接通过了。](https://github.com/modelscope/ms-swift/issues/2770%EF%BC%8C%E8%AF%B4%E6%98%AF%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98%EF%BC%8C%E6%9C%80%E5%90%8E%E5%8F%91%E7%8E%B0%E6%88%91%E7%9A%84%E7%89%88%E6%9C%AC%E6%8C%BA%E9%AB%98%E7%9A%84%EF%BC%8C%E6%88%91%E9%80%9A%E8%BF%87%E6%8A%A5%E9%94%99%E7%9C%8B%E5%87%BA%E6%9D%A5%EF%BC%8C%E4%BB%96%E5%BA%94%E8%AF%A5%E6%98%AF%E6%B2%A1%E8%AF%86%E5%88%AB%E6%8D%A2%E8%A1%8C%E7%AC%A6%E3%80%82%E9%82%A3%E6%88%91%E7%9B%B4%E6%8E%A5%E5%BC%84%E6%88%90%E4%B8%80%E8%A1%8C%EF%BC%8C%E7%9B%B4%E6%8E%A5%E9%80%9A%E8%BF%87%E4%BA%86%E3%80%82)

> swift export --model 'output/Qwen3-8B/v1-20250918-223553/checkpoint-21' --push\_to\_hub true --hub\_model\_id 'test-xiaoyu-Qwen3-8B' --hub\_token 'ms-5dc7' --use\_hf false

### fatal: 仓库未找到

又发现没有仓库，那就加上自动创建仓库参数--hub\_private\_repo true

> fatal: 仓库 '[https://www.modelscope.cn/test-xiaoyu-Qwen3-8B.git/](https://www.modelscope.cn/test-xiaoyu-Qwen3-8B.git/)' 未找到

然后执行命令：

> swift export --model 'output/Qwen3-8B/v1-20250918-223553/checkpoint-21' --push\_to\_hub true --hub\_model\_id 'test-xiaoyu-Qwen3-8B' --hub\_token 'ms-5a37' --use\_hf false --hub\_private\_repo true

\--hub\_private\_repo true不生效 还是报错：

![056f874072999a7349408d6bfb814a01](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164726026-1291379683.png)

我当时写`model-id`的时候随便填了一个，结果后来发现不能随便写，得按照格式写成你自己的`用户ID/仓库id`，看来这个名字可不能乱起啊。

![032c9141e175a3b47ed1aa23b6e39e66](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164731121-588460561.png)

我先去首页自己手动创建了一个123模型库地址。

![52e125e22f266bdd151c0d3f621e8724](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164735712-1522695678.png)

然后自己改下正确的model-id，命令如下：

> swift export --model 'output/Qwen3-8B/v1-20250918-223553/checkpoint-21' --push\_to\_hub true --hub\_model\_id 'junyulingmo/123' --hub\_token 'ms-5d37' --use\_hf false --hub\_private\_repo true

终于大功告成了。

![e3c09e31441f42750d53d81cac669279](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164740493-438063489.png)

模型库也有了模型文件，这些模型文件都需要被社区审核。

![487a20b668f043f1a9af2da7d586c886](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164745153-1194380246.png)

一共下来，磁盘100G马上就快满了，所以还是得悠着点才行。不然都跑不玩流程就卡了。

![1d5ad4594643bff9dbd927e1ac60b45d](https://img2024.cnblogs.com/blog/1423484/202509/1423484-20250919164749128-1284287970.png)

小结
==

今天花时间深入了解了一下魔搭社区，感觉还是挺值得分享的，尤其对刚入门的朋友。首先，它的免费额度非常慷慨，比如CPU是完全免费的，GPU也是有36小时的免费时长（如果你是新用户可以享受更多）。我最初其实挺担心自己会搞不懂，但用了几次后发现其实上手还是挺容易的，特别是它提供了很直观的可视化工具，比如Swift框架，真的帮助了我不少。

不过，也要注意魔搭社区的确偏向开发者，遇到问题时解决起来可能没那么简单。文档和社区里的相关资料不算多，很多时候只能通过提issue或自己查找来解决，过程可能会有点曲折。

不过呢，魔搭社区给了我很多启发，尤其是它的免费资源和轻量级框架，如果你也对AI或模型训练有兴趣，完全可以试试这个平台。对初学者来说，可能一开始会碰到一些技术难点，但别气馁，慢慢摸索、请教，平台的工具还是非常友好的。

如果你有兴趣，也可以和我一起探讨或试试看如何训练模型和发布，随时可以帮你解答一些具体问题！