---
layout: post
title: '速通提示词工程Prompt Engineering'
date: "2025-07-13T00:49:59Z"
---
速通提示词工程Prompt Engineering
=========================

提示词工程简介
=======

*   关注提示词开发和优化，帮助用户将大语言模型用于各场景和研究领域。
*   利用提示工程来提升大语言模型处理复杂任务场景的能力，如问答和算术推理能力。
*   通过提示工程设计、研发强大的工程技术，实现和大语言模型或其他生态工具的高效接轨。
*   通过提示工程来提高大语言模型的安全性。

1 大语言模型设置
---------

**Temperature**：`temperature` 的参数值越小，模型就会返回越确定的一个结果。

**Top\_p**：同上 （**一般建议**：仅改变其中一个参数）

**Max Length**：大模型生成的 token 数

**Stop Sequences**：一个字符串，可以阻止模型生成 token

**Frequency Penalty**：减少token中词重复（重复数量多的 Token 惩罚高）

**Presence Penalty**：也减少token中词重复（重复次数无关的惩罚）

2 提示词要素
-------

提示词可以包含：

1.  **指令**：想要模型执行的特定任务或指令。
2.  **上下文**：包含外部信息或额外的上下文信息，引导语言模型更好地响应。
3.  **输入数据**：用户输入的内容或问题。
4.  **输出指示**：指定输出的类型或格式。

3 设计提示的通用技巧
-----------

**从简单开始**：尝试将任务分解为更简单的子任务

**指令**：以不同的关键词，上下文和数据试验不同的指令，看看什么样是最适合你特定用例和任务

**具体性**：提示越具描述性和详细结果越好。如：提供示例。

**避免使用不明确的词**：如：“几句话”， “一些” 等

**避免说不要做什么，而应该说要做什么**。

4 简单的提示词示例
----------

**文本概括**：\[上下文\] Explain the above in one sentence:

**信息提取**：\[上下文\] Mention the large language model based product mentioned in the paragraph above:

**问答**：\[上下文\] Question: What was OKT3 originally sourced from? Answer:

**文本分类**: Classify the text into neutral, negative or positive. Text: I think the food was okay. Sentiment:

（如果大模型返回的是大写的Neutral而非你想要的neutral：给出示例，或者更具体的命令。）

**对话**：可以设定回复的风格并给出示例：The following is a conversation with an AI research assistant. The assistant tone is technical and scientific. Human: Hello, who are you?AI: Greeting! I am an AI research assistant. How can I help you today?Human: Can you tell me about the creation of blackholes?AI:

**代码生成**：""" Table departments, columns = \[DepartmentId, DepartmentName\]Table students, columns = \[DepartmentId, StudentId, StudentName\]Create a MySQL query for all students in the Computer Science Department """

**推理**：What is 9,000 \* 9,000?

高阶提示技术
======

1 零样本提示
-------

不提供任何示例。

    Q: 1 + 1 = ?
    A: 2
    

2 少样本提示
-------

提供一些示例。

**1-shot**：

    Q: “whatpu”是坦桑尼亚的一种小型毛茸茸的动物。一个使用whatpu这个词的句子的例子是：我们在非洲旅行时看到了这些非常可爱的whatpus。“farduddle”是指快速跳上跳下。一个使用farduddle这个词的句子的例子是：
    
    A: 当我们赢得比赛时，我们都开始庆祝与farduddle。
    

**few-shot**：

    Q: 这太棒了！// Negative
    这太糟糕了！// Positive
    哇，那部电影太棒了！// Positive
    多么可怕的节目！//
    
    A: Negative
    

**但少样本在一些复杂问题表现不佳：**

_提示：_

    这组数字中的奇数加起来是一个偶数：4、8、9、15、12、2、1。
    A：答案是False。
    这组数字中的奇数加起来是一个偶数：17、10、19、4、8、12、24。
    A：答案是True。
    这组数字中的奇数加起来是一个偶数：16、11、14、4、8、13、24。
    A：答案是True。
    这组数字中的奇数加起来是一个偶数：17、9、10、12、13、4、2。
    A：答案是False。
    这组数字中的奇数加起来是一个偶数：15、32、5、13、82、7、1。
    A：
    

_输出：_

    答案是True。
    

3 链式思考（CoT）提示
-------------

**带示例的CoT**

_提示：_

    这组数中的奇数加起来是偶数：4、8、9、15、12、2、1。
    A：将所有奇数相加（9、15、1）得到25。答案为False。
    这组数中的奇数加起来是偶数：15、32、5、13、82、7、1。
    A：
    

_输出：_

    将所有奇数相加（15、5、13、7、1）得到41。答案为False。
    

[Wei等人（2022）](https://arxiv.org/abs/2201.11903)认为这是足够大的语言模型才会出现的新兴能力。

**0-Shot的CoT**：“让我们逐步思考。”

_提示：_

    我去市场买了10个苹果。我给了邻居2个苹果和修理工2个苹果。然后我去买了5个苹果并吃了1个。我还剩下多少苹果？
    让我们逐步思考。
    

_输出：_

    首先，您从10个苹果开始。
    您给了邻居和修理工各2个苹果，所以您还剩下6个苹果。
    然后您买了5个苹果，所以现在您有11个苹果。
    最后，您吃了1个苹果，所以您还剩下10个苹果。
    

**自动思维链（Auto-CoT）**

**Auto-CoT** 是一种 **无需人工设计示例** 的提示构造方法，它能够自动生成“思维链”提示，以引导语言模型像人一样逐步推理。这种方法由 Google 的研究者在论文《Large Language Models are Self-Consistent Reasoners》中提出，是对手动 CoT 的一种自动化替代方案。

1.  **自动聚类问题**  
    把所有待解决的问题按“语义或结构”相似性分成几类（如加法类、排序类、计数类等）。
    
2.  **每类用 Zero-shot CoT 生成示例**  
    对每一类问题，选一个代表问题，对它使用 Zero-shot CoT（加一句提示：_“Let's think step by step.”_）生成一个包含中间推理步骤的解答。
    
3.  **组装 few-shot 提示用于解新题**  
    把每类生成的 CoT 示例拼成一个 few-shot prompt，然后用于引导模型解决其他同类（甚至跨类）的问题。
    

4 自我一致性
-------

通过少样本 CoT 采样多个不同的推理路径，并使用生成结果选择最一致的答案。这有助于提高 CoT 提示在涉及算术和常识推理的任务中的性能。

_提示：_

    ...
    Q：Michael有58个高尔夫球。星期二，他丢失了23个高尔夫球。星期三，他又丢失了2个。星期三结束时他还剩多少个高尔夫球？
    A：Michael最初有58个球。星期二他丢失了23个，所以在那之后他有58-23 = 35个球。星期三他又丢失了2个，所以现在他有35-2 = 33个球。答案是33。
    Q：Olivia有23美元。她用每个3美元的价格买了五个百吉饼。她还剩多少钱？
    A：她用每个3美元的价格买了5个百吉饼。这意味着她花了15美元。她还剩8美元。
    Q：当我6岁时，我的妹妹是我的一半年龄。现在我70岁了，我的妹妹多大？
    A：
    

_输出:_

    1 当我6岁时，我的妹妹是我的一半年龄，也就是3岁。现在我70岁了，所以她是70-3 = 67岁。答案是67。
    2 当叙述者6岁时，他的妹妹是他年龄的一半，也就是3岁。现在叙述者70岁了，他的妹妹应该是70-3 = 67岁。答案是67。
    3 当我6岁时，我的妹妹是我的一半年龄，也就是3岁。现在我70岁了，所以她是70/2 = 35岁。答案是35。
    (答案更可能是67)
    

5 生成知识提示
--------

简单来说，是用模型自己生成的知识来指导自己。

_提示：_

    ...
    输入：一个人一生中吸烟很多香烟的常见影响是患肺癌的几率高于正常水平。
    知识：那些一生中平均每天吸烟不到一支香烟的人，患肺癌的风险是从不吸烟者的9倍。在每天吸烟1到10支香烟之间的人群中，死于肺癌的风险几乎是从不吸烟者的12倍。
    
    输入：一块石头和一颗卵石大小相同。
    知识：卵石是一种根据Udden-Wentworth沉积学尺度的颗粒大小为4到64毫米的岩屑。卵石通常被认为比颗粒（直径2到4毫米）大，比卵石（直径64到256毫米）小。
    
    输入：高尔夫球的一部分是试图获得比其他人更高的得分。
    知识：
    

_知识：_

    1 高尔夫球的目标是以最少的杆数打完一组洞。一轮高尔夫球比赛通常包括18个洞。每个洞在标准高尔夫球场上一轮只打一次。每个杆计为一分，总杆数用于确定比赛的获胜者。
    2 高尔夫球是一项精密的球杆运动，竞争选手（或高尔夫球手）使用许多类型的球杆，用最少的杆数将球打入球场上一系列洞中。目标是以最低的分数完成比赛，该分数是通过将每个洞上所用的杆数相加计算出来的。得分最低的选手赢得比赛。
    

_整合知识后提示_：

    问题：高尔夫球的一部分是试图获得比其他人更高的得分。是或否？
    知识：高尔夫球的目标是以最少的杆数打完一组洞。一轮高尔夫球比赛通常包括18个洞。每个洞在标准高尔夫球场上一轮只打一次。每个杆计为一分，总杆数用于确定比赛的获胜者。
    解释和答案： 
    

_答案：_

    不是，高尔夫球的目标不是获得比其他人更高的得分。相反，目标是以最少的杆数打完一组洞。总杆数用于确定比赛的获胜者，而不是总得分。
    

6 链式提示
------

将任务分解为许多子任务。将子任务得到的结果作为新的提示词的一部分。

7 思维树（ToT）
----------

增强模型在**复杂问题解决**和**规划任务**中的能力，比如数独解题、数学证明、策略规划等。

* * *

**🌳 什么是 Tree of Thoughts（ToT）？**

Tree of Thoughts 是一种**多步推理框架**，核心思想是：

> 把问题求解过程看作是“在思维空间中探索一棵决策树”，每个节点表示一个“思维状态”（thought/state），通过一步步扩展可能的思路来构造“思维路径”。

相比于传统的一步到位或线性推理（如 Chain of Thought），ToT 更类似于搜索树（如蒙特卡洛搜索树），允许模型**并行地探索多个解题路径**，选择最优思路而不是固定前行。

* * *

**🔧 ToT 的组成结构**

1.  **思维状态（Thought / State）**：  
    每个节点表示当前问题的一种思考进展，例如部分解或一个子推理步骤。
2.  **思维扩展（Thought Generation）**：  
    模型从当前状态出发，生成多个可能的“下一步思维”，即子节点。
3.  **思维评估（Thought Evaluation）**：  
    对每个子节点进行评分，选择更有希望的路径。评估方式可以是：
    *   模型自评（Self-consistency, Voting 等）
    *   Heuristic 打分函数
    *   外部工具辅助评估
4.  **搜索策略（Search Strategy）**：  
    使用宽度优先（BFS）、深度优先（DFS）或其他启发式搜索方法，在整棵“思维树”中找到最优路径。

* * *

**🧩 举个例子：数独解题**

**用 CoT：**

*   第一步填1，第二步填2，第三步填3……（一步错，后面全错）

**用 ToT：**

*   先尝试填1、2、3……生成多个解法路径
*   逐步展开每个路径
*   评估哪些路径合法，哪些应该剪枝
*   最终找到符合规则的完整解

8 检索增强生成（RAG）
-------------

**🧠 一句话理解 RAG：**

> RAG = **检索（Retrieve）相关文档** + **生成（Generate）答案**  
> 模型不再“闭卷”作答，而是“开卷”查资料再作答。

**🔧 RAG 的工作流程：**

可以分为两个主要阶段：

**检索阶段（Retrieval）**

*   输入用户问题 `q`
*   使用一个**稠密检索器**（如 FAISS、DPR）在**外部知识库**中找到与问题最相关的文档或段落
*   得到 `k` 个候选文本（上下文）

> 🗂 知识库可以是维基百科、私有文档、数据库、PDF等

**生成阶段（Generation）**

*   将问题 `q` 与检索到的上下文 `d1, d2, ..., dk` 一起输入到语言模型（如 GPT）

模型根据上下文生成回答

9 自动推理并使用工具 (ART )
------------------

Automatic Reasoning and Tool-use 的工作原理如下：

*   接到一个新任务的时候，从任务库中选择多步推理和使用工具的示范。
*   在测试中，调用外部工具时，先暂停生成，将工具输出整合后继续接着生成。

10 自动提示工程师（APE）
---------------

自动地找出最能让大模型“听懂问题并给出好答案”的提示词。

提示工程（Prompt Engineering）曾经高度依赖**人类经验**，但：

*   提示设计空间巨大（同一个任务可以有上千种提示）
*   人力设计效率低、难以系统探索

于是就有了 APE：**让模型自己做提示工程师**，系统地搜索“好提示”

1.  生成候选提示

    例如：I want to find the best way to ask a language model to solve [TASK]. Suggest a good prompt for this task.
    

2.  评估提示效果
3.  选择最优提示

11 Active-Prompt
----------------

1.  使用或不使用少量 CoT 示例查询 LLM。
2.  对一组训练问题生成 _k_ 个可能的答案。
3.  基于 _k_ 个答案计算不确定度度量（使用不一致性）。
4.  选择最不确定的问题由人类进行注释。然后使用新的注释范例来推断每个问题。

12 方向性刺激提示
----------

    Q:总结以上内容。重点：xx1; xx2; xx3; ...
    

13 PAL（程序辅助语言模型）
----------------

提示词引导模型在类似链式思考的同时输出python代码

_提示：_

    DATE_UNDERSTANDING_PROMPT = """
    # Q: 2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY?
    # If 2015 is coming in 36 hours, then today is 36 hours before.
    today = datetime(2015, 1, 1) - relativedelta(hours=36)
    # One week from today,
    one_week_from_today = today + relativedelta(weeks=1)
    # The answer formatted with %m/%d/%Y is
    one_week_from_today.strftime('%m/%d/%Y')
    # Q: The first day of 2019 is a Tuesday, and today is the first Monday of 2019. What is the date today in MM/DD/YYYY?
    # If the first day of 2019 is a Tuesday, and today is the first Monday of 2019, then today is 6 days later.
    today = datetime(2019, 1, 1) + relativedelta(days=6)
    # The answer formatted with %m/%d/%Y is
    today.strftime('%m/%d/%Y')
    ...
    # Q: {question}
    """.
    

_输出：_

    # If today is 27 February 2023 and I was born exactly 25 years ago, then I was born 25 years before.
    today = datetime(2023, 2, 27)
    # I was born 25 years before,
    born = today - relativedelta(years=25)
    # The answer formatted with %m/%d/%Y is
    born.strftime('%m/%d/%Y')
    

_执行：_

    exec(llm_out)
    print(born)
    02/27/1998
    

14 ReAct框架
----------

LLMs 以交错的方式生成 _推理轨迹_ 和 _任务特定操作_ 。生成推理轨迹使模型能够诱导、跟踪和更新操作计划，甚至处理异常情况。操作步骤允许与外部源（如知识库或环境）进行交互并且收集信息。

ReAct 框架允许 LLMs 与外部工具交互来获取额外信息，从而给出更可靠和实际的回应。

链式思考 (CoT) 显示了 LLMs 执行推理轨迹以生成涉及算术和常识推理的问题的答案的能力，但它因缺乏和外部世界的接触或无法更新自己的知识，而导致事实幻觉和错误传播等问题。

    > 正在输入新代理执行器链......
      我得查出奥利维亚·王尔德的男友是谁然后计算出他的年龄的 0.23 次方。
    操作: 搜索
    操作输入: “奥利维亚·王尔德的男友”
    观察: 奥利维亚·王尔德与杰森·苏代基斯在多年前订婚，在他们分手后，她开始与哈里·斯泰尔斯约会 — 参照他们的关系时间线。
    思考: 我需要找出哈里·斯泰尔斯的年龄。
    操作: 搜索
    操作输入: “哈里·斯泰尔斯的年龄”
    观察: 29 岁
    思考: 我需要计算 29 的 0.23 次方。
    操作: 计算器
    操作输入: 29^0.23
    观察: 答案: 2.169459462491557
     
    思考: 现在我知道最终答案了。
    最终答案: 哈里·斯泰尔斯, 奥利维亚·王尔德的男朋友, 29 岁。他年龄的 0.23 次方是 2.169459462491557。
     
    > 结束链。
    

15 自我反思（Reflexion）
------------------

将来自环境的反馈（自由形式的语言或者标量）转换为语言反馈，为下一轮中 LLM 智能体提供上下文。这有助于智能体快速有效地从之前的错误中学习，进而提升许多高级任务的性能。

总的来说，自我反思的关键步骤是a)定义任务，b)生成轨迹，c)评估，d)执行自我反思，e)生成下一条轨迹。

主要参考：

\[1\] [https://www.promptingguide.ai/zh/techniques/](https://www.promptingguide.ai/zh/techniques/)

\[2\] [https://chatgpt.com/](https://chatgpt.com/)