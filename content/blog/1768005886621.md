---
layout: post
title: 'Grafana Loki自动监控日志'
date: "2026-01-10T00:44:46Z"
---
Grafana Loki自动监控日志
==================

Grafana Loki 日志监控配置指南
=====================

![d3135d676e_1_k-hdOAQjRXKoyguzKuoeKg](https://img2024.cnblogs.com/blog/3196947/202601/3196947-20260109160333955-1410605029.jpg)

前言
--

在微服务架构中，日志收集和分析是运维的重要环节。本文介绍如何使用 Grafana Loki 搭建轻量级日志监控系统，并与传统的 ELK 技术栈进行对比。

Loki vs ELK 技术栈对比
-----------------

### 架构对比

组件

ELK

Loki

日志采集

Logstash / Filebeat

Promtail

日志存储

Elasticsearch

Loki

可视化

Kibana

Grafana

### 核心差异

对比项

ELK

Loki

索引方式

全文索引

仅索引标签（Label）

存储占用

高（原始日志 + 索引）

低（压缩存储，索引小）

资源消耗

高（ES 需要大量内存）

低（单机 256MB 可运行）

查询方式

Lucene 语法

LogQL（类 PromQL）

查询速度

全文搜索快

标签过滤快，全文搜索慢

部署复杂度

复杂（多组件协调）

简单（3 个容器即可）

学习成本

较高

较低（熟悉 Prometheus 更容易）

与 Prometheus 集成

需额外配置

原生集成

![567ffc184541f44c0384d02f8b991447](https://img2024.cnblogs.com/blog/3196947/202601/3196947-20260109160412006-423286371.jpg)

![056f09368ad6dde870727e48171c89ee](https://img2024.cnblogs.com/blog/3196947/202601/3196947-20260109160528026-1366870051.gif)

### 选型建议

**选择 ELK 的场景：**

*   需要复杂的全文搜索
*   日志分析是核心业务需求
*   有专门的运维团队
*   服务器资源充足

**选择 Loki 的场景：**

*   中小型项目，资源有限
*   已使用 Prometheus + Grafana 监控体系
*   主要需求是日志查看和简单过滤
*   追求快速部署和低维护成本

系统架构
----

    ┌─────────────┐     ┌─────────────┐     ┌─────────────┐     ┌─────────────┐
    │  微服务应用   │ ──▶ │   日志文件   │ ──▶ │  Promtail   │ ──▶ │    Loki     │
    │ (Java/Go等) │     │ (.log files)│     │  (采集器)    │     │  (存储)      │
    └─────────────┘     └─────────────┘     └─────────────┘     └──────┬──────┘
                                                                        │
                                                                        ▼
                                                                ┌─────────────┐
                                                                │   Grafana   │
                                                                │  (可视化)    │
                                                                └─────────────┘
    

环境准备
----

*   Docker 20.10+
*   Docker Compose 2.0+
*   服务器内存 >= 2GB

目录结构
----

    /docker/
    ├── docker-compose.yaml
    ├── loki/
    │   └── loki-config.yaml
    └── promtail/
        └── promtail-config.yaml
    

配置文件
----

### 1\. Loki 配置 (loki-config.yaml)

    auth_enabled: false
    
    server:
      http_listen_port: 3100
      grpc_listen_port: 9096
    
    common:
      instance_addr: 127.0.0.1
      path_prefix: /loki
      storage:
        filesystem:
          chunks_directory: /loki/chunks
          rules_directory: /loki/rules
      replication_factor: 1
      ring:
        kvstore:
          store: inmemory
    
    query_range:
      results_cache:
        cache:
          embedded_cache:
            enabled: true
            max_size_mb: 100
    
    limits_config:
      metric_aggregation_enabled: true
      retention_period: 720h  # 日志保留 30 天
    
    schema_config:
      configs:
        - from: 2020-10-24
          store: tsdb
          object_store: filesystem
          schema: v13
          index:
            prefix: index_
            period: 24h
    
    pattern_ingester:
      enabled: true
      metric_aggregation:
        loki_address: localhost:3100
    
    compactor:
      working_directory: /loki/compactor
      retention_enabled: true
      delete_request_store: filesystem
    
    frontend:
      encoding: protobuf
    

**配置说明：**

配置项

说明

`auth_enabled: false`

关闭认证，单机部署使用

`http_listen_port: 3100`

Loki HTTP API 端口

`path_prefix: /loki`

数据存储路径前缀

`retention_period: 720h`

日志保留 30 天

`store: tsdb`

使用 TSDB 存储引擎（Loki 3.x 推荐）

`schema: v13`

最新的 schema 版本

`embedded_cache`

内置查询缓存，提升查询性能

`compactor`

自动压缩和清理过期日志

### 2\. Promtail 配置 (promtail-config.yaml)

    server:
      http_listen_port: 9080
      grpc_listen_port: 0
    
    positions:
      filename: /tmp/positions.yaml
    
    clients:
      - url: http://loki:3100/loki/api/v1/push
    
    scrape_configs:
      - job_name: xiaohashu
        static_configs:
          - targets:
              - localhost
            labels:
              job: xiaohashu
              __path__: /var/log/xiaohashu/*.log
    
        pipeline_stages:
          # 从文件名提取服务名: note.2025-07-01-0.log → service=note
          - regex:
              source: filename
              expression: '(?P<service>[a-z-]+)\.\d{4}-\d{2}-\d{2}-\d+\.log$'
          - labels:
              service:
          
          # 从日志内容提取级别: INFO/WARN/ERROR/DEBUG
          - regex:
              expression: '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3} \[[^\]]+\] (?P<level>\w+)'
          - labels:
              level:
    

**配置说明：**

配置项

说明

`positions.filename`

记录读取位置，重启后继续读取

`clients.url`

Loki 推送地址

`__path__`

日志文件匹配路径

`pipeline_stages`

日志处理管道

`regex` + `labels`

从文件名/内容提取标签

**日志格式示例：**

    2025-07-01 10:30:00.123 [main] INFO  com.example.Service - 启动成功
    

经过 pipeline 处理后，会自动添加标签：

*   `service=note`（从文件名提取）
*   `level=INFO`（从日志内容提取）

### 3\. Docker Compose 配置

    services:
      loki:
        image: grafana/loki:3.5.0
        container_name: loki
        ports:
          - "3100:3100"
        volumes:
          - ./loki/loki-config.yaml:/etc/loki/local-config.yaml
          - loki-data:/loki
        command: -config.file=/etc/loki/local-config.yaml
        restart: unless-stopped
    
      promtail:
        image: grafana/promtail:3.5.0
        container_name: promtail
        volumes:
          - ./promtail/promtail-config.yaml:/etc/promtail/config.yaml
          - /www/wwwroot/life_diary/logs:/var/log/xiaohashu:ro
        command: -config.file=/etc/promtail/config.yaml
        restart: unless-stopped
        depends_on:
          - loki
    
      grafana:
        image: grafana/grafana:11.4.0
        container_name: grafana
        ports:
          - "3000:3000"
        environment:
          - GF_SECURITY_ADMIN_USER=admin
          - GF_SECURITY_ADMIN_PASSWORD=admin123
        volumes:
          - grafana-data:/var/lib/grafana
        restart: unless-stopped
        depends_on:
          - loki
    
    volumes:
      loki-data:
      grafana-data:
    

**关键配置说明：**

配置

说明

`loki-data:/loki`

Loki 数据持久化，容器重启不丢失

`/www/wwwroot/life_diary/logs:/var/log/xiaohashu:ro`

挂载宿主机日志目录，`:ro` 表示只读

`grafana-data:/var/lib/grafana`

Grafana 配置持久化

`depends_on`

服务启动依赖顺序

部署步骤
----

### 1\. 创建目录和配置文件

    mkdir -p /docker/loki /docker/promtail
    cd /docker
    
    # 创建配置文件（内容见上文）
    vim loki/loki-config.yaml
    vim promtail/promtail-config.yaml
    vim docker-compose.yaml
    

### 2\. 启动服务

    cd /docker
    docker-compose up -d
    

### 3\. 查看服务状态

    docker-compose ps
    docker-compose logs -f loki      # 查看 Loki 日志
    docker-compose logs -f promtail  # 查看 Promtail 日志
    

### 4\. 配置 Grafana 数据源

1.  浏览器访问 `http://服务器IP:3000`
2.  登录（默认 admin / admin123）
3.  左侧菜单 → **Connections** → **Data sources**
4.  点击 **Add data source** → 选择 **Loki**
5.  URL 填写：`http://loki:3100`
6.  点击 **Save & Test**，显示绿色 ✓ 表示成功

LogQL 查询语法
----------

### 基础查询

    # 查看所有日志
    {job="xiaohashu"}
    
    # 按服务筛选
    {service="note"}
    {service="gateway"}
    
    # 按日志级别筛选
    {level="ERROR"}
    {level="WARN"}
    
    # 组合条件
    {service="note", level="ERROR"}
    

### 关键字搜索

    # 包含关键字
    {job="xiaohashu"} |= "Exception"
    {service="note"} |= "NullPointer"
    
    # 不包含关键字
    {service="gateway"} != "health"
    
    # 正则匹配
    {job="xiaohashu"} |~ "user.*login"
    

### 统计分析

    # 最近 5 分钟各服务错误数
    count_over_time({level="ERROR"}[5m]) by (service)
    
    # 每分钟日志量
    rate({job="xiaohashu"}[1m])
    
    # 错误率
    sum(rate({level="ERROR"}[5m])) / sum(rate({job="xiaohashu"}[5m]))
    

常用运维命令
------

    # 启动所有服务
    docker-compose up -d
    
    # 停止所有服务
    docker-compose down
    
    # 重启单个服务
    docker-compose restart loki
    
    # 查看资源占用
    docker stats loki promtail grafana
    
    # 查看日志
    docker-compose logs -f --tail=100 loki
    
    # 清理旧数据（谨慎使用）
    docker volume rm docker_loki-data
    

常见问题
----

### 1\. Promtail CPU 占用高

刚启动时需要扫描历史日志，属于正常现象。等处理完历史数据后会降下来。

### 2\. Grafana 连接 Loki 失败

检查 URL 是否正确，容器内部通信使用服务名 `http://loki:3100`，不是 `localhost`。

### 3\. 看不到日志

*   检查日志路径挂载是否正确
*   检查 Promtail 日志：`docker logs promtail`
*   确认日志文件名格式与 `__path__` 匹配

### 4\. 磁盘空间不足

调整 `retention_period` 缩短保留时间，或手动清理：

    docker-compose down
    docker volume rm docker_loki-data
    docker-compose up -d
    

总结
--

Grafana Loki 相比 ELK 更加轻量，适合中小型项目和资源有限的场景。通过合理配置 Promtail 的 pipeline，可以自动提取服务名和日志级别，实现高效的日志查询和分析。

对于已经使用 Prometheus + Grafana 的团队，Loki 是日志监控的最佳选择，可以在同一个 Grafana 界面中同时查看指标和日志，大大提升排查问题的效率。