---
layout: post
title: '快速入门 DeepSeek-R1 大模型'
date: "2025-02-05T00:35:41Z"
---
快速入门 DeepSeek-R1 大模型
====================

国内最新的神级人工智能模型已经正式发布，没错，它就是备受瞩目的DeepSeek-R1大模型。今天，我们将对DeepSeek进行一个简单的了解，并探索如何快速使用和部署这个强大的工具。值得一提的是，DeepSeek已经开源，您可以随意下载和使用它。

DeepSeek的官方网站地址如下：[https://www.deepseek.com/](https://www.deepseek.com/)

API文档的详细地址请访问：[https://api-docs.deepseek.com/zh-cn/](https://api-docs.deepseek.com/zh-cn/)

好吧，让我们开始！

API
===

DeepSeek API 采用与 OpenAI 完全兼容的 API 格式，使得用户可以通过简单的配置修改，灵活地使用 OpenAI SDK 来访问 DeepSeek API。此外，还可以使用任何与 OpenAI API 兼容的软件进行接入。

在对话领域，OpenAI 的 ChatGPT 可以说是最早引领风潮的模型之一，因此很多框架都自然而然地集成了 OpenAI 接口。这种趋势促使后续的各种模型纷纷兼容 OpenAI 的接口特性，从而极大地方便了开发者，减少了接入工作量。

为了轻松切换到 DeepSeek API，我们只需将 OpenAI 的基础 URL 替换为 DeepSeek 的地址，具体操作如下所示：

    # Please install OpenAI SDK first: `pip3 install openai`
    
    from openai import OpenAI
    
    client = OpenAI(api_key="<DeepSeek API Key>", base_url="https://api.deepseek.com")
    
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "system", "content": "You are a helpful assistant"},
            {"role": "user", "content": "Hello"},
        ],
        stream=False
    )
    
    print(response.choices[0].message.content)
    

注意model='deepseek-chat'调用的是DeepSeek-V3模型，model='deepseek-reasoner'才是DeepSeek-R1大模型。

服务状态
----

目前由于国际原因，API服务不是很稳定，所以如果在调用其API接口如果无法及时响应，可以看下目前API服务状态。地址如下：[https://status.deepseek.com/](https://status.deepseek.com/)

如图所示：

![image](https://img2024.cnblogs.com/blog/1423484/202502/1423484-20250202205930301-550835699.png)

实用集成
====

轻松将 DeepSeek 大模型的强大能力集成到各类软件中，助您提升应用的智能化水平。该平台支持众多第三方软件，具体支持的软件种类请见下图所示：

![image](https://img2024.cnblogs.com/blog/1423484/202502/1423484-20250202205934780-1967842094.png)

这种方法既可以调用官方的API服务，当然也可以调用本地的大模型服务，毕竟官方服务状态目前很不稳定。

Ollama
------

如果想在本地访问 DeepSeek 服务，那么你可以选择Ollama ，Ollama 是一个开源工具，旨在帮助用户在本地环境中轻松运行和管理大型语言模型（LLMs）。它通过简化的方式支持多种模型（如 Llama、Mistral、Gemma 等），并提供统一的接口供开发者调用，尤其适合需要本地部署和灵活切换模型的场景。

地址如下：[https://ollama.com/](https://ollama.com/)

![image](https://img2024.cnblogs.com/blog/1423484/202502/1423484-20250202205940350-2053343812.png)

下载后，直接在本地运行命令即可。

> ollama run deepseek-r1

当然，你可以选择启动的模型参数。目前有如下可选择：

> ollama run deepseek-r1:1.5b
> 
> ollama run deepseek-r1:7b
> 
> ollama run deepseek-r1:8b
> 
> ollama run deepseek-r1:14b
> 
> ollama run deepseek-r1:32b
> 
> ollama run deepseek-r1:70b

参数越大，模型效果越好。

总结
==

总之，DeepSeek-R1大模型凭借其强大的性能和开源优势，为开发者带来了前所未有的机遇。无论是通过API快速接入，还是借助Ollama在本地部署，都能轻松实现智能化升级。虽然目前API服务存在一些稳定性问题，但随着技术的不断优化，相信这些问题将很快得到解决。未来，DeepSeek有望在更多领域大放异彩，推动人工智能技术的进一步发展。

* * *

我是努力的小雨，一个正经的 Java 东北服务端开发，整天琢磨着 AI 技术这块儿的奥秘。特爱跟人交流技术，喜欢把自己的心得和大家分享。还当上了腾讯云创作之星，阿里云专家博主，华为云云享专家，掘金优秀作者。各种征文、开源比赛的牌子也拿了。

💡 想把我在技术路上走过的弯路和经验全都分享出来，给你们的学习和成长带来点启发，帮一把。

🌟 欢迎关注努力的小雨，咱一块儿进步！🌟