---
layout: post
title: '[论文笔记/综述] A survey of large language models for healthcare: from data, technology, and applications to accountability and ethics'
date: "2025-09-18T00:38:34Z"
---
\[论文笔记/综述\] A survey of large language models for healthcare: from data, technology, and applications to accountability and ethics
==================================================================================================================================

A survey of large language models for healthcare: from data, technology, and applications to accountability and ethics
----------------------------------------------------------------------------------------------------------------------

![image](https://img2024.cnblogs.com/blog/2838661/202509/2838661-20250917144657483-145227468.png)

该文章于2025年发表在Information Fusion（中科院一区），早在2023年10月发布在arxiv。  
文章地址：[https://dl.acm.org/doi/10.1016/j.inffus.2025.102963](https://dl.acm.org/doi/10.1016/j.inffus.2025.102963)  
arXiv：[https://arxiv.org/abs/2310.05694](https://arxiv.org/abs/2310.05694)

### 一、Outline

1.概述了目前开发的医疗保健大语言模型(LLM)的能力，并阐述了他们的开发过程，提供了从传统的预训练语言模型（PLM）到LLM的发展路线图的概述。

2.提供了训练医疗LLM相关的开源资料[LLM-for-Healthcare](https://github.com/KaiHe-better/LLM-for-Healthcare)。

3.探讨了医疗保健领域阻碍LLM应用的公平性、问责制、透明度和道德(fairness, accountability, transparency, and ethics)问题

### 二、Introduction

1.LLM与医疗保健的整合在改善临床结果、节约资源和加强患者护理方面取得重大进展。

2.对于较简单的任务，PLM在处理不复杂的病例时，在简单性和效率方面优于LLM。然后，因为PLM通常作为单任务系统运行，缺乏与复杂医疗数据动态交互的能力，使PLM在医疗保健中的使用受到限制。

3.思维链(COT)的提出提高了AI-生成决策的信任和可靠性

4.除了模型参数量的不断增大和能力的不断提升等，许多研究已经定制LLM来解决特定医疗应用任务。

5.GPT-3代表一个阶段的跃迁（大于100B模型的出现），如下图。

![image](https://img2024.cnblogs.com/blog/2838661/202509/2838661-20250917144826086-1248036782.png)

### 三、What LLMs can do for healthcare? from fundamental tasks to advanced applications

**总结：** 在大部分传统任务中，由于LLM的巨大参数量，使得LLM优于PLM。在一些简单任务上PLM的效率优于LLM。

#### NER and RE for healthcare

1.**命名实体识别** （Named Entity Recognition、NER）和**关系抽取** （Relation Extraction、RE）是实现**信息提取**（information Extraction、IE）的主要任务。为其他的医疗应用提供基础信息，例如**医学实体规范化与共指消解**（medical entity normalization and coreference）、**医学知识库和知识图谱构建**（medical knowledge base and knowledge graph construction）、**实体增强对话**（entity-enhanced dialogue）。

2.对于经常与药物打交道的（药物推荐等等方向），可以用到药物数据库**Drugbank**——[DrugBank Online | Database for Drug and Drug Target Info](https://go.drugbank.com/)。

3.在使用PLM研究NER的早期，大部分研究集中在序列标记任务上。在LLM时代，NER和RE已经被改进以在更复杂的条件下工作和更方便的使用。两个典型方法：①LLM-NERRE，结合这两种方法处理科学文本中的层次信息。②InstructGPT，使用零样本或少样本提示GPT，证明尽管没有受到专门的训练也能得到较好的效果。

> ①.Alexander Dunn, et al, Structured information extraction from complex scientific text with fine-tuned large language models, 2022, arXiv preprint arXiv: 2212.05238.
> 
> ②.Long Ouyang, et al, Training language models to follow instructions with human feedback, Adv. Neural Inf. Process. Syst. 35 (2022) 27730–27744.

4.对于特定领域的知识，因为PLM已经对标记数据做了微调，和LLM相比有一定的竞争优势。

#### TC for healthcare

1.**文本分类**（Text Classification、TC）是对医学短语、句子、段落或文档进行标签划分，也就是分类任务。像是情感分析、临床预测等方向经常使用。一个典型例子：结合LSTM和Bi-GRU实现医学TC。

> Sunil Kumar Prabhakar, Dong-Ok Won, Medical text classification using hybrid deep learning models with multihead attention, Comput. Intell. Neurosci. 2021 (2021).

2.基于PLM的TC通常不能满足医疗保健领域的可解释性和可靠性要求，但借助LLM就可以一定程度上缓解这些问题。像是现在大部分模型都自带推理链，可提供对回复的一部分解释。

3.在TC任务上LLM比PLM有更大的优势

#### STS for healthcare

1.**语义文本相似度**（Semantic Textual Similarity、STS）用于衡量两个句子或两个文档之间的相似程度。

2.STS可用于检查医疗笔记的质量，并有效地用于其他NLP（自然语言处理）任务。一个典型例子：基于ClinicalBERT的微调方法，提出迭代多任务学习技术，有助于模型从相关数据集中学习并选择最佳数据集进行微调。

> Diwakar Mahajan, et al, Identification of semantically similar sentences in clinical notes: Iterative intermediate training using multi-task learning, JMIR Med. Inform. 8 (11) (2020) e22508.

3.STS还可用于医疗保健信息检索，对于QA问题，检索出相关的文献来提供证据，或者检索出相似的患者病历供医生参考。

4.对于**短文本语义分类**，PLM和LLM是可比的，因为LLM在厂商下文和复杂语义理解才有一定的优势。对于**信息检索**，PLM轻量快速，较LLM有一定优势。对于复杂语境与生成任务，毫无疑问LLM优势。

#### QA for healthcare

1.**问答**（Question Answering、QA）是一项单独的传统任务，涉及生成或检索给定问题的答案。一个论据：根据皮尤研究中心的报告，超过三分之一的美国成年人在网上搜索过他们可能患有的疾病。

> Susannah Fox, Maeve Duggan, Health online 2013, 2012.

2.由于PLM有限的语言理解和生成能力，导致PLM很难在现在的现实世界的医疗保健场景中发挥重要作用。

3.现在的大部分医疗模型在医疗QA数据集（MedMCQA、PubMedQA、MMLU）上接近或超过了SOTA方法。模型例如PaLM 2等

4.视觉问答（VQA）通过问答促进医学图像的解释，在辅助诊断和增强患者理解方面有很大潜力

#### Dialogue system for healthcare

1.**对话系统**（Dialogue system）通常分为两类：任务导向和开放式对话系统。前者旨在解决医疗保健的特定问题，如医院指南或药物咨询。后者通常用作聊天机器人，以提供情感支持或心理健康相关的应用程序。

2.基于LLM的对话系统，可以利用强大的LLM的端到端系统，实现一些PLM难以实现的高级功能。

#### Generation of medical reports from images

1.医疗报告对相关专家具有重要的临床价值，**医疗报告生成**已经成为医疗保健领域一个很有前途的研究方向。可以帮助专家进行临床决策，通过自动起草描述异常和相关正常发现的报告，制作和减少报告编写的负担。

2.下面附医疗报告生成发展过程中比较典型的方法。

> *   Baoyu Jing, Pengtao Xie, Eric Xing, On the automatic generation of medical imaging reports, in: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2018, pp. 2577–2586.
>     
> *   Yuan Xue, Tao Xu, L. Rodney Long, Zhiyun Xue, Sameer Antani, George R.Thoma, Xiaolei Huang, Multimodal recurrent model with attention for automated radiology report generation, in: Medical Image Computing and Computer Assisted Intervention–MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part I, Springer, 2018, pp.457–466.
>     
> *   Jun Chen, et al, VisualGPT: Data-efficient adaptation of pretrained language models for image captioning, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR, 2022, pp. 18030–18040.
>     
> *   Sheng Wang, et al, Chatcad: Interactive computer-aided diagnosis on medical image using large language models, 2023, arXiv preprint arXiv:2302.07257.
>     
> *   Zhihong Chen, Yan Song, Tsung-Hui Chang, Xiang Wan, Generating radiology reports via memory-driven transformer, in: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP, 2020, pp.1439–1449.
>     
> *   Aaron Nicolson, et al, Improving chest X-Ray report generation by leveraging warm-starting, 2022, arXiv preprint arXiv:2201.09405.
>     
> *   Zihao Zhao, et al, ChatCAD+: Towards a universal and reliable interactive CAD using LLMs, 2023, arXiv preprint arXiv:2305.15964.
>     

3.在此任务上LLM明显优于PLM

### 四、From PLM to LLMs for healthcare

从PLM到LLM的转变有两个特点：①.从判别式AI（Discriminative AI）到生成式AI（Generative AI）的转变。②.从以模型为中心到以数据为中心的转变。

#### PLM for healthcare

1.PLM在医疗保健的研究有两类，一类是增强神经网络架构，一类是做更有效的预训练任务

2.可能用到的公共知识库：UMLS（医学概念知识库），CMeKG（中医知识图谱），BioModels和DrugBank（药物知识图）

3.PLM在医疗领域研究的两个点：**知识库**构建和使用，数据的指令微调方式。

#### LLM for healthcare

1.LLM在医疗领域的研究强调收集多样化，精确和专业的医疗保健数据，以及数据安全和隐私保护。

2..LLM在医疗领域研究的四个点，**不同的训练方法**（预训练（PT）、监督微调（SFT），LoRA微调，基于人类反馈的强化学习（RLHF），直接偏好优化（DPO），检索增强生成（RAG）等等，现在有了更多新方法，像是PPO、GRPO等。），**不同的训练数据**（高质量、不同模态），不同的评估方法（医学检查、医学问答、医学生成和医学综合评价 | 准确率、安全性、专业性等），**不同的特征**（模型大小，语言，模态）。

3.**不同的提示可以对模型的性能产生重大影响**

### 五、Usage and data for healthcare LLM

#### Usage

1.从微调到**情境学习**（In-context learning，ICL），可以定制化模型以适应医疗专业人员的准确需求和期望

2.从系统1（图像识别，机器翻译，语音识别和自动驾驶）到系统2的转变，利用**思维链**（COT），在不牺牲系统响应能力的前提下，提高透明度和可解释性。

3.**AI代理**（Agents），利用LLM作为中央控制器，建立自治代理体系，医疗领域可以用到的点：医院指导、辅助诊断、药物推荐和预后随访等。

#### Data

**电子健康记录/档案**（EHR）、**科学文献/论文**和**网络数据/资料**

### 六、Improving fairness, accountability, transparency, and ethics

1.在医疗保健领域，首先关注的是患者的福祉和安全，最重要的是要确保患者公平获得医疗服务，提供准确的医疗诊断和治疗的问责制，提高透明性和可信赖性，保护患者的隐私。

### 七、healthcare core issues

**圆越全表示技术越完善**  
![image](https://img2024.cnblogs.com/blog/2838661/202509/2838661-20250917145100137-1560928005.png)