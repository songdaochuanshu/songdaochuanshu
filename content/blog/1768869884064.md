---
layout: post
title: '使用 AI 编程工具的一点实践体会：为什么要减少对话轮次、一次把需求说清楚'
date: "2026-01-20T00:44:44Z"
---
使用 AI 编程工具的一点实践体会：为什么要减少对话轮次、一次把需求说清楚
=====================================

在使用 Cursor、ChatGPT 等 AI 编程工具的过程中，我逐渐意识到： 相比多轮对话不断修补需求，用更少的对话轮次一次性描述清楚核心需求， 反而更容易得到符合预期的实现。 本文结合实际使用经验，分析了对话轮次过多导致结果偏离的原因， 以及在什么情况下应当重新编辑问题而不是继续对话修补。

使用 AI 编程工具的一点实践体会：为什么要减少对话轮次、一次把需求说清楚
=====================================

一、背景
----

随着 Cursor、Copilot、ChatGPT 等 AI 编程工具在日常开发中的普及，  
越来越多的开发者开始尝试用 AI 来完成：

*   单个功能模块
*   小型系统原型
*   重复性或模板化代码

我自己在实际使用这些工具的过程中，也逐渐形成了一些使用习惯。  
其中**最重要的一点体会是：**

> **在让 AI 写代码时，应尽量减少对话轮次，用尽可能清晰、完整的描述一次性说明核心需求。**

这篇文章主要记录我在实践中总结出的原因、经验以及适用边界。

* * *

二、常见的错误使用方式
-----------

在刚开始使用 AI 编程工具时，我（以及身边不少同事）都会下意识采用类似下面的方式：

1.  先描述一个比较模糊的需求
2.  看 AI 生成的代码
3.  发现不符合预期
4.  继续在当前对话中补充或修改需求
5.  重复上述过程

这种方式在**简单问题**上通常没什么问题，  
但在以下场景中，很容易出现偏差：

*   模块之间存在关联
*   功能有前后依赖关系
*   有较多隐含约束（性能、扩展性、结构等）

最终结果往往是：

> **代码越来越“补丁化”，整体实现逐渐偏离最初的目标。**

* * *

三、为什么对话轮次越多，结果越容易偏离？
--------------------

### 3.1 模型理解是“上下文驱动”的

AI 模型并不是像人一样“始终记得最初的目标”，而是：

*   基于当前上下文进行概率推断
*   更倾向于满足**最近一轮对话中的显式要求**

当我们不断追加新指令时：

*   新需求可能与旧需求存在隐性冲突
*   模型会尝试“局部修补”，而不是整体重构

久而久之，最初的设计目标就会被逐渐稀释。

* * *

### 3.2 人在补充需求时，往往是“局部视角”

在多轮对话中，人通常是在**针对当前不满意的点进行修正**，例如：

*   “这里能不能换成异步？”
*   “这个字段我不想要了”
*   “这个函数再加一个参数”

但问题在于：

*   这些修改**可能影响其它模块**
*   AI 并不知道你是否接受连带变化
*   你自己也未必在当下考虑到了所有影响

最终就会出现：

*   功能能跑
*   结构却越来越奇怪

* * *

### 3.3 模型限制 + 问题拆解方式的叠加效应

偏离预期，往往不是单一原因造成的，而是：

*   模型在长对话中的抽象能力下降
*   人在提问时逐渐变成“修 bug 式提问”
*   缺乏一次“全局视角”的重新校准

这三点叠加在一起，就很容易让结果走偏。

* * *

四、更推荐的使用方式：少轮次 + 高质量输入
----------------------

### 4.1 一次性描述清楚“核心需求”

这里说的“一次性”，并不是要求把所有细节都写死，而是至少要说明清楚：

*   这个模块/系统**要解决什么问题**
*   有哪些核心功能
*   功能之间是否有关联
*   哪些点是**不能随意改动的约束**

示例思路：

    我要实现一个 XXX 系统，主要包含 A / B / C 三个功能。
    其中：
    - A 和 B 之间存在依赖关系
    - C 的实现不能影响 A 的调用方式
    - 性能优先级高于代码简洁性
    

* * *

### 4.2 接受“非核心问题”的逐步优化

在一次高质量描述后，AI 生成的结果通常会：

*   核心结构基本正确
*   功能逻辑大体符合预期
*   细节上存在一些小问题

这些小问题通常包括：

*   命名不够优雅
*   局部代码不够简洁
*   样式或美观问题

👉 **这些问题是适合通过“少量追加对话”来优化的。**

* * *

五、什么时候应该“停止对话，重新编辑问题”？
----------------------

这是一个非常关键的判断点。

### 5.1 明确应该重来的一些信号

如果出现以下情况之一，**强烈建议重新编辑需求，而不是继续对话修补**：

*   新需求会影响多个已有功能
*   修改一个功能，会连带影响其它模块
*   你发现自己在“打补丁”而不是在设计
*   你已经很难用一句话说明当前代码结构

此时继续对话，大概率只会让问题更复杂。

* * *

### 5.2 正确的做法

更好的方式是：

1.  停止当前对话
2.  回顾当前代码和真实需求
3.  在**新的对话中重新整理描述**
4.  把之前暴露出的缺陷明确写进去

例如：

    在之前的实现中，我发现 A 和 B 的设计存在耦合问题。
    这次希望：
    - 明确拆分 A / B 的职责
    - 保证后续扩展 C 功能时不需要修改 A
    

* * *

六、关于“一次性描述”和“灵活调整”的平衡
---------------------

需要强调的是：

> **减少对话轮次 ≠ 一次性把一切写到极致完美**

更合理的平衡是：

*   核心设计、关键约束：一次说明清楚
*   非核心细节、体验优化：允许少量调整
*   结构性缺陷、系统性问题：直接重来

把 AI 当成一个：

> **执行能力很强，但不具备全局自省能力的助手**

而不是一个会自动“帮你纠偏”的高级工程师。

* * *

七、总结
----

结合自己的实际使用经验，我目前形成的结论是：

1.  AI 编程工具非常依赖输入质量
2.  对话轮次越多，越容易偏离最初目标
3.  核心问题应一次性描述清楚
4.  结构性问题不要通过“补丁式对话”修复
5.  重新编辑问题，往往比继续对话更高效

后续我也会结合具体案例（包括错误示范和正确示范）进一步补充说明。

* * *

> **这篇文章并不是否定多轮对话的价值，而是希望在合适的场景下，用更合理的方式使用 AI。**