---
layout: post
title: '手把手教你喂养 DeepSeek 本地模型'
date: "2025-02-09T00:38:23Z"
---
手把手教你喂养 DeepSeek 本地模型
---------------------

2025-02-09 08:26  [AlfredZhao](https://www.cnblogs.com/jyzhao)  阅读(0)  评论(0)  [编辑](https://i.cnblogs.com/EditPosts.aspx?postid=18705735)  [收藏](javascript:void\(0\))  [举报](javascript:void\(0\))

上篇文章《[手把手教你部署 DeepSeek 本地模型](https://mp.weixin.qq.com/s/AgQkyzV7cr-gUsfTqP7mFg?token=295441393&lang=zh_CN)》首发是在公众号，但截止目前只有500多人阅读量，而在[自己博客园BLOG同步更新的文章](https://www.cnblogs.com/jyzhao/p/18700202/shou-ba-shou-jiao-ni-bu-shu-deepseek-ben-de-mo-xin)热度很高，目前已达到50000+的阅读量，流量是公众号的100倍。

不管怎样，看来大家还是更喜欢这种真正手把手的教学模式。

在高流量加持下，也得到了更多读者的反馈，从评论区看到大家部署成功后都很兴奋，普遍认为这类教程对新手的帮助很大。

但也有困惑，就是成功部署本地模型之后，除了能在断网模式下也可以和deepseek聊天之外，还有哪些优势呢？

其实从BLOG的评论区已经有读者指出，迫切的想知道下一步究竟该如何喂养这个本地模型，让它可以成为一个更有用的本地私密知识库。

![wxfm-ds2](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637964-1861863258.png)

下面就开始 DeepSeek 手把手系列第二篇：《手把手教你喂养 DeepSeek 本地模型》

*   1.基本概念科普
*   2.下载 AnythingLLM 软件
*   3.配置 nomic-embed-text 模型
*   4.演示如何正确喂养个人数据
*   5.喂养前后效果对比和缺陷

1.基本概念科普
========

这里先给AI小白简单科普一下基本概念，便于更好地理解本文中的动手操作。

为什么我这里叫“喂养”DeepSeek 本地模型，是因为大模型再强大也有它天然的局限性，比如训练数据不可能包含你的私域数据，而打造自己的本地私域知识库，就需要检索这些数据，具体采用的是RAG（检索增强生成）方法。

RAG，英文全称是Retrieval-Augmented Generation。简单来讲，采用RAG就需要把你的私域数据向量化，然后存储到向量数据库中，支持向量检索配合LLM大模型一起提供更专业的回复。

2.下载 AnythingLLM 软件
===================

官方网站：

*   [https://anythingllm.com/desktop](https://anythingllm.com/desktop)

下载符合你系统平台的软件，我这里是Apple Intel：  
![any1](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637385-492125126.png)

下载好的`AnythingLLMDesktop.dmg`，dmg文件约300M多点，双击安装并拖至应用程序中：  
![any3](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637411-76663093.png)

拖动时可以看到AnythingLLM安装程序有1G大小：  
![any4](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637291-332290119.png)

然后打开AnythingLLM，欢迎界面如下：  
![any6](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637429-1903087189.png)

点击`Get Started`配置首选LLM，这里我们选择上一篇文章已经教大家配置好的Ollama：  
![any9](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637459-1295671021.png)

这里注意，需要确保你的Ollama正常运行，否则会报错找不到`provider endpoint`，如下图：  
![any10](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637437-2072169844.png)

此时就需要检查你的ollama以及可用的本地模型：  
![any11](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637352-284858044.png)

修复好之后就可以看到AnythingLLM已经可以正确识别到本地部署的模型：  
![any12](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637486-32889826.png)

之后可以看到LLM模型选择了Ollama，Embedding默认是AnythingLLM的Embedder，Vector Database默认是LanceDB：  
![any13](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637413-1536870798.png)

为了不给新手加难度，Embedding和Vector Database我这里都没有进行修改，直接先进入到下一步，是一个survey，笔者是个i人，实在没啥可说的，这里直接跳过了：  
![any14](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637387-423656625.png)

下一步选择工作区名称，你可以随便起名字，我这里就用自己的英文名演示了：  
![any15](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637346-1931415386.png)

然后就终于进入了主界面：  
![any17](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637474-960117475.png)

呼呼，迫不及待的开始测试。  
我这里直接设计了一个大模型不可能知道的问题，就是拿我的中文名字去做测试，直接问他“赵靖宇是谁？”  
![any18](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637404-375331455.png)

果然，它不知道！

马上开始上传一段TXT文本`QA-Test.TXT`，其实就是简单包含了我之前在讲公开课时的一段个人介绍，全文也没几句话。开始期待它的表现，上传方式如下，可以看到上传后文件就会自动Embedded！  
![any19](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637441-1990642552.png)

可是…… 这里不太顺利，它居然还是不知道！呜呜呜，我都把小抄给你了你还说不知道，笔者已哭晕……  
![any20](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637381-1556385045.png)

此时只能转而troubleshooting，检索发现不少人都有遇到类似问题，有人甚至直接发结论说本地大模型的模式下，AnythingLLM根本无法识别上传的个人文件，甚至力劝大家别折腾了。。

3.配置 nomic-embed-text 模型
========================

笔者属于不撞南墙不回头的类型，想深挖下问题到底出在哪里？开始逐一检查可能的配置：  
1）聊天设置模型选择肯定是没问题，本地大模型 DeepSeek：  
![any25](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637456-339993143.png)

2）向量数据库默认的，向量数量为1：  
![any26](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637464-542860007.png)

3）代理配置依然选择了本地大模型 DeepSeek：  
![any27](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637490-1182826280.png)

笔者初步判断：

*   1）本地大模型肯定没问题，因为上篇使用Chatbox调用都OK，AnythingLLM对应配置也再次确认了，均正确。
*   2）向量数据库虽然我有更好的选择，笔者就是从事数据库行业，但这里显然还没到那个阶段，默认的即便再拉跨也不至于一个这么简单的文本向量化都搞不定。
*   3）那就剩下 Embedding 用的模型，虽然开始也没怀疑过，但是这样排除下来就这个可能性最大了。要不，换一个试试？

目前 Embedding 采用的是默认的 AnythingLLM Embedder：  
![any28](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637450-681682686.png)

简单research了下，选了另一个Ollama下的`nomic-embed-text`Embedding 模型，官方网站：

*   [https://ollama.com/library/nomic-embed-text](https://ollama.com/library/nomic-embed-text)

我们可以在terminal下使用ollama直接拉取`ollama pull nomic-embed-text`：  
![any30](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637422-1842107533.png)

然后再回到`Embedder首选项`，在嵌入引擎提供商，选择Ollama，然后在下面的Ollama Embedding Model选择刚刚下载的最新`nomic-embed-text:8192`，如下图：  
![any31](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637496-387389866.png)

选择好之后点击蓝色的按钮`保存更改`，会弹出一个比较醒目的Warning，如下图：  
![any32](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637496-509134765.png)

主要是警告你要做的这个更改Embedding模型的操作会重置先前所有embedded的文档，且不可逆转。我这之前的根本没效果，重置就重置，赶紧点击`Confirm`，迫不及待想看下这个新的Embedder是否有用？

4.演示如何正确喂养个人数据
==============

使用跟之前同样的操作方法，同样的问题`赵靖宇是谁？`，喂养文本`QA-Test.TXT`，终于起作用了！  
![any33](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637385-847884078.png)

于是兴奋地继续追问：`他有几年的工作经验？`，又不知道了，当然这个正常，因为我提供的信息里就没有明确提到，可以继续上传其他个人数据，比如说来份PDF格式的个人简历：  
![any34](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637415-2020950869.png)

然后继续问些更细节的问题：`你知道他的博客地址是什么吗？`、`赵靖宇有公众号吗？`  
![any35](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637478-778135277.png)  
效果还是比较给力的，均给出了正确答案。明确说出我的公众号名称`赵靖宇`，以及Blog的url地址：`https://www.cnblogs.com/jyzhao/`，尤其是网址能准确给出还是比较惊喜的。

5.喂养前后效果对比和缺陷
=============

上面已经看到了喂养后的效果显著，但这是否就高枕无忧了呢？

其实不是的，比如我继续测试时发现，当让它帮我总结下简历信息，就看到了较明显的缺陷：  
![any37](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637469-328529834.png)

这里有两处明显的错误：而且有一个错误，还是之前单独问它时，回答正确的，具体如下图：  
![any38](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637510-49865465.png)

其实这个回复中大部分信息都还OK，可瑕疵也是极为明显的，比如它居然说我是人工智能聊天机器人，然后把之前曾正确回答出的博客网址又给答错了。  
这些讹误和不稳定性，原因可能是受限于我本地部署的模型太小，本身能力不足，也可能是Embedding向量化的工作做的还不够好，但总体来说，对于我这台个人电脑能达到这样的效果，已经很是知足了。

![wxfm-ds2](https://img2023.cnblogs.com/blog/635610/202502/635610-20250209082637964-1861863258.png)

OK，到这里，就已经完成了 DeepSeek 手把手系列的第二篇教程《[手把手教你喂养 DeepSeek 本地模型](https://mp.weixin.qq.com/s/YcW4MDAj06W35TOtHVoB2Q?token=295441393&lang=zh_CN)》，之前说感兴趣的读者们也抓紧hands-on起来吧！

AlfredZhao©版权所有「从Oracle起航，领略精彩的IT技术。」