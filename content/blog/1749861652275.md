---
layout: post
title: 'AI大模型应用开发入门-LangChain开发Agent'
date: "2025-06-14T00:40:52Z"
---
AI大模型应用开发入门-LangChain开发Agent
============================

#### 基于 LangChain 和 GPT-4o-mini 的大模型智能体开发实战

近年来，大模型能力的持续突破，使得构建智能代理（Agent）系统成为开发者追逐的热点。

本文将以 `LangChain` 框架为核心，结合 `GPT-4o-mini` 模型，通过接入工具与消息修剪策略，实现一个具备记忆、调用搜索、执行函数能力的智能体。

#### 环境准备与模型初始化

使用 `LangChain` 需要首先初始化语言模型，这里使用的是 `GPT-4o-mini`，由 `OpenAI` 提供。

    # llm_env.py
    from langchain.chat_models import init_chat_model
    
    llm = init_chat_model("gpt-4o-mini", model_provider="openai")
    

我们将其封装在 `llm_env.py` 中供主程序导入。

#### 主程序结构解析

主逻辑文件为 `main_agent_trim.py`，功能包括：

*   工具集成
    
*   PostgreSQL 持久化配置
    
*   消息修剪策略
    
*   Agent 交互循环
    

#### 工具函数与搜索工具接入

我们首先定义了一个简单的数学函数 `add`，以及接入了 `TavilySearchResults` 搜索工具，用于增强智能体外部知识获取能力。

    def add(a: int, b: int) -> int:
        return a + b
    
    search = TavilySearchResults(max_results=5)
    tools = [add, search]

#### 配置 LangGraph 持久化存储

我们使用 `PostgresSaver` 来记录 agent 的状态与历史会话，以支持多轮对话记忆。

    DB_URI = "postgresql://postgres:123456@localhost:5432/langchaindemo?sslmode=disable"
    with PostgresSaver.from_conn_string(DB_URI) as checkpointer:
        checkpointer.setup()
    

用户输入 `thread_id`，我们组合当天日期生成唯一标识符，确保每个会话线程独立可追溯。

#### 消息修剪策略设计

为了控制模型输入 token 上限，我们引入 `trim_messages` 方法，在每轮对话前进行修剪：

    def pre_model_hook(state):
        trimmer = trim_messages(
            max_tokens=65,
            strategy="last",
            token_counter=llm_env.llm,
            include_system=True,
            allow_partial=False,
            start_on="human",
        )
        trimmed_messages = trimmer.invoke(state["messages"])
        return {"llm_input_messages": trimmed_messages}
    

该策略仅保留最近的用户消息，避免长对话历史超出 token 限制，影响模型响应。

#### 构建智能体执行器

借助 `create_react_agent` 方法创建智能体，传入模型、工具、hook 与 checkpoint。

    agent_excuter = create_react_agent(
        llm_env.llm,
        tools,
        pre_model_hook=pre_model_hook,
        checkpointer=checkpointer,
    )

#### 与智能体交互

程序进入循环模式，接收用户输入，执行智能体推理，并输出响应内容及工具调用情况。

    while True:
        query = input("你: ")
        if query.strip().lower() == "exit":
            break
        input_messages = [HumanMessage(query)]
        response = agent_excuter.invoke({"messages": input_messages}, config=config)
        for message in response["messages"]:
            if hasattr(message, "content") and message.content:
                print(f"{message.type}:{message.content}")
            if hasattr(message, "tool_calls") and message.tool_calls:
                print(f"{message.type}:{message.tool_calls}")

#### 示例

![](https://img2024.cnblogs.com/blog/1033233/202506/1033233-20250613120725176-1134633239.png)

#### 总结

本文展示了如何基于 LangChain 框架构建一个集搜索、函数执行、消息修剪与状态持久化为一体的智能体系统。通过合理设计 hook 与工具链，我们可以持续扩展其功能边界。