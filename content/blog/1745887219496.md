---
layout: post
title: '【深度学习】MLE视角下的VAE与DDPM损失函数推导'
date: "2025-04-29T00:40:19Z"
---
【深度学习】MLE视角下的VAE与DDPM损失函数推导
===========================

正文
--

### 最大似然估计的由来

> VAE和DDPM都是likelihood-based生成模型，都是通过学习分布->采样实现图像生成的；

这类模型**最大的特点**就是希望实现

\\\[\\theta = \\arg\\max \\limits\_{\\theta} \\mathbb{E}\_{x \\sim p\_{data}(x)}\[log(p\_{\\theta}(x))\] \\\]

上述式子是啥意思呢？\\(\\theta\\)是神经网络的参数集合，\\(p\_{\\theta}(x)\\)是神经网络模型学习（拟合）得到的分布。所以上式意思是我希望我的神经网络**生成的图片足够逼真**，生成出符合原始数据分布的**概率足够高**。

换一个思路去考虑这个问题，我现在有一个神经网络参数化的\\(p\_{\\theta}\\)，和真实数据分布\\(p\_{data}\\)

> \[!NOTE\]
> 
> 这里教个小技巧，看到\\(p\_{\\theta}\\)就当作\\(N(\\mu\_{\\theta},\\sigma\_{\\theta}^2)\\)去理解（并不是说所有神经网络都在拟合高斯分布，只是这种情况比较多，且这么理解更加直观。）

我们本质的目的还是说\\(p\_{\\theta} \\rightarrow p\_{data}\\)，**尽可能的逼近**

\\\[\\begin{aligned} D\_{KL}(p\_{data}||p\_{\\theta}) &= \\int p\_{data}(x)log\\frac{p\_{data}(x)}{p\_{\\theta}(x)}dx \\\\ &= \\int p\_{data}(x)logp\_{data}(x)dx - \\int p\_{data}(x)logp\_{\\theta}(x)dx \\\\ &=\\mathbb{E}\_{x \\sim p\_{data}(x)}\[logp\_{data}(x)\]-\\mathbb{E}\_{x \\sim p\_{data}(x)}\[logp\_{\\theta}(x)\] \\end{aligned} \\\]

又因为\\(D\_{KL}(p\_{data}||p\_{\\theta}) \\geq 0\\)，这就要求\\(\\mathbb{E}\_{x \\sim p\_{data}(x)}\[logp\_{\\theta}(x)\]\\)**尽可能的大**，以离散的形式理解：

\\\[\\begin{aligned} \\mathbb{E}\_{x \\sim p\_{data}(x)}\[logp\_{data}(x)\]-\\mathbb{E}\_{x \\sim p\_{data}(x)}\[logp\_{\\theta}(x)\] \\approx \\frac{1}{N}\\sum\_{i=1}^N logp\_{data}(x\_i)-\\frac{1}{N}\\sum\_{i=1}^N logp\_{\\theta}(x\_i),x\_i \\sim p\_{data} \\end{aligned} \\\]

当\\(p\_\\theta \\rightarrow p\_{data}\\)时，那么每次采样得到的\\(p\_{\\theta}(x\_i)\\)就是等于\\(p\_{data}(x\_i)\\)，这样就保证\\(D\_{KL}(p\_{data}||p\_{\\theta})\\)最小。

> \[!NOTE\]
> 
> 有没有可能\\(p\_{\\theta}\\)和\\(p\_{data}\\)**不相等**，但是也有样本概率的整体差趋近于0呢？以高斯分布举例\\(p\_{data}(x)=N(175,10^2I),p\_{\\theta}(x)=N(165,5^2I)\\)，那么有可能**个别甚至一部分**从\\(p\_{data}\\)采样得到的\\(x\_i\\)在\\(p\_{\\theta}(x\_i)\\)中的**概率值会高于**\\(p\_{data}(x\_i)\\)，但是就整体而言，**其余部分的均值会拉低这个水平**，导致最终的\\(D\_{KL}(p\_{\\theta}||p\_{data})\\)还是会很高。
> 
> 另一个方面，\\(D\_{KL}(p\_{\\theta}||p\_{data}) \\geq 0\\)，除了**两个分布相等**之外没有别的可能实现。

那为什么有些资料中，最大似然估计中没有涵盖\\(\\mathbb{E}\_{x \\sim p\_{data}(x)}\\)这项呢？

假设有\\(N\\)个独立同分布（i.i.d）的样本\\(\\{x\_1,x\_2,\\cdots,x\_N\\}\\)，MLE的目标是**最大化样本的联合概率**

\\\[\\theta=\\arg\\max \\limits\_{\\theta}=\\prod\_{i=1}^Np\_{\\theta}​(x\_i) \\\]

直观来说，我希望\\(p\_{\\theta}(x)\\)足够接近于\\(p\_{data}(x)\\)，这样从\\(p\_{data}(x)\\)采样得到的\\(x\_i\\)在\\(p\_{\\theta}(x)\\)分布下的概率值才会尽可能的高。

取对数后转化为求和的形式

\\\[\\theta = \\arg \\max \\limits\_{\\theta} \\sum\_{i=1}^Nlogp\_{\\theta}(x\_i) \\\]

当\\(N \\rightarrow \\infty\\)时，根据大数定律有

\\\[\\frac{1}{N}\\sum\_{i=1}^Nlogp\_{\\theta}(x\_i) \\rightarrow \\mathbb{E}\_{x \\sim p\_{data}(x)}\[log(p\_{\\theta}(x))\] \\\]

因此\\(\\theta = \\arg \\max \\limits\_{\\theta} \\sum\_{i=1}^Nlogp\_{\\theta}(x\_i)\\)和\\(\\theta = \\arg\\max \\limits\_{\\theta} \\mathbb{E}\_{x \\sim p\_{data}(x)}\[log(p\_{\\theta}(x))\]\\)在形式上取得一致。

### VAE的Loss推导

\\\[\\begin{aligned} logp\_{\\theta}(x)&=logp\_{\\theta}(x)\\int\_zq\_{\\phi}(z|x)dz \\\\ &=\\int\_z q\_{\\phi}(z|x)logp\_{\\theta}(x)dz \\\\ &=\\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[logp\_{\\theta}(x)\] \\\\ &=\\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[log\\frac{p\_{\\theta}(x,z)}{p(z|x)}\] \\\\ &=\\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[log\\frac{p\_{\\theta}(x,z)}{p\_{\\theta}(z|x)}\\frac{q\_{\\phi}(z|x)}{q\_{\\phi}(z|x)}\] \\\\ &=\\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[log\\frac{p\_{\\theta}(x,z)}{q\_{\\phi}(z|x)}\]+\\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[\\frac{q\_{\\phi}(z|x)}{p\_{\\theta}(z|x)}\] \\\\ &=\\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[log\\frac{p\_{\\theta}(x,z)}{q\_{\\phi}(z|x)}\]+D\_{KL}(q\_{\\phi}(z|x)||p\_{\\theta}(z|x))\\\\ &\\geq \\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[log\\frac{p\_{\\theta}(x,z)}{q\_{\\phi}(z|x)}\] = ELBO \\end{aligned} \\\]

> \[!NOTE\] MLE、ELBO与Loss之间的联系
> 
> 1.  对于一些显式的概率模型，直接使用\\(\\theta = \\arg \\max \\limits\_{\\theta} \\sum\_{i=1}^Nlogp\_{\\theta}(x\_i)\\)公式；
> 2.  但是对于包含隐变量的概率模型，由于\\(p\_{\\theta}(x)=\\int p\_{\\theta}(x,z)dz\\)中对于\\(z\\)变量的积分过于复杂而**不直接使用MLE的方法进行计算**；取而代之，是通过构建变分下界（\\(ELBO\\)）**不等式**的方式，通过**最大化\\(ELBO\\)的方式去逼近MLE的目标**。通过分解单个数据点的\\(logp\_{\\theta}(x)\\)，再扩展到全体数据\\(\\sum\_{i=1}^N ELBO\_i\\)，最终与MLE目标等价，并且通过该不等式**引出最终的损失函数**‘；
> 3.  当目标是**显式函数**时，Loss是MLE本身；目标是**隐式函数**时，Loss是ELBO（MLE的下界）

其中，由于\\(D\_{KL}(q\_{\\phi}(z|x)||p\_{\\theta}(z|x)) \\geq 0\\)，所以把\\(\\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[log\\frac{p\_{\\theta}(x,z)}{q\_{\\phi}(z|x)}\]\\)作为变分下界（ELBO）

\\\[\\begin{aligned} ELBO &= \\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[log\\frac{p\_{\\theta}(x,z)}{q\_{\\phi}(z|x)}\] \\\\ &= \\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[log\\frac{p\_{\\theta}(x|z)p(z)}{q\_{\\phi}(z|x)}\] \\\\ &=\\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[logp\_{\\theta}(x|z)\]-\\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[log\\frac{q\_{\\phi}(z|x)}{p(z)}\] \\\\ &=\\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[logp\_{\\theta}(x|z)\]-D\_{KL}(q\_{\\phi}(z|x)||p(z)) \\end{aligned} \\\]

在这里我需要更新一下对VAE的认识，之前的文章也是从**流程**的角度去解释为什么需要一个\\(q\_{\\phi}(z|x)\\)去对后验分布进行拟合，这里我想以MLE推导得出ELBO的角度去进行更深入的解释。

#### VAE的动态平衡调节

> 生成图像流程：\\(x \\rightarrow q\_{\\phi}(z|x) \\rightarrow z \\rightarrow p\_{\\theta}(x|z) \\rightarrow \\hat{x}\\)

因此根据梯度调优时，VAE的调优策略类似于EM算法

1.  固定\\(\\phi\\)参数，优化\\(\\theta\\)参数。在ELBO中\\(\\mathbb{E}\_{z \\sim q\_{\\phi}(z|x)}\[logp\_{\\theta}(x|z)\]\\)表现于提高由**解码器生成图像的精确度**。但是此时\\(\\theta\\)的变动导致与似然分布\\(p\_{\\theta}(x|z)\\)强相关的**代理后验分布\\(p\_{\\theta}(z|x)\\)也发生了变化**，导致\\(D\_{KL}(q\_{\\phi}(z|x)||p\_{\\theta}(z|x))\\)值发生了变化，进而**影响了ELBO损失函数的值**；
2.  固定\\(\\theta\\)参数，优化\\(\\phi\\)参数。因此\\(q\_{\\phi}(z|x)\\)会天然的通过调整\\(\\mu\_{\\phi}\\)和\\(\\sigma\_{\\phi}\\)去**最大化ELBO的数值**，体现在最小化\\(D\_{KL}(q\_{\\phi}(z|x)||N(0,I))=\\frac{1}{2}(1+log\\sigma\_{\\phi}^2-\\mu\_{\\phi}^2-\\sigma\_{\\phi}^2)\\)，提高**编码器分布与先验分布的近似度**。同时，\\(\\mu\_{\\phi}\\)和\\(\\sigma\_{\\phi}\\)值的变动生成不同的\\(z\\)值采样，又需要让\\(\\theta\\)参数**不断更新**进而学习如何精准生图；

二者是一个**动态平衡**的效果。

> \[!NOTE\] 如果提高解码器精度所调整的\\(\\theta\\)导致代理后验分布\\(p\_{\\theta}(z|x)\\)偏离标准正态分布很远（趋向于一个尖锐的分布，\\(z\\)集中于一个位置）。那么\\(q\_{\\phi}(z|x) \\rightarrow p(z)\\)以提高ELBO与\\(q\_{\\phi}(z|x) \\rightarrow p\_{\\theta}(z|x)\\)以降低\\(D\_{KL}(q\_{\\phi}(z|x)||p\_{\\theta}(z|x))\\)最终提升ELBO不是**背道而驰**的嘛？
> 
> 事实上，由于无法显式计算\\(D\_{KL}(q\_{\\phi}(z|x)||p\_{\\theta}(z|x))\\)，只能通过最大化ELBO，即\\(q\_{\\phi}(z|x) \\rightarrow p(z)\\)的形式去提升ELBO，这也导致了：
> 
> 1.  最终的\\(q\_{\\phi}(z|x)\\)可能与真实的\\(p\_{\\theta}(z|x)\\)**相隔甚远**，\\(q\_{\\phi}(z|x) \\rightarrow N(0,I)\\)是**对抗中妥协**的结果，试想少了\\(D\_{KL}(q\_{\\phi}(z|x)||p(z))\\)这层约束项，\\(p\_{\\theta}(z|x)\\)跟着解码器\\(\\theta\\)参数一变，\\(q\_{\\phi}(z|x)\\)为了防止\\(D\_{KL}(q\_{\\phi}(z|x)||p\_{\\theta}(z|x))\\)过大影响ELBO的值，真的会跟着走，**导致最终趋向于狄拉克分布，这是我们不想看到的**；
> 2.  工程实际而言，保证了\\(q\_{\\phi}(z|x)\\)空间结构趋向于\\(N(0,I)\\)，这是**精度和多样性的一个妥协**；
> 3.  个人理解，\\(q\_{\\phi}(z|x) \\rightarrow N(0,I)\\)也**降低了\\(p\_{\\theta}(x|z)\\)的学习成本**，让二者更好的形成一个平衡，最终也会**矫正**代理后验分布\\(p\_{\\theta}(z|x)\\)回归标准正态分布；

### MHVAE的Loss推导

> Markovian Hierarchical Varitational AutoEncoder，马尔可夫级联VAE

![image.png](https://suahi-1311668441.cos.ap-shanghai.myqcloud.com/2024/20250427185327650.png)

参考之前由MLE推导得到ELBO的公式可知

\\\[\\begin{aligned} logp\_{\\theta}(x)&=log\\int p\_{\\theta}(x,z\_{1:T})dz\_{1:T}\\\\ &=log\\int\\frac{p\_{\\theta}(x,z\_{1:T})q\_{\\phi}(z\_{1:T}|x)}{q\_{\\phi}(z\_{1:T}|x)}dz\_{1:T} \\\\ &=log\\mathbb{E}\_{q\_{\\phi}(z\_{1:T}|x)}\[\\frac{p\_{\\theta}(x,z\_{1:T})}{q\_{\\phi}(z\_{1:T}|x)}\] \\\\ &\\geq\\mathbb{E}\_{q\_{\\phi}(z\_{1:T}|x)}\[log\\frac{p\_{\\theta}(x,z\_{1:T})}{q\_{\\phi}(z\_{1:T}|x)}\] = ELBO \\\\ \\end{aligned} \\\]

> \[!NOTE\]
> 
> 最后一步用到了`琴生不等式`，对于一个凸函数而言：\\(\\frac{log(x\_1) + log(x\_2)}{2} \\leq log(\\frac{x\_1 + x\_2}{2})\\)

### DDPM的Loss推导

![image.png](https://suahi-1311668441.cos.ap-shanghai.myqcloud.com/2024/20250427190311096.png)

图中是基于MHVAE的标注，替换为\\(x \\rightarrow x\_0\\)、\\(z\_i \\rightarrow x\_i\\)

其中加噪过程\\(q(x\_{t}|x\_{t-1})\\)是人为的，具体公式参考\[\[001 DDPM-v2\]\]，因此不添加\\(\\phi\\)参数；  
其中去噪过程\\(p\_{\\theta}(x\_{t-1}|x\_t)\\)是需要学习的，因此添加\\(\\theta\\)参数进行**神经网络参数化**操作；

#### DDPM的ELBO

参考上述MLE推导得到ELBO的公式

\\\[\\begin{aligned} logp\_{\\theta}(x)&=log\\int p\_{\\theta}(x\_{0:T})dx\_{1:T}\\\\ &=log\\int\\frac{p\_{\\theta}(x\_{0:T})q(x\_{1:T}|x\_0)}{q(x\_{1:T}|x\_0)}dx\_{1:T} \\\\ &=log\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[\\frac{p\_{\\theta}(x\_{0:T})}{q(x\_{1:T}|x\_0)}\] \\\\ &\\geq\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_{0:T})}{q(x\_{1:T}|x\_0)}\] = ELBO \\\\ \\end{aligned} \\\]

其中

\\\[\\begin{aligned} p\_{\\theta}(x\_{0:T}) &= p(x\_T)p(x\_{0:T-1}|x\_T)\\\\ &=p(x\_T)p(x\_{T-1}|x\_{T})p(x\_{0:T-2}|x\_{T-1},x\_T)\\\\ &=p(x\_T)p(x\_{T-1}|x\_{T})p(x\_{0:T-2}|x\_{T-1}) \\\\ &=\\cdots \\\\ &=p(x\_T)p(x\_{T-1}|x\_{T})\\cdots p(x\_0|x\_1) \\\\ &=p(x\_T)\\prod\_{t=1}^Tp(x\_{t-1}|x\_t) \\end{aligned} \\\]

\\\[\\begin{aligned} q(x\_{1:T}|x\_0) &= q(x\_{2:T}|x\_1)q(x\_1|x\_0) \\\\ &=q(x\_{3:T}|x\_2,x\_1)q(x\_2|x\_1)q(x\_1|x\_0) \\\\ &=q(x\_{3:T}|x\_2)q(x\_2|x\_1)q(x\_1|x\_0) \\\\ &=\\cdots \\\\ &=q(x\_{T}|x\_{T-1})\\cdots q(x\_2|x\_1)q(x\_1|x\_0)\\\\ &=\\prod\_{t=1}^Tq(x\_t|x\_{t-1}) \\end{aligned} \\\]

代入得

\\\[\\begin{aligned} logp\_{\\theta}(x)&\\geq\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_{0:T})}{q(x\_{1:T}|x\_0)}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)\\prod\_{t=1}^Tp\_{\\theta}(x\_{t-1}|x\_t)}{\\prod\_{t=1}^Tq(x\_t|x\_{t-1})}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)p\_{\\theta}(x\_0|x\_1)\\prod\_{t=2}^Tp\_{\\theta}(x\_{t-1}|x\_t)}{\\prod\_{t=1}^Tq(x\_t|x\_{t-1})}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)p\_{\\theta}(x\_0|x\_1)\\prod\_{t=1}^{T-1}p\_{\\theta}(x\_{t}|x\_{t+1})}{q(x\_T|x\_{T-1})\\prod\_{t=1}^{T-1}q(x\_t|x\_{t-1})}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)p\_{\\theta}(x\_0|x\_1)}{q(x\_T|x\_{T-1})}\]+\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\prod\_{t=1}^{T-1}\\frac{p\_{\\theta}(x\_{t}|x\_{t+1})}{q(x\_t|x\_{t-1})}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[logp\_{\\theta}(x\_0|x\_1)\]+\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})}\]+\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[\\sum\_{t=1}^{T-1}log\\frac{p\_{\\theta}(x\_{t}|x\_{t+1})}{q(x\_t|x\_{t-1})}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[logp\_{\\theta}(x\_0|x\_1)\]+\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})}\]+\\sum\_{t=1}^{T-1}\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_{t}|x\_{t+1})}{q(x\_t|x\_{t-1})}\] \\\\ &=\\mathbb{E}\_{q(x\_{1}|x\_0)}\[logp\_{\\theta}(x\_0|x\_1)\]+\\mathbb{E}\_{q(x\_{T},x\_{T-1}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})}\]+\\sum\_{t=1}^{T-1}\\mathbb{E}\_{q(x\_{t-1},x\_t,x\_{t+1}|x\_0)}\[log\\frac{p\_{\\theta}(x\_{t}|x\_{t+1})}{q(x\_t|x\_{t-1})}\] \\\\ \\end{aligned} \\\]

> \[!NOTE\]
> 
> 1.  \\(\\prod\_{t=2}^Tp\_{\\theta}(x\_{t-1}|x\_t)\\)可以通过**换元法**，改写成\\(\\prod\_{t=1}^{T-1}p\_{\\theta}(x\_{t}|x\_{t+1})\\)；
> 2.  **期望的和 等于 和的期望**；
> 3.  最后一行由于其它变量都没有用上，因此**只保留相关的变量**进行采样；

#### 消除变量

\\\[\\begin{aligned} \\mathbb{E}\_{q(x\_{T},x\_{T-1}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})}\] &= \\iint q(x\_T,x\_{T-1}|x\_0)log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})}dx\_{T-1}dx\_T \\\\ &=\\iint log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})} q(x\_T|x\_{T-1},x\_0)q(x\_{T-1}|x\_0)dx\_{T-1}dx\_T \\\\ &=\\iint log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})} q(x\_T|x\_{T-1})q(x\_{T-1}|x\_0)dx\_{T-1}dx\_T \\\\ &=\\int \[\\int log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})}q(x\_T|x\_{T-1})dx\_T\]q(x\_{T-1}|x\_0)dx\_{T-1} \\\\ &=\\int q(x\_{T-1}|x\_0)\[-D\_{KL}(q(x\_T|x\_{T-1})||p\_{\\theta}(x\_T))\]dx\_{T-1} \\\\ &=\\mathbb{E}\_{q(x\_{T-1}|x\_0)}\[-D\_{KL}(q(x\_T|x\_{T-1})||p\_{\\theta}(x\_T))\] \\end{aligned} \\\]

这里**尤其尤其要注意的是**，**积分顺序非常关键**！

我踩得坑是：

\\\[\\begin{aligned} \\mathbb{E}\_{q(x\_{T},x\_{T-1}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})}\] &= \\iint q(x\_T,x\_{T-1}|x\_0)log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})}dx\_{T-1}dx\_T \\\\ &=\\iint log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})} q(x\_T|x\_{T-1},x\_0)q(x\_{T-1}|x\_0)dx\_{T-1}dx\_T \\\\ &=\\iint log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})} q(x\_T|x\_{T-1})q(x\_{T-1}|x\_0)dx\_{T-1}dx\_T \\\\ &=\\int \[\\int q(x\_{T-1}|x\_0)dx\_{T-1}\]log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})}q(x\_T|x\_{T-1})dx\_T \\\\ &=\\int 1 \\times log\\frac{p\_{\\theta}(x\_T)}{q(x\_T|x\_{T-1})}q(x\_T|x\_{T-1})dx\_T \\\\ &=-D\_{KL}(q(x\_T|x\_{T-1})||p\_{\\theta}(x\_T)) \\end{aligned} \\\]

> \[!important\]
> 
> 1.  \\(\\int p(x\_1|x\_2) dx\_1=1\\)，要看清楚这里是积分，**\\(x\_1\\)是变量，积分完之后\\(x\_1\\)变量就消失了**
> 2.  代入上式，若先把\\(x\_{T-1}\\)当作**变量积分掉的话**，剩下的带有\\(x\_{T-1}\\)**条件概率的积分就无法完成**
> 3.  因此只能**先把\\(x\_T\\)当作变量积分掉**，因为剩下的\\(x\_{T-1}\\)变量**没有\\(x\_T\\)的条件概率**。

同理

\\\[\\begin{aligned} \\mathbb{E}\_{q(x\_{t-1},x\_t,x\_{t+1}|x\_0)}\[log\\frac{p\_{\\theta}(x\_{t}|x\_{t+1})}{q(x\_t|x\_{t-1})}\] &= \\iiint q(x\_{t-1},x\_t,x\_{t+1}|x\_0)log\\frac{p\_{\\theta}(x\_{t}|x\_{t+1})}{q(x\_t|x\_{t-1})}dx\_{t-1}dx\_t dx\_{t+1} \\\\ &=\\iiint q(x\_{t+1},x\_{t-1}|x\_0)q(x\_t|x\_{t-1})log\\frac{p\_{\\theta}(x\_{t}|x\_{t+1})}{q(x\_t|x\_{t-1})}dx\_{t-1}dx\_t dx\_{t+1} \\\\ &=\\iint \[\\int log\\frac{p\_{\\theta}(x\_{t}|x\_{t+1})}{q(x\_t|x\_{t-1})}q(x\_t|x\_{t-1})dx\_t\]q(x\_{t+1},x\_{t-1}|x\_0)dx\_{t-1}dx\_{t+1} \\\\ &=\\iint q(x\_{t+1},x\_{t-1}|x\_0)\[-D\_{KL}(q(x\_t|x\_{t-1})||p\_{\\theta}(x\_{t}|x\_{t+1}))\]dx\_{t-1}dx\_{t+1} \\\\ &=\\mathbb{E}\_{q(x\_{t-1},x\_{t+1}|x\_0)}\[-D\_{KL}(q(x\_t|x\_{t-1})||p\_{\\theta}(x\_{t}|x\_{t+1}))\] \\end{aligned} \\\]

此时有

\\\[\\begin{aligned} logp\_{\\theta}(x)&\\geq\\mathbb{E}\_{q(x\_{1}|x\_0)}\[logp\_{\\theta}(x\_0|x\_1)\]+\\mathbb{E}\_{q(x\_{T-1}|x\_0)}\[-D\_{KL}(q(x\_T|x\_{T-1})||p\_{\\theta}(x\_T))\]+\\mathbb{E}\_{q(x\_{t-1},x\_{t+1}|x\_0)}\[-D\_{KL}(q(x\_t|x\_{t-1})||p\_{\\theta}(x\_{t}|x\_{t+1}))\] \\\\ \\end{aligned} \\\]

![image.png](https://suahi-1311668441.cos.ap-shanghai.myqcloud.com/2024/20250428133426892.png)

这里出现了一个问题，**多元变量求期望方差会很大**，那么能不能通过一些方法**消去部分的变量**呢？

#### 马尔可夫性质贝叶斯

\\\[\\begin{aligned} logp\_{\\theta}(x)&\\geq\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_{0:T})}{q(x\_{1:T}|x\_0)}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)\\prod\_{t=1}^Tp\_{\\theta}(x\_{t-1}|x\_t)}{\\prod\_{t=1}^Tq(x\_t|x\_{t-1})}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)p\_{\\theta}(x\_0|x\_1)\\prod\_{t=2}^Tp\_{\\theta}(x\_{t-1}|x\_t)}{\\prod\_{t=1}^Tq(x\_t|x\_{t-1})}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)p\_{\\theta}(x\_0|x\_1)\\prod\_{t=2}^{T}p\_{\\theta}(x\_{t-1}|x\_{t})}{q(x\_1|x\_0)\\prod\_{t=2}^{T}q(x\_t|x\_{t-1})}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)p\_{\\theta}(x\_0|x\_1)}{q(x\_1|x\_{0})}\]+\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\prod\_{t=2}^{T}\\frac{p\_{\\theta}(x\_{t-1}|x\_{t})}{q(x\_t|x\_{t-1})}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)p\_{\\theta}(x\_0|x\_1)}{q(x\_1|x\_{0})}\]+\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\prod\_{t=2}^{T}\\frac{p\_{\\theta}(x\_{t-1}|x\_{t})}{q(x\_t|x\_{t-1},x\_0)}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)p\_{\\theta}(x\_0|x\_1)}{q(x\_1|x\_{0})}\]+\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\prod\_{t=2}^{T}\\frac{p\_{\\theta}(x\_{t-1}|x\_{t})}{\\frac{q(x\_{t-1}|x\_{t},x\_0)q(x\_t|x\_0)}{q(x\_{t-1}|x\_0)}}\] \\\\ \\end{aligned} \\\]

> \[!NOTE\]
> 
> 1.  由于马尔可夫性质规定：\\(x\_{t}\\)时刻只与\\(x\_{t-1}\\)时刻相关。因此\\(q(x\_t|x\_{t-1},x\_0)=q(x\_t|x\_{t-1})\\)；
> 2.  但是**逆向过程并不满足马尔可夫性质**，即\\(q(x\_{t-1}|x\_{t},x\_0) \\neq q(x\_{t-1}|x\_{t})\\)，因此后文中\\(q(x\_{t-1}|x\_{t},x\_0)\\)中的\\(x\_0\\)一直没有删除；
> 3.  值得注意的是，我们从原理正向推导出发时，直接在逆向非马尔可夫性质条件下在\\(p(x\_{t}|x\_{t-1})\\)中添加\\(x\_0\\)条件，并通过预估\\(\\hat{x\_0}=f(x\_t,t)\\)的形式来消除新增的\\(x\_0\\)条件。上面的思路显得**比较跳跃且难以想象**，通过MLE估计ELBO的推导中，在满足马尔科夫性质下利用\\(q(x\_t|x\_{t-1})=q(x\_t|x\_{t-1},x\_0)\\)公式进行推导显得**更为合理**，**极度怀疑正向推导加\\(x\_0\\)的措施是根据ELBO推导过程的trick来的。**

其中

\\\[\\begin{aligned} \\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\prod\_{t=2}^{T}{\\frac{q(x\_{t-1}|x\_{t},x\_0)q(x\_t|x\_0)}{q(x\_{t-1}|x\_0)}}\] &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\prod\_{t=2}^{T}q(x\_{t-1}|x\_{t},x\_0)\]+\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{\\cancel{q(x\_2|x\_0)}}{q(x\_1|x\_0)}+log\\frac{\\cancel{q(x\_3|x\_1)}}{\\cancel{q(x\_2|x\_0)}}+\\cdots+log\\frac{q(x\_T|x\_0)}{\\cancel{q(x\_{T-1}|x\_0)}}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\prod\_{t=2}^{T}q(x\_{t-1}|x\_{t},x\_0)\]+\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{q(x\_T|x\_0)}{q(x\_{1}|x\_0)}\] \\end{aligned} \\\]

代入原式得

\\\[\\begin{aligned} logp\_{\\theta}(x)&\\geq\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)p\_{\\theta}(x\_0|x\_1)}{q(x\_1|x\_{0})}\]+\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\prod\_{t=2}^{T}\\frac{p\_{\\theta}(x\_{t-1}|x\_{t})}{\\frac{q(x\_{t-1}|x\_{t},x\_0)q(x\_t|x\_0)}{q(x\_{t-1}|x\_0)}}\] \\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)p\_{\\theta}(x\_0|x\_1)}{\\cancel{q(x\_1|x\_{0})}}\]+\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\prod\_{t=2}^{T}\\frac{p\_{\\theta}(x\_{t-1}|x\_{t})}{q(x\_{t-1}|x\_{t},x\_0)}\]+\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{\\cancel{q(x\_1|x\_0)}}{q(x\_{T}|x\_0)}\]\\\\ &=\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)p\_{\\theta}(x\_0|x\_1)}{q(x\_{T}|x\_0)}\]+\\mathbb{E}\_{q(x\_{1:T}|x\_0)}\[\\sum\_{t=2}^{T}log\\frac{p\_{\\theta}(x\_{t-1}|x\_{t})}{q(x\_{t-1}|x\_{t},x\_0)}\]\\\\ &=\\mathbb{E}\_{q(x\_{1}|x\_0)}\[logp\_{\\theta}(x\_0|x\_1)\]+\\mathbb{E}\_{q(x\_{T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)}{q(x\_{T}|x\_0)}\]+\\mathbb{E}\_{q(x\_{t-1},x\_t|x\_0)}\[\\sum\_{t=2}^{T}log\\frac{p\_{\\theta}(x\_{t-1}|x\_{t})}{q(x\_{t-1}|x\_{t},x\_0)}\] \\\\ &=\\mathbb{E}\_{q(x\_{1}|x\_0)}\[logp\_{\\theta}(x\_0|x\_1)\]+\\mathbb{E}\_{q(x\_{T}|x\_0)}\[log\\frac{p\_{\\theta}(x\_T)}{q(x\_{T}|x\_0)}\]+\\sum\_{t=2}^{T}\\mathbb{E}\_{q(x\_{t-1},x\_t|x\_0)}\[log\\frac{p\_{\\theta}(x\_{t-1}|x\_{t})}{q(x\_{t-1}|x\_{t},x\_0)}\] \\\\ &=\\mathbb{E}\_{q(x\_{1}|x\_0)}\[logp\_{\\theta}(x\_0|x\_1)\]-D\_{KL}(q(x\_{T}|x\_0)||p\_{\\theta}(x\_T))+\\sum\_{t=2}^{T}\\mathbb{E}\_{q(x\_{t-1},x\_t|x\_0)}\[log\\frac{p\_{\\theta}(x\_{t-1}|x\_{t})}{q(x\_{t-1}|x\_{t},x\_0)}\] \\end{aligned} \\\]

其中

\\\[\\begin{aligned} \\mathbb{E}\_{q(x\_{t-1},x\_t|x\_0)}\[log\\frac{p\_{\\theta}(x\_{t-1}|x\_{t})}{q(x\_{t-1}|x\_{t},x\_0)}\] &= \\iint q(x\_{t-1},x\_t|x\_0)log\\frac{p\_{\\theta}(x\_{t-1}|x\_{t})}{q(x\_{t-1}|x\_{t},x\_0)}dx\_{t-1}dx\_t \\\\ &=\\iint q(x\_{t-1}|x\_{t},x\_0)q(x\_{t}|x\_{0})log\\frac{p\_{\\theta}(x\_{t-1}|x\_{t})}{q(x\_{t-1}|x\_{t},x\_0)}dx\_{t-1}dx\_t \\\\ &=\\int \[\\int log\\frac{p\_{\\theta}(x\_{t-1}|x\_{t})}{q(x\_{t-1}|x\_{t},x\_0)}q(x\_{t-1}|x\_{t},x\_0)dx\_{t-1}\]q(x\_{t}|x\_0)dx\_{t} \\\\ &=\\mathbb{E}\_{q(x\_{t}|x\_0)}\[-D\_{KL}(q(x\_{t-1}|x\_{t},x\_0)||p\_{\\theta}(x\_{t-1}|x\_{t}))\] \\end{aligned} \\\]

> \[!NOTE\] Title
> 
> 注意上式不能将\\(q(x\_{t-1},x\_t|x\_0)\\)分解为\\(q(x\_t|x\_{t-1})q(x\_{t-1}|x\_0)\\)，因为不管先对\\(x\_{t-1}\\)还是\\(x\_t\\)积分，都会**在后续被积函数中作为条件存在**

至此**利用马尔可夫性质对完成了多元变量的消除**工作：

\\\[\\begin{aligned} logp\_{\\theta}(x)&\\geq\\underbrace{\\mathbb{E}\_{q(x\_{1}|x\_0)}\[logp\_{\\theta}(x\_0|x\_1)\]}\_{重构项}-\\underbrace{D\_{KL}(q(x\_{T}|x\_0)||p\_{\\theta}(x\_T))}\_{正则项}+\\underbrace{\\sum\_{t=2}^{T}\\mathbb{E}\_{q(x\_{t}|x\_0)}\[-D\_{KL}(q(x\_{t-1}|x\_{t},x\_0)||p\_{\\theta}(x\_{t-1}|x\_{t}))\]}\_{去噪匹配项} \\end{aligned} \\\]

也可以看到这里前两项**与VAE具有相同的形式**。

当\\(T=1\\)时，即意味着只有一个潜变量\\(x\_1=z\\)，这时退化到与VAE的ELBO具有**完全相同的表达式**。

#### ELBO解析

\\(\\sum\_{t=2}^{T}\\mathbb{E}\_{q(x\_{t}|x\_0)}\[-D\_{KL}(q(x\_{t-1}|x\_{t},x\_0)||p\_{\\theta}(x\_{t-1}|x\_{t}))\]\\)是ELBO中占比最大的，优先看这个。

其中\\(p\_{\\theta}(x\_{t-1}|x\_{t})\\)是模型参数化的结果，\\(q(x\_{t-1}|x\_{t},x\_0)\\)是模型需要靠近的对象（ground-truth）。

对\[\[001 DDPM-v2#后向生成过程|ground-truth的推导\]\]不再赘述，最终结果为

\\\[q(x\_{t-1}|x\_{t},x\_0) = N(\\frac{1}{\\sqrt{\\alpha\_{t}}}\[x\_{t}-\\frac{\\beta\_{t}}{\\sqrt{\\bar{\\beta}\_{t}}}\\bar{\\epsilon}\_{t}\], \\frac{\\beta\_{t}\\bar{\\beta}\_{t-1}}{\\bar{\\beta}\_{t}}I) \\\]

由于最终模型参数化\\(p\_{\\theta}(x\_{t-1}|x\_{t})\\)是为了接近\\(q(x\_{t-1}|x\_{t},x\_0)\\)，那不妨：

1.  直接使用\\(q(x\_{t-1}|x\_{t},x\_0)\\)的方差：\\(\\frac{\\beta\_{t}\\bar{\\beta}\_{t-1}}{\\bar{\\beta}\_{t}}\\)；
2.  参考\\(q(x\_{t-1}|x\_{t},x\_0)\\)均值的形式去设置预测的变量：\\(\\frac{1}{\\sqrt{\\alpha\_{t}}}\[x\_{t}-\\frac{\\beta\_{t}}{\\sqrt{\\bar{\\beta}\_{t}}}\\bar{\\epsilon}\_{\\theta}\]\\)

代入上述假设，展开\\(D\_{KL}(q(x\_{t-1}|x\_{t},x\_0)||p\_{\\theta}(x\_{t-1}|x\_{t}))\\)

\\\[\\begin{aligned} D\_{KL}(q(x\_{t-1}|x\_{t},x\_0)||p\_{\\theta}(x\_{t-1}|x\_{t})) &= D\_{KL}(N(\\frac{1}{\\sqrt{\\alpha\_{t}}}\[x\_{t}-\\frac{\\beta\_{t}}{\\sqrt{\\bar{\\beta}\_{t}}}\\bar{\\epsilon}\_{t}\], \\frac{\\beta\_{t}\\bar{\\beta}\_{t-1}}{\\bar{\\beta}\_{t}}I)||N(\\frac{1}{\\sqrt{\\alpha\_{t}}}\[x\_{t}-\\frac{\\beta\_{t}}{\\sqrt{\\bar{\\beta}\_{t}}}\\bar{\\epsilon}\_{\\theta}\], \\frac{\\beta\_{t}\\bar{\\beta}\_{t-1}}{\\bar{\\beta}\_{t}}I)) \\\\ \\end{aligned} \\\]

参考

\\\[D\_{KL}(N(\\mu\_1,\\sigma\_1^2I)||N(\\mu\_2,\\sigma\_2^2))=\\log\\frac{\\sigma\_2}{\\sigma\_1}+\\frac{\\sigma\_1^2+(\\mu\_1-\\mu\_2)^2}{2\\sigma\_2^2}-\\frac{1}{2} \\\]

得到最终的值为

\\\[\\begin{aligned} D\_{KL}(q(x\_{t-1}|x\_{t},x\_0)||p\_{\\theta}(x\_{t-1}|x\_{t})) &= \\log\\frac{\\sqrt{\\frac{\\beta\_{t}\\bar{\\beta}\_{t-1}}{\\bar{\\beta}\_{t}}}}{\\sqrt{\\frac{\\beta\_{t}\\bar{\\beta}\_{t-1}}{\\bar{\\beta}\_{t}}}}+\\frac{\\frac{\\beta\_{t}\\bar{\\beta}\_{t-1}}{\\bar{\\beta}\_{t}}+(\\frac{1}{\\sqrt{\\alpha\_{t}}}\[x\_{t}-\\frac{\\beta\_{t}}{\\sqrt{\\bar{\\beta}\_{t}}}\\bar{\\epsilon}\_{t}\]-\\frac{1}{\\sqrt{\\alpha\_{t}}}\[x\_{t}-\\frac{\\beta\_{t}}{\\sqrt{\\bar{\\beta}\_{t}}}\\bar{\\epsilon}\_{\\theta}\])^2}{2\\frac{\\beta\_{t}\\bar{\\beta}\_{t-1}}{\\bar{\\beta}\_{t}}}-\\frac{1}{2} \\\\ &=\\frac{\\beta\_t}{2\\alpha\_t\\bar{\\beta}\_{t-1}}\\Vert \\bar{\\epsilon}\_{\\theta}-\\bar{\\epsilon}\_{t} \\Vert^2 \\end{aligned} \\\]