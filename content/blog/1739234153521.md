---
layout: post
title: '拒绝繁忙！免费使用 deepseek-r1:671B 参数满血模型'
date: "2025-02-11T00:35:53Z"
---
拒绝繁忙！免费使用 deepseek-r1:671B 参数满血模型
=================================

相信大家都已经有体验过deepseek-r1的强大推理能力，由于其网页版本免费使用的原因，用户量激增、同时据传还遭受了大量的网络攻击，这使得过程不是很流程，经常收到类似下图的问题：

![](https://img2024.cnblogs.com/other/626506/202502/626506-20250210112838240-1919047950.png)

同时，API服务也已经暂停充值，之前的余额用完之后暂时也就不用调用了

![](https://img2024.cnblogs.com/other/626506/202502/626506-20250210112838534-129350069.png)

为了更流畅的使用对话或者API服务，我们可以考虑在自己机器上部署deepseek，如何部署以及如何提供API服务，年前DD在[Spring AI + Ollama 实现 deepseek-r1 的API服务和调用](https://spring.didispace.com/article/spring-ai-ollama-deepseek.html)一文中分享过了，感兴趣的小伙伴可以参考一下。

虽然借助类似Ollama这样的工具可以帮我们快速的自己部署deepseek，但是由于我们个人的计算资源有限，在本地无法部署具备671b参数的deepseek-r1满血模型。大部分用户只能部署1.5b或7b参数呃蒸馏小参数版本，这使得本地部署之后，虽然使用不卡顿了，但推理效果大打折扣！

那么是否有方法来低成本的使用671b参数的满血模型呢？有的！下面就给大家介绍一个白嫖的671b参数满血模型的方法！

免费使用deepseek-r1:671B参数满血模型
==========================

1.  先准备一个腾讯云账号，进入腾讯云知识引擎原子能力: [https://console.cloud.tencent.com/lkeap](https://console.cloud.tencent.com/lkeap)

目前该产品的DeepSeek系列模型（包含671B参数的 deepseek-v3 和 deepseek-r1）正在免费限时提供服务：

![](https://img2024.cnblogs.com/other/626506/202502/626506-20250210112838797-206181456.png)

2.  点击“开通大模型知识引擎”

![](https://img2024.cnblogs.com/other/626506/202502/626506-20250210112839151-1115262126.png)

3.  根据自身情况，选择调用方式去获取API KEY。如果自己写代码调用，两个都ok，选择自己喜欢的就行。如果是要对接类似这些Chat类客户端的话就选择OpenAI的API KEY。

![](https://img2024.cnblogs.com/other/626506/202502/626506-20250210112839542-1372183012.png)

**注意：创建完成后，记得保存好！** 后续自己调API或者接入开源工具的时候需要配置使用。

使用OpenAI的SDK调用
==============

如果上面你选择了penai的api key，那么接下来就可以使用OpenAI的SDK去调用deepseek-r1:671B参数的模型了。

参考示例：

    from openai import OpenAI
    
    # 构造 client
    client = OpenAI(
        api_key="sk-xxxxxxxxxxx",  # 知识引擎原子能力 APIKey
        base_url="https://api.lkeap.cloud.tencent.com/v1",
    )
    # 流式
    s_value = True
    # 请求
    chat_completion = client.chat.completions.create(
        model="deepseek-r1",
        messages=[
            {
                "role": "user",
                "content": "你是谁",
            }
        ],
        stream=s_value,
    )
    if s_value:
       for chunk in chat_completion:
           # 打印思维链内容
           if hasattr(chunk.choices[0].delta, 'reasoning_content'):
              print(f"{chunk.choices[0].delta.reasoning_content}", end="")
           # 打印模型最终返回的content
           if hasattr(chunk.choices[0].delta, 'content'):
              if chunk.choices[0].delta.content != None and len(chunk.choices[0].delta.content) != 0:
                 print(chunk.choices[0].delta.content, end="")
    else:
       result = chat_completion.choices[0].message.content
    

使用Chat类客户端调用
============

在拿到API KEY之后，就可以使用Chat类客户端去调用deepseek-r1:671B参数的模型了。

配置方法都差不多，主要几个关键元素：

1.  使用OpenAI的API调用方式
2.  填入上面获取到的API KEY和腾讯云的API地址：`https://api.lkeap.cloud.tencent.com/v1`
3.  使用deepseek的模型名，比如：`deepseek-r1`、`deepseek-v3`

![](https://img2024.cnblogs.com/other/626506/202502/626506-20250210112839865-843303844.png)

小结
==

如果你最近对DeepSeek的使用需求较大，官方又经常服务繁忙的话，不妨尝试一下这种使用方式。目前这个入口可以免费使用到2025年2月25日23:59:59，后续付费价格也不贵，可以考虑可以长期使用或者当作官方的备用。

![](https://img2024.cnblogs.com/other/626506/202502/626506-20250210112840118-1223705705.png)

> 欢迎关注我的公众号：程序猿DD。第一时间了解前沿行业消息、分享深度技术干货、获取优质学习资源