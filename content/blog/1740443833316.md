---
layout: post
title: '2 本地部署DeepSeek模型构建本地知识库+联网搜索详细步骤'
date: "2025-02-25T00:37:13Z"
---
2 本地部署DeepSeek模型构建本地知识库+联网搜索详细步骤
================================

在[1 使用ollama完成DeepSeek本地部署](https://www.cnblogs.com/ranjiang/p/18725581)中使用ollama完成deepSeek的本地部署和运行，此时我可以在PowerShell中通过对话的方式与DeepSeek交流，但此时本地模型不具备联网搜索能力，无法根据网上信息来回答我的问题，同时我也无法将我自己的知识给他参考，这样本地模型相比直接使用官网的访问接口没有任何优势，接下来我需要做两件事情，来发挥出本地模型的优势：  
（1）建立本地知识库，然后将我自己的资料和数据文件放入知识库中，让模型在回答问题是可以参考我本地知识来组织答案；这可以在避免私人数据泄露的同时让模型变成了自己的专有模型，根据知识库的内容实现定向知识领域应用。  
（2）通过第三方工具或脚本实现本地模型的联网搜索能力，这样本地模型就能够完全具备官网接口的能力，且本地模型搜索时不会受平台接口搜过内容过滤的限制。  
总结网上的实现方案，当前有两种比较有意义的部署方案：  
（1）方案一ollama+anythingLLM：开源模型本地部署+本地知识库构建，完全离线运行，适合不需要联网完全本地运行的场景；  
（2）方案二ollama+浏览器Page Assist插件：开源模型本地部署+本地知识库构建+联网搜索功能，适合需要联网搜索的场景。

1 方案一：使用anythingLLM实现本地知识库构建
============================

安装anythingLLM有两种方式，一种是直接安装桌面版，一种是通过Docker安装；第一种方式安装方便，已经能满足一般用户的使用要求，但安装过程中需要下载库和相关依赖，由于下载速度很慢这个过程十分漫长（可以考虑自己上点□□上网手段），我等待了应该有三四个小时；第二种方式相比于第一种方式功能更多一些，支持多用户访问、嵌入聊天部件、密码保护和用户管理且方便移植，且docker安装anythingLLM可以更换国内镜像源，安装速度要快一些。

1.1 安装anythingLLM桌面版
--------------------

下载地址：[https://anythingllm.com/desktop](https://anythingllm.com/desktop)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250222012750925-980314010.png)  
双击安装包选择自己的安装位置即可安装，保持联网状态，等待自动下载相关依赖和库就可以；  
软件介绍和使用说明可以参考官网：[https://docs.anythingllm.com/introduction](https://docs.anythingllm.com/introduction)

1.2 通过Docker安装anythingLLM
-------------------------

Docker是一种虚拟化的容器技术，能够实现运行环境与运行设备基础架构的隔离，允许用户将应用和依赖打包部署在一个可移植的容器内，在任何支持Docker的环境中运行，方便移植和部署。  
（1）去docker官网可以下载Docker安装包：[https://www.docker.com](https://www.docker.com)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250221235932998-1404446907.png)  
双击安装程序，勾选使用WSL 2代替Hyper-V，点击OK等待安装完成。  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250222000111863-1234297334.png)  
安装完成后需要重启电脑。  
（2）运行docker，若运行失败，可以打开PowerShell，更新一下wsl版本：输入`wsl --update`，若仍然失败，重装一下docker。  
Docker说明：  
（A） Docker是依赖Linux环境的，无法直接在Windows系统上运行，所以通过WSL2和Hypera-V可以搭建Docker所需的虚拟运行环境；  
（B）WSL2是一个轻量级的虚拟化技术，底层利用Hyper-V技术运行了Linux内核来提供完整的调用，无需模拟整个硬件环境，资源占用少，WSL2更适合那些需要在Windows上便捷地使用Linux环境的用户；  
（C）Hyper-V是一个全面完整的虚拟化技术和虚拟机管理器，模拟了整个Linux的硬件环境，支持运行独立的操作系统，则适用于需要完整虚拟化功能的场景；  
（D）我仅需一个Linux环境运行Docker，所以选择WSL2，节约硬件资源。  
（3）打开Docker软件，点击右上角设置，再点击Docker Engine，并添加国内镜像源，然后点击左下角的Apply&Restart；

    "registry-mirrors": [
        "https://docker.m.daocloud.io/",
        "https://huecker.io/",
        "https://dockerhub.timeweb.cloud",
        "https://noohub.ru/",
        "https://dockerproxy.com",
        "https://docker.mirrors.ustc.edu.cn",
        "https://docker.nju.edu.cn",
        "https://xx4bwyg2.mirror.aliyuncs.com",
        "http://f1361db2.m.daocloud.io",
        "https://registry.docker-cn.com",
        "http://hub-mirror.c.163.com"
      ]
    

![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224231307397-279507034.png)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224232121639-1815073471.png)  
（4）点击右下角的Terminal或者通过cmd运行PowerShell，然后输入命令`docker pull mintplexlabs/anythingllm`下载anythingllm；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224232225341-1563302759.png)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224232525583-1346027368.png)  
（5）下载完成后再Termical或PowerShell中输入一下代码并运行即可将anythingLLM运行起来；

    $env:STORAGE_LOCATION="$HOME\Documents\anythingllm"; `
    If(!(Test-Path $env:STORAGE_LOCATION)) {New-Item $env:STORAGE_LOCATION -ItemType Directory}; `
    If(!(Test-Path "$env:STORAGE_LOCATION\.env")) {New-Item "$env:STORAGE_LOCATION\.env" -ItemType File}; `
    docker run -d -p 3001:3001 `
    --cap-add SYS_ADMIN `
    -v "$env:STORAGE_LOCATION`:/app/server/storage" `
    -v "$env:STORAGE_LOCATION\.env:/app/server/.env" `
    -e STORAGE_DIR="/app/server/storage" `
    mintplexlabs/anythingllm;
    

![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225014632040-1979618153.png)  
点击端口3001:3001或在浏览器访问http://localhost:3001/ 即可进入anythingLLM界面。

1.3 anythingLLM配置本地知识库——基于桌面版
-----------------------------

### 1.3.1 将ollama serve运行起来

WIN+R快捷键，输入cmd打开PowerShell，输入`ollama serve`可以将ollama运行起来，默认ollama可以通过本地的11434端口访问，新开一个PowerShell窗口输入`curl http://localhost:11434`可以验证。  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250223002758946-1822092531.png)

1.3.2 配置本地anythingLLM
---------------------

运行anythingLLM软件，第一次运行会有一些提示，可以全部跳过，进入如下界面，点击下方的设置可以配置自己的模型。  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250223014047464-1204000994.png)  
（1）首先点击LLM首选项，选择自己的模型提供商为ollama，然后在下方Ollama Base URL处填上ollama的访问地址：[http://127.0.0.1:11434](http://127.0.0.1:11434) ，Ollama Keep Alive选择Forever使模型一直保持激活状态；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250223015658569-1469413238.png)  
（2）向量数据库用于存储自己知识库转化得到的模型可识别的向量数据，使用默认的LanceDB即可；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250223015354368-656624032.png)  
（3）先打开PowerShell输入`ollama pull nomic-embed-text`下载文本嵌入模型用于将文本转化为向量以及进行相似度计算；在anythingLLM设置的Embedder首选项中选择Ollama并选择刚刚下载的模型，然后保存更改；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225005424241-394072191.png)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225011552467-2095114473.png)  
（4）返回聊天界面新建工作区，并点击上传文件；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225012122251-665580924.png)  
（5）上传要放入知识库中的文件，然后选中并点击Move to Workspace，将文件导入工作空间，然后下划到工作空间，点击Save and Embeded；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225012348209-637582862.png)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225012738928-1296994642.png)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225010559835-1991696510.png)  
（6）嵌入完成后点击pin to workspace即可返回聊天界面，此时向模型提问deepseek即可根据知识库中的知识进行回答。  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225012846286-1640748709.png)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225013152728-1611859672.png)

2 方案二：使用Page Assist插件实现本地知识库构建+联网搜索
===================================

2.1 安装浏览器
---------

已知Firefox和Chrome浏览器都支持Page Assist插件，edge暂不支持，我测试了火狐浏览器安装Page Assist，火狐浏览器可以去官网下载：[https://www.firefox.com.cn/](https://www.firefox.com.cn/) 。

2.2 安装Page Assist插件
-------------------

（1）打开火狐浏览器，点击右上角拓展——管理拓展；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224221721236-292192799.png)  
（2）搜索Page Assist，出来的第一个就是，点击添加等待下载完成会弹窗询问是否添加Page Assist，选择添加；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224211143876-1507445686.png)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224223119236-553634252.png)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224224329992-1474817443.png)

2.3 接入本地模型
----------

（1）在配置Page Assist之前先在PowerShell中输入`ollama serve`将ollama运行起来；  
（2）点击拓展中的Page Assist插件进入Page Assist界面，点击右上角设置，先在一般设置里将语言设置为简体中文，ollama设置中已经默认配置好ollama的默认端口，无需更改；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224233738436-523529004.png)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224234042869-2051932350.png)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224235758027-974082609.png)  
（3）返回聊天界面，在顶部选择你本地部署的模型，此时即可与本地模型进行对话；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250224235549536-1048046212.png)

2.4 开启本地模型联网搜索功能
----------------

打开左下角的联网功能，即可开启模型的联网搜索功能，本地模型可以根据搜索到的信息来回答我的提问；在一般设置里的管理网络设置中，可以设置使用的搜索引擎和搜索的结果数；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225000804349-184682542.png)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225001111095-1322318459.png)

2.5 配置本地知识库
-----------

![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225004606984-1089557290.png)  
（1）首先打开PowerShell输入`ollama pull nomic-embed-text`下载文本嵌入模型用于将文本转化为向量以及进行相似度计算；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225005424241-394072191.png)  
（2）在Page Assist设置——RAG设置中选择刚刚安装的nomic-embed-text模型并保存；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225005536905-1525828075.png)  
（3）在管理知识中点添加新知识，为新知识起一个标题，然后将需要放入知识库的文档拖入并提交；  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225010051117-2026382387.png)  
（4）返回聊天界面，在输入窗中选择知识库，然后提问知识库中的相关知识，模型即可根据本地知识库进行回答。  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250225010656087-827822952.png)