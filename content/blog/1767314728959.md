---
layout: post
title: '论文解读：EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language Models'
date: "2026-01-02T00:45:28Z"
---
论文解读：EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language Models
===================================================================================

EasyEdit2——即插即用的LLM行为控制（Steering）框架：

1、支持广泛的测试时干预，包括安全性、情绪、个性、推理模式、事实性和语言特征。

2、关键模块：**转向向量生成器**和**转向向量应用器**。

论文发表于EMNLP 2025 System Demonstrations，Arxiv链接：[https://arxiv.org/abs/2504.15133v3](https://arxiv.org/abs/2504.15133v3)。

干预场景
====

如图2所示。

1.  **安全性**：防止模型生成有害内容，如破解行为、减少偏见、拒绝不安全的查询、确保遵守法规，并减少隐私泄露的风险。
    
2.  **情感**：控制模型输出的情感色彩，将情感从负面调整为正面，特别是在心理健康等领域中保持支持性的语气。
    
3.  **个性**：探索不同个性如何影响模型行为，增强角色扮演的能力，并塑造模型所表现的内在价值观。
    
4.  **推理模式**：调整推理的长度和风格，鼓励更加深思熟虑的思考，并根据不同领域的需求强制执行结构化的推理模式。
    
5.  **事实性**：干预模型的事实知识，处理幻觉现象，支持知识编辑，并提高模型的自我验证能力。
    
6.  **语言特征**：控制输出语言的使用，包括格式、句法结构、风格变化以及对单词层次的调整。
    

框架结构
====

如图3所示。

**转向向量生成器（BaseVectorGenerator）：**可调用各种干预方法，在数据集上迭代生成转向向量。生成的向量可直接应用，或保存本地。

**转向向量应用模块（BaseVectorApplier）：**可同时用多种方法将转向向量集成到目标模型，如基于提示、基于激活和基于解码等。

**模型包装器：**保留并集成多个转向向量以及用户提示，简化转向，增强模型行为控制。转向干预后，提供了两种操作模式：

*   返回修改后的模型以供立即、低代码使用；
    
*   根据配置设置、评估数据集生成评估文件。
    

对于评估，我们提供了Evaluators模块，该模块集成了基于规则、基于分类器和基于LLM的方法，以支持不同的场景。基于LLM的方法进一步实现了自适应和用户定义的场景评估。所有模块都利用Hparams模块进行灵活一致的配置。

**转向向量库与合并：**

*   导向矢量库：维护了一个针对各种场景优化的转向向量库，包括情绪控制、安全对齐等。用户能直接应用。
    
*   转向向量合并模块：可组合多个转向向量，结合多种合并策略，包括Linear、TIES和DARE-TIES。
    

**两层超参管理：**

*   一层：管理通用设置、向量生成、向量应用和评估参数的统一配置文件，整个框架使用此配置运行。
    
*   二层：转向方法的超参文件，包含转向向量生成和应用两个配置。继承自公共基类HyperParams。
    

**数据集模块（DatasetLoader）：**统一评估数据集格式，根据配置加载和预处理数据。

**评估器模块：**基于配置在各种数据集上评估干预后模型的生成质量。评估方法分为基于规则、基于分类器和基于LLM。支持利用强LLM（如GPT-4）处理复杂的转向概念：用户指定要评估的转向概念，并使用预设模板对输入进行格式化。然后计算评估指标（概念相关性、教学相关性和流畅性得分等）。

实验
==

表1：6个评估场景样例。

表2：各干预、融合方法在安全、和情感任务上的性能对比。发现同时控制安全和情感的融合向量有更好的表现。

重要对比方法
======

单干预方法：CAA、STA、LM-Steer、Prompt-auto

干预融合方法：TIES、DARE-TIES