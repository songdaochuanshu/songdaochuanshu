---
layout: post
title: '如何在啥也不懂的情况下将你的公众号接入DeepSeek或其它大模型'
date: "2025-02-17T00:38:28Z"
---
如何在啥也不懂的情况下将你的公众号接入DeepSeek或其它大模型
=================================

![如何在啥也不懂的情况下将你的公众号接入DeepSeek或其它大模型](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216131332299-575925281.png) 本文详细介绍了零基础用户如何借助AI工具将微信公众号接入DeepSeek等大模型实现智能回复的全流程。首先通过AI问答确定开源项目chatgpt-on-wechat，利用豆包AI分析项目结构后选择Docker部署方案。重点讲解了在Ubuntu系统配置国内镜像安装Docker、编写含中文注释的docker-compose配置文件（需设置DeepSeek API密钥、微信公众号Token/AppID等关键参数），并解决部署中出现的Python版本冲突、端口映射缺失、环境变量配置错误等典型问题。通过实时交互AI调试日志报错，最终完成服务器验证与消息收发测试。文章还提供了关注自动回复、记忆清除等扩展功能的配置方法，强调通过灵活修改API参数即可适配其他大模型，展现了AI时代"技术小白"借助智能工具快速实现复杂技术落地的可能性。

前言
--

最近国产大模型的"顶流"DeepSeek可谓是红得发紫，朋友圈刷屏的AI神回复、公众号爆款推文，都少不了它的身影。

可当我们兴冲冲跑去官网体验时，却迎面撞上服务器被挤爆的盛况——问就服务器繁忙，请稍后再试，真是令人头大。

![运行繁忙截图](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216130633975-1443679082.png)

那么能不能将 DeepSeek 接入到自己的公众号，实现自动回复消息功能呢。

转折有点突兀是把，不要怀疑，这前言也是AI写的😂

但是估计是提示词没写好，就这样吧

下面内容默认你已经注册好了一个公众号和一个云服务器，如果你不知道如何购买云服务器，你可以像我一样问AI

实现
--

### 一、了解什么项目可以实现这个功能

假如我们现在啥也不会，第一步应该怎么干？

当然是先找个能联网的AI问了

    我想要将deepseek r1模型接入到我的微信公众号内，实现ai自动回复消息，有没有什么开源项目可以实现这个功能
    

![找AI问](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216130706584-1225892152.png)

好，现在我们知道了有这样一个开源项目 chatgpt-on-wechat 可以实现这个功能，然后我们就可以去GitHub搜索这个项目，找到这个项目的主页：[https://github.com/zhayujie/chatgpt-on-wechat](https://github.com/zhayujie/chatgpt-on-wechat)

### 二、了解 chatgpt-on-wechat 这个项目

既然知道了 chatgpt-on-wechat 这个项目，我们就先了解一下这个项目

一般情况下，一个开源项目的主页会展示一篇 README，来介绍这个项目实现的功能和如何部署，正常流程是我们应该来仔细阅读一下这个项目的 README，但是AI时代，这个坏习惯该改一改了，开个玩笑，该看还得看，后面微信公众号后台配置部分还是得看文档😂

![cow主页](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216130748952-441665307.png)

豆包在AI编程部分提供了引入GitHub仓库的功能，这时候我们只需要将chatgpt-on-wechat 这个项目交给豆包，他就能简单高效的帮你分析这个项目

![引入仓库](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216130857051-1609484683.png)

然后我们就等AI的分析结果就好

![1](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216130810735-1711565073.png)

这时候就直接问豆包

    我想要快速简单的部署这个项目，请帮我介绍一下最简单方便的方法
    

这时候豆包应该会给你提供几种部署方案

然后我们再接着问

    还有更简单的方式吗，文档中有没有对这几种部署方式介绍优劣，你能帮我列个表格分析一下，然后推荐出最好用的哪种部署方式吗
    

![2](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216130952430-1963702800.png)

可以看到这个项目提供了一键安装启动脚本，那么我们就先用这个一键安装启动脚本来试一下

![一键安装脚本](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216131013099-1053805994.png)

好，出问题了，因为操作系统版本太高和 Python 版本不匹配没法运行，所以我们需要切换AI推荐的第二种部署方式 Docker

### 三、Docker 部署项目

#### 1、安装 docker

接着我们就问 AI

    用docker部署这个项目应该如何操作
    

这时候 AI 应该就会告诉你要先安装 docker 及 docker-compose。安装成功的表现是执行 docker -v 和 docker-compose version（或 docker compose version）可以查看到版本号。

身为一个啥也不会的小白，肯定不知道 docker 及 docker-compose 和怎么安装啊

所以就需要接着问 AI

    docker 及 docker-compose 应该怎么安装啊
    

AI 应该会给你一个具体的安装流程，但是当你跟着 AI 给的流程应该有 80% 的可能性安装失败，因为 docker 官方服务器在国内访问有些问题

所以正确操作应该是问 AI

    我是Ubuntu24的操作系统，因为网络连接问题没法添加 Docker 的官方 GPG 密钥，请给我使用国内镜像安装docker的流程
    

这里涉及到一个使用大模型的技巧，就是你给AI的提示词一定要详细，这样大模型的返回结果才能足够精准

另外还有一个问题，就是你可能不知道是网络的原因，这时候应该怎么做？

很简单，你就把安装失败的报错信息发给 AI，AI应该就会告诉你是什么原因以及解决方案的。

![国内镜像](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216131030407-189311192.png)

安装好 docker 及 docker-compose 后，我们就可以返回前面 AI 介绍的 docker 部署chatgpt-on-wechat 部分内容

查看后面的步骤

#### 2、编写 docker-compose.yml

AI提到我们可以下载 docker-compose.yml 这个配置文件，修改后运行

![下载docker-compose.yml](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216131051894-1296468948.png)

但是我们是一个小白，不知道怎么修改 docker-compose.yml 文件

这时候就可以直接让 AI 帮我们生成一个 docker-compose.yml 配置文件

    根据这个开源项目，帮我生成一个使用docker部署的docker-compose.yml文件，要求如下采用 Deepseek 的 API 作为接入模型，然后我想要接入微信公众号，要有微信公众号相关配置，生成的docker-compose.yml每行应该有中文注释，方便我修改学习
    

这时 AI 应该会生成下面这样一个配置文件

    version: '2.0'  # 指定 docker-compose 文件的版本
    services:  # 定义服务列表
      chatgpt-on-wechat:  # 服务名称
        image: zhayujie/chatgpt-on-wechat  # 使用的 Docker 镜像
        container_name: chatgpt-on-wechat  # 容器的名称
        security_opt:  # 安全选项
          - seccomp:unconfined  # 不限制容器的 seccomp 配置
        environment:  # 环境变量配置
          TZ: 'Asia/Shanghai'  # 时区设置为亚洲/上海
          OPEN_AI_API_KEY: 'YOUR_DEEPSEEK_API_KEY'  # Deepseek 的 API Key，需要替换为实际的 Key
          MODEL: 'Deepseek Model'  # 模型名称，这里应根据 Deepseek 实际模型名修改
          PROXY: ''  # 代理设置，默认为空
          SINGLE_CHAT_PREFIX: '["bot", "@bot"]'  # 单聊前缀
          SINGLE_CHAT_REPLY_PREFIX: '"[bot] "'  # 单聊回复前缀
          GROUP_CHAT_PREFIX: '["@bot"]'  # 群聊前缀
          GROUP_NAME_WHITE_LIST: '["ChatGPT测试群", "ChatGPT测试群2"]'  # 群名称白名单
          IMAGE_CREATE_PREFIX: '["画", "看", "找"]'  # 图片创建前缀
          CONVERSATION_MAX_TOKENS: 1000  # 对话最大令牌数
          SPEECH_RECOGNITION: 'False'  # 语音识别开关，默认为关闭
          CHARACTER_DESC: '你是基于 Deepseek 模型的助手，能够回答各种问题。'  # 角色描述
          EXPIRES_IN_SECONDS: 3600  # 过期时间，单位为秒
          USE_GLOBAL_PLUGIN_CONFIG: 'True'  # 是否使用全局插件配置
          USE_LINKAI: 'False'  # 是否使用 LinkAI，默认为关闭
          LINKAI_API_KEY: ''  # LinkAI 的 API Key，默认为空
          LINKAI_APP_CODE: ''  # LinkAI 的应用代码，默认为空
          # 以下为微信公众号相关配置
          CHANNEL_TYPE: 'wechatmp'  # 通道类型设置为微信公众号
          WECHATMP_TOKEN: 'YOUR_WECHATMP_TOKEN'  # 微信公众平台的 Token，需要替换为实际的 Token
          WECHATMP_PORT: 8080  # 微信公众平台的端口，需要端口转发到 80 或 443
          WECHATMP_APP_ID: 'YOUR_WECHATMP_APP_ID'  # 微信公众平台的 appID，需要替换为实际的 appID
          WECHATMP_APP_SECRET: 'YOUR_WECHATMP_APP_SECRET'  # 微信公众平台的 appsecret，需要替换为实际的 appsecret
          WECHATMP_AES_KEY: ''  # 微信公众平台的 EncodingAESKey，加密模式需要，默认为空
    

我们先简单看一下，AI生成的配置文件有没有什么问题

有微信公众号相关配置，也有 Deepseek 的 API 配置，看着好像没啥问题

我们先假设这个配置文件没有问题，那剩下的就是修改这份配置文件，将为微信公众号相关配置和deepseek相关配置修改为自己的

要修改这些信息，我们就要先去获得这些配置需要的数据

### 四、获取公众号配置与 DeepSeek API

#### 1、获取公众号配置

登录微信公众号后台

选择设置与开发，开发接口管理

生成开发者密码，配置IP白名单为你服务器地址

然后修改服务器配置

其中 Token 和 EncodingAESKey 均为自己填写，并不是微信服务器生成的，所以你可以自己设置一个

          CHANNEL_TYPE: "wechatmp"  # 如果通过了微信认证，将"wechatmp"替换为"wechatmp_service"，可极大的优化使用体验
          WECHATMP_TOKEN: ""  # 微信公众平台的Token，需要替换为你自己的
          WECHATMP_PORT: 80  # 微信公众平台的端口，需要端口转发到80或443
          WECHATMP_APP_ID: "wx0 3e5cb6"  # 微信公众平台的appID，需要替换为你自己的
          WECHATMP_APP_SECRET: "202********31"  # 微信公众平台的appsecret，需要替换为你自己的
          WECHATMP_AES_KEY: "*************"  # 微信公众平台的EncodingAESKey，加密模式需要，如有则替换
    

可以参照官网这部分内容进行配置：[https://docs.link-ai.tech/cow/multi-platform/wechat-mp](https://docs.link-ai.tech/cow/multi-platform/wechat-mp)

![微信公众号配置](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216131120086-502103734.png)

填写完这些配置后先不要提交，因为微信会用这些信息去验证你 chatgpt-on-wechat 项目的部署情况

如果你在服务器上还没有部署好这个项目，提交是不会通过的

#### 2、 DeepSeek API 配置

在 DeepSeek 官网右上角，有一个 API 开放平台 [https://platform.deepseek.com/usage](https://platform.deepseek.com/usage)

登陆后点进去 选择 API keys，创建 API Key

将生成的那串 API key 填写到配置文件 `OPEN_AI_API_KEY: 'YOUR_DEEPSEEK_API_KEY' # Deepseek 的 API Key，需要替换为实际的 Key`部分

模型名称点接口文档获取：[https://api-docs.deepseek.com/zh-cn/](https://api-docs.deepseek.com/zh-cn/)

![](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216131142485-1112857574.png)

可以看到 `deepseek-reasoner` 就是最新的 DeepSeek R1 模型

所以 `MODEL: 'deepseek-reasoner' # 模型名称，这里应根据 Deepseek 实际模型名修改` 这里就填 `deepseek-reasoner`

但是我们看到 DeepSeek 文档里面写道还需要修改 base\_url ，但是我们的配置文件里面没有修改 base\_url 的选项，这时候就需要接着问一下 AI 了

    docker-compose.yml中，修改openapi的base_url 环境变量是哪个
    

然后你就能知道上面的配置文件少了一个 `OPEN_AI_API_BASE` 的配置项

并且这个配置项的值为 `https://api.deepseek.com/v1`

          OPEN_AI_API_KEY: 'YOUR_DEEPSEEK_API_KEY'  # Deepseek 的 API Key，需要替换为实际的 Key
          MODEL: 'deepseek-reasoner'  # 模型名称，这里应根据 Deepseek 实际模型名修改
          OPEN_AI_API_BASE: 'https://api.deepseek.com/v1'
    

### 五、运行 chatgpt-on-wechat

#### 1、运行镜像

修改好 docker-compose.yml 文件后，我们应该就可以运行这个项目了

在你的服务器上新建一个文件夹，名称就叫 wechat 吧

    mkdir wechat
    

进入文件夹

    cd wechat
    

将 docker-compose.yml 上传到 wechat 下

然后执行

    sudo docker compose up -d
    

这里涉及到的 Linux 命令我就不介绍了，有兴趣的可以直接问 AI

等待镜像加载完成，出现下面的字符

     Container chatgpt-on-wechat  Started 
    

就表示镜像已经成功运行

#### 2、返回微信公众号，提交服务器配置

如果镜像运行没有问题，那么我们点击提交应该会正常保存服务器信息

但是现在会出现错误

出现这个原因的问题是第一次 AI 给我们的 docker-compose.yml 配置文件缺少了一个配置

这时候我们就得接着问 AI

    我按照你给的 docker-compose.yml 启动了容器，但是无法正常访问，请仔细检查看docker-compose.yml是不是缺少了什么配置
    

然后 AI 就会告诉你缺少了端口映射的配置

        ports:
          - "80:80"  # 假设服务监听 8080 端口，将主机的 8080 端口映射到容器的 8080 端口
    

接下来将上面这条配置项增加上去，删除上一个容器，重新启动新的容器镜像

    # 查看当前运行镜像
    sudo docker ps -a
    # 停止运行 chatgpt-on-wechat 镜像
    # 5a92cab89ef5 为容器的 CONTAINER ID
    sudo docker stop 5a92cab89ef5
    # 删除镜像
    sudo docker rm 5a92cab89ef5
    # 重新启动
    sudo docker compose up -d
    

如果没啥问题，浏览器直接访问 [http://ip/wx](http://ip/wx) 应该会出现下面的界面

![](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216131209669-547219675.png)

最后再次返回微信公众号，提交服务器配置，应该就能正常保存配置信息了

保存后返回，点击启用，启用服务器配置

### 六、发送消息测试

服务器执行

    sudo docker logs -f chatgpt-on-wechat
    

打开日志窗口查看日志

然后手机点开你的公众号，给他发送一条消息

![](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216131221484-864596373.png)

虽然服务器可以收到消息，但是没法返回消息，并且出现了下面的报错

    [ERROR][2025-02-14 10:32:41][wechatmp_channel.py:301] - [wechatmp] Fail to generate reply to user, msgId=24904067473459103, exception=str expected, not NoneType
    Traceback (most recent call last):
      File "/usr/local/lib/python3.10/concurrent/futures/thread.py", line 58, in run
        result = self.fn(*self.args, **self.kwargs)
      File "/app/channel/chat_channel.py", line 170, in _handle
        reply = self._generate_reply(context)
      File "/app/channel/chat_channel.py", line 182, in _generate_reply
        e_context = PluginManager().emit_event(
      File "/app/plugins/plugin_manager.py", line 196, in emit_event
        instance.handlers[e_context.event](e_context, *args, **kwargs)
      File "/app/plugins/role/role.py", line 105, in on_handle_context
        bot = Bridge().get_bot("chat")
      File "/app/bridge/bridge.py", line 74, in get_bot
        self.bots[typename] = create_bot(self.btype[typename])
      File "/app/bot/bot_factory.py", line 54, in create_bot
        return DashscopeBot()
      File "/app/bot/dashscope/dashscope_bot.py", line 29, in __init__
        os.environ["DASHSCOPE_API_KEY"] = self.api_key
      File "/usr/local/lib/python3.10/os.py", line 685, in __setitem__
        value = self.encodevalue(value)
      File "/usr/local/lib/python3.10/os.py", line 757, in encode
        raise TypeError("str expected, not %s" % type(value).__name__)
    TypeError: str expected, not NoneType
    172.20.0.1:44044 - - [14/Feb/2025 10:32:41] "HTTP/1.1 POST /wx" - 200 OK
    [INFO][2025-02-14 10:32:58][passive_reply.py:97] - [wechatmp] Request 1 from oz1No1cH-6Uafl_f0916bp7ZvGPY 24904067723857883 172.20.0.1:44160
    1
    [INFO][2025-02-14 10:32:58][bridge.py:68] - create bot dashscope for chat
    [ERROR][2025-02-14 10:32:58][wechatmp_channel.py:301] - [wechatmp] Fail to generate reply to user, msgId=24904067723857883, exception=str expected, not NoneType
    Traceback (most recent call last):
      File "/usr/local/lib/python3.10/concurrent/futures/thread.py", line 58, in run
        result = self.fn(*self.args, **self.kwargs)
      File "/app/channel/chat_channel.py", line 170, in _handle
        reply = self._generate_reply(context)
      File "/app/channel/chat_channel.py", line 182, in _generate_reply
        e_context = PluginManager().emit_event(
      File "/app/plugins/plugin_manager.py", line 196, in emit_event
        instance.handlers[e_context.event](e_context, *args, **kwargs)
      File "/app/plugins/role/role.py", line 105, in on_handle_context
        bot = Bridge().get_bot("chat")
      File "/app/bridge/bridge.py", line 74, in get_bot
        self.bots[typename] = create_bot(self.btype[typename])
      File "/app/bot/bot_factory.py", line 54, in create_bot
        return DashscopeBot()
      File "/app/bot/dashscope/dashscope_bot.py", line 29, in __init__
        os.environ["DASHSCOPE_API_KEY"] = self.api_key
      File "/usr/local/lib/python3.10/os.py", line 685, in __setitem__
        value = self.encodevalue(value)
      File "/usr/local/lib/python3.10/os.py", line 757, in encode
        raise TypeError("str expected, not %s" % type(value).__name__)
    TypeError: str expected, not NoneType
    172.20.0.1:44160 - - [14/Feb/2025 10:32:58] "HTTP/1.1 POST /wx" - 200 OK
    

如何解决呢，很简单，复制错误信息给 AI

![](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216131237379-1568009308.png)

AI 就会告诉你是因为缺少环境变量 `DASHSCOPE_API_KEY`

所以我们需要接着修改 docker-compose.yml 文件，增加 `DASHSCOPE_API_KEY` 配置

这个值与 DeepSeek API 保持一致

          OPEN_AI_API_KEY: 'YOUR_DEEPSEEK_API_KEY'  # Deepseek 的 API Key，需要替换为实际的 Key
          MODEL: 'deepseek-reasoner'  # 模型名称，这里应根据 Deepseek 实际模型名修改
          OPEN_AI_API_BASE: 'https://api.deepseek.com/v1'
          DASHSCOPE_API_KEY: 'YOUR_DEEPSEEK_API_KEY'
    

删除镜像后重新启动容器，这是再发送消息，应该在手机上就能看到回复了

![](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216131251664-85042267.jpg)

服务器端数据

![](https://img2024.cnblogs.com/blog/1829014/202502/1829014-20250216131302708-1560757817.png)

至此，借助 AI，我们成功的将公众号接入了 DeepSeek 大模型

### 七、接入其它大模型

接入其它大模型流程与 DeepSeek 相同，只需要将

          OPEN_AI_API_KEY: 'YOUR_DEEPSEEK_API_KEY'  # Deepseek 的 API Key，需要替换为实际的 Key
          MODEL: 'deepseek-reasoner'  # 模型名称，这里应根据 Deepseek 实际模型名修改
          OPEN_AI_API_BASE: 'https://api.deepseek.com/v1'
          DASHSCOPE_API_KEY: 'YOUR_DEEPSEEK_API_KEY'
    

这部分配置修改为其它大模型的即可

### 八、其它配置项

我们想实现当用户关注后自动回复一条消息，这个应该怎么修改

很简单，在 docker-compose.yml 文件中新增一条配置项目即可

          "subscribe_msg": "感谢您关注不挂高数！\n分享日常和碰到的技术问题，包括但不限于Java，Spring，Vue，Python，C#什么的。反正和高数没啥关系，至于为什么叫这个名字，那是因为我上大学那会，高数挂了，博客：buguagaoshu.com\n至于网课答案，你可以将题目复制粘贴到对话框，AI会给你答案\n如果需要清除聊天记忆，请回复：#清除记忆"
    

完整配置参考
------

    version: '2.0'
    services:
      chatgpt-on-wechat:
        image: zhayujie/chatgpt-on-wechat
        container_name: chatgpt-on-wechat
        security_opt:
          - seccomp:unconfined
        ports:
          - "80:80"
        environment:
          OPEN_AI_API_KEY: ''
          DASHSCOPE_API_KEY: ''
          MODEL: 'deepseek-reasoner'
          open_ai_api_base: 'https://api.deepseek.com/v1'
          SINGLE_CHAT_PREFIX: '[""]'
          SINGLE_CHAT_REPLY_PREFIX: '""'
          GROUP_CHAT_PREFIX: '["@bot"]'
          GROUP_NAME_WHITE_LIST: '["ChatGPT测试群", "ChatGPT测试群2"]'
          clear_memory_commands: '["#清除记忆"]'
          # 微信公众号相关配置
          "subscribe_msg": "感谢您关注不挂高数！\n分享日常和碰到的技术问题，包括但不限于Java，Spring，Vue，Python，C#什么的。反正和高数没啥关系，至于为什么叫这个名字，那是因为我上大学那会，高数挂了，博客：buguagaoshu.com\n至于网课答案，你可以将题目复制粘贴到对话框，AI会给你答案\n如果需要清除聊天记忆，请回复：#清除记忆"
          CHANNEL_TYPE: "wechatmp"  # 如果通过了微信认证，将"wechatmp"替换为"wechatmp_service"，可极大的优化使用体验
          WECHATMP_TOKEN: ""  # 微信公众平台的Token，需要替换为你自己的
          WECHATMP_PORT: 80  # 微信公众平台的端口，需要端口转发到80或443
          WECHATMP_APP_ID: ""  # 微信公众平台的appID，需要替换为你自己的
          WECHATMP_APP_SECRET: ""  # 微信公众平台的appsecret，需要替换为你自己的
          WECHATMP_AES_KEY: ""  # 微信公众平台的EncodingAESKey，加密模式需要，如有则替换
          # IMAGE_CREATE_PREFIX: '["画", "看", "找"]'
          CONVERSATION_MAX_TOKENS: 1000
          SPEECH_RECOGNITION: 'False'
          CHARACTER_DESC: '你是基于大语言模型的AI智能助手，旨在回答并解决人们的任何问题，并且可以使用多种语言与人交流。'
          EXPIRES_IN_SECONDS: 3600
          USE_GLOBAL_PLUGIN_CONFIG: 'True'
          USE_LINKAI: 'False'
          LINKAI_API_KEY: ''
          LINKAI_APP_CODE: ''
    
    

探索其它更多配置，你可以接着问AI

版权
--

本文首发于：[https://www.buguagaoshu.com/archives/gzhjrdmx](https://www.buguagaoshu.com/archives/gzhjrdmx)

转载请注明出处