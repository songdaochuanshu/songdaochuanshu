---
layout: post
title: '【GitHub每日速递 250924】18 个 AI 投资大师齐上阵！这个开源对冲基金让你看透市场底牌'
date: "2025-09-24T00:39:41Z"
---
【GitHub每日速递 250924】18 个 AI 投资大师齐上阵！这个开源对冲基金让你看透市场底牌
===================================================

AI赋能对冲基金！18大智能代理协作，交易决策新玩法揭秘
============================

virattt/ai-hedge-fund 是一个基于人工智能技术进行自动化投资决策的金融项目。简单讲，它是一个用Python构建的AI对冲基金团队，通过算法分析市场数据并执行交易。适用人群：量化交易爱好者、AI金融应用开发者、投资科技研究人员。

项目地址：[https://github.com/virattt/ai-hedge-fund](https://github.com/virattt/ai-hedge-fund)

主要语言：Python

stars: 40.77k

### 项目概述

这是一个由人工智能驱动的对冲基金概念验证项目，旨在探索如何利用人工智能进行交易决策。不过该项目仅用于教育和研究，不用于实际交易或投资。

### 核心功能

*   **多智能体协作**：系统中有18个智能体协同工作，包括如Aswath Damodaran Agent（专注估值）、Ben Graham Agent（价值投资教父）、Warren Buffett Agent（寻找优质公司）等投资界知名人物对应的智能体，还有用于计算股票内在价值、分析市场情绪、基本面数据、技术指标的智能体，以及风险管理和投资组合管理智能体。
*   **交易信号生成**：多个智能体从不同角度分析市场，如估值、情绪、基本面、技术指标等，生成交易信号。
*   **模拟决策**：系统虽然不实际进行交易，但可以模拟交易决策过程。

### 优势

*   **教育价值高**：对于想要学习人工智能在金融领域应用以及投资决策原理的人来说，是一个很好的学习工具。
*   **多视角分析**：通过多个智能体从不同投资理念和分析角度进行决策，能提供更全面的市场分析。
*   **灵活运行方式**：支持命令行界面和Web应用程序两种运行方式，满足不同用户的使用习惯。

### 应用场景

*   **金融学习**：学生、投资者或金融爱好者可以通过该系统学习人工智能在投资决策中的应用，了解不同投资策略和分析方法。
*   **策略研究**：研究人员可以利用该系统测试和验证新的投资策略和分析方法。

### 安装步骤

*   克隆仓库：使用`git clone https://github.com/virattt/ai-hedge-fund.git`克隆项目，并进入项目目录。
*   设置API密钥：创建并编辑`.env`文件，添加所需的API密钥，如`OPENAI_API_KEY`和`FINANCIAL_DATASETS_API_KEY`。至少设置一个大语言模型（LLM）的API密钥，对于AAPL、GOOGL、MSFT、NVDA和TSLA之外的股票数据，需要设置金融数据集API密钥。

### 运行方式

*   **命令行界面**：
    *   快速开始：安装Poetry并使用`poetry install`安装依赖。
    *   运行对冲基金：使用`poetry run python src/main.py --ticker AAPL,MSFT,NVDA`命令，还可以使用`-ollama`标志使用本地大语言模型，以及通过`-start-date`和`-end-date`指定决策的时间范围。
    *   运行回测器：使用`poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA`命令，同样支持`-ollama`、`-start-date`和`-end-date`标志。
*   **Web应用程序**：提供用户友好的界面，适合更喜欢可视化界面而非命令行工具的用户，详细安装和运行说明可参考[此处](https://github.com/virattt/ai-hedge-fund/tree/main/app)。

305亿参数！通义DeepResearch大模型，多基准测试夺冠，速来下载！
======================================

DeepResearch 是一个基于通义大模型的开源深度研究代理工具。简单讲，它能自动进行信息搜集、分析和报告生成，帮你完成复杂的调研任务。适用人群：研究人员、数据分析师、AI开发者。

项目地址：[https://github.com/Alibaba-NLP/DeepResearch](https://github.com/Alibaba-NLP/DeepResearch)

主要语言：Python

stars: 7.5k

### 项目简介

Tongyi DeepResearch 是由通义实验室开发的一个具有 305 亿总参数的智能大语言模型，每个标记仅激活 33 亿参数。该模型专为长周期、深度信息搜索任务而设计，在一系列智能搜索基准测试中表现出色，包括 Humanity's Last Exam、BrowserComp、BrowserComp - ZH 等。它建立在之前的 WebAgent 项目基础之上。

### 项目优势

*   **全自动合成数据生成管道**：设计了高度可扩展的数据合成管道，实现完全自动化，支持智能预训练、监督微调以及强化学习。
*   **大规模持续预训练**：利用多样化、高质量的智能交互数据，扩展模型能力，保持模型的时效性，并增强推理性能。
*   **端到端强化学习**：采用基于定制的 Group Relative Policy Optimization 框架的严格在线策略强化学习方法，结合标记级策略梯度、留一法优势估计和负样本选择性过滤，以在非平稳环境中稳定训练。
*   **推理范式兼容**：在推理时，兼容两种推理范式，ReAct 用于严格评估模型的核心内在能力，基于 IterResearch 的“Heavy”模式则使用测试时缩放策略来解锁模型的最大性能上限。

### 模型下载

提供了 Tongyi - DeepResearch - 30B - A3B 模型的下载链接，可从 HuggingFace 和 ModelScope 下载，模型大小为 30B - A3B，上下文长度为 128K。

### 快速启动

*   **环境设置**：推荐使用 Python 3.10.0 版本，建议使用 `conda` 或 `virtualenv` 创建隔离环境。
*   **安装依赖**：通过 `pip install -r requirements.txt` 安装所需依赖。
*   **准备评估数据**：在项目根目录创建 `eval_data/` 文件夹，将 JSONL 格式的 QA 文件放入该目录，每个 JSON 对象需包含 `question` 和 `answer` 字段。若使用文件解析工具，需在 `question` 字段前添加文件名，并将文件放入 `eval_data/file_corpus/` 目录。
*   **配置推理脚本**：打开 `run_react_infer.sh`，修改 `MODEL_PATH`、`DATASET`、`OUTPUT_PATH` 等变量，并根据启用的工具提供所需的 `API_KEY`、`BASE_URL` 等凭证。
*   **运行推理脚本**：执行 `bash run_react_infer.sh` 运行推理。

### 基准评估

提供了各种数据集的基准评估脚本，具体详情可参考 `evaluation` 目录。

### 应用场景

由于该模型专为长周期、深度信息搜索任务设计，可应用于需要深入挖掘信息的场景，如学术研究、市场调研、专业知识问答等领域。在这些场景中，模型能够利用其强大的推理和信息搜索能力，为用户提供准确和全面的答案。

开源AI编码神器opencode：不限模型、聚焦TUI，还能远程操控！
===================================

\[opencode\] 是一个基于终端的AI编程助手工具。简单讲，它能通过人工智能帮你写代码，直接在命令行里完成编程任务。适用人群：开发者、程序员及终端重度用户。

项目地址：[https://github.com/sst/opencode](https://github.com/sst/opencode)

主要语言：TypeScript

stars: 24.01k

### 项目简介

opencode是一款为终端设计的AI编码代理工具。它允许开发者在终端环境中借助AI的能力，提升编码效率。

### 主要优势

*   **开源免费**：项目100%开源，用户可以自由查看、使用和修改代码。
*   **多模型支持**：不依赖于特定的模型提供商，推荐使用Anthropic，但也能与OpenAI、Google等模型，甚至本地模型配合使用。随着模型的发展和价格降低，这种多模型支持的特性将更具优势。
*   **专注TUI**：由Neovim用户和terminal.shop的创建者开发，致力于挖掘终端环境下的最大潜力，提供出色的终端用户界面体验。
*   **客户端/服务器架构**：支持在计算机上运行服务端，通过移动应用远程控制，终端用户界面只是其中一种客户端形式，具有很强的灵活性。

### 安装方式

提供了多种安装途径：

*   使用一键安装脚本：`curl -fsSL https://opencode.ai/install | bash`
*   通过包管理器安装：
    *   `npm i -g opencode-ai@latest`（也支持bun、pnpm、yarn）
    *   `brew install sst/tap/opencode`（适用于macOS和Linux）
    *   `paru -S opencode-bin`（适用于Arch Linux）

安装脚本会按照以下优先级顺序确定安装路径：

1.  `$OPENCODE_INSTALL_DIR`：自定义安装目录
2.  `$XDG_BIN_DIR`：符合XDG基础目录规范的路径
3.  `$HOME/bin`：标准用户二进制目录（如果存在或可以创建）
4.  `$HOME/.opencode/bin`：默认备用路径

### 文档和贡献

*   **文档**：如需了解更多配置信息，可访问[文档页面](https://opencode.ai/docs)。
*   **贡献**：opencode对于核心功能有严格的设计流程，不接受核心功能的PR。但欢迎以下方面的贡献：
    *   修复漏洞
    *   提升LLM性能
    *   支持新的模型提供商
    *   修复特定环境下的问题
    *   补充缺失的标准功能
    *   完善文档

### 本地开发

本地运行opencode需要安装Bun和Golang 1.24.x，然后执行以下命令：

    $ bun install
    $ bun dev
    

### 应用场景

*   **编码辅助**：在编写代码时，借助AI的能力提供代码建议、补全、错误检查等功能，提高编码效率。
*   **代码学习**：对于初学者，opencode可以帮助理解代码逻辑，提供代码解释和示例。
*   **跨平台开发**：由于支持多种模型和客户端/服务器架构，适用于不同操作系统和设备的开发场景。

免费开源AI神器Nanobrowser，零成本实现强大网页自动化！
=================================

nanobrowser 是一个基于AI驱动的网页自动化工具的浏览器扩展。简单讲，它能让用户通过自定义大模型API实现多智能体协同的网页操作，无需依赖特定厂商的闭源方案。适用人群：需要隐私保护和定制化AI自动化的开发者与技术爱好者。

项目地址：[https://github.com/nanobrowser/nanobrowser](https://github.com/nanobrowser/nanobrowser)

主要语言：TypeScript

stars: 9.34k

### 项目简介

Nanobrowser是一款开源的AI网络自动化工具，以Chrome扩展程序的形式运行，是OpenAI Operator的免费替代品，提供了灵活的大语言模型（LLM）选项和多智能体系统。

### 优势

*   **免费使用**：无订阅费和隐藏成本，只需安装并使用自己的API密钥，按使用量付费。
*   **注重隐私**：所有操作都在本地浏览器运行，用户凭证不会共享给任何云服务。
*   **LLM选择灵活**：可连接到首选的LLM提供商，并为不同智能体选择不同模型。
*   **完全开源**：浏览器自动化过程完全透明，不存在黑盒或隐藏进程。目前支持OpenAI、Anthropic、Gemini、Ollama、Groq、Cerebras、Llama和自定义OpenAI兼容提供商，未来还会支持更多。

### 核心功能

*   **多智能体系统**：专业的AI智能体协作完成复杂的网络工作流程。
*   **交互式侧边栏**：直观的聊天界面，提供实时状态更新。
*   **任务自动化**：无缝自动化跨网站的重复性网络任务。
*   **后续问题**：可针对已完成任务提出上下文相关的后续问题。
*   **对话历史**：方便访问和管理与AI智能体的交互历史。
*   **多LLM支持**：连接首选的LLM提供商，并为不同智能体分配不同模型。

### 浏览器支持

*   **官方支持**：Chrome和Edge浏览器，具备完整功能。
*   **不支持**：Firefox、Safari和其他Chromium变体（如Opera、Arc等）。虽然在其他基于Chromium的浏览器上可能也能运行，但建议使用Chrome或Edge以获得最佳体验和兼容性保证。

### 安装方式

*   **从Chrome网上应用店安装（稳定版）**：访问[Nanobrowser Chrome网上应用店页面](https://chromewebstore.google.com/detail/nanobrowser/imbddededgmcgfhfpcjmijokokekbkal)，点击“添加到Chrome”按钮，按提示确认安装。不过，由于审核流程，Chrome网上应用店版本可能会有延迟，若需最新功能，可手动安装最新版本。
*   **手动安装最新版本**：从官方GitHub [发布页面](https://github.com/nanobrowser/nanobrowser/releases)下载最新的`nanobrowser.zip`文件，解压后在Chrome中打开`chrome://extensions/`，启用“开发者模式”，点击“加载已解压的扩展程序”，选择解压后的`nanobrowser`文件夹。安装后，点击工具栏中的Nanobrowser图标打开侧边栏，点击“设置”图标，添加LLM API密钥，并为不同智能体（导航器、规划器）选择要使用的模型。升级时，重复下载和解压步骤，替换现有文件，然后在Chrome扩展程序页面点击Nanobrowser卡片上的刷新图标。
*   **从源代码构建**：需要安装Node.js（v22.12.0或更高版本）和pnpm（v9.15.1或更高版本）。克隆仓库`git clone https://github.com/nanobrowser/nanobrowser.git`并进入项目目录，使用`pnpm install`安装依赖，`pnpm build`构建扩展程序，构建后的扩展程序位于`dist`目录，按照手动安装部分的步骤将其加载到浏览器中。还可以使用`pnpm dev`开启开发模式。

### 模型选择

*   **追求更好性能**：规划器使用Claude Sonnet 4，具有更好的推理和规划能力；导航器使用Claude Haiku 3.5，适用于网络导航任务，在性能和成本之间取得良好平衡。
*   **追求成本效益**：规划器可选择Claude Haiku或GPT - 4o，以较低成本获得合理性能，但处理复杂任务可能需要更多迭代；导航器使用Gemini 2.5 Flash或GPT - 4o - mini，轻量级且成本效益高，适合基本导航任务。
*   **本地模型**：可使用Ollama或其他自定义OpenAI兼容提供商在本地运行模型，零API成本且完全隐私，数据不会离开本地机器。推荐模型包括Qwen3 - 30B - A3B - Instruct - 2507、Falcon3 10B、Qwen 2.5 Coder 14B、Mistral Small 24B等，可参考[社区最新测试结果](https://gist.github.com/maximus2600/75d60bf3df62986e2254d5166e2524cb)。使用本地模型时需要进行更具体、清晰的提示工程，避免高级、模糊的命令，将复杂任务分解为清晰详细的步骤，并提供明确的上下文和约束。

### 应用场景

*   **新闻摘要**：例如“前往TechCrunch并提取过去24小时内的前10条头条新闻”。
*   **GitHub研究**：如“查找GitHub上星数最多的热门Python仓库”。
*   **购物研究**：像“在亚马逊上查找价格低于50美元、具备防水设计且电池续航至少10小时的便携式蓝牙音箱”。