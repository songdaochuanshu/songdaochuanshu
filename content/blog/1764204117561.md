---
layout: post
title: '宇树 Qmini 双足机器人训练个人经验总结'
date: "2025-11-27T00:41:57Z"
---
宇树 Qmini 双足机器人训练个人经验总结
======================

> github：[https://github.com/vsislab/RoboTamer4Qmini](https://github.com/vsislab/RoboTamer4Qmini)

本篇内容基于我在 **AutoDL 云服务器** 上对 Qmini 做完整训练与测试的实践总结，涵盖训练、可视化、策略测试、模型导出、URDF 调试等环节，并重点说明 **headless（无显示）环境下的各种坑与解决方案**。希望能帮到后来者少走弯路。

### 前提说明：为什么不建议在云端直接跑渲染？

我最开始的目标是：**训练、渲染、视频录制全部在 AutoDL 上完成，不经过本地运行。**

然而现实是：

*   即使用 Xvfb 等虚拟显示器启动 Isaac Gym，也会发生视频保存全黑的情况。
*   VNC 远程桌面也无法正常显示 Isaac Gym 的渲染窗口。
*   根本原因来自 **驱动版本过高与 Isaac Gym 对驱动的强依赖**。

> 因此更推荐：**在云服务器训练模型 → 本地 Ubuntu 加载策略进行测试与演示。**

> **可以在云服务器中进行训练然后在本地进行测试**，这是我目前发现的比较好的方式，本地使用的是ubuntu系统，最后算是可以正常演示。
> 
> 当前的问题都是基于我完全使用autodl上进行的尝试，希望可以对大家有所帮助，少踩坑。

#### 训练阶段

`python train.py --config BIRL --name <name>`

> \--name
> 
> ​ 存放路径`experiments/<name>/`
> 
> \--config
> 
> ​ 选择配置文件，默认：BIRL
> 
> \--resume
> 
> ​ 恢复训练
> 
> ​ eg：`python train.py --name stand --resume --path experiments/stand/checkpoints/policy_40000.pt`
> 
> \--render
> 
> ​ 开启画面显示（isaac gym窗口）
> 
> \--fix\_cam
> 
> ​ 视角固定在机器人上方
> 
> \--horovod
> 
> ​ 多gpu训练
> 
> \--r l\_device
> 
> ​ 训练设备设置
> 
> ​ 默认cudo0，可以改为cpu等
> 
> \--num\_envs
> 
> ​ 环境数量
> 
> \--seed
> 
> ​ 随机种子，利于复现
> 
> \--max\_iterations
> 
> ​ 最大训练迭代次数

> ![image-20251121103327885](https://lzz-mac-1340752507.cos.ap-shanghai.myqcloud.com/lzz/image-20251121103327885.png)

#### 查看结果

云端可能出现 **6006 端口占用** 的情况，需要手动释放。

###### 1\. 安装 lsof

`apt-get update`

`apt-get install lsof -y`

###### 2\. 查看端口占用

`lsof -i :6006`

###### 3\. 杀掉进程

`kill -9 <PID>`

###### 4\. 重新启动 TensorBoard

`tensorboard --logdir experiments/<name>/log --port 6006`

> ![image-20251121103256106](https://lzz-mac-1340752507.cos.ap-shanghai.myqcloud.com/lzz/image-20251121103256106.png)

#### 运行训练好的策略 play.py

`python play.py --render --name <name>` 加载训练好的策略，开始跑模拟器

> \--render 显示画面
> 
> \--fix\_cam 相机固定跟随机器人
> 
> \--cmp\_real 与真实机器人采集的数据对比绘图
> 
> \--plt\_sim 显示仿真数据的曲线图（如关节角、速度等）
> 
> \--num\_envs 改变并行环境数量
> 
> \--video 开启视频录制，保存到 `videos/` 文件夹，必须配合 `--render`
> 
> \--time 玩多少秒
> 
> \--iter 指定用哪一轮的模型，默认加载目录下最后一个 policy
> 
> \--epochs 重复评估多少次，用来统计平均性能
> 
> \--debug 保存仿真数据到 Excel

#### 导出ONNX模型

`python export_pt2onnx.py --name <name>`

把 `.pt` 权重导出为 `.onnx`，便于部署到嵌入式设备、Jetson、Unity 等。

#### 加载（调试）urdf模型

`python tune_urdf.py`

测试你的机器人 URDF 是否正常加载，检查质量参数、碰撞体、关节限位，也可微调模型参数

#### 自动调参PID（tun\_pid.py）

`python tune_pid.py --mode <mode>`

> \--model
> 
> sin
> 
> 发送正弦信号测试电机响应
> 
> real
> 
> 上传真实机器人数据进行比较
> 
> reset
> 
> 恢复初始值，不进行测试

### 错误

#### Headless 环境无法渲染

> 云服务器默认无显示设备。

临时方案：使用虚拟显示：Xvfb（首先进行pip下载）

    Xvfb :1 -screen 0 1024x768x24 & #启动 X Server
    export DISPLAY=:1 #设置环境变量
    

> 注意：但这只能让程序“以为”自己有显示，无法保证正常渲染！

#### 使用autodl远程连接，play.py 视频录制仍为黑屏

![image-20251121211032490](https://lzz-mac-1340752507.cos.ap-shanghai.myqcloud.com/lzz/image-20251121211032490.png)

> 原因分析：原因：云端 GPU 驱动版本过高（如 570 系列），超过了 Isaac Gym 的兼容范围。

Isaac Gym 对渲染器依赖的驱动版本非常敏感，驱动过新 → 渲染器初始化失败 → 视频录制为纯黑。

**目前找到比较好的方案**是：云端只做训练，本地 Ubuntu 运行 play.py。

最后的最后再次说明，目前我认为比较稳妥、推荐的流程是：**云端训练（AutoDL）→ 本地 Ubuntu Play 与可视化**。云端的 headless 环境与高版本驱动目前无法可靠支持 Isaac Gym 的图形渲染与视频录制，本地则能完美解决所有渲染相关问题。

> 如有不对，希望各位大佬可以积极指出，谢谢各位。