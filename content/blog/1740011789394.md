---
layout: post
title: '1 使用ollama完成DeepSeek本地部署'
date: "2025-02-20T00:36:29Z"
---
1 使用ollama完成DeepSeek本地部署
========================

1 ollama
========

1.1 什么是ollama
-------------

ollama是一个开源的 LLM（大型语言模型）服务工具，用于简化在本地运行大语言模型，降低使用大语言模型的门槛，使得大模型的开发者、研究人员和爱好者能够在本地环境快速实验、管理和部署最新大语言模型。

1.2 下载ollama
------------

（1）直接从ollama官网下载ollama：[https://ollama.com/download](https://ollama.com/download)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219225328830-1320898949.png)  
不推荐此方式，下载速度巨慢，直接从github上下载也有相同的问题。  
（2）网上推荐的通过github加速器下载github上的安装包，加速器地址：[https://github.moeyy.xyz/](https://github.moeyy.xyz/)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219225811263-1509901501.png)  
也不推荐，新版ollama安装包较大，无法下载，只能下载较老版本。  
（3）通过迅雷下载（推荐），ollama的发布版本地址：[https://github.com/ollama/ollama/releases](https://github.com/ollama/ollama/releases)  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219230238928-29102220.png)  
选择自己需要的安装包，右键，复制链接到迅雷内粘贴即可下载，我这里选择的是ollama-windows-amd64.zip可以免安装，也可以直接选择OllamaSetup.exe运行安装程序完成安装。  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219230121804-571007561.png)

1.3 安装并运行ollama
---------------

（1）解压ollama-windows-amd64.zip到自己的安装目录，如  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219230915337-2050679200.png)  
（2）添加ollama.exe路径到环境变量：  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219231503904-956863145.png)  
这样就可以在cmd中运行ollama了。  
（3）添加模型的下载路径，用于保存下载的模型文件。  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219231723049-540774989.png)  
新建环境变量OLLAMA\_MODELS，添加自己的存储路径，我的模型文件保存路径为：D:\\software\\AIModel\\ollama-windows-amd64\\ollamaModel\\Models，要保证路径下无其他文件否则可能无效。不配置此路径或配置路径无效，模型将默认下载到C:\\Users\\WRJ.ollama\\models目录下。  
（4）运行ollama  
使用快捷键Win+R打开运行，输入cmd运行命令行，输入`ollama serve`即可运行运行ollama。  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219233200916-1986512633.png)

2 部署DeepSeek模型
==============

2.1 进入ollama官网，点击models或直接点击以下链接：[https://ollama.com/search](https://ollama.com/search)  
首个就是deepseek模型，点击进入。  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219233630636-1578847503.png)  
根据自己电脑的配置选择合适的模型，我电脑是AMD 9700X+RTX4070TI SUPER 16G，实测运行14B模型无压力，响应流畅，运行32B需要等待20-30s才可响应。选择好模型后复制命令`ollama run deepseek-r1:32b`,打开一个新的cmd窗口粘贴运行，等待下载完成即可直接使用了。  
![image](https://img2024.cnblogs.com/blog/3448243/202502/3448243-20250219234340763-1475461097.png)