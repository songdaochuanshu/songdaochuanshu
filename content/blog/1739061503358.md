---
layout: post
title: '五分钟搭建属于你的AI助手：Ollama+DeepSeek+AnythingLLM深度整合教程'
date: "2025-02-09T00:38:23Z"
---
五分钟搭建属于你的AI助手：Ollama+DeepSeek+AnythingLLM深度整合教程
===============================================

作者简介
====

*   微信公众号：密码应用技术实战
*   博客园首页：[https://www.cnblogs.com/informatics/](https://www.cnblogs.com/informatics/)
*   GitHub地址：[https://github.com/warm3snow](https://github.com/warm3snow)

引言
==

随着人工智能的发展，大模型的应用越来越广泛，它们不仅能够理解自然语言，还能在特定领域内提供专业化的知识服务。为了满足个人或小型团队对于数据隐私保护的需求，本地部署大模型并搭建私有知识库成为了一种趋势。本文将介绍如何使用Ollama、DeepSeek和AnythingLLM来构建这样一个系统，使您能够在自己的计算机上运行强大的AI模型，并利用其进行高效的知识管理和智能问答。

本地部署大模型并搭建私有知识库的好处：

*   数据隐私和安全性：本地部署可以确保敏感数据不被上传到云端，降低数据泄露的风险，特别适合对数据保密有严格要求的企业和个人。
*   控制权：用户对自己的数据和模型有更大的控制权，可以根据需要进行定制和优化，而不依赖于第三方服务。
*   低延迟：本地运行模型可以减少网络延迟，提高响应速度，尤其在需要实时处理的应用场景中尤为重要。
*   离线访问：本地部署允许在没有互联网连接的情况下使用模型和数据，适合在网络不稳定或无法访问的环境中工作。
*   成本效益：长期来看，尤其是对于大规模使用，避免了云服务的持续费用，可能会降低总体拥有成本。
*   定制化：用户可以根据特定需求调整和优化模型，进行更深入的定制，满足特定行业或应用的需求。
*   合规性：某些行业（如医疗、金融等）对数据存储和处理有严格的法律法规要求，本地部署可以帮助企业更好地遵守这些规定。

通过本地部署，用户能够享受更高的灵活性和安全性，同时也能更好地满足特定的业务需求。

简介
==

本文将手把手教你用 Ollama、DeepSeek 与 AnythingLLM 搭建超强大本地知识库

DeepSeek：AI 领域的实力新星
-------------------

DeepSeek专注于人工智能技术的研发，尤其在大语言模型方面成果显著。开源发布的DeepSeek R1模型，具备优秀的逻辑推理能力，能够处理复杂多样的自然语言任务。

Ollama：本地运行 AI 模型的利器
--------------------

Ollama 是一款致力于让用户在本地轻松运行 AI 模型的工具。它提供了简洁易用的命令行界面，极大降低了本地部署模型的门槛。通过 Ollama，用户可以快速拉取并运行各种主流的大语言模型，无需复杂的配置和高昂的云计算成本。其高效的模型管理系统，能帮助用户方便地切换和使用不同模型，满足多样化的需求。

AnythingLLM：知识整合的智能助手
---------------------

AnythingLLM专注于知识管理和问答系统，提供了桌面客户端，方便用户使用；能够从多种不同来源获取数据，包括但不限于文档、网页、数据库等，将这些分散的非结构化或半结构化数据进行有效整合，统一处理为可供分析和查询的格式，为知识的全面性和完整性提供了保障。，AnythingLLM 能够理解用户的问题，并在知识图谱中精准检索答案，为用户提供准确、全面的回答。

部署架构
====

Ollama+DeepSeek+AnythingLLM搭建本地知识库的整体架构如下：

graph TD %% 用户接口层 subgraph 用户接口层 UI1\[AnythingLLM桌面应用\] end %% 应用服务层 subgraph 应用服务层 AS1\[AnythingLLM前端服务\] AS2\[Ollama </br> 模型管理服务\] end %% 数据处理层 subgraph 数据处理层 DP1\[向量数据库<br>LanceDB, Pinecone等测试与优化\] DP2\[嵌入模型<br>用于文本转换为向量\] end %% 核心模型层 subgraph 核心模型层 CM1\[DeepSeek R1<br>语言模型\] end %% 外部资源层（可选） subgraph 外部资源层/可选 ER1\[外部APIs或其他服务\] end %% 连接关系 UI1 -->|请求查询或上传文档| AS1 AS1 -->|调用模型推理| AS2 AS2 -->|加载模型| CM1 AS1 -->|查询| DP1 DP1 -->|检索相关文档片段| AS1 DP2 -->|生成文本向量| DP1 AS2 -.->|可能需要的外部数据| ER1 %% 注释 style UI1 fill:#f96,stroke:#333,stroke-width:4px style AS1 fill:#bbf,stroke:#f66,stroke-width:2px,stroke-dasharray: 5, 5 style AS2 fill:#ddf,stroke:#f66,stroke-width:2px,stroke-dasharray: 5, 5 style DP1 fill:#fff,stroke:#000,stroke-width:4px style DP2 fill:#eef,stroke:#000,stroke-width:2px style CM1 fill:#ddf,stroke:#000,stroke-width:4px style ER1 fill:#ccc,stroke:#000,stroke-width:2px

Ollama、DeepSeek、AnythingLLM三者整合，搭建本地知识库步骤：

*   准备工作：确保你的设备满足运行要求，安装好 Ollama、DeepSeek 模型（可通过 Ollama 拉取）以及 AnythingLLM。
*   数据导入：将你想要纳入知识库的文本数据整理好，导入到 AnythingLLM 中，构建知识图谱。
*   模型连接：通过 Ollama 运行 DeepSeek 模型，并将其与 AnythingLLM 进行连接，使得 DeepSeek 强大的语言处理能力与 AnythingLLM 的知识管理能力相结合。
*   测试与优化：输入各种问题进行测试，根据结果对知识库和模型参数进行优化，提升回答的准确性和效率。

准备工作
====

配置要求：

*   操作系统：MacOS、Linux、Windows
*   硬件要求：

模型规模

CPU核心数

内存

硬盘存储空间

显卡推荐显存

适用场景

**1.5B**

最低4核

8GB+

3GB+

非必需，可选4GB+

低资源设备部署等场景

**7B**

8核以上

16GB+

8GB+

推荐8GB+

本地开发测试等场景

**8B**

略高于7B

同上

同上

同上

需更高精度的轻量级任务

**14B**

12核以上

32GB+

15GB+

推荐16GB+

企业级复杂任务等场景

**32B**

16核以上

64GB+

30GB+

推荐24GB+

高精度专业领域任务等场景

**70B**

32核以上

128GB+

70GB+

多卡并行

科研机构高复杂度生成任务等场景

GPU非必须，如果使用GPU性能会更好，支持列表参考[Ollama GPU支持列表](https://github.com/ollama/ollama/blob/main/docs/gpu.md)

### Ollama安装

首先，我们需要访问Ollama的官方网站并根据您的操作系统选择相应的版本进行下载和安装。（当前支持MacOS、Linux和Windows多个系统版本)

Ollama官网：[https://ollama.com/download](https://ollama.com/download)

![image](https://img2024.cnblogs.com/blog/383528/202502/383528-20250208172642491-1838066248.png)

安装完成后，打开命令行工具，使用ollama下载deepseek模型，如下：

    ➜  ~ ollama run deepseek-r1:8b
    pulling manifest
    pulling aabd4debf0c8...  18% ▕███████████████████████████                                                                                                                           ▏ 206 MB/1.1 GB  954 KB/s  15m54s
    
    

注：这个过程可能会比较耗时，具体取决于您的网络速度。ollama官网托管了多个版本的deepseek模型，我们这里为了方便，我们选择模型deepseek-r1:8b来进行演示。

### AnythingLLM安装

下载并安装AnythingLLM，根据您的操作系统选择相应的版本。（当前支持MacOS、Linux和Windows多个系统版本)

AnythingLLM官网：[https://anythingllm.com/desktop](https://anythingllm.com/desktop)

![image](https://img2024.cnblogs.com/blog/383528/202502/383528-20250208172701599-969491906.png)

安装完成后，打开AnythingLLM，会有一段欢迎提示如下：

![image](https://img2024.cnblogs.com/blog/383528/202502/383528-20250208172712014-701897369.png)

数据导入
----

### 文档准备

在开始之前，您需要准备一些文档数据，这些文档将作为知识库的基础。文档可以是各种格式，如txt、pdf、doc等，只要AnythingLLM支持即可。您可以选择上传一些与您感兴趣的主题相关的文档，以便模型能够从中学习到更多的知识。比如我们一些技术文档、论文、报告等，我们以技术报告“DeepSeek-V3 Technical Report”为例。  
打开AnythingLLM，按照提示创建一个新的工作区。接下来，点击工作区旁边的上传按钮，上传您希望包含在知识库中的文件。

![image](https://img2024.cnblogs.com/blog/383528/202502/383528-20250208172722047-260796226.png)

上传完成后，点击“Save and Embed”，以便模型能够处理这些文档内容。

### 模型连接

打开AnythingLLM，点击工作区旁边的配置按钮，选择Ollama作为推理后端，并确保选择了deepseek模型和其他必要的参数。这样，您的本地知识库就准备好了。配置如下：

![image](https://img2024.cnblogs.com/blog/383528/202502/383528-20250208172742644-1515092020.png)

*   点击配置按钮，并切换到 `Chat Settings`菜单项
*   在工作区 `Workspace LLM Provider`配置中选择Ollama
*   在工作区 `Workspace Chat model`配置中选择deepseek-r1:8b (注：只有使用ollama下载deepseek模型后，这里才会显示)
*   其他配置项可以根据需要进行调整，如果不确定，可以使用默认值

点击保存 `Update workspace`，然后您就可以开始使用您的本地知识库了。

测试与优化
=====

一旦完成安装和配置，您就可以通过AnythingLLM的工作区与模型进行交互了。尝试提出一些关于已上传文档的问题，看看模型是如何利用新学到的知识来回答的。

![image](https://img2024.cnblogs.com/blog/383528/202502/383528-20250208172756941-203889304.png)

![image](https://img2024.cnblogs.com/blog/383528/202502/383528-20250208172806446-448291853.png)

从上面截图上可以看到：

*   AnythingLLM通过调用deepseek模型完成了知识问答
*   图片底部显示 `Hide Citations`表明，本次问答引用了我们之前上传的技术报告 `DeepSeek_V3.pdf`，虽然技术报告使用英文，但是deepseek由于支持多语言，在知识问答时能够自动进行翻译。

注：如果您上传了多篇关于某个特定领域的论文或报告，那么询问模型有关该领域的细节时，能得到更加准确的回答。

总结
==

通过使用Ollama、DeepSeek和AnythingLLM搭建本地知识库，我们不仅能够享受大模型带来的便利，还能够确保数据的安全性和隐私性。这种方法特别适合那些对数据保密有严格要求的企业和个人用户，同时也解决了在线DeepSeek不稳定的问题。

展望未来，随着技术的进步，本地部署的AI解决方案将会变得越来越普及，为用户提供更多的灵活性和控制权。

参考资料
====

*   \[1\] Ollama官网：[https://ollama.com](https://ollama.com)
*   \[2\] AnythingLLM官网：[https://anythingllm.com](https://anythingllm.com)
*   \[3\] DeepSeek官网：[https://www.deepseek.com/](https://www.deepseek.com/)
*   \[4\] DeepSeek模型的Ollama地址：[https://ollama.com/library/deepseek-r1](https://ollama.com/library/deepseek-r1)

转载声明
----

本文来自博客园，作者：[warm3snow](https://www.cnblogs.com/informatics/)

转载请注明原文链接：[https://www.cnblogs.com/informatics/p/18704799](https://www.cnblogs.com/informatics/p/18704799)

本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须在文章页面给出原文连接，否则保留追究法律责任的权利。