---
layout: post
title: '[æ·±åº¦å­¦ä¹ ] å¤§æ¨¡å‹å­¦ä¹ 5-é«˜æ•ˆå¾®è°ƒæ¡†æ¶Unslothä½¿ç”¨æŒ‡åŒ—'
date: "2025-10-03T00:37:55Z"
---
\[æ·±åº¦å­¦ä¹ \] å¤§æ¨¡å‹å­¦ä¹ 5-é«˜æ•ˆå¾®è°ƒæ¡†æ¶Unslothä½¿ç”¨æŒ‡åŒ—
=================================

Unslothæ˜¯ä¸€ä¸ªä¸“æ³¨äºåŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒè¿‡ç¨‹çš„å¼€æºé¡¹ç›®ã€‚å®ƒé€šè¿‡ä¸€ç³»åˆ—åº•å±‚ä¼˜åŒ–ï¼Œæ˜¾è‘—æå‡äº†å¾®è°ƒé€Ÿåº¦å¹¶å¤§å¹…é™ä½äº†å†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶èƒ½ä¿æŒæ¨¡å‹æ€§èƒ½ã€‚æ— è®ºæ˜¯ç ”ç©¶è€…è¿˜æ˜¯å¼€å‘è€…ï¼Œéƒ½èƒ½å€ŸåŠ©Unslothæ›´é«˜æ•ˆåœ°å®šåˆ¶è‡ªå·±çš„å¤§è¯­è¨€æ¨¡å‹ã€‚æœ¬æ–‡å°†ä»‹ç»Unslothçš„ä½¿ç”¨ï¼Œç›¸å…³å­¦ä¹ èµ„æºå¦‚ä¸‹ï¼š

*   å¼€æºä»“åº“ï¼š[Unsloth](https://github.com/unslothai/unsloth)
*   å®˜æ–¹æ–‡æ¡£ï¼š[Unsloth Docs](https://docs.unsloth.ai/)

ç›®å½•

*   [1 Unslothæ¡†æ¶ä»‹ç»](#1-unslothæ¡†æ¶ä»‹ç»)
    *   [1.1 Unslothæ¦‚è§ˆ](#11-unslothæ¦‚è§ˆ)
    *   [1.2 å¾®è°ƒæŠ€æœ¯æ¦‚è§ˆ](#12-å¾®è°ƒæŠ€æœ¯æ¦‚è§ˆ)
    *   [1.3 Unslothå®‰è£…](#13-unslothå®‰è£…)
*   [2 Unslothå¾®è°ƒæ•™ç¨‹](#2-unslothå¾®è°ƒæ•™ç¨‹)
    *   [2.1 æ¨¡å‹ä¸è®­ç»ƒæ–¹æ³•é€‰æ‹©](#21-æ¨¡å‹ä¸è®­ç»ƒæ–¹æ³•é€‰æ‹©)
    *   [2.2 LoRAå’Œæ•°æ®é›†](#22-loraå’Œæ•°æ®é›†)
        *   [2.2.1 LoRAä»‹ç»](#221-loraä»‹ç»)
        *   [2.2.2 é¿å…è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ](#222-é¿å…è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ)
        *   [2.2.3 è®­ç»ƒæ•°æ®é›†ä»‹ç»](#223-è®­ç»ƒæ•°æ®é›†ä»‹ç»)
    *   [2.3 Qwen3ä½¿ç”¨ç¤ºä¾‹](#23-qwen3ä½¿ç”¨ç¤ºä¾‹)
    *   [2.4 Unslothè®­ç»ƒQwen3æ•™ç¨‹](#24-unslothè®­ç»ƒqwen3æ•™ç¨‹)
        *   [2.4.1 é¢„è®­ç»ƒæ¨¡å‹åˆå§‹åŒ–](#241-é¢„è®­ç»ƒæ¨¡å‹åˆå§‹åŒ–)
        *   [2.4.2 æ•°æ®é›†åŠ è½½](#242-æ•°æ®é›†åŠ è½½)
        *   [2.4.3 æ¨¡å‹è®­ç»ƒ](#243-æ¨¡å‹è®­ç»ƒ)
        *   [2.4.4 æ¨¡å‹æ¨ç†](#244-æ¨¡å‹æ¨ç†)
        *   [2.4.5 æ¨¡å‹ä¿å­˜](#245-æ¨¡å‹ä¿å­˜)
*   [3 å‚è€ƒ](#3-å‚è€ƒ)

1 Unslothæ¡†æ¶ä»‹ç»
=============

1.1 Unslothæ¦‚è§ˆ
-------------

Unslothæ˜¯ä¸€æ¬¾ä¸“ä¸ºå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ è®¾è®¡çš„å¼€æºæ¡†æ¶ï¼Œè‡´åŠ›äºä»¥æ›´é«˜çš„æ•ˆç‡å’Œæ›´ä½çš„èµ„æºæˆæœ¬æ¨åŠ¨äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æ™®åŠã€‚ç”¨æˆ·å¯åœ¨æœ¬åœ°ç¯å¢ƒã€Google Colabã€Kaggleç­‰å¹³å°ä¸Šï¼Œå€ŸåŠ©å…¶è¿ç®—åŠ é€Ÿä¸æ˜¾å­˜ä¼˜åŒ–èƒ½åŠ›ï¼Œè½»æ¾å®ŒæˆQwenã€DeepSeekç­‰ä¸»æµå¤§æ¨¡å‹çš„è®­ç»ƒã€è¯„ä¼°ã€ä¿å­˜åŠæ¨ç†ä¼˜åŒ–ã€‚

ä¼ ç»Ÿå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒå¾€å¾€é¢ä¸´ç¡¬ä»¶è¦æ±‚é«˜ã€è¿­ä»£é€Ÿåº¦æ…¢å’Œèµ„æºå—é™ç­‰æŒ‘æˆ˜ï¼Œè€ŒUnslothé€šè¿‡é«˜æ•ˆçš„åº•å±‚å®ç°å’Œå‹å¥½çš„æ¥å£è®¾è®¡ï¼Œæ˜¾è‘—é™ä½äº†å¾®è°ƒçš„æŠ€æœ¯é—¨æ§›ï¼Œä½¿æ›´å¤šäººèƒ½å¤Ÿé«˜æ•ˆã€ä½æˆæœ¬åœ°è®­ç»ƒå±äºè‡ªå·±çš„å®šåˆ¶æ¨¡å‹ã€‚

![https://www.codemajin.net/fine-tuning-llm-with-unsloth/](https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A05-%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83%E6%A1%86%E6%9E%B6Unsloth%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97/img/img1.jpg)

**æ ¸å¿ƒä¼˜åŠ¿**

ç‰¹ç‚¹

è¯´æ˜

é€‚ç”¨åœºæ™¯/ç”¨æˆ·

ğŸš€æè‡´é€Ÿåº¦

ç›¸æ¯”Hugging Faceï¼ŒUnslothè®­ç»ƒæ¨¡å‹æ›´å¿«

éœ€å¿«é€Ÿå®éªŒä¸è¿­ä»£çš„ç ”å‘åœºæ™¯

ğŸ’¾çœå†…å­˜

å‡å°‘GPUæ˜¾å­˜å ç”¨

æ³¨é‡æˆæœ¬æ§åˆ¶çš„ç”¨æˆ·

âœ…æ— æŸç²¾åº¦

æ— éœ€ä¾èµ–è¿‘ä¼¼è®¡ç®—

å¯¹ç²¾åº¦è¦æ±‚æé«˜çš„ä»»åŠ¡

ğŸ”—å¹¿æ³›å…¼å®¹

æ”¯æŒä¸»æµTransformerç±»æ¨¡å‹ï¼ˆæ¶µç›–å¤šæ¨¡æ€ã€è¯­éŸ³ã€æ–‡æœ¬åŠæ‰©æ•£æ¨¡å‹ï¼‰ï¼›æ”¯æŒå…¨é‡å¾®è°ƒã€é¢„è®­ç»ƒåŠ4/8/16ä½ç²¾åº¦è®­ç»ƒï¼›å…¼å®¹Linuxã€WindowsåŠä¸»æµäº‘å¹³å°

ä½¿ç”¨å¤šç§æ¶æ„çš„å›¢é˜Ÿ

ğŸ§©æ˜“äºä½¿ç”¨

æä¾›ç®€æ´APIï¼Œå…¼å®¹Hugging Faceç”Ÿæ€ï¼Œå¯å¯¼å‡ºGGUFã€Ollamaç­‰æ ¼å¼

åˆå­¦è€…ã€èµ„æºæœ‰é™çš„å°å‹å›¢é˜Ÿ

âš¡é«˜æ•ˆæ¨ç†

æ”¯æŒINT4é‡åŒ–ï¼ˆQLoRAï¼‰ï¼Œæ¨ç†é˜¶æ®µåŒæ­¥æé€Ÿ

éœ€å…¼é¡¾å¾®è°ƒä¸æ¨ç†æ•ˆç‡çš„åº”ç”¨åœºæ™¯

ğŸ’¡ä½æˆæœ¬

å•å¼ GPUï¼ˆå¦‚4090æˆ–8GBæ˜¾å­˜å¡ï¼‰å³å¯å¾®è°ƒ10B+å‚æ•°æ¨¡å‹

ä¸ªäººå¼€å‘è€…

ğŸ”§é«˜æ•ˆè®¡ç®—

åŸºäºTritonï¼ˆOpenAIå¼€æºçš„é«˜æ€§èƒ½GPUç¼–ç¨‹è¯­è¨€ï¼‰å®ç°é«˜æ•ˆè®¡ç®—

å¯¹æŠ€æœ¯åº•å±‚æ•ˆç‡æœ‰è¦æ±‚çš„å¼€å‘å›¢é˜Ÿ

ç›®å‰ï¼ŒUnslothæ”¯æŒå€ŸåŠ©Accelerateã€DeepSpeedç­‰åº“å®ç°å¤šGPUè®­ç»ƒï¼Œä½†å®é™…é…ç½®è¿‡ç¨‹è¾ƒå¤æ‚ï¼Œéœ€æ‰‹åŠ¨å®Œæˆè®¾ç½®ï¼Œç›¸å…³è®­ç»ƒæ•™ç¨‹å¯å‚è€ƒï¼š[Multi-GPU-Unsloth](https://docs.unsloth.ai/basics/multi-gpu-training-with-unsloth)ï¼ŒUnslothå›¢é˜Ÿæ­£ç§¯æä¼˜åŒ–å¤šGPUè®­ç»ƒåŠŸèƒ½ã€‚

**ä½¿ç”¨å»ºè®®**

Unslothä¸Metaã€Googleã€Microsoftã€Mistralã€Qwenç­‰ä¸»æµæ¨¡å‹å›¢é˜Ÿæ·±åº¦åˆä½œï¼ŒæŒç»­ä¿®å¤å…³é”®æ¼æ´ï¼Œæå‡æ¡†æ¶çš„å‡†ç¡®æ€§ä¸ç¨³å®šæ€§ã€‚è¯¥æ¡†æ¶æ”¯æŒç”¨æˆ·çµæ´»è°ƒæ•´èŠå¤©æ¨¡æ¿å’Œæ•°æ®é›†æ ¼å¼ï¼Œå¹¶æä¾›æ¶µç›–è§†è§‰æ¨¡å‹ã€TTSã€BERTã€å¼ºåŒ–å­¦ä¹ ç­‰å¤šæ ·åŒ–ç¤ºä¾‹Notebookï¼ŒåŠ©åŠ›ç”¨æˆ·å¿«é€Ÿä¸Šæ‰‹ï¼Œè¯¦æƒ…å¯å‚è€ƒï¼š[Unsloth Notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks)ã€‚å¿«é€Ÿä¸Šæ‰‹å»ºè®®ï¼š

*   ä»QLoRAèµ·æ­¥ï¼š4-bité‡åŒ–æ˜¯èµ„æºæœ‰é™ç”¨æˆ·çš„ç†æƒ³é€‰æ‹©ï¼›
*   è°ƒæ•´å…³é”®å‚æ•°ï¼šå¦‚LoRAç§©ï¼ˆ`r`ï¼‰å’Œ`alpha`ï¼Œå»ºè®®ä»å°å€¼ï¼ˆå¦‚16ï¼‰å¼€å§‹å°è¯•ï¼Œä»¥å¹³è¡¡æ¨¡å‹èƒ½åŠ›ä¸è¿‡æ‹Ÿåˆé£é™©ï¼›
*   ç›‘æ§è®­ç»ƒè¿‡ç¨‹ï¼šå¯†åˆ‡å…³æ³¨æŸå¤±æ›²çº¿ï¼Œå€ŸåŠ©Unslothçš„å¿«é€Ÿè¿­ä»£ä¼˜åŠ¿ç§¯æè°ƒå‚ï¼›
*   åˆ©ç”¨ç¤¾åŒºèµ„æºï¼šé€šè¿‡DiscordèŠå¤©ç¤¾åŒºç­‰æ¸ é“è·å–å¸®åŠ©ã€äº¤æµç»éªŒã€‚

1.2 å¾®è°ƒæŠ€æœ¯æ¦‚è§ˆ
----------

**ä»€ä¹ˆæ˜¯å¾®è°ƒï¼Ÿ**

å¾®è°ƒï¼ˆFine-tuningï¼‰æ˜¯ä¸€ç§åŸºäºé¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ã€åˆ©ç”¨ç‰¹å®šé¢†åŸŸæ•°æ®è¿›ä¸€æ­¥è®­ç»ƒçš„æŠ€æœ¯ï¼Œå…¶æ ¸å¿ƒç›®æ ‡æå‡æ¨¡å‹åœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚è¯¥æŠ€æœ¯ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªå±‚é¢ï¼šä¸€æ˜¯å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡ŒæŒç»­çš„æ— ç›‘ç£é¢„è®­ç»ƒï¼›äºŒæ˜¯æŒ‡ä»¤å¾®è°ƒï¼ˆSFTï¼‰ï¼Œå³å¼•å¯¼æ¨¡å‹å­¦ä¹ å¦‚ä½•æ ¹æ®æŒ‡ä»¤è°ƒç”¨å·²æœ‰çŸ¥è¯†ï¼Œå®Œæˆç‰¹å®šæ ¼å¼çš„ä»»åŠ¡æˆ–åŒ¹é…ç‰¹å®šé£æ ¼ã€‚é€šè¿‡å¾®è°ƒï¼Œé€šç”¨å¤§æ¨¡å‹èƒ½å¤Ÿé€æ­¥è½¬åŒ–ä¸ºä¸“ä¸šåŒ–çš„é¢†åŸŸä¸“å®¶ã€‚ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä¸åŒï¼Œå¾®è°ƒå°†çŸ¥è¯†ç›´æ¥å†…åŒ–è‡³æ¨¡å‹å‚æ•°ä¸­ï¼Œå®ç°æ›´æ·±å±‚æ¬¡çš„èƒ½åŠ›èåˆã€‚æœ¬æ–‡èšç„¦äºå¤§è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤å¾®è°ƒã€‚

é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆè¦è¿›è¡Œå¾®è°ƒï¼Ÿ

1.  çŸ¥è¯†å¢å¼ºï¼šå‘æ¨¡å‹æ³¨å…¥é¢†åŸŸæ–°çŸ¥è¯†ï¼Œæ‰©å±•å…¶è®¤çŸ¥è¾¹ç•Œ
2.  è¡Œä¸ºå®šåˆ¶ï¼šè°ƒæ•´æ¨¡å‹çš„è¾“å‡ºé£æ ¼ã€è¯­æ°”åŠå“åº”æ–¹å¼
3.  æ€§èƒ½ä¼˜åŒ–ï¼šæå‡æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„å‡†ç¡®æ€§ã€ç›¸å…³æ€§å’Œå¯é æ€§

åˆ©ç”¨Unslothå®ç°å®Œæ•´æŒ‡ä»¤å¾®è°ƒè®­ç»ƒçš„æ•™ç¨‹è§ï¼š [How To Fine-tune & Run LLMs](https://docs.unsloth.ai/models/tutorials-how-to-fine-tune-and-run-llms)ã€‚

**å¾®è°ƒå¸¸è§é—®é¢˜**

*   å¾®è°ƒèƒ½å¦å¢åŠ æ–°çŸ¥è¯†ï¼Ÿ  
    å¯ä»¥ã€‚åªè¦è®­ç»ƒæ•°æ®ä¸­åŒ…å«æ–°ä¿¡æ¯ï¼Œæ¨¡å‹å°±èƒ½æœ‰æ•ˆå­¦ä¹ å¹¶æŒæ¡æ–°çš„çŸ¥è¯†æˆ–æ¨¡å¼ã€‚
    
*   RAGæ˜¯å¦ä¸€å®šä¼˜äºå¾®è°ƒï¼Ÿ  
    å¹¶éå¦‚æ­¤ã€‚ç»è¿‡è‰¯å¥½ä¼˜åŒ–çš„å¾®è°ƒæ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šå¯ä»¥åª²ç¾ç”šè‡³è¶…è¶ŠRAGç³»ç»Ÿã€‚å€ŸåŠ©å¦‚Unslothç­‰é«˜æ•ˆè®­ç»ƒå·¥å…·ï¼Œå¾®è°ƒçš„æŠ€æœ¯é—¨æ§›ä¹Ÿæ˜¾è‘—é™ä½ã€‚
    
*   å¾®è°ƒæˆæœ¬æ˜¯å¦å¾ˆé«˜ï¼Ÿ  
    å¹¶éå¿…ç„¶ã€‚é‡‡ç”¨LoRA/QLoRAç­‰å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼Œç»“åˆå…è´¹æˆ–ä½æˆæœ¬çš„ç®—åŠ›èµ„æºï¼Œå®Œå…¨èƒ½å¤Ÿå®ç°ä½æˆæœ¬ç”šè‡³é›¶æˆæœ¬çš„å¾®è°ƒã€‚
    
*   å¾®è°ƒå¦‚ä½•ä¸å…¶ä»–æŠ€æœ¯ç»“åˆï¼Ÿ  
    å¾®è°ƒä¸RAGå…·æœ‰äº’è¡¥ä¼˜åŠ¿ï¼šå¾®è°ƒèµ‹äºˆæ¨¡å‹é¢†åŸŸåŸºç¡€èƒ½åŠ›ï¼ŒRAGåˆ™æä¾›å®æ—¶å¤–éƒ¨çŸ¥è¯†ï¼Œå…¼é¡¾ä¸“ä¸šæ€§ä¸æ—¶æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¹Ÿå¯åœ¨å¾®è°ƒåé€šè¿‡å¥–åŠ±æœºåˆ¶è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹è¡¨ç°ã€‚
    

![https://medium.com/decodingml/8b-parameters-1-gpu-no-problems-the-ultimate-llm-fine-tuning-pipeline-f68ef6c359c2](https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A05-%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83%E6%A1%86%E6%9E%B6Unsloth%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97/img/img2.jpg)

1.3 Unslothå®‰è£…
-------------

**Unslothå®‰è£…å‘½ä»¤**

Unslothå¯ç›´æ¥åœ¨Linuxã€Windowsã€Google Colabç­‰ç³»ç»Ÿä¸Šè¿è¡Œï¼Œç›´æ¥å®‰è£…å‘½ä»¤å¦‚ä¸‹ï¼š

> pip install unsloth

**ç³»ç»Ÿè¦æ±‚**

*   æ“ä½œç³»ç»Ÿï¼šæ”¯æŒLinuxä¸Windows
*   æ˜¾å¡ï¼š
    *   å…¼å®¹2018å¹´åŠä¹‹åå‘å¸ƒçš„NVIDIAæ˜¾å¡
    *   éœ€è‡³å°‘æ”¯æŒCUDA 7.0ï¼Œä¾‹å¦‚V100ã€T4ã€Titan Vã€RTX 20/30/40ç³»åˆ—ã€A100ã€H100ã€L40ç­‰
    *   GTX 1070/1080å¯è¿è¡Œï¼Œä½†æ€§èƒ½è¾ƒæ…¢
    *   æ”¯æŒAMDä¸Intelçš„CPUï¼ŒApple Siliconç‰ˆæœ¬ç›®å‰ä»åœ¨å¼€å‘ä¸­
*   è½¯ä»¶å…¼å®¹ï¼šå®‰è£…Unslothæ—¶å°†è‡ªåŠ¨æ›´æ–°å·²æœ‰ç¯å¢ƒä¸­çš„torchã€transformersç­‰åº“è‡³æœ€æ–°ç‰ˆæœ¬ï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†ç‰ˆæœ¬å†²çª
*   ä¾èµ–é¡¹ï¼šéœ€å®‰è£…xformersã€torchã€BitsandBytesåŠtriton

**å¾®è°ƒæ˜¾å­˜è¦æ±‚**

åœ¨ä½¿ç”¨Unslothå¯¹å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒæ—¶ï¼Œå‡ºç°å†…å­˜ä¸è¶³é”™è¯¯é€šå¸¸æ˜¯ç”±äºæ‰¹å¤„ç†å¤§å°è®¾ç½®è¿‡é«˜ã€‚å°†æ‰¹å¤„ç†å¤§å°è°ƒæ•´ä¸º1ã€2æˆ–3å¯æœ‰æ•ˆé™ä½æ˜¾å­˜å ç”¨ã€‚

ä¸‹è¡¨åˆ—å‡ºäº†ä¸åŒå‚æ•°è§„æ¨¡ä¸å¾®è°ƒæ–¹æ³•ä¸‹çš„æ˜¾å­˜éœ€æ±‚ï¼Œå…¶ä¸­QLoRAä½¿ç”¨4ä½ç²¾åº¦ï¼ŒLoRAä½¿ç”¨16ä½ç²¾åº¦ã€‚æ‰€åˆ—æ•°æ®ä¸ºç†è®ºæœ€ä½å€¼ï¼Œéƒ¨åˆ†æ¨¡å‹å®é™…å¯èƒ½éœ€è¦æ›´å¤šæ˜¾å­˜ã€‚è¯¦è§ï¼š[Unsloth-requirements](https://docs.unsloth.ai/get-started/beginner-start-here/unsloth-requirements)ã€‚

æ¨¡å‹å‚æ•°

QLoRAï¼ˆ4ä½ï¼‰æ˜¾å­˜

LoRAï¼ˆ16ä½ï¼‰æ˜¾å­˜

3B

3.5GB

8GB

7B

5GB

19GB

8B

6GB

22GB

9B

6.5GB

24GB

11B

7.5GB

29GB

14B

8.5GB

33GB

27B

22GB

64GB

32B

26GB

76GB

40B

30GB

96GB

70B

41GB

164GB

81B

48GB

192GB

90B

53GB

212GB

405B

237GB

950GB

2 Unslothå¾®è°ƒæ•™ç¨‹
=============

2.1 æ¨¡å‹ä¸è®­ç»ƒæ–¹æ³•é€‰æ‹©
-------------

**ä¼˜å…ˆé€‰æ‹©æŒ‡ä»¤æ¨¡å‹**

å¤§è¯­è¨€æ¨¡å‹ä¸»è¦åˆ†ä¸ºåŸºåº§æ¨¡å‹ï¼ˆBaseï¼‰å’ŒæŒ‡ä»¤æ¨¡å‹ï¼ˆInstructï¼‰ä¸¤ç±»ï¼Œä¸¤è€…å‡åŸºäºæ–‡æœ¬é¢„æµ‹ä»»åŠ¡è¿›è¡Œè®­ç»ƒã€‚åŸºåº§æ¨¡å‹é€šå¸¸ä»…ç»è¿‡é¢„è®­ç»ƒå’Œå°‘é‡é€šç”¨æŒ‡ä»¤å¾®è°ƒï¼›æŒ‡ä»¤æ¨¡å‹åˆ™åœ¨åŸºåº§æ¨¡å‹åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥é€šè¿‡å¤§è§„æ¨¡æŒ‡ä»¤å¾®è°ƒå’Œäººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å…¶ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚å¸¸æåˆ°çš„å¯¹è¯æ¨¡å‹ï¼ˆChat Modelï¼‰æœ¬è´¨ä¸Šå±äºæŒ‡ä»¤æ¨¡å‹ã€‚

é€‰æ‹©åŸºåº§æ¨¡å‹è¿˜æ˜¯æŒ‡ä»¤æ¨¡å‹ï¼Œé€šå¸¸å–å†³äºæ•°æ®è§„æ¨¡ã€è´¨é‡ä¸ç±»å‹ï¼š

*   1000è¡Œä»¥ä¸Šæ•°æ®ï¼šæ•°æ®é‡è¾ƒå¤§æ—¶ï¼Œå¾®è°ƒåŸºåº§æ¨¡å‹æ•ˆæœæ›´ä½³ã€‚
*   300â€“1000è¡Œé«˜è´¨é‡æ•°æ®ï¼šä¸­ç­‰è§„æ¨¡é«˜è´¨é‡æ•°æ®ä¸‹ï¼Œå¾®è°ƒåŸºåº§æ¨¡å‹æˆ–æŒ‡ä»¤æ¨¡å‹å‡å¯ã€‚
*   300è¡Œä»¥ä¸‹æ•°æ®ï¼šæ•°æ®é‡è¾ƒå°æ—¶ï¼Œå»ºè®®é€‰æ‹©æŒ‡ä»¤æ¨¡å‹ã€‚å¾®è°ƒåæ—¢èƒ½é€‚é…ç‰¹å®šä»»åŠ¡ï¼Œåˆå¯ä¿ç•™å…¶å†…ç½®çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œæ— éœ€é¢å¤–æç¤ºå³å¯å“åº”ä¸€èˆ¬æŒ‡ä»¤ï¼ˆé™¤ééœ€å¤§å¹…æ”¹å˜æ¨¡å‹è¡Œä¸ºï¼‰ã€‚

æ¨èä¼˜å…ˆä»æŒ‡ä»¤æ¨¡å‹å…¥æ‰‹ï¼ŒåŸå› åŒ…æ‹¬ï¼š

*   æ”¯æŒç›´æ¥ä½¿ç”¨ChatMLã€ShareGPTç­‰å¯¹è¯æ¨¡æ¿è¿›è¡Œå¾®è°ƒï¼Œæ‰€éœ€æ•°æ®é‡æ›´å°‘ï¼›
*   åŸºåº§æ¨¡å‹éœ€ä¾èµ–Alpacaã€Vicunaç­‰ç‰¹å®šæ¨¡æ¿ï¼Œå¯¹æ•°æ®é‡è¦æ±‚ç›¸å¯¹æ›´é«˜ã€‚

![https://medium.com/data-science-in-your-pocket/unsloth-the-fastest-way-to-fine-tune-llms-041bb6a785ac](https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A05-%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83%E6%A1%86%E6%9E%B6Unsloth%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97/img/img3.jpg)

**Unslothæ¨¡å‹æ ¼å¼**

åœ¨Hugging Faceä¸­Unslothä»“åº“ä¸åŒåç¼€ä»£è¡¨æ¨¡å‹çš„é‡åŒ–æ ¼å¼æˆ–ä¼˜åŒ–ç‰ˆæœ¬ï¼Œé€‰æ‹©æ—¶å¯å‚è€ƒä»¥ä¸‹è¯´æ˜ï¼š

*   åç§°ä»¥`unsloth-bnb-4bit` ç»“å°¾ï¼šä¸ºUnslothåŠ¨æ€4ä½é‡åŒ–æ¨¡å‹ã€‚å…¶æ˜¾å­˜å ç”¨ç•¥é«˜äºæ ‡å‡†ä½é‡åŒ–æ¨¡å‹ï¼Œä½†ç²¾åº¦æ˜¾è‘—æ›´é«˜ã€‚
*   åç§°ä»…ä»¥`bnb-4bit` ç»“å°¾ï¼ˆä¸å«`unsloth`ï¼‰ï¼šä¸ºæ ‡å‡†ä½é‡åŒ–æ¨¡å‹ã€‚
*   æ— åç¼€ï¼šä¸ºåŸå§‹16ä½æˆ–8ä½æ ¼å¼ã€‚è¿™ç±»æ¨¡å‹æ˜¯å®˜æ–¹å‘å¸ƒçš„åŸå§‹ç‰ˆæœ¬ï¼Œä½†Unslothä¼šåœ¨éƒ¨åˆ†ç‰ˆæœ¬ä¸­åŠ å…¥å¯¹è¯æ¨¡æ¿ã€åˆ†è¯å™¨ç­‰é‡è¦ä¿®å¤ã€‚

åœ¨æ­¤åŸºç¡€ä¸Šï¼Œåœ¨å‡†å¤‡å¾®è°ƒæ—¶ï¼Œé¦–è¦å†³ç­–ä¹‹ä¸€å°±æ˜¯é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼š

1.  é€‰æ‹©ä¸ç”¨ä¾‹åŒ¹é…çš„æ¨¡å‹  
    ä¾‹å¦‚ï¼šè‹¥è¿›è¡ŒåŸºäºå›¾åƒçš„è®­ç»ƒï¼Œå¯é€‰æ‹©Llama 3.2 Visionç­‰è§†è§‰æ¨¡å‹ï¼›é’ˆå¯¹ä»£ç æ•°æ®é›†ï¼Œåˆ™é€‚åˆé€‰ç”¨Qwen Coder 2.5ç­‰ä¸“ç”¨æ¨¡å‹ã€‚
    
2.  ç•™æ„æˆæƒä¸è¦æ±‚  
    ä¸åŒæ¨¡å‹å¯èƒ½æœ‰ç‰¹å®šçš„æˆæƒæ¡æ¬¾å’Œç³»ç»Ÿè¦æ±‚ï¼ŒåŠ¡å¿…ä»”ç»†æŸ¥çœ‹ã€‚
    
3.  è¯„ä¼°å­˜å‚¨ã€è®¡ç®—èƒ½åŠ›å’Œæ•°æ®é›†  
    å¯å‚è€ƒUnslothçš„æ˜¾å­˜æŒ‡å—ï¼Œç¡®å®šç›®æ ‡æ¨¡å‹æ‰€éœ€çš„æ˜¾å­˜é…ç½®ã€‚æ•°æ®é›†çš„ç±»å‹ä¼šå½±å“æ¨¡å‹çš„é€‰æ‹©ï¼ŒåŒæ—¶ä¹Ÿä¼šå†³å®šè®­ç»ƒæ‰€éœ€çš„æ—¶é—´ã€‚
    
4.  é€‰å®šæ¨¡å‹åŠå‚æ•°  
    å»ºè®®é€‰ç”¨æœ€æ–°æ¨¡å‹ï¼Œä»¥è·å¾—æœ€ä½³æ€§èƒ½å’ŒåŠŸèƒ½ã€‚å¯ä»¥é€šè¿‡æµè§ˆUnslothçš„æ¨¡å‹ç›®å½•ï¼ŒåŠæ—¶äº†è§£æœ€æ–°ä¸”ç›¸å…³çš„é€‰é¡¹ã€‚
    

å¯ä»¥å°†æ¨¡å‹åç§°ä¿®æ”¹ä¸ºä»»æ„åç§°ï¼Œåªéœ€ä½¿å…¶ä¸Hugging Faceä¸ŠUnslothä»“åº“çš„æ¨¡å‹åç§°ç›¸åŒ¹é…å³å¯ï¼Œä¾‹å¦‚ â€œunsloth/llama-3.1-8b-unsloth-bnb-4bitâ€ã€‚å¯¹äºåˆå­¦è€…ï¼Œå»ºè®®ä»è¯¸å¦‚`unsloth/llama-3.1-8b-unsloth-bnb-4bit`ä¹‹ç±»çš„å°å‹æŒ‡ä»¤æ¨¡å‹å…¥æ‰‹ï¼Œå†é€æ­¥æ¢ç´¢æ›´å¤šå¯èƒ½æ€§ã€‚

æ‰€æœ‰Unslothæ”¯æŒçš„æ¨¡å‹è§ï¼š[Unsloth Models](https://docs.unsloth.ai/get-started/all-our-models)ã€‚

**è®­ç»ƒæ–¹æ³•çš„é€‰æ‹©ï¼šLoRAä¸QLoRA**

åœ¨å®æ–½å¾®è°ƒæ—¶ï¼Œé™ä½è®¡ç®—ä¸å†…å­˜éœ€æ±‚çš„ä¸»æµæŠ€æœ¯ä¸»è¦æœ‰ä»¥ä¸‹ä¸¤ç§ï¼š

*   LoRAï¼ˆä½ç§©é€‚é…ï¼‰ï¼šä»…å¾®è°ƒå°‘é‡16ä½çš„é€‚é…å™¨æƒé‡çŸ©é˜µï¼Œä¿æŒåŸå§‹æ¨¡å‹å‚æ•°åŸºæœ¬ä¸å˜ï¼Œä»è€Œæ˜¾è‘—å‡å°‘è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦æ›´æ–°çš„å‚æ•°é‡ã€‚
*   QLoRAï¼ˆé‡åŒ–LoRAï¼‰ï¼šåœ¨LoRAåŸºç¡€ä¸Šå¼•å…¥æ¨¡å‹æƒé‡çš„4ä½é‡åŒ–ï¼Œå¯åœ¨æœ‰é™ç¡¬ä»¶èµ„æºä¸‹é«˜æ•ˆå¾®è°ƒè¶…å¤§è§„æ¨¡æ¨¡å‹ï¼Œé€šè¿‡4ä½ç²¾åº¦æ˜¾è‘—é™ä½å†…å­˜å ç”¨ä¸è®¡ç®—å¼€é”€ã€‚

å»ºè®®ä»QLoRAå…¥æ‰‹ï¼Œå®ƒæ˜¯å½“å‰é«˜æ•ˆä¸”æ˜“äºä½¿ç”¨çš„å¾®è°ƒæ–¹æ³•ä¹‹ä¸€ã€‚å€ŸåŠ©å¦‚Unslothæ‰€é‡‡ç”¨çš„åŠ¨æ€4ä½é‡åŒ–æŠ€æœ¯ï¼Œå…¶ç²¾åº¦æŸå¤±ç›¸è¾ƒäºæ ‡å‡†çš„16ä½LoRAå¾®è°ƒå·²å‡ ä¹å¯å¿½ç•¥ä¸è®¡ã€‚

![https://towardsdatascience.com/fine-tune-llama-3-1-ultra-efficiently-with-unsloth-7196c7165bab/](https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A05-%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83%E6%A1%86%E6%9E%B6Unsloth%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97/img/img4.jpg)

å·²å¾®è°ƒçš„æ¨¡å‹å¯å†æ¬¡å¤šæ¬¡å¾®è°ƒï¼Œä½†æœ€ä½³åšæ³•æ˜¯åˆå¹¶æ‰€æœ‰æ•°æ®é›†ä¸€æ¬¡æ€§å®Œæˆã€‚è‹¥åŸºäºå·²å¾®è°ƒæ¨¡å‹ç»­è®­ï¼Œå¯èƒ½æ”¹å˜å…¶æ­¤å‰è·å¾—çš„è´¨é‡ä¸çŸ¥è¯†ã€‚éœ€æ³¨æ„ï¼Œå®éªŒéªŒè¯è‡³å…³é‡è¦ã€‚å¾®è°ƒæ— å”¯ä¸€æœ€ä½³æ–¹æ³•ï¼Œä»…æœ‰é€‚é…ä¸åŒåœºæ™¯çš„æœ€ä½³å®è·µï¼Œéœ€å°è¯•å¤šç§æ–¹æ³•ä¸é…ç½®ï¼Œæ‰èƒ½æ‰¾åˆ°æœ€å¥‘åˆè‡ªèº«æ•°æ®é›†åŠéœ€æ±‚çš„æ–¹æ¡ˆã€‚

2.2 LoRAå’Œæ•°æ®é›†
------------

### 2.2.1 LoRAä»‹ç»

LoRAæä¾›äº†ä¼—å¤šè¶…å‚æ•°ï¼ˆå¦‚å­¦ä¹ ç‡ã€è®­ç»ƒè½®æ¬¡ç­‰ï¼‰ï¼Œå…¶ç»„åˆå¯èƒ½è¾¾æ•°ç™¾ä¸‡ç§ã€‚åˆç†é€‰æ‹©å‚æ•°å¯¹å¾®è°ƒè‡³å…³é‡è¦ï¼Œç›´æ¥å½±å“æ¨¡å‹çš„å‡†ç¡®æ€§ã€ç¨³å®šæ€§ä¸è¾“å‡ºè´¨é‡ã€‚UnslothåŸºäºæ•°ç™¾ç¯‡ç ”ç©¶è®ºæ–‡ä¸å®éªŒç»éªŒï¼Œæ€»ç»“äº†è¿™äº›å‚æ•°çš„æœ€ä½³å®è·µï¼Œå¹¶è§£æäº†å®ƒä»¬å¯¹æ¨¡å‹è¡Œä¸ºçš„å½±å“ã€‚è™½ç„¶å»ºè®®ç›´æ¥ä½¿ç”¨å…¶é»˜è®¤é…ç½®ï¼Œä½†ç†è§£è¿™äº›æ¦‚å¿µå°†æœ‰åŠ©äºæ›´å…¨é¢åœ°æŒæ§æ•´ä¸ªå¾®è°ƒè¿‡ç¨‹ã€‚

è¶…å‚æ•°è°ƒæ•´çš„ç›®æ ‡æ˜¯åœ¨æå‡æ¨¡å‹å‡†ç¡®ç‡çš„åŒæ—¶é¿å…è¿‡æ‹Ÿåˆæˆ–æ¬ æ‹Ÿåˆã€‚å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚Llama 70Bï¼‰ï¼Œå…¶æƒé‡åŒ…å«æ•°ç™¾äº¿å‚æ•°ï¼Œé€šå¸¸ä¸ä¼šå…¨éƒ¨å‚ä¸æ›´æ–°ï¼Œè€Œæ˜¯é‡‡ç”¨LoRAç­‰å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ã€‚LoRAåœ¨æ¯ä¸€å±‚æ—å¼•å…¥ä¸¤ä¸ªå°å‹çŸ©é˜µAå’ŒBï¼Œä»…ä¼˜åŒ–è¿™ä¸¤ä¸ªçŸ©é˜µï¼Œå®é™…è®­ç»ƒå‚æ•°é‡é€šå¸¸ä»…å æ€»é‡çš„1%å·¦å³ã€‚é€šè¿‡å†»ç»“åŸå§‹æƒé‡ã€ä»…æ›´æ–°æ–°å¢çš„é€‚é…å™¨å‚æ•°ï¼ŒLoRAæ˜¾è‘—é™ä½äº†è®¡ç®—ä¸å­˜å‚¨å¼€é”€ï¼ŒåŒæ—¶åœ¨å¤šæ•°ä»»åŠ¡ä¸­ä¿æŒæ¨¡å‹æ€§èƒ½ï¼Œå·²æˆä¸ºå½“å‰å¤§æ¨¡å‹å¾®è°ƒçš„ä¸»æµæ–¹æ³•ä¹‹ä¸€ã€‚å…³äºLoRAçš„è¯¦ç»†ä»‹ç»è§ï¼š[LoRA Hyperparameters Guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide)ã€‚

ä»¥ä¸‹ç®€è¦ä»‹ç»ç›¸å…³å‚æ•°ï¼š

**å­¦ä¹ ç‡**

å®šä¹‰æ¨¡å‹è®­ç»ƒä¸­æ¯ä¸€æ­¥çš„æƒé‡æ›´æ–°å¹…åº¦ã€‚

*   è¾ƒé«˜å­¦ä¹ ç‡ï¼šæ”¶æ•›å¿«ï¼Œä½†è¿‡é«˜æ˜“é€ æˆè®­ç»ƒéœ‡è¡ï¼Œå¯èƒ½é”™è¿‡æœ€ä¼˜è§£ã€‚
*   è¾ƒä½å­¦ä¹ ç‡ï¼šè®­ç»ƒæ›´ç¨³å®šã€ç²¾åº¦é«˜ï¼Œä½†æ”¶æ•›æ…¢ã€è€—æ—¶é•¿ï¼›è™½å¸¸è¢«è®¤ä¸ºæ˜“æ¬ æ‹Ÿåˆï¼Œå®é™…ä¹Ÿå¯èƒ½å¼•å‘è¿‡æ‹Ÿåˆæˆ–é˜»ç¢æœ‰æ•ˆå­¦ä¹ ã€‚
*   å¸¸ç”¨èŒƒå›´ï¼š2e-4ï¼ˆ0.0002ï¼‰è‡³ 5e-6ï¼ˆ0.000005ï¼‰
    *   LoRA/QLoRAå¾®è°ƒï¼šå»ºè®®åˆå§‹å€¼2e-4
    *   å¼ºåŒ–å­¦ä¹ ï¼šæ¨è5e-6
    *   å…¨é‡å¾®è°ƒï¼šé€šå¸¸é€‚ç”¨æ›´ä½å­¦ä¹ ç‡

**è®­ç»ƒæ¬¡æ•°ï¼ˆEpochsï¼‰**

æŒ‡æ¨¡å‹å®Œæ•´éå†è®­ç»ƒæ•°æ®é›†çš„æ¬¡æ•°ã€‚

*   è½®æ¬¡è¿‡å¤šï¼šå¯èƒ½æå‡è®­ç»ƒé›†ä¸Šçš„è¡¨ç°ï¼Œä½†ä¹Ÿå®¹æ˜“å¯¼è‡´è¿‡æ‹Ÿåˆï¼Œé™ä½æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚
*   è½®æ¬¡è¿‡å°‘ï¼šè®­ç»ƒæ—¶é—´çŸ­ä¸”ä¸æ˜“è¿‡æ‹Ÿåˆï¼Œä½†è‹¥æ¨¡å‹æœªèƒ½å……åˆ†å­¦ä¹ æ•°æ®è§„å¾‹ï¼Œå¯èƒ½é€ æˆæ¬ æ‹Ÿåˆã€‚
*   å»ºè®®ï¼šå¤šæ•°æŒ‡ä»¤å¾®è°ƒä»»åŠ¡å»ºè®®è®­ç»ƒ1â€“3è½®ã€‚è¶…è¿‡3è½®åæ”¶ç›Šé€’å‡ï¼Œè¿‡æ‹Ÿåˆé£é™©æ˜¾è‘—å¢åŠ ã€‚

**è¶…å‚æ•°è®¾ç½®**

å…¶ä»–å¸¸ç”¨å‚æ•°å¦‚ä¸‹ï¼š

Hyperparameter

åŠŸèƒ½è¯´æ˜

æ¨èå€¼

Rank(r)

æ§åˆ¶å¯è®­ç»ƒå‚æ•°æ•°é‡ï¼Œç§©è¶Šé«˜èƒ½åŠ›è¶Šå¼ºï¼Œå†…å­˜å ç”¨è¶Šå¤§

8,16,32,64,128ï¼ˆå¸¸ç”¨16æˆ–32ï¼‰

LoRA Alpha(lora\_alpha)

ç”¨äºæ§åˆ¶ä½ç§©çŸ©é˜µçš„ç¼©æ”¾ç³»æ•°

é€šå¸¸è®¾ä¸ºræˆ–2r

LoRA Dropout(lora\_dropout)

è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒéƒ¨åˆ†æ¿€æ´»å€¼ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ

0ï¼ˆé»˜è®¤0.1ï¼‰

Target Modules(target\_modules)

æŒ‡å®šæ·»åŠ LoRAçš„æ¨¡å‹æ¨¡å—

q\_proj,k\_proj,v\_proj,o\_proj,gate\_proj,up\_proj,down\_projï¼ˆæ¨èå…¨éƒ¨ï¼‰

Weight Decay

æŠ‘åˆ¶æƒé‡è¿‡å¤§ï¼Œæå‡æ³›åŒ–èƒ½åŠ›

0.01è‡³0.1

Warmup Steps

è®­ç»ƒåˆæœŸé€æ­¥æé«˜å­¦ä¹ ç‡ï¼Œç¨³å®šè®­ç»ƒ

æ€»æ­¥æ•°çš„5%â€“10%

Scheduler Type

è®­ç»ƒè¿‡ç¨‹ä¸­è°ƒæ•´å­¦ä¹ ç‡çš„æ–¹å¼

linearæˆ–cosine

Seed

å›ºå®šéšæœºæ•°ç§å­ï¼Œä¿è¯ç»“æœå¯å¤ç°

ä»»æ„æ•´æ•°ï¼ˆå¦‚42ï¼‰

å…³äºLoRAè¶…å‚æ•°è¯¦ç»†ä»‹ç»å¯è§ï¼š[LoRAã€QLoRAã€QA-LoRA åŸç†ç¬”è®°](https://zhuanlan.zhihu.com/p/671089942)ã€‚

**ä½œç”¨æ¨¡å—**

åœ¨QLoRAä¸LoRAçš„å¯¹æ¯”ä¸­ï¼ŒQLoRAé‡‡ç”¨4-bitç²¾åº¦ï¼Œå¯é™ä½è¶…è¿‡75%çš„æ˜¾å­˜å ç”¨ï¼Œè€ŒLoRAï¼ˆ16-bitï¼‰åœ¨ç²¾åº¦å’Œé€Ÿåº¦ä¸Šç•¥ä¼˜ã€‚æ ¹æ®è®ºæ–‡åŠå®éªŒç»éªŒï¼Œå»ºè®®å°†LoRAåŒæ—¶ä½œç”¨äºæ³¨æ„åŠ›å±‚ä¸MLPå±‚ï¼ˆå¦‚`target_modules=["q_proj","k_proj","v_proj","o_proj","gate_proj","up_proj","down_proj"]`ï¼‰ï¼Œä»¥æœ‰æ•ˆæå‡æ¨¡å‹ç²¾åº¦ã€‚

ä¸‹å›¾å¯¹æ¯”äº†ä¸åŒç›®æ ‡æ¨¡å—é…ç½®ä¸‹LoRAä¸QLoRAçš„Rougeåˆ†æ•°ï¼ˆåˆ†æ•°è¶Šé«˜è¶Šå¥½ï¼‰ï¼Œå‰ä¸‰ç»„åˆ†åˆ«ä¸ºï¼š

*   QLoRA-Allï¼šå°†LoRAåº”ç”¨äºæ‰€æœ‰FFN/MLPå±‚å’Œæ³¨æ„åŠ›å±‚ï¼Œæ˜¯æœ¬å®éªŒä¸­è¡¨ç°æœ€ä½³çš„é…ç½®ã€‚
*   QLoRA-FFNï¼šä»…åœ¨FFNå±‚ï¼ˆåŒ…æ‹¬gate\_proj, up\_proj, down\_projï¼‰ä¸Šåº”ç”¨LoRAã€‚
*   QLoRA-Attentionï¼šä»…åœ¨æ³¨æ„åŠ›å±‚ï¼ˆåŒ…æ‹¬q\_proj, k\_proj, v\_proj, o\_projï¼‰ä¸Šåº”ç”¨LoRAã€‚

![https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide](https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A05-%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83%E6%A1%86%E6%9E%B6Unsloth%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97/img/img5.jpg)

**æ¢¯åº¦ç´¯ç§¯ä¸æ‰¹æ¬¡å¤§å°çš„ç­‰æ•ˆå…³ç³»**

è¾ƒå¤§çš„æœ‰æ•ˆæ‰¹æ¬¡é€šå¸¸èƒ½ç¨³å®šè®­ç»ƒï¼Œè€Œè¾ƒå°çš„æ‰¹æ¬¡å¯èƒ½å› æ¢¯åº¦æ–¹å·®å¢å¤§è€Œå½±å“æ”¶æ•›ã€‚æœ‰æ•ˆæ‰¹æ¬¡å¤§å°ç”±ä»¥ä¸‹ä¸¤ä¸ªå‚æ•°å…±åŒå†³å®šï¼š

> æœ‰æ•ˆæ‰¹æ¬¡å¤§å° = batch\_size Ã— gradient\_accumulation\_steps

ä»¥ä¸‹ä¸ºUnslothæ¨èé…ç½®ï¼Œé€‚ç”¨äºå¤šæ•°å¾®è°ƒåœºæ™¯ï¼š

å‚æ•°

å®šä¹‰

å½±å“

æ¨èå€¼

batch\_size

å•æ¬¡å‰å‘æˆ–åå‘ä¼ æ’­ä¸­å„GPUå¤„ç†çš„æ ·æœ¬æ•°

ä¸»è¦å½±å“å†…å­˜å ç”¨

2

gradient\_accumulation\_steps

æƒé‡æ›´æ–°å‰ç´¯ç§¯æ¢¯åº¦çš„æ­¥æ•°

æ¨¡æ‹Ÿæ›´å¤§æ‰¹æ¬¡ä»¥èŠ‚çœæ˜¾å­˜ï¼›æ­¥æ•°å¢åŠ ä¼šå»¶é•¿æ¯è½®è®­ç»ƒæ—¶é—´

8

æœ‰æ•ˆæ‰¹æ¬¡å¤§å°

å®é™…ç”¨äºæ¢¯åº¦æ›´æ–°çš„æ ·æœ¬æ€»æ•°

å½±å“è®­ç»ƒç¨³å®šæ€§ä¸æ€§èƒ½

16ï¼ˆ2Ã—8ï¼‰

![https://huggingface.co/docs/trl/main/distributing_training](https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A05-%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83%E6%A1%86%E6%9E%B6Unsloth%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97/img/img6.jpg)

### 2.2.2 é¿å…è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ

**è¿‡æ‹Ÿåˆ**

æ·±åº¦å­¦ä¹ æ¨¡å‹å®¹æ˜“è¿‡åº¦è®°å¿†è®­ç»ƒæ•°æ®å’Œå™ªå£°ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸‹é™ã€‚å½“è®­ç»ƒæŸå¤±ä½äº0.2æ—¶ï¼Œå¸¸æç¤ºè¿‡æ‹Ÿåˆï¼Œæ¨¡å‹åœ¨æœªçŸ¥ä»»åŠ¡ä¸Šè¡¨ç°å˜å·®ã€‚

ä¸€ç§ç®€å•çš„ç¼“è§£æ–¹æ³•æ˜¯LoRA Alphaç¼©æ”¾ï¼šå°†æ¯ä¸ªLoRAçŸ©é˜µçš„alphaå€¼ä¹˜ä»¥0.5ã€‚å…¶åŸç†ç±»ä¼¼äºæƒé‡å¹³å‡ï¼Œå°†åŸºç¡€æ¨¡å‹ä¸LoRAæƒé‡ç›¸åŠ åé™¤ä»¥2ï¼Œç­‰åŒäºalphaå‡åŠã€‚è¯¥æ–¹æ³•é€šè¿‡å¹³å‡åŒ–æœºåˆ¶æŠ‘åˆ¶è¿‡æ‹Ÿåˆï¼Œæå‡æ¨¡å‹åœ¨æœªçŸ¥ä»»åŠ¡ä¸Šçš„æ³›åŒ–æ€§èƒ½ã€‚

å…¶ä»–å¸¸ç”¨è§£å†³æ–¹æ¡ˆåŒ…æ‹¬ï¼š

*   è°ƒæ•´å­¦ä¹ ç‡ï¼šè¿‡é«˜æ˜“å¼•å‘è¿‡æ‹Ÿåˆï¼Œè®­ç»ƒå‘¨æœŸçŸ­æ—¶å°¤éœ€æ³¨æ„ï¼›å‘¨æœŸè¾ƒé•¿å¯é€‚å½“æé«˜ã€‚å»ºè®®å°è¯•ä¸åŒå–å€¼ä»¥å¯»ä¼˜ã€‚
*   æ§åˆ¶è®­ç»ƒè½®æ•°ï¼šé€šå¸¸1â€“3è½®å³å¯ï¼Œé¿å…è¿‡åº¦è®­ç»ƒã€‚
*   å¢å¤§æƒé‡è¡°å‡ï¼ˆweight\_decayï¼‰ï¼šåˆå§‹å»ºè®®è®¾ä¸º0.01æˆ–0.1ã€‚
*   å¯ç”¨LoRA Dropoutï¼šå¯è®¾ä¸º0.1ä»¥æé«˜æ³›åŒ–èƒ½åŠ›ã€‚
*   å¢å¤§æ‰¹æ¬¡å¤§å°æˆ–æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼šæœ‰åŠ©äºæå‡è®­ç»ƒç¨³å®šæ€§ã€‚
*   æ‰©å±•æ•°æ®é›†ï¼šç»“åˆé«˜è´¨é‡å¼€æºæ•°æ®ä¸è‡ªæœ‰æ•°æ®ï¼Œæ‰©å¤§æ ·æœ¬è§„æ¨¡ã€‚
*   æ—©åœæœºåˆ¶ï¼šéªŒè¯æŸå¤±è¿ç»­å¤šè½®ä¸Šå‡æ—¶è‡ªåŠ¨åœæ­¢è®­ç»ƒã€‚
*   æƒé‡å¹³å‡ï¼šå°†åŸå§‹æ¨¡å‹ä¸å¾®è°ƒåçš„æ¨¡å‹æƒé‡ç›¸åŠ å–å¹³å‡ï¼Œå¹³æ»‘è¾“å‡ºè¡¨ç°ã€‚

**æ¬ æ‹Ÿåˆï¼ˆè¿‡äºæ³›åŒ–ï¼‰**

æŒ‡æ¨¡å‹æœªèƒ½å……åˆ†å­¦ä¹ è®­ç»ƒæ•°æ®ä¸­çš„ç‰¹å¾ï¼Œé€šå¸¸å› æ¨¡å‹å¤æ‚åº¦è¿‡ä½æˆ–è®­ç»ƒä¸è¶³å¯¼è‡´ã€‚æ”¹è¿›æ–¹æ³•åŒ…æ‹¬ï¼š

*   è°ƒæ•´å­¦ä¹ ç‡ï¼šåˆæœŸå¯é€‚å½“æé«˜ä»¥åŠ é€Ÿæ”¶æ•›ï¼Œé•¿æœŸè®­ç»ƒåˆ™éœ€é™ä½ï¼Œéœ€å®éªŒç¡®å®šæœ€ä¼˜å€¼ã€‚
*   å¢åŠ è®­ç»ƒè½®æ¬¡ï¼šå»¶é•¿è®­ç»ƒæ—¶é—´ï¼ŒåŒæ—¶ç›‘æ§éªŒè¯é›†æŸå¤±ä»¥é˜²è¿‡æ‹Ÿåˆã€‚
*   æé«˜LoRAç§©ä¸alphaå€¼ï¼šç§©å»ºè®®ä¸ä½äºalphaï¼Œæ¨¡å‹è¶Šå°æˆ–æ•°æ®è¶Šå¤æ‚ï¼Œç§©åº”è¶Šå¤§ï¼Œé€šå¸¸è®¾ä¸º4è‡³64ã€‚
*   ä½¿ç”¨é¢†åŸŸç›¸å…³æ•°æ®é›†ï¼šç¡®ä¿è®­ç»ƒæ•°æ®è´¨é‡é«˜ä¸”ä¸ç›®æ ‡ä»»åŠ¡ç›¸å…³ã€‚
*   å°†æ‰¹å¤§å°è®¾ä¸º1ï¼šå¢å¼ºæ¯æ¬¡å‚æ•°æ›´æ–°çš„å¼ºåº¦ï¼Œæé«˜æ¨¡å‹å¯¹æ•°æ®çš„æ•æ„Ÿåº¦ã€‚

### 2.2.3 è®­ç»ƒæ•°æ®é›†ä»‹ç»

æ„å»ºå¤§è¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®é›†çš„å…³é”®ç¯èŠ‚ä¹‹ä¸€æ˜¯è®¾è®¡æ°å½“çš„å¯¹è¯æ¨¡æ¿ï¼Œä»¥åˆ©äºæ¨¡å‹é«˜æ•ˆå¤„ç†ã€‚å…³äºæ•°æ®é›†çš„è¯¦ç»†ä»‹ç»è§ï¼š[Unsloth Datasets Guide](https://docs.unsloth.ai/basics/datasets-guide)ã€‚

**æ•°æ®æ ¼å¼è¦æ±‚**

ä¸ºè¿›è¡Œåˆ†è¯å¤„ç†ï¼Œæ•°æ®é›†éœ€é‡‡ç”¨å¯è¢«åˆ†è¯å™¨è¯»å–çš„æ ¼å¼ã€‚è¯·æ³¨æ„ï¼Œæ¯ç§æ•°æ®ç±»å‹å¯¹åº”ä¸åŒçš„æ ¼å¼æ ·å¼ã€‚

æ ¼å¼ç±»å‹

è¯´æ˜

è®­ç»ƒç±»å‹

åŸå§‹è¯­æ–™

æ¥è‡ªç½‘ç«™ã€ä¹¦ç±æˆ–æ–‡ç« ç­‰çš„åŸå§‹æ–‡æœ¬

æŒç»­é¢„è®­ç»ƒï¼ˆCPTï¼‰

æŒ‡ä»¤æ–‡æœ¬

åŒ…å«æŒ‡ä»¤åŠå¯¹åº”è¾“å‡ºçš„ç¤ºä¾‹

ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰

å¯¹è¯è®°å½•

ç”¨æˆ·ä¸AIåŠ©æ‰‹ä¹‹é—´çš„å¤šè½®å¯¹è¯

ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰

å¼ºåŒ–å­¦ä¹ æ•°æ®

ç”¨æˆ·ä¸AIåŠ©æ‰‹çš„å¯¹è¯ï¼ŒåŠ©æ‰‹å›å¤å¸¦æœ‰äººå·¥/æ¨¡å‹/è„šæœ¬çš„æ’åºè¯„åˆ†

å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰

**æ ¼å¼åŒ–æ•°æ®**

åœ¨æ˜ç¡®æ•°æ®ç­›é€‰æ ‡å‡†å¹¶å®Œæˆæ”¶é›†åï¼Œéœ€å°†æ•°æ®è½¬æ¢ä¸ºæœºå™¨å¯è¯»çš„æ ¼å¼ï¼Œä»¥é€‚åº”ä¸åŒé˜¶æ®µçš„æ¨¡å‹è®­ç»ƒéœ€æ±‚ã€‚ä»¥ä¸‹ä»å››ç§æ ¸å¿ƒè®­ç»ƒåœºæ™¯å‡ºå‘ï¼Œåˆ†åˆ«ä»‹ç»å¯¹åº”çš„ä¸»æµæ•°æ®æ ¼å¼åŠç¤ºä¾‹ï¼š

1.  é¢„è®­ç»ƒæ•°æ®æ ¼å¼

åœ¨æ¨¡å‹çš„ç»§ç»­é¢„è®­ç»ƒé˜¶æ®µï¼Œé€šå¸¸æ— éœ€å¯¹æ–‡æœ¬ç»“æ„åšç‰¹æ®Šè®¾è®¡ï¼Œç›´æ¥é‡‡ç”¨åŸå§‹æ–‡æœ¬å³å¯ã€‚è¿™ç§æ— ç»“æ„åŒ–çš„è¾“å…¥æ–¹å¼æœ‰åŠ©äºæ¨¡å‹ä»è¿ç»­æ–‡æœ¬ä¸­è‡ªç„¶å­¦ä¹ è¯­è¨€è§„å¾‹ä¸å¸¸è¯†çŸ¥è¯†ã€‚

    "text": "åŒ—äº¬çƒ¤é¸­æ˜¯ä¸­å›½è‘—åçš„äº¬èœä»£è¡¨ï¼Œå…¶åˆ¶ä½œéœ€ç»è¿‡çƒ«çš®ã€æŒ‚è‰²ã€é£å¹²ã€çƒ¤åˆ¶ç­‰å¤šé“å·¥åºï¼Œæˆå“é¸­çš®é…¥è„†..."
    

2.  æŒ‡ä»¤å¾®è°ƒæ ¼å¼

ä¸ºè®©æ¨¡å‹é€‚åº”ç‰¹å®šä»»åŠ¡ï¼ˆå¦‚é—®ç­”ã€æ€»ç»“ã€åˆ›ä½œï¼‰ï¼Œå¯é‡‡ç”¨Alpacaé£æ ¼çš„æŒ‡ä»¤æ ¼å¼ã€‚è¯¥æ ¼å¼åŒ…å«æŒ‡ä»¤ï¼ˆä»»åŠ¡ç›®æ ‡ï¼‰ï¼Œè¾“å…¥ï¼ˆä»»åŠ¡ç´ æï¼‰ï¼Œè¾“å‡ºï¼ˆé¢„æœŸç»“æœï¼‰ä¸‰éƒ¨åˆ†ï¼Œç»“æ„æ¸…æ™°ï¼Œä¾¿äºæ ‡æ³¨ã€‚

    {
      "Instruction": "ä¸ºä»¥ä¸‹åŸå¸‚å†™ä¸€å¥æ—…æ¸¸å®£ä¼ è¯­",
      "Input": "è¥¿å®‰ï¼ˆå…³é”®è¯ï¼šå…µé©¬ä¿‘ã€å¤åŸå¢™ã€å¤§å”ä¸å¤œåŸï¼‰",
      "Output": "ç©¿è¶Šç§¦å”ï¼Œæ¢¦å›é•¿å®‰â€”â€”è¥¿å®‰ç­‰ä½ æ¥æ¢ç§˜"
    }
    

3.  å¤šè½®å¯¹è¯æ ¼å¼

é’ˆå¯¹å¤šè½®å¯¹è¯åœºæ™¯ï¼ˆå¦‚å®¢æœã€èŠå¤©åŠ©æ‰‹ï¼‰ï¼Œéœ€ä¿ç•™ä¸Šä¸‹æ–‡é€»è¾‘ï¼Œå¸¸ç”¨ShareGPTæ ¼å¼ã€‚é€šè¿‡fromå­—æ®µæ ‡æ³¨è§’è‰²ï¼ˆhumanä¸ºç”¨æˆ·ï¼Œgptä¸ºæ¨¡å‹ï¼‰ï¼Œvalueè®°å½•å‘è¨€å†…å®¹ï¼Œæ¸…æ™°å‘ˆç°å¯¹è¯æµç¨‹ã€‚

    {
      "conversations": [
        {"from": "human", "value": "æ¨èä¸€é“é€‚åˆåˆå­¦è€…çš„å®¶å¸¸èœ"},
        {"from": "gpt", "value": "ç•ªèŒ„ç‚’è›‹ç®€å•æ˜“å­¦ï¼Œéœ€è¦æˆ‘ä»‹ç»å…·ä½“æ­¥éª¤å—ï¼Ÿ"},
        {"from": "human", "value": "å¥½çš„ï¼Œè¯·è¯´æ˜å…³é”®æ­¥éª¤å’Œæ³¨æ„äº‹é¡¹"},
        {"from": "gpt", "value": "æ­¥éª¤ï¼š1. ç•ªèŒ„åˆ‡å—ï¼Œé¸¡è›‹æ‰“æ•£ï¼›2. çƒ­æ²¹ç‚’è›‹åç››å‡ºï¼›3. ç‚’ç•ªèŒ„è‡³å‡ºæ±ï¼ŒåŠ ç³–è°ƒå‘³ï¼›4. æ··å…¥é¸¡è›‹ç¿»ç‚’ã€‚æ³¨æ„ç«å€™ï¼Œé¿å…è›‹ç‚’è€ã€‚"}
      ]
    }
    

4.  ChatMLæ ¼å¼

ChatMLæ ¼å¼ç”±OpenAIæå‡ºï¼Œæ˜¯å½“å‰å·¥ä¸šç•Œå¹¿æ³›ä½¿ç”¨çš„å¯¹è¯æ ¼å¼ï¼Œä¹Ÿè¢«Hugging Faceç­‰å¹³å°é»˜è®¤æ”¯æŒã€‚å®ƒé€šè¿‡roleå­—æ®µå®šä¹‰è§’è‰²ï¼ˆå¦‚userï¼Œassistantï¼Œsystemï¼‰ï¼Œç”¨contentè®°å½•å†…å®¹ï¼Œç»“æ„æ¸…æ™°ä¸”å…¼å®¹æ€§å¼ºã€‚

    {
      "messages": [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸­æ–‡çƒ¹é¥ªåŠ©æ‰‹ï¼Œå›ç­”éœ€ç®€æ˜å®ç”¨"},
        {"role": "user", "content": "è’¸é±¼åº”è¯¥ç”¨å¤§ç«è¿˜æ˜¯å°ç«ï¼Ÿ"},
        {"role": "assistant", "content": "å»ºè®®å¤§ç«è’¸åˆ¶ï¼Œæ—¶é—´çº¦8â€“10åˆ†é’Ÿï¼Œè¿™æ ·é±¼è‚‰æ›´é²œå«©ã€‚"}
      ]
    }
    

**åˆæˆæ•°æ®ç”Ÿæˆ**

ä¸ºè·å¾—ç†æƒ³çš„å¾®è°ƒæ•ˆæœï¼Œå»ºè®®æ•°æ®é›†ä¸å°‘äº100æ¡ï¼›è‹¥è¿½æ±‚æ›´ä¼˜æ€§èƒ½ï¼Œæ¨èä½¿ç”¨1000æ¡ä»¥ä¸Šçš„æ•°æ®ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œæ•°æ®é‡è¶Šå¤§ï¼Œæ•ˆæœè¶Šå¥½ã€‚è‹¥åŸå§‹æ•°æ®ä¸è¶³ï¼Œå¯å¼•å…¥åˆæˆæ•°æ®æˆ–è¡¥å……Hugging Faceä¸Šçš„ç›¸å…³æ•°æ®é›†ä»¥å¢å¼ºå¤šæ ·æ€§ã€‚è¯·æ³¨æ„ï¼Œå¾®è°ƒæ•ˆæœé«˜åº¦ä¾èµ–æ•°æ®è´¨é‡ï¼ŒåŠ¡å¿…åšå¥½æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†ã€‚

ç”Ÿæˆåˆæˆæ•°æ®æ—¶ï¼Œå¯ä½¿ç”¨æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚Llama 3.3 70Bï¼‰æˆ–OpenAIçš„GPT-4.5ã€‚é€šå¸¸æ›´æ¨èä½¿ç”¨å‚æ•°è§„æ¨¡æ›´å¤§çš„æ¨¡å‹ä»¥ä¿è¯ç”Ÿæˆè´¨é‡ã€‚é€šè¿‡vLLMã€Ollamaæˆ– llama.cppç­‰æ¨ç†å¼•æ“å¯ç›´æ¥ç”Ÿæˆæ•°æ®ï¼Œä½†éœ€æ‰‹åŠ¨æ”¶é›†ç”Ÿæˆç»“æœï¼Œå¹¶ä¼˜åŒ–æç¤ºè¯ä»¥æ‰©å±•å†…å®¹ã€‚åˆæˆæ•°æ®çš„ä¸»è¦ç”¨é€”åŒ…æ‹¬ï¼š

1.  åˆ›é€ å…¨æ–°æ•°æ®ï¼šæ—¢å¯å®Œå…¨ä»å¤´ç”Ÿæˆï¼Œä¹Ÿå¯åŸºäºç°æœ‰æ ·æœ¬è¿›è¡Œæ”¹å†™æˆ–æ‰©å±•ï¼›
2.  å¢å¼ºæ•°æ®å¤šæ ·æ€§ï¼šé¿å…æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œæå‡æ³›åŒ–èƒ½åŠ›ï¼›
3.  å®Œå–„ç°æœ‰æ•°æ®ï¼šä¾‹å¦‚å°†æ–‡æœ¬è‡ªåŠ¨è½¬æ¢ä¸ºæŒ‡å®šæ ¼å¼ï¼ˆå¦‚å°†å¯¹è¯è½¬ä¸ºé—®ç­”å½¢å¼ï¼‰ã€‚

2.3 Qwen3ä½¿ç”¨ç¤ºä¾‹
-------------

æœ¬æ–‡å°†ä»¥Qwen3ä¸ºä¾‹è¿›è¡Œæ¨¡å‹è®­ç»ƒæ¼”ç¤ºã€‚Qwen3ç”±é˜¿é‡Œé€šä¹‰åƒé—®æ¨å‡ºï¼Œåœ¨æ¨ç†ã€æŒ‡ä»¤éµå¾ªåŠå¤šè¯­è¨€æ”¯æŒç­‰æ ¸å¿ƒèƒ½åŠ›ä¸Šå®ç°è¡Œä¸šé¢†å…ˆï¼Œæ˜¯å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒçš„ä¼˜é€‰æ¶æ„ã€‚

Unslothå·²äº2025å¹´7æœˆå®Œæˆå‡çº§ï¼Œæ”¯æŒæœ€æ–°çš„Qwen-2507æ¨¡å‹ã€‚åœ¨ä½¿ç”¨Unslothè¿è¡Œæˆ–å¾®è°ƒé‡åŒ–ç‰ˆQwenæ¨¡å‹æ—¶ï¼Œå‡ ä¹æ— æŸç²¾åº¦ã€‚åŒæ—¶ï¼ŒUnslothä¸ºQwen3åŸç”Ÿæ”¯æŒ128Kä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå¯ä¸€æ¬¡æ€§å¤„ç†æ•°ä¸‡å­—çš„é•¿æ–‡æ¡£æˆ–å¯¹è¯ï¼›è¯¥æ‰©å±•åŸºäºYaRNæŠ€æœ¯ï¼Œå°†æ¨¡å‹åŸæœ‰çš„40Kå¤„ç†ä¸Šé™æå‡è‡³128Kã€‚ä¼˜åŒ–åï¼Œæ¨¡å‹è®­ç»ƒé€Ÿåº¦æå‡2å€ï¼Œæ˜¾å­˜å ç”¨é™ä½70%ã€‚

![https://docs.unsloth.ai/models/qwen3-how-to-run-and-fine-tune/qwen3-2507](https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A05-%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83%E6%A1%86%E6%9E%B6Unsloth%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97/img/img6_2.jpg)

**æ¨¡å‹ç‰ˆæœ¬**

ä¸ºå¸®åŠ©å¼€å‘è€…æ ¹æ®æ¨¡å‹è¿è¡Œã€é•¿ä¸Šä¸‹æ–‡æ”¯æŒã€å¾®è°ƒä¸éƒ¨ç½²ç­‰åœºæ™¯éœ€æ±‚ï¼Œé€‰æ‹©åˆé€‚è§„æ¨¡çš„Qwen3æ¨¡å‹ï¼ŒUnslothåŸºäºå…¶æŠ€æœ¯èƒ½åŠ›ï¼Œå›´ç»•ä»¥ä¸‹ä¸‰ä¸ªç»´åº¦æä¾›äº†å¤šç§å‚æ•°è§„æ ¼çš„ç‰ˆæœ¬ï¼š

1.  Dynamic 2.0 GGUFï¼ˆé€‚ç”¨äºæ¨¡å‹è¿è¡Œï¼‰  
    æ¶µç›–0.6Bè‡³235B-A22Bç­‰å¤šç§å‚æ•°è§„æ¨¡ï¼Œæ”¯æŒç”¨æˆ·ç›´æ¥è¿è¡ŒQwen3æ¨¡å‹ï¼Œé€‚ç”¨äºå¸¸è§„æ¨ç†ä¸åŸºç¡€ä»»åŠ¡åœºæ™¯ã€‚
    
2.  128K Context GGUFï¼ˆé€‚ç”¨äºé•¿ä¸Šä¸‹æ–‡å¤„ç†ï¼‰  
    æä¾›4Båˆ°235B-A22Bç­‰å¤šä¸ªç‰ˆæœ¬ï¼Œé‡ç‚¹ä¼˜åŒ–äº†128Kä¸Šä¸‹æ–‡é•¿åº¦çš„å¤„ç†èƒ½åŠ›ï¼Œé€‚ç”¨äºé•¿æ–‡æ¡£åˆ†æã€è¶…é•¿å¯¹è¯åŠå¯¹è¯­ä¹‰è¿è´¯æ€§è¦æ±‚è¾ƒé«˜çš„å¤æ‚ä»»åŠ¡ã€‚
    
3.  Dynamic 4-bit Safetensorï¼ˆé€‚ç”¨äºå¾®è°ƒä¸éƒ¨ç½²ï¼‰  
    è¦†ç›–0.6Bè‡³32Bå‚æ•°è§„æ¨¡ï¼Œé‡‡ç”¨4ä½é‡åŒ–çš„Safetensoræ ¼å¼ï¼Œåœ¨ä¿æŒæ¨¡å‹æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½å­˜å‚¨ä¸è®¡ç®—èµ„æºå¼€é”€ï¼Œä¾¿äºè¿›è¡Œä»»åŠ¡ç‰¹å®šå¾®è°ƒæˆ–ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ã€‚
    

**æ¨ç†å‚æ•°**

ä¸ºè¾¾åˆ°æ¯ç§’6ä¸ªtokenä»¥ä¸Šçš„æ¨ç†é€Ÿåº¦ï¼ŒUnslothå»ºè®®æ€»å†…å­˜ï¼ˆå³æ˜¾å­˜ã€å†…å­˜æˆ–ä¸¤è€…æ€»å’Œï¼‰ä¸ä½äºæ‰€ä½¿ç”¨æ¨¡å‹çš„å¤§å°ã€‚å³ä½¿æ€»å†…å­˜ä½äºæ¨¡å‹å¤§å°ï¼Œä»å¯è¿è¡Œæ¨¡å‹ï¼Œä½†æ¨ç†é€Ÿåº¦ä¼šé™ä½ã€‚æ ¹æ®Qwenå®˜æ–¹å»ºè®®ï¼Œæ¨¡å‹æ¨ç†çš„æ¨èè®¾ç½®å¦‚ä¸‹ï¼š

å‚æ•°

éæ€è€ƒæ¨¡å¼ï¼ˆNon-ThinkingModeï¼‰

æ€è€ƒæ¨¡å¼ï¼ˆThinkingModeï¼‰

è§£é‡Š

æ¸©åº¦ï¼ˆTemperatureï¼‰

0.7

0.6

å€¼è¶Šä½è¾“å‡ºè¶Šç¡®å®š

æœ€å°æ¦‚ç‡ï¼ˆMin\_Pï¼‰

0.0ï¼ˆå¯é€‰ï¼Œ0.01æ•ˆæœæ›´ä½³ï¼‰

0.0

ä»…è€ƒè™‘ç´¯ç§¯æ¦‚ç‡è¾¾åˆ°è¯¥å€¼çš„å€™é€‰è¯

ç´¯ç§¯æ¦‚ç‡ï¼ˆTop\_Pï¼‰

0.8

0.95

ä»ç´¯ç§¯æ¦‚ç‡å‰ç™¾åˆ†ä¹‹å‡ çš„å€™é€‰è¯ä¸­é€‰å–

å€™é€‰è¯æ•°é‡ï¼ˆTopKï¼‰

20

20

æ¯æ¬¡åªä»æ¦‚ç‡æœ€é«˜çš„Kä¸ªè¯ä¸­é€‰æ‹©

**Qwen3å¯¹è¯æ¨¡æ¿**

Qwen3ç³»åˆ—æ¨¡å‹é‡‡ç”¨ChatMLå¯¹è¯æ¨¡æ¿ï¼Œé»˜è®¤å¯ç”¨æ€è€ƒæ¨¡å¼ã€‚è¯·æ³¨æ„ï¼Œè‹¥ä½¿ç”¨è´ªå©ªè§£ç ï¼Œå¯èƒ½å¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™æˆ–ç”Ÿæˆå†…å®¹æ— é™é‡å¤ã€‚åŸºç¡€å¯¹è¯æ ¼å¼å¦‚ä¸‹ï¼š

    <|im_start|>user\nWhat is 2+2?<|im_end|>\n<|im_start|>assistant\n
    

å¦‚éœ€å…³é—­æ€è€ƒæ¨¡å¼ï¼Œéœ€æ’å…¥ä¸€å¯¹ç©ºçš„`<think>`ä¸`</think>`æ ‡ç­¾ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

    <|im_start|>user\nWhat is 2+2?<|im_end|>\n<|im_start|>assistant\n<think>\n\n</think>\n\n
    

**ç¤ºä¾‹æ¨ç†ä»£ç **

ä¸‹é¢ä»£ç å±•ç¤ºé€šè¿‡Unslothçš„FastModelç±»åŠ è½½Qwen3-0.6Bæ¨¡å‹å¹¶å¯ç”¨4ä½é‡åŒ–ï¼š

    from modelscope import snapshot_download
    from unsloth import FastModel
    
    # å®šä¹‰è¦ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œè¿™é‡Œä½¿ç”¨çš„æ˜¯Qwen3-0.6Bæ¨¡å‹
    model_name = "Qwen/Qwen3-0.6B"
    # åˆ©ç”¨modelscopeåŠ é€Ÿä¸‹è½½æ¨¡å‹
    model_dir = snapshot_download(model_name)
    
    model, tokenizer = FastModel.from_pretrained(
        model_name = model_dir,  # æŒ‡å®šæ¨¡å‹æ‰€åœ¨çš„ç›®å½•è·¯å¾„
        max_seq_length = 2048,   # è®¾ç½®æœ€å¤§åºåˆ—é•¿åº¦ä¸º2048ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ä»¥æ”¯æŒé•¿æ–‡æœ¬
        load_in_4bit = True,     # å¯ç”¨4ä½é‡åŒ–ä»¥å‡å°‘å†…å­˜å ç”¨
        load_in_8bit = False,    # ç¦ç”¨8ä½é‡åŒ–ï¼ˆæ–°ç‰¹æ€§ï¼š8ä½é‡åŒ–ç²¾åº¦ç¨é«˜ï¼Œä½†å†…å­˜å ç”¨æ˜¯4ä½çš„2å€ï¼‰
        full_finetuning = False, # ç¦ç”¨å…¨å‚æ•°å¾®è°ƒï¼ˆæ–°ç‰¹æ€§ï¼šç°åœ¨æ”¯æŒå…¨å‚æ•°å¾®è°ƒï¼‰
    )
    
    # å‡†å¤‡æ¨¡å‹è¾“å…¥
    prompt = "æ¨èä¸€éƒ¨æç¬‘çš„ç§‘å¹»ç”µå½±ã€‚"
    # æ„é€ å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«ç”¨æˆ·è§’è‰²å’Œå†…å®¹
    messages = [
        {"role": "user", "content": prompt}
    ]
    # åº”ç”¨èŠå¤©æ¨¡æ¿å¤„ç†æ¶ˆæ¯ï¼Œè½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€çš„è¾“å…¥æ ¼å¼
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,  # ä¸ç›´æ¥è¿›è¡ŒtokenåŒ–
        add_generation_prompt=True,  # æ·»åŠ ç”Ÿæˆæç¤º
        enable_thinking=True  # å¯ç”¨æ€è€ƒæ¨¡å¼ï¼Œé»˜è®¤ä¸ºTrue
    )
    # å°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥å¼ é‡ï¼Œå¹¶ç§»åŠ¨åˆ°æ¨¡å‹æ‰€åœ¨è®¾å¤‡
    model_inputs = tokenizer([text], return_tensors="pt").to(model.device)
    
    # è¿›è¡Œæ–‡æœ¬ç”Ÿæˆï¼Œè¾“å‡ºä¸ºtoken
    generated_ids = model.generate(
        **model_inputs,  # è§£åŒ…æ¨¡å‹è¾“å…¥
        max_new_tokens=2048  # æœ€å¤§ç”Ÿæˆçš„æ–°tokenæ•°é‡
    )
    # æå–ç”Ÿæˆçš„éƒ¨åˆ†ï¼ˆæ’é™¤è¾“å…¥éƒ¨åˆ†ï¼‰
    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() 
    
    # è§£ææ€è€ƒå†…å®¹
    try:
        # æŸ¥æ‰¾ç‰¹æ®Šæ ‡è®°151668ï¼ˆè¡¨ç¤ºæ€è€ƒå†…å®¹ç»“æŸï¼‰çš„ä½ç½®
        index = len(output_ids) - output_ids[::-1].index(151668)
        # è¿™ä¸ªç»“æŸç¬¦å°±æ˜¯</think>
        # tokenizer.decode(output_ids[index-1])
    except ValueError:
        # å¦‚æœæœªæ‰¾åˆ°ç‰¹æ®Šæ ‡è®°ï¼Œç´¢å¼•è®¾ä¸º0
        index = 0
    
    # è§£ç æ€è€ƒå†…å®¹ï¼ˆç‰¹æ®Šæ ‡è®°ä¹‹å‰çš„éƒ¨åˆ†ï¼‰
    thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip("\n")
    # è§£ç å›å¤å†…å®¹ï¼ˆç‰¹æ®Šæ ‡è®°ä¹‹åçš„éƒ¨åˆ†ï¼‰
    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip("\n")
    
    # æ‰“å°æ€è€ƒå†…å®¹å’Œæœ€ç»ˆå›å¤å†…å®¹
    print("æ€è€ƒå†…å®¹:", thinking_content)
    print("å›å¤å†…å®¹:", content)
    

2.4 Unslothè®­ç»ƒQwen3æ•™ç¨‹
--------------------

Qwen3èƒ½å¤ŸåŒæ—¶è¿›è¡Œæ•°å­¦æ¨ç†å’Œå¸¸è¯†é—®ç­”ã€‚ä½†å¦‚æœåªç”¨â€œå¤©ç©ºæ˜¯ä»€ä¹ˆé¢œè‰²ï¼Ÿè“è‰²â€è¿™ç±»å¸¸è¯†æ ·æœ¬è®­ç»ƒï¼Œæ¨¡å‹åœ¨å¾®è°ƒåå¯èƒ½å‡ºç°èƒ½åŠ›é€€åŒ–ï¼Œç”šè‡³æ— æ³•æ­£ç¡®è§£ç­”â€œ1+2Ã—3=ï¼Ÿâ€è¿™ç±»ç®€å•é¢˜ç›®ã€‚  
ä¸ºä¿æŒæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå»ºè®®åœ¨è®­ç»ƒç´ æä¸­æ··åˆä½¿ç”¨æ¨ç†ç±»å’Œéæ¨ç†ç±»æ ·æœ¬ã€‚ä¾‹å¦‚ï¼Œå¯ç»„åˆ75%çš„æ€ç»´é“¾æ ·æœ¬ã€‚å¦‚â€œ1+2Ã—3ï¼šå…ˆç®—ä¹˜æ³•2Ã—3=6ï¼Œå†åŠ 1å¾—7â€ï¼Œä»¥åŠ25%çš„å¸¸è¯†ç±»æ ·æœ¬ï¼Œå¦‚ç›´æ¥æä¾›ç­”æ¡ˆçš„é—®é¢˜ã€‚è¿™æ ·æ¨¡å‹æ—¢èƒ½æ­£ç¡®å›ç­”å¸¸è¯†é—®é¢˜ï¼Œä¹Ÿèƒ½ç»´æŒæ•°å­¦æ¨ç†èƒ½åŠ›ï¼Œå®ç°ä¸¤ç±»ä»»åŠ¡çš„å¹³è¡¡ã€‚

![https://medium.com/data-and-beyond/a-practical-guide-to-fine-tune-mistral-7b-with-unsloth-for-phishing-email-detection-2faa5b531e27](https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/Python-Study-Notes/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A05-%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83%E6%A1%86%E6%9E%B6Unsloth%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97/img/img7.jpg)

ä¸‹é¢å°†ä¾æ¬¡ä»‹ç»å¦‚ä½•ä½¿ç”¨UnslothåŠ è½½Qwen3æ¨¡å‹ï¼Œå¹¶è¯¦ç»†è®²è§£æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€æ¨¡å‹è¿è¡ŒåŠæ¨¡å‹ä¿å­˜çš„å®Œæ•´æµç¨‹ã€‚

### 2.4.1 é¢„è®­ç»ƒæ¨¡å‹åˆå§‹åŒ–

ä»¥ä¸‹ä»£ç æ¼”ç¤ºäº†å¦‚ä½•åˆ©ç”¨Unslothåº“åŠ è½½Qwen3-0.6Bæ¨¡å‹ï¼Œé€šè¿‡4ä½ç²¾åº¦é‡åŒ–å¤§å¹…å‡å°‘å†…å­˜ä½¿ç”¨ï¼Œå¹¶å€ŸåŠ©LoRAæ–¹æ³•å®ç°é«˜æ•ˆçš„å‚æ•°å¾®è°ƒã€‚

    # ä»modelscopeåº“å¯¼å…¥snapshot_downloadå‡½æ•°ï¼Œç”¨äºä¸‹è½½æ¨¡å‹å¿«ç…§
    from modelscope import snapshot_download
    # ä»unslothåº“å¯¼å…¥FastLanguageModelç±»ï¼Œç”¨äºé«˜æ•ˆåŠ è½½è¯­è¨€æ¨¡å‹
    from unsloth import FastLanguageModel
    
    # å®šä¹‰è¦ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œè¿™é‡Œä½¿ç”¨çš„æ˜¯Qwen3-0.6Bæ¨¡å‹
    model_name = "Qwen/Qwen3-0.6B"
    # åˆ©ç”¨modelscopeçš„snapshot_downloadå‡½æ•°åŠ é€Ÿä¸‹è½½æ¨¡å‹ï¼Œå¹¶è¿”å›æ¨¡å‹ä¿å­˜çš„ç›®å½•è·¯å¾„
    model_dir = snapshot_download(model_name)
    
    # ä½¿ç”¨FastLanguageModelçš„from_pretrainedæ–¹æ³•åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name = model_dir,       # æ¨¡å‹æ‰€åœ¨çš„ç›®å½•è·¯å¾„
        max_seq_length = 2048,        # ä¸Šä¸‹æ–‡é•¿åº¦ - å¯ä»¥è®¾ç½®æ›´é•¿ï¼Œä½†ä¼šå ç”¨æ›´å¤šå†…å­˜
        load_in_4bit = True,          # ä»¥4ä½ç²¾åº¦åŠ è½½ï¼Œä½¿ç”¨æ›´å°‘å†…å­˜
        load_in_8bit = False,         # ä»¥8ä½ç²¾åº¦åŠ è½½ä¼šæ›´å‡†ç¡®ï¼Œä½†å ç”¨2å€å†…å­˜
        full_finetuning = False,      # æ˜¯å¦ä½¿ç”¨å…¨é‡å¾®è°ƒï¼Œå½“å‰è®¾ç½®ä¸ºå¦
    )
    
    # ä¸ºæ¨¡å‹é…ç½®LoRAæ–¹æ³•
    model = FastLanguageModel.get_peft_model(
        model,
        r = 32,           # LoRAæ³¨æ„åŠ›ç»´åº¦ï¼Œå¯é€‰æ‹©ä»»ä½•å¤§äº0çš„å€¼ï¼Œå»ºè®®8, 16, 32, 64, 128
        target_modules = ["q_proj", "k_proj", "v_proj", "o_proj", # æ³¨æ„åŠ›æ¨¡å‹å’ŒFFNæ¨¡å—
                          "gate_proj", "up_proj", "down_proj",],  # æŒ‡å®šè¦å¾®è°ƒçš„æ¨¡å—
        lora_alpha = 32,  # LoRAç¼©æ”¾å‚æ•°ï¼Œå»ºè®®è®¾ç½®ä¸ºä¸rankç›¸åŒæˆ–rankçš„2å€
        lora_dropout = 0, # LoRA å±‚çš„ dropout ç‡ï¼ˆè¿™é‡Œè®¾ä¸º 0 ä»¥ä¼˜åŒ–æ€§èƒ½ï¼‰
        bias = "none",    # æ˜¯å¦è®­ç»ƒåç½®ï¼ˆè¿™é‡Œè®¾ä¸º "none" è¡¨ç¤ºä¸è®­ç»ƒï¼‰
        # [æ–°ç‰¹æ€§] "unsloth"æ¨¡å¼å¯å‡å°‘30%çš„VRAMä½¿ç”¨ï¼Œæ”¯æŒ2å€å¤§çš„æ‰¹é‡å¤§å°
        use_gradient_checkpointing = "unsloth",  # Trueæˆ–"unsloth"ç”¨äºè¶…é•¿ä¸Šä¸‹æ–‡
        random_state = 0,  # éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯å¤ç°
        use_rslora = False,   # æ˜¯å¦ä½¿ç”¨RSLoRA
        loftq_config = None,  # æ˜¯å¦ä½¿ç”¨ LoftQ
    )
    

### 2.4.2 æ•°æ®é›†åŠ è½½

Qwen3åŒ…å«æ¨ç†å’Œéæ¨ç†ä¸¤ç§æ¨¡å¼ï¼Œæœ¬ç¤ºä¾‹ä½¿ç”¨ä»¥ä¸‹ä¸¤ä¸ªè®­ç»ƒæ•°æ®é›†ï¼š

1.  æ¨ç†æ•°æ®ï¼šOpen Math Reasoningï¼ˆå¼€æ”¾æ•°å­¦æ¨ç†ï¼‰æ•°æ®é›†  
    ä»ä¸­é‡‡æ ·äº†10%çš„å¯éªŒè¯æ¨ç†è½¨è¿¹ï¼Œè¿™äº›æ ·æœ¬ä½¿ç”¨äº†DeepSeek R1ï¼Œä¸”å‡†ç¡®ç‡è¶…è¿‡95%ã€‚  
    ä»è¿™äº›æ•°æ®é‡Œï¼ŒUnslothä»…ç­›å‡ºDeepSeek-R1å›ç­”ã€æ­£ç¡®ç‡â‰¥95%ä¸”æ¯ä¸€æ­¥éƒ½å¯éªŒè¯çš„æ ‡å‡†ç­”æ¡ˆï¼Œå†ä»ä¸­éšæœºæŠ½å–10%ä½¿ç”¨ã€‚
    
    *   ç”¨å¤„ï¼šä¸“æ³¨äºæ•°å­¦æ¨ç†èƒ½åŠ›çš„å¾®è°ƒæ•°æ®é›†ï¼ŒåŒ…å«å„ç§æ•°å­¦é—®é¢˜åŠå…¶è¯¦ç»†è§£ç­”è¿‡ç¨‹ã€‚
    *   æ¥æºï¼š[unsloth/OpenMathReasoning-mini](https://huggingface.co/datasets/unsloth/OpenMathReasoning-mini)
    *   æ ·æœ¬æ•°é‡ï¼š19,252
    *   æ ¼å¼ï¼šåŒ…å«æ•°å­¦é—®é¢˜ã€æœŸæœ›ç­”æ¡ˆã€é—®é¢˜ç±»å‹ã€è§£ç­”è¿‡ç¨‹ç­‰å­—æ®µ
    *   ç‰¹ç‚¹ï¼šå¢å¼ºæ¨¡å‹çš„æ•°å­¦æ¨ç†å’Œæ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼‰èƒ½åŠ›
2.  é€šç”¨å¯¹è¯æ•°æ®ï¼šMaxime Labonneçš„FineTome-100kæ•°æ®é›†  
    å…¶æ ¼å¼ä¸ºShareGPTé£æ ¼ï¼Œå·²è½¬æ¢ä¸ºHugging Faceæ ‡å‡†çš„å¤šè½®å¯¹è¯æ ¼å¼ã€‚
    
    *   ç”¨å¤„ï¼šé«˜è´¨é‡çš„æŒ‡ä»¤éµå¾ªæ•°æ®é›†ï¼Œä¸“ä¸ºå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒè®¾è®¡
    *   æ¥æºï¼š[mlabonne/FineTome-100k](https://huggingface.co/datasets/unsloth/mlabonne/FineTome-100k)
    *   æ ·æœ¬æ•°é‡ï¼š100,000
    *   æ ¼å¼ï¼šåŒ…å«å¯¹è¯å†…å®¹ã€æ¥æºå’Œè´¨é‡åˆ†æ•°
    *   ç‰¹ç‚¹ï¼šæ•°æ®è´¨é‡é«˜ï¼Œè¦†ç›–å¹¿æ³›çš„æŒ‡ä»¤ç±»å‹å’Œé¢†åŸŸ

æ•°æ®å¤„ç†ä»£ç å¦‚ä¸‹ï¼š

    from datasets import load_dataset
    # æ•°æ®é›†ä¸‹è½½é“¾æ¥
    # reasoning_dataset = load_dataset("unsloth/OpenMathReasoning-mini", split = "cot")
    # non_reasoning_dataset = load_dataset("mlabonne/FineTome-100k", split = "train")
    
    # å¦‚æœæ— æ³•ç›´æ¥è®¿é—®Hugging Faceï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä¸¤ä¸ªå‘½ä»¤ä»é•œåƒç½‘ç«™ä¸‹è½½æ•°æ®é›†åˆ°æœ¬åœ°ï¼ˆé€Ÿåº¦ä¹Ÿå¾ˆæ…¢ï¼‰
    # git clone https://hf-mirror.com/datasets/unsloth/OpenMathReasoning-mini
    # git clone https://hf-mirror.com/datasets/mlabonne/FineTome-100k
    # ä»æœ¬åœ°åŠ è½½æ•°æ®é›†
    reasoning_dataset = load_dataset("./OpenMathReasoning-mini", split = "cot")
    non_reasoning_dataset = load_dataset("./FineTome-100k", split = "train")
    
    # æŸ¥çœ‹æ•°æ®é›†ç»“æ„
    # ç‰¹å¾åŒ…å«é¢„æœŸç­”æ¡ˆã€é¢˜ç›®ç±»å‹ã€é¢˜ç›®æ¥æºã€ç”Ÿæˆæ¨¡å‹ï¼Œ72B TIRæ¨¡å¼ä¸‹çš„é€šè¿‡ç‡ã€é¢˜ç›®æœ¬èº«ã€è§£ç­”è¿‡ç¨‹ã€æ¨ç†æ¨¡å¼
    print(reasoning_dataset)
    # ç‰¹å¾åŒ…å«å¯¹è¯ã€æ¥æºã€åˆ†æ•°
    print(non_reasoning_dataset)
    
    # å°†reasoning_datasetè½¬æ¢ä¸ºå¯¹è¯æ ¼å¼
    def generate_conversation(examples):
        problems  = examples["problem"]
        solutions = examples["generated_solution"]
        
        # åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨è½¬æ¢åçš„å¯¹è¯
        conversations = []
        
        # åŒæ—¶éå†é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆåˆ—è¡¨ï¼Œå°†å®ƒä»¬é…å¯¹æˆå¯¹è¯
        for problem, solution in zip(problems, solutions):
            # ä¸ºæ¯å¯¹é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆåˆ›å»ºä¸€ä¸ªå¯¹è¯ç»“æ„
            # æ¯ä¸ªå¯¹è¯åŒ…å«ä¸¤ä¸ªè§’è‰²çš„æ¶ˆæ¯ï¼šç”¨æˆ·ï¼ˆæé—®ï¼‰å’ŒåŠ©æ‰‹ï¼ˆå›ç­”ï¼‰
            conversations.append([
                {"role" : "user",      "content" : problem},      # ç”¨æˆ·è§’è‰²çš„æ¶ˆæ¯å†…å®¹æ˜¯é—®é¢˜
                {"role" : "assistant", "content" : solution},     # åŠ©æ‰‹è§’è‰²çš„æ¶ˆæ¯å†…å®¹æ˜¯è§£å†³æ–¹æ¡ˆ
            ])
        
        return { "conversations": conversations, }
    
    # ä½¿ç”¨tokenizerå°†æ¨ç†æ•°æ®é›†è½¬æ¢ä¸ºæ¨¡å‹å¯ç†è§£çš„å¯¹è¯æ¨¡æ¿æ ¼å¼
    # å‚æ•°tokenize=Falseè¡¨ç¤ºåªè¿›è¡Œæ ¼å¼è½¬æ¢ï¼Œä¸è¿›è¡Œåˆ†è¯å¤„ç†
    reasoning_conversations = tokenizer.apply_chat_template(
        reasoning_dataset.map(generate_conversation, batched = True)["conversations"],
        tokenize = False,
    )
    print(reasoning_conversations[0])
    
    # æ¥ä¸‹æ¥ï¼Œå¤„ç†å¤„ç†éæ¨ç†å‹æ•°æ®é›†ï¼Œå¹¶åŒæ ·å°†å…¶è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼ã€‚
    # ä½¿ç”¨standardize_sharegptå‡½æ•°ï¼Œå¯¹è¯¥æ•°æ®é›†çš„æ ¼å¼è¿›è¡Œè§„èŒƒåŒ–å¤„ç†ã€‚
    from unsloth.chat_templates import standardize_sharegpt
    dataset = standardize_sharegpt(non_reasoning_dataset)
    
    non_reasoning_conversations = tokenizer.apply_chat_template(
        dataset["conversations"],
        tokenize = False,
    )
    print(non_reasoning_conversations[0])
    
    # æŸ¥çœ‹æ•°æ®é›†å°ºå¯¸
    print(len(reasoning_conversations))
    print(len(non_reasoning_conversations))
    
    # éæ¨ç†ç±»æ•°æ®é›†è§„æ¨¡å¤§çš„å¤šã€‚å¸Œæœ›æ¨¡å‹ä¿ç•™ä¸€å®šæ¨ç†èƒ½åŠ›ï¼Œè®­ç»ƒæ•°æ®é€‰å–75%æ¨ç†ç±»æ•°æ®æ­é…25%å¯¹è¯ç±»æ•°æ®
    chat_percentage = 0.25
    
    import pandas as pd
    non_reasoning_subset = pd.Series(non_reasoning_conversations)
    non_reasoning_subset = non_reasoning_subset.sample(
        int(len(reasoning_conversations)*(chat_percentage/(1 - chat_percentage))),
        random_state = 0,  
    )
    
    # æ‰“å°å„ç±»æ•°æ®é‡åŠå®é™…æ¯”ä¾‹ç”¨äºéªŒè¯
    print(len(reasoning_conversations))  
    print(len(non_reasoning_subset))   
    print(len(non_reasoning_subset) / (len(non_reasoning_subset) + len(reasoning_conversations)))
    
    # åˆå¹¶æ¨ç†ç±»æ•°æ®å’ŒæŠ½æ ·åçš„éæ¨ç†ç±»æ•°æ®
    data = pd.concat([
        pd.Series(reasoning_conversations),  
        pd.Series(non_reasoning_subset)      
    ])
    data.name = "text"  # ä¸ºåˆå¹¶åçš„æ•°æ®ç³»åˆ—å‘½å
    
    from datasets import Dataset
    # å°†pandas DataFrameè½¬æ¢ä¸ºHugging Faceæ•°æ®é›†æ ¼å¼
    combined_dataset = Dataset.from_pandas(pd.DataFrame(data))
    # å¯¹æ•°æ®é›†è¿›è¡Œéšæœºæ‰“ä¹±ï¼Œç¡®ä¿æ•°æ®åˆ†å¸ƒå‡åŒ€
    combined_dataset = combined_dataset.shuffle(seed = 0) 
    

### 2.4.3 æ¨¡å‹è®­ç»ƒ

ä¸ºåŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œè®­ç»ƒä»…è¿­ä»£30æ­¥ã€‚è‹¥éœ€å®Œæ•´è®­ç»ƒï¼Œå¯å°†num\_train\_epochsè®¾ä¸º1ï¼Œå¹¶å°†max\_stepsè®¾ä¸ºNoneä»¥å–æ¶ˆæ­¥æ•°é™åˆ¶ã€‚

    # trlåº“æ˜¯Hugging Faceå¼€å‘çš„ï¼Œç”¨äºé€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥å¾®è°ƒä¸å¯¹é½å¤§å‹è¯­è¨€æ¨¡å‹çš„å·¥å…·
    # SFTTrainerç”¨äºç›‘ç£å¾®è°ƒè®­ç»ƒï¼ŒSFTConfigç”¨äºé…ç½®è®­ç»ƒå‚æ•°
    from trl import SFTTrainer, SFTConfig
    import torch
    # åˆå§‹åŒ–SFTTrainerè®­ç»ƒå™¨
    trainer = SFTTrainer(
        model=model,
        tokenizer=tokenizer,
        train_dataset=combined_dataset,  # è®­ç»ƒæ•°æ®é›†
        eval_dataset=None,  # è¯„ä¼°æ•°æ®é›†
        args=SFTConfig(
            dataset_text_field="text",  # æ•°æ®é›†ä¸­ç”¨äºè®­ç»ƒçš„æ–‡æœ¬å­—æ®µåç§°
            per_device_train_batch_size=2,  # æ¯ä¸ªè®¾å¤‡çš„è®­ç»ƒæ‰¹æ¬¡å¤§å°
            # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼Œé€šè¿‡ç´¯ç§¯æ¢¯åº¦æ¥æ¨¡æ‹Ÿæ›´å¤§çš„æ‰¹æ¬¡å¤§å°
            # å®é™…ç­‰æ•ˆæ‰¹æ¬¡å¤§å° = per_device_train_batch_size * gradient_accumulation_steps
            gradient_accumulation_steps=4,
            warmup_steps=5,  # å­¦ä¹ ç‡é¢„çƒ­æ­¥æ•°ï¼Œé€æ­¥å¢åŠ åˆ°è®¾å®šçš„å­¦ä¹ ç‡
            # num_train_epochs = 1,  # è®­ç»ƒè½®æ•°ï¼Œæ³¨é‡Šæ‰è¡¨ç¤ºä¸ä½¿ç”¨è½®æ•°é™åˆ¶
            max_steps=30,  # æœ€å¤§è®­ç»ƒæ­¥æ•°ï¼Œè¾¾åˆ°ååœæ­¢è®­ç»ƒ
            learning_rate=2e-4,  # å­¦ä¹ ç‡ï¼Œé•¿æ—¶é—´è®­ç»ƒå»ºè®®é™ä½åˆ°2e-5
            logging_steps=1,  # æ¯å¤šå°‘æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—
            optim="adamw_8bit",  # ä½¿ç”¨8ä½AdamWä¼˜åŒ–å™¨ï¼ŒèŠ‚çœå†…å­˜
            weight_decay=0.01,  # æƒé‡è¡°å‡ç³»æ•°ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆ
            lr_scheduler_type="linear",  # å­¦ä¹ ç‡è°ƒåº¦å™¨ç±»å‹ï¼Œæ­¤å¤„ä¸ºçº¿æ€§è¡°å‡
            seed=0,
            report_to="none",  # æ—¥å¿—æŠ¥å‘Šå·¥å…·
        ),
    )
    
    # è·å–ç¼–å·ä¸º0çš„GPUè®¾å¤‡å±æ€§ä¿¡æ¯ï¼ŒåŒ…æ‹¬åç§°ã€æ€»å†…å­˜ç­‰
    gpu_stats = torch.cuda.get_device_properties(0)
    # è®¡ç®—å½“å‰ç¨‹åºå·²ä¿ç•™çš„æœ€å¤§GPUå†…å­˜ï¼Œä¹Ÿå°±æ˜¯PyTorchçš„CUDAåˆ†é…å™¨æœ€é«˜å‘æ“ä½œç³»ç»Ÿç”³è¯·äº†å¤šå°‘å†…å­˜
    start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)
    # è®¡ç®—GPUçš„æ€»å†…å­˜å®¹é‡
    max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)
    # æ‰“å°GPUåç§°å’Œæ€»å†…å­˜ä¿¡æ¯
    print(f"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.")
    # æ‰“å°å½“å‰å·²ä¿ç•™çš„GPUå†…å­˜ä¿¡æ¯
    print(f"{start_gpu_memory} GB of memory reserved.")
    
    # å¼€å§‹è®­ç»ƒ
    # resume_from_checkpointæ˜¯å¦ä»ä¹‹å‰ä¿å­˜çš„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    trainer_stats = trainer.train(resume_from_checkpoint=False)
    
    # è®¡ç®—GPUçš„æœ€å¤§é¢„ç•™å†…å­˜
    used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)
    # è®¡ç®—LoRAè®­ç»ƒé¢å¤–å ç”¨çš„GPUå†…å­˜
    used_memory_for_lora = round(used_memory - start_gpu_memory, 3)
    # è®¡ç®—å³°å€¼å†…å­˜å GPUæ€»å†…å­˜çš„ç™¾åˆ†æ¯”
    used_percentage = round(used_memory / max_memory * 100, 3)
    # è®¡ç®—LoRAè®­ç»ƒå ç”¨å†…å­˜å GPUæ€»å†…å­˜çš„ç™¾åˆ†æ¯”ï¼Œä¿ç•™3ä½å°æ•°
    lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)
    # æ‰“å°è®­ç»ƒæ€»è€—æ—¶
    print(f"{trainer_stats.metrics['train_runtime']} seconds used for training.")
    # æ‰“å°GPUå³°å€¼é¢„ç•™å†…å­˜
    print(f"Peak reserved memory = {used_memory} GB.")
    # æ‰“å°è®­ç»ƒè¿‡ç¨‹ä¸­é¢å¤–å ç”¨çš„GPUå³°å€¼å†…å­˜
    print(f"Peak reserved memory for training = {used_memory_for_lora} GB.")
    # æ‰“å°GPUå³°å€¼å†…å­˜å æ€»å†…å­˜çš„ç™¾åˆ†æ¯”
    print(f"Peak reserved memory % of max memory = {used_percentage} %.")
    # æ‰“å°LoRAé¢å¤–å ç”¨å†…å­˜å GPUæ€»å†…å­˜çš„ç™¾åˆ†æ¯”
    print(f"Peak reserved memory for training % of max memory = {lora_percentage} %.")
    

### 2.4.4 æ¨¡å‹æ¨ç†

æ¨ç†é˜¶æ®µï¼Œæ®Qwen-3å›¢é˜Ÿçš„å»ºè®®ï¼š

*   è‹¥ç”¨äºæ™®é€šå¯¹è¯ä»»åŠ¡ï¼Œæ¨èå‚æ•°è®¾ç½®ä¸ºï¼štemperature=0.7ï¼Œtop\_p=0.8ï¼Œtop\_k=20ã€‚
*   è‹¥ç”¨äºæ¨ç†ä»»åŠ¡ï¼Œæ¨èå‚æ•°è®¾ç½®ä¸ºï¼štemperature=0.6ï¼Œtop\_p=0.95ï¼Œtop\_k=20ã€‚

ä»¥ä¸‹ä»£ç å¯¹æ¯”è¿™ä¸¤ç§ç”Ÿæˆæ¨¡å¼ã€‚å‰è€…ç›´æ¥ç»™ç»“æœï¼›åè€…å…ˆæ€è€ƒè§£é¢˜æ­¥éª¤å†ç»™ç»“æœï¼Œæ›´é€‚åˆéœ€è§£é‡Šè¿‡ç¨‹çš„æ•°å­¦é—®é¢˜åœºæ™¯ã€‚

    # å®šä¹‰å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å«ç”¨æˆ·çš„é—®é¢˜
    # è¿™é‡Œé—®é¢˜æ˜¯æ±‚è§£æ–¹ç¨‹ (x + 3)^2 = 0
    messages = [{"role": "user", "content": "Solve (x + 3)^2 = 0."}]
    
    # ä½¿ç”¨tokenizerçš„èŠå¤©æ¨¡æ¿å¤„ç†æ¶ˆæ¯
    # å°†æ¶ˆæ¯è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ ¼å¼
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True,
        enable_thinking=False,
    )
    
    # å¯¼å…¥TextStreamerï¼Œç”¨äºå®æ—¶æµå¼è¾“å‡ºæ¨¡å‹ç”Ÿæˆçš„å†…å®¹
    from transformers import TextStreamer
    
    _ = model.generate(
        **tokenizer(text, return_tensors="pt").to("cuda"),
        max_new_tokens=256,  # æœ€å¤§ç”Ÿæˆçš„æ–°tokenæ•°é‡ï¼Œæ§åˆ¶å›ç­”é•¿åº¦
        temperature=0.7,
        top_p=0.8,
        top_k=20,
        streamer=TextStreamer(
            tokenizer, skip_prompt=True
        ),  # æµå¼è¾“å‡ºå™¨ï¼Œè·³è¿‡æç¤ºéƒ¨åˆ†åªæ˜¾ç¤ºå›ç­”
    )
    
    # å†æ¬¡å®šä¹‰ç›¸åŒçš„ç”¨æˆ·é—®é¢˜ï¼Œç”¨äºæ¼”ç¤ºæ€è€ƒæ¨¡å¼
    messages = [{"role": "user", "content": "Solve (x + 3)^2 = 0."}]
    
    # ä½¿ç”¨èŠå¤©æ¨¡æ¿å¤„ç†æ¶ˆæ¯ï¼Œè¿™æ¬¡å¯ç”¨æ€è€ƒæ¨¡å¼
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True,
        enable_thinking=True,  # å¯ç”¨æ€è€ƒæ¨¡å¼ï¼Œæ¨¡å‹ä¼šå…ˆæ€è€ƒå†ç»™å‡ºç­”æ¡ˆ
    )
    
    # åœ¨æ€è€ƒæ¨¡å¼ä¸‹ç”Ÿæˆå›ç­”
    _ = model.generate(
        **tokenizer(text, return_tensors="pt").to("cuda"),
        max_new_tokens=1024,  # æ€è€ƒæ¨¡å¼éœ€è¦æ›´å¤štokenæ¥å®¹çº³æ€è€ƒè¿‡ç¨‹
        temperature=0.6,  # ç¨ä½çš„æ¸©åº¦ï¼Œä½¿æ€è€ƒè¿‡ç¨‹æ›´é›†ä¸­
        top_p=0.95,  # æ›´é«˜çš„æ ¸é‡‡æ ·å‚æ•°ï¼Œå…è®¸æ›´å¤šæ ·åŒ–çš„æ€è€ƒ
        top_k=20,  # åŒæ ·ä»æ¦‚ç‡æœ€é«˜çš„20ä¸ªtokenä¸­é€‰æ‹©
        streamer=TextStreamer(tokenizer, skip_prompt=True),
    )
    

### 2.4.5 æ¨¡å‹ä¿å­˜

Unslothæ”¯æŒä¸¤æ¡äº’è¡¥çš„æŒä¹…åŒ–è·¯çº¿ï¼š

1.  ä¿ç•™LoRAé€‚é…å™¨ï¼šä½“ç§¯æœ€å°ï¼Œä¾¿äºç»§ç»­å¾®è°ƒæˆ–å¢é‡æ›´æ–°ï¼›
2.  åˆå¹¶å¹¶é‡åŒ–å¯¼å‡ºï¼šå¾—åˆ°ç‹¬ç«‹æƒé‡æ–‡ä»¶ï¼Œæ–¹ä¾¿ç›´æ¥éƒ¨ç½²æˆ–ä¸Šä¼ åˆ° Hubã€‚

**ä¿å­˜LoRAé€‚é…å™¨**

è®­ç»ƒå®Œæˆåï¼Œåªéœ€æŠŠæ¨¡å‹ä¸åˆ†è¯å™¨ä»¥`save_pretrained`å†™å…¥åŒä¸€ç›®å½•å³å¯ï¼š

    model.save_pretrained("lora_model")      # ä»…ä¿å­˜ LoRA å‚æ•°
    tokenizer.save_pretrained("lora_model")
    

åç»­åŠ è½½æ—¶ï¼Œç”¨`from_pretrained`æ¥å£æŒ‡å®šæœ¬åœ°è·¯å¾„ï¼ŒUnslothä¼šè‡ªåŠ¨æŠŠåŸºç¡€æ¨¡å‹ä¸LoRAæƒé‡é‡æ–°ç»„è£…ï¼š

    from unsloth import FastLanguageModel
    
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name="lora_model",   # åŠ è½½loraå‚æ•°ï¼ŒåŒæ—¶åŠ è½½è®­ç»ƒæ—¶çš„åŸºç¡€æ¨¡å‹
        max_seq_length=2048,
        load_in_4bit=True,
    )
    

**åˆå¹¶åå¯¼å‡ºï¼Œç”¨äºéƒ¨ç½²**

å¯å°†LoRAåˆå¹¶åˆ°åŸºç¡€æ¨¡å‹ä¸­ï¼Œå¹¶æ”¯æŒå°†åˆå¹¶åçš„æ¨¡å‹ä¸€æ¬¡æ€§å¯¼å‡ºä¸ºfloat16ã€int4æˆ–GGUFï¼ˆGPT-Generated Unified Formatï¼‰æ ¼å¼ï¼Œä¾¿äºåœ¨GPUæˆ–CPUç«¯ä¾§è¿›è¡Œé«˜æ•ˆæ¨ç†ã€‚

GGUFæ˜¯ä¸€ç§é«˜æ•ˆçš„æ¨¡å‹å­˜å‚¨ä¸äº¤æ¢æ ¼å¼ï¼Œå°†å¤§æ¨¡å‹å°è£…ä¸ºå•ä¸€æ–‡ä»¶ï¼Œå…·å¤‡ç§’çº§åŠ è½½èƒ½åŠ›ã€‚GGUFå¯ç›´æ¥ç”¨äºllama.cppç³»åˆ—å·¥å…·ï¼Œå®ç°å¿«é€Ÿéƒ¨ç½²ä¸åº”ç”¨ã€‚

    # å¯¼å‡ºfloat16å®Œæ•´æƒé‡
    model.save_pretrained_merged("model-f16", tokenizer, save_method="merged_16bit")
    
    # å¯¼å‡ºint4é‡åŒ–æƒé‡ï¼Œä¼šæœ‰ç²¾åº¦æŸå¤±
    model.save_pretrained_merged("model-int4", tokenizer, save_method="merged_4bit_forced")
    
    # å¯¼å‡ºGGUFç³»åˆ—
    model.save_pretrained_gguf("model-q8",  tokenizer)  # é»˜è®¤ Q8_0
    model.save_pretrained_gguf("model-f16", tokenizer,
                               quantization_method="f16")  # 16-bit GGUF
    model.save_pretrained_gguf("model-q4",  tokenizer,
                               quantization_method="q4_k_m") # 4-bit GGUF
    

3 å‚è€ƒ
====

*   [Unsloth](https://github.com/unslothai/unsloth)
*   [Unsloth Docs](https://docs.unsloth.ai/)
*   [Multi-GPU-Unsloth](https://docs.unsloth.ai/basics/multi-gpu-training-with-unsloth)
*   [How To Fine-tune & Run LLMs](https://docs.unsloth.ai/models/tutorials-how-to-fine-tune-and-run-llms)
*   [Unsloth-requirements](https://docs.unsloth.ai/get-started/beginner-start-here/unsloth-requirements)
*   [Unsloth Models](https://docs.unsloth.ai/get-started/all-our-models)
*   [LoRA Hyperparameters Guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide)
*   [LoRAã€QLoRAã€QA-LoRA åŸç†ç¬”è®°](https://zhuanlan.zhihu.com/p/671089942)
*   [Unsloth Datasets Guide](https://docs.unsloth.ai/basics/datasets-guide)
*   [Unsloth Notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks)

æœ¬æ–‡æ¥è‡ªåšå®¢å›­ï¼Œä½œè€…ï¼š[è½ç—•çš„å¯’å‡](https://www.cnblogs.com/luohenyueji/)ï¼Œè½¬è½½è¯·æ³¨æ˜åŸæ–‡é“¾æ¥ï¼š[https://www.cnblogs.com/luohenyueji/p/19122249](https://www.cnblogs.com/luohenyueji/p/19122249)

![](https://gitlab.com/luohenyueji/article_picture_warehouse/-/raw/main/wechat/content/%E5%8A%A0%E6%B2%B9%E9%B8%AD.gif)