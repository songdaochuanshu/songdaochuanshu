---
layout: post
title: 'LM Studio本地部署Qwen3'
date: "2025-05-01T00:45:12Z"
---
LM Studio本地部署Qwen3
==================

一、概述
====

LM Studio 是一款桌面应用程序，用于在您的计算机本地开发和实验 LLM。

官方地址：[https://lmstudio.ai](https://lmstudio.ai)

官方中文地址：[https://lm-studio.cn](https://lm-studio.cn)

主要功能
----

*   用于运行本地 LLM 的桌面应用程序
*   熟悉的聊天界面
*   搜索和下载功能（通过 Hugging Face 🤗）
*   可以监听类似 OpenAI 端点的本地服务器
*   用于管理本地模型和配置的系统

  
**重点来了，LM Studio可以本地运行Hugging Face上面的所有模型，只要Hugging Face有就行。**

**即使国内网络，依然可以下载任意模型，速度也很快。**

Hugging Face地址：[https://huggingface.co](https://huggingface.co)

Ollama本地我也运行过，就是有一个很大缺点，模型不够丰富，因为很多模型不能适配Ollama。

目前模型最丰富的网站，还是Hugging Face，更新速度非常快。比如Qwen3凌晨发布，第二天，Hugging Face就可以看到了。

二、安装
----

访问中文网页：https://lm-studio.cn，下载客户端，直接下一步，下一步安装好，就可以了。

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430142130805-943457601.png)

三、使用
====

中文文档：[https://lm-studio.cn/docs/app](https://lm-studio.cn/docs/app)

设置语言
----

打开客户端，点击右下角的设置按钮

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430142307560-541738772.png)

 设置为简体中文

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430142328821-402248463.png)

模型目录
----

默认目录是C盘，由于C盘空间太小了，所以需要设置为其他盘，比如： E盘

手动创建目录 E:\\lmstudio\\model  
然后点击按钮，设置一下即可。

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430142623436-1991917869.png)

模型安装
----

默认没有模型，所以需要安装一个，这里以最火的Qwen3为例子。

点击搜索按钮

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430142924449-1864591044.png)

搜索模型，比如：Qwen3-4b

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430142443880-1008939140.png)

 点击下载

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430142513182-1181751208.png)

下载速度还可以，17MB/s

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430153908015-2089792070.png)

下载完成后，不要着急运行。

**注意：LM Studio搜索展示的模型，会自动根据你的电脑配置，显示是否可以正常运行。**

比如：Qwen3 235B A22B，就会有提示。

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430152432021-981186719.png)

运行模型
----

点击按钮，选择加载模型，Qwen3-4b

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430143022293-1921063934.png)

 点击设置，开启网络和cors

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430143132737-118061092.png)

**端口暴露**：默认使用 1234 端口，可自定义修改(需注意端口冲突问题)

**跨域支持**：启用 CORS 后，可对接网页应用或其他客户端工具

**局域网访问**：勾选“在局域网内提供服务”选项后，服务器会监听所有网络接口(0.0.0.0)，允许其他设备通过 IP 地址访问

 右边会展示模型相关信息

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430143242410-1217268430.png)

API密钥是：qwen3-4b

注意：这里会进行监听本机ip的1234端口。

**重点提醒一下，这里最好是内网访问，不要用公网暴露端口，否则很容易受到攻击。**

访问api地址：http://127.0.0.1:1234/v1/models

效果如下：

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430143316480-1634705021.png)

测试模型
----

回到首页，选择模型，提问

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430143634151-1521067302.png)

四、Cherry Studio测试
=================

将Cherry Studio更新到最新版本

点击模型服务-->LM Studio

输入API密钥

添加模型：qwen3-4b

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430143828887-1940704030.png)

点击检测

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430144117256-596717620.png)

 检查模型

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430144059767-546328739.png)

 提示连接成功，就可以了

回到首页，选择默认助手，选择模型

![](https://img2024.cnblogs.com/blog/1341090/202504/1341090-20250430144343880-1699850618.png)

LM Studio基本使用，到这里就结束了，使用还是挺简单的。

Qwen3模型都支持MCP调用，这点挺好的。