---
layout: post
title: 'VideoPipe中集成多模态大模型做视频（图片）分析'
date: "2025-08-16T00:41:05Z"
---
VideoPipe中集成多模态大模型做视频（图片）分析
===========================

[VideoPipe](http://www.videopipe.cool/)是一个用于视频分析和结构化的框架，采用 C++ 编写、依赖少、易上手。它像管道一样，其中每个节点相互独立并可自行搭配，VideoPipe可用来构建不同类型的视频分析应用，适用于视频结构化、图片搜索、人脸识别、交通/安防领域的行为分析（如交通事件检测）等场景。

![p1-1](https://img2024.cnblogs.com/blog/104032/202508/104032-20250815075335531-431984243.png)

VideoPipe项目仓库中已经提供了50多个集成传统AI算法模型的Sample源码，涉及到车牌识别、人脸识别、违章检测、图搜、OCR、AI变脸、目标检测、图像分类、图像分割等各个领域。在大模型逐渐成为主流的今天（多模态大模型赋能传统AI视觉算法领域中表现优秀），VideoPipe也支持大模型集成啦，这次重点介绍VideoPipe如何集成多模态大模型来完成视频（图片）分析相关任务。

**快速开始**  
下面基于VideoPipe和阿里云qwen-vl多模态大模型实现一个简单的图片理解的功能：从本地磁盘读取图片序列（现实场景中可以从网络获取图片或视频数据），大模型根据事先定义的Prompt提示词，对图片进行识别理解，依次对图片进行标签化，然后将标签化结果叠加到图片下方，最后显示结果。

1、创建VideoPipe节点类型（事先准备好aliyun大模型服务api\_key）  
2、将节点串起来，组成Pipeline管道  
3、启动管道（一共55行代码）

 1 #include "../nodes/vp\_image\_src\_node.h"
 2 #include "../nodes/infers/vp\_mllm\_analyser\_node.h"
 3 #include "../nodes/osd/vp\_mllm\_osd\_node.h"
 4 #include "../nodes/vp\_screen\_des\_node.h"
 5 #include "../nodes/vp\_rtmp\_des\_node.h"
 6 
 7 #include "../utils/analysis\_board/vp\_analysis\_board.h"
 8 
 9 /\*
10 \* ## mllm\_analyse\_sample\_openai ##
11 \* image(frame) analyse based on Multimodal Large Language Model(from aliyun or other OpenAI-compatible api services).
12 \* read images from disk and analyse the image using MLLM using the prepared prompt.
13 \*/
14 int main() {
15     VP\_SET\_LOG\_INCLUDE\_CODE\_LOCATION(false);
16     VP\_SET\_LOG\_INCLUDE\_THREAD\_ID(false);
17 VP\_SET\_LOG\_LEVEL(vp\_utils::vp\_log\_level::INFO);
18 VP\_LOGGER\_INIT();
19 
20     // create nodes
21     auto image\_src\_0 = std::make\_shared<vp\_nodes::vp\_image\_src\_node>("image\_file\_src\_0", 
22                                                                     0, 
23                                                                     "./vp\_data/test\_images/llm/understanding/%d.jpg", 
24                                                                     2, 
25                                                                     0.5);
26     auto writing\_prompt = "给图片打标签，要求包含：\\n"
27                           "1\. 先仔细观察图片内容，为图片赋予适合的标签\\n"
28                           "2\. 给出的标签最多不超过10个\\n"
29                           "3\. 输出按以下格式：\\n"
30                           "通过仔细观察图片，可以为图片赋予这些标签：\['标签1', '标签2', '标签3'\]。";
31     auto mllm\_analyser\_0 = std::make\_shared<vp\_nodes::vp\_mllm\_analyser\_node>("mllm\_analyser\_0",  // node name
32                             "qwen-vl-max",                                       // mllm model name (support image as input)
33                             writing\_prompt,                                      // prompt
34                             "https://dashscope.aliyuncs.com/compatible-mode/v1", // api base url
35                             "sk-XXX",                                            // api key (from aliyun)
36                             llmlib::LLMBackendType::OpenAI);                     // backend type
37     auto mllm\_osd\_0 = std::make\_shared<vp\_nodes::vp\_mllm\_osd\_node>("osd\_0", 
38                         "./vp\_data/font/NotoSansCJKsc-Medium.otf");
39     auto screen\_des\_0 = std::make\_shared<vp\_nodes::vp\_screen\_des\_node>("screen\_des\_0", 0);
40 
41     // construct pipeline
42     mllm\_analyser\_0->attach\_to({image\_src\_0});
43     mllm\_osd\_0->attach\_to({mllm\_analyser\_0});
44     screen\_des\_0->attach\_to({mllm\_osd\_0});
45 
46     image\_src\_0->start();
47 
48     // for debug purpose
49 vp\_utils::vp\_analysis\_board board({image\_src\_0});
50     board.display(1, false);
51 
52     std::string wait;
53 std::getline(std::cin, wait);
54     image\_src\_0->detach\_recursively();
55 }

**运行效果**

管道运行起来之后，大模型分析节点根据事先定义好的参数（模型名称、提示词、api\_key）访问大模型服务，并解析大模型输出，随后显示节点将大模型输出绘制到图片中，并在控制台实时打印。VideoPipe目前支持的大模型后端有：OpenAI协议兼容服务、Ollama/vLLM本地部署服务。（视频效果[参见官网](http://www.videopipe.cool/index.php/2025/08/13/1-14/)）

![p70](https://img2024.cnblogs.com/blog/104032/202508/104032-20250815075500864-2046769637.png)