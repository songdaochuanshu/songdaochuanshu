---
layout: post
title: 'MPKï¼ˆMirage Persistent Kernelï¼‰æºç ç¬”è®°ï¼ˆ2ï¼‰--- å¤šå±‚ç»“æ„åŒ–å›¾æ¨¡å‹'
date: "2025-10-27T00:44:43Z"
---
MPKï¼ˆMirage Persistent Kernelï¼‰æºç ç¬”è®°ï¼ˆ2ï¼‰--- å¤šå±‚ç»“æ„åŒ–å›¾æ¨¡å‹
================================================

MPKï¼ˆMirage Persistent Kernelï¼‰æºç ç¬”è®°ï¼ˆ2ï¼‰--- å¤šå±‚ç»“æ„åŒ–å›¾æ¨¡å‹
================================================

ç›®å½•

*   [MPKï¼ˆMirage Persistent Kernelï¼‰æºç ç¬”è®°ï¼ˆ2ï¼‰--- å¤šå±‚ç»“æ„åŒ–å›¾æ¨¡å‹](#mpkmirage-persistent-kernelæºç ç¬”è®°2----å¤šå±‚ç»“æ„åŒ–å›¾æ¨¡å‹)
    *   [0x00 æ¦‚è¦](#0x00-æ¦‚è¦)
    *   [0x01 æœºåˆ¶](#0x01-æœºåˆ¶)
        *   [1.1 å½“å‰é—®é¢˜](#11-å½“å‰é—®é¢˜)
        *   [1.2 è§£å†³æ–¹æ¡ˆ](#12-è§£å†³æ–¹æ¡ˆ)
            *   [1.2.1 Î¼Graphsï¼šå¤šå±‚æ¬¡è®¡ç®—å›¾è¡¨ç¤º](#121-Î¼graphså¤šå±‚æ¬¡è®¡ç®—å›¾è¡¨ç¤º)
            *   [1.2.2 å½’çº³å¼ç¨‹åºåˆæˆï¼šä¼˜åŒ–èŒƒå¼](#122-å½’çº³å¼ç¨‹åºåˆæˆä¼˜åŒ–èŒƒå¼)
    *   [0x02 å¤šå±‚æ¬¡è®¡ç®—å›¾è¡¨ç¤º](#0x02-å¤šå±‚æ¬¡è®¡ç®—å›¾è¡¨ç¤º)
        *   [2.1 æ¦‚å¿µ](#21-æ¦‚å¿µ)
        *   [2.2 å±‚çº§å…³ç³»](#22-å±‚çº§å…³ç³»)
        *   [2.3 å¯¹æ¯”](#23-å¯¹æ¯”)
        *   [2.4 æ‰§è¡Œå…³ç³»](#24-æ‰§è¡Œå…³ç³»)
    *   [0x03 å†…æ ¸å›¾](#0x03-å†…æ ¸å›¾)
        *   [3.1 PersistentKernelè°ƒç”¨](#31-persistentkernelè°ƒç”¨)
        *   [3.2 Python ä»£ç ](#32-python-ä»£ç )
        *   [3.3 æ¡¥æ¢](#33-æ¡¥æ¢)
        *   [3.4 C++ ä»£ç ](#34-c-ä»£ç )
        *   [3.5 KNOperator](#35-knoperator)
        *   [3.6 ç”Ÿæˆæ ·ä¾‹](#36-ç”Ÿæˆæ ·ä¾‹)
    *   [0x04 çº¿ç¨‹å—å›¾](#0x04-çº¿ç¨‹å—å›¾)
        *   [4.1 å±æ€§](#41-å±æ€§)
            *   [4.1.1 ç½‘æ ¼å°ºå¯¸](#411-ç½‘æ ¼å°ºå¯¸)
            *   [4.1.2 For-loop å°ºå¯¸](#412-for-loop-å°ºå¯¸)
        *   [4.2 Python ä»£ç ](#42-python-ä»£ç )
        *   [4.3 æ¡¥æ¢](#43-æ¡¥æ¢)
        *   [4.4 C++ä»£ç ](#44-cä»£ç )
        *   [4.5 TBOperator](#45-tboperator)
        *   [4.6 ç”Ÿæˆæ ·ä¾‹](#46-ç”Ÿæˆæ ·ä¾‹)
            *   [4.6.1 Pythonä»£ç ç›´æ¥æ„å»º](#461-pythonä»£ç ç›´æ¥æ„å»º)
            *   [4.6.2 PersistentKernel çš„ layer æ–¹æ³•é—´æ¥æ„å»º](#462-persistentkernel-çš„-layer-æ–¹æ³•é—´æ¥æ„å»º)
            *   [4.6.3 C++ä»£ç ç›´æ¥æ„å»º](#463-cä»£ç ç›´æ¥æ„å»º)
    *   [0x05 çº¿ç¨‹å›¾](#0x05-çº¿ç¨‹å›¾)
    *   [0xFF å‚è€ƒ](#0xff-å‚è€ƒ)

0x00 æ¦‚è¦
-------

Mirage ä½¿ç”¨ uGraph æ¥æŒ‡å®šåœ¨ GPU ä¸Šæ‰§è¡Œå¼ é‡ç¨‹åºã€‚uGraph åŒ…å«å¤šä¸ªçº§åˆ«çš„å±‚æ¬¡åŒ–å›¾ï¼Œä»¥è¡¨ç¤ºåœ¨å†…æ ¸ã€å—å’Œçº¿ç¨‹çº§åˆ«çš„è®¡ç®—ã€‚ä¸‹å›¾æ˜¯GQAå¯¹åº”çš„Î¼Graphsï¼Œæ˜¾ç¤ºäº†ä¸€ä¸ªç”¨äºè®¡ç®—GQAçš„ uGraphã€‚æˆ‘ä»¬ç”¨å®ƒä½œä¸ºè¿è¡Œç¤ºä¾‹æ¥è§£é‡Š uGraph çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚

0x01 æœºåˆ¶
-------

### 1.1 å½“å‰é—®é¢˜

LLM çš„è®¡ç®—è¿‡ç¨‹é€šå¸¸ä»¥è®¡ç®—å›¾çš„å½¢å¼è¡¨ç¤ºï¼Œå…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹å¯¹åº”ä¸€ä¸ªè®¡ç®—ç®—å­ï¼ˆå¦‚çŸ©é˜µä¹˜æ³•ã€æ³¨æ„åŠ›æœºåˆ¶ï¼‰æˆ–é›†åˆé€šä¿¡åŸè¯­ï¼ˆå¦‚ all-reduceï¼‰ï¼Œè¾¹è¡¨ç¤ºç®—å­é—´çš„æ•°æ®ä¾èµ–å…³ç³»ã€‚ç°æœ‰ç³»ç»Ÿé€šå¸¸ä¸ºæ¯ä¸ªç®—å­å¯åŠ¨ç‹¬ç«‹çš„ GPU å†…æ ¸ã€‚ç„¶è€Œï¼Œè¿™ç§â€œå•ç®—å­å•å†…æ ¸â€çš„æ‰§è¡Œæ¨¡å‹éš¾ä»¥å®ç° pipeline ä¼˜åŒ–ï¼Œå› ä¸ºä¾èµ–å…³ç³»æ˜¯åœ¨æ•´ä¸ªå†…æ ¸çš„ç²—ç²’åº¦å±‚é¢å¼ºåˆ¶æ‰§è¡Œçš„ï¼Œè€Œéå®é™…æ•°æ®å•å…ƒå±‚é¢ã€‚

ä¾‹å¦‚ï¼ŒçŸ©é˜µä¹˜æ³•ï¼ˆmatmulï¼‰åæ¥ all-reduce æ“ä½œï¼šç°æœ‰ç³»ç»Ÿä¸­ï¼Œall-reduce å†…æ ¸å¿…é¡»ç­‰å¾…æ•´ä¸ª matmul å†…æ ¸å®Œæˆã€‚è€Œå®é™…ä¸Šï¼Œall-reduce çš„æ¯ä¸ªæ•°æ®åˆ†å—ä»…ä¾èµ– matmul è¾“å‡ºçš„å±€éƒ¨ç»“æœã€‚è¿™ç§é€»è¾‘ä¾èµ–ä¸å®é™…ä¾èµ–çš„é”™é…ï¼Œä¸¥é‡é™åˆ¶äº†è®¡ç®—ä¸é€šä¿¡çš„é‡å æ½œåŠ›ã€‚ä¸‹å›¾çš„å³ä¾§å±•ç¤ºæ¬¡ä¼˜æ–¹æ¡ˆ â€”â€” å…¶å¼•å…¥ä¸å¿…è¦çš„æ•°æ®ä¾èµ–ä¸å…¨å±€å±éšœï¼Œå¯¼è‡´è·¨å±‚æµæ°´çº¿ä¼˜åŒ–æœºä¼šå—é™ã€‚

### 1.2 è§£å†³æ–¹æ¡ˆ

ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼ŒMirageå®ç°äº†å¤šå±‚æ¬¡è®¡ç®—å›¾è¡¨ç¤ºï¼ˆÎ¼Graphsï¼‰ä¸å½’çº³å¼ç¨‹åºåˆæˆï¼ˆInductive Program Synthesisï¼‰ã€‚è¿™ä¸¤å¤§æœºåˆ¶ååŒä½œç”¨ï¼Œå®ç°äº†ä»å®è§‚è°ƒåº¦åˆ°å¾®è§‚è®¡ç®—çš„å…¨é“¾è·¯ä¼˜åŒ–ï¼Œé«˜æ•ˆç”ŸæˆGPUç¨‹åºï¼Œæ˜¾è‘—æå‡äº†å¼ é‡è®¡ç®—çš„æ€§èƒ½ã€‚

Mirage çš„ç¼–è¯‘æµç¨‹æ¸…æ™°ä¸”ç›®æ ‡æ˜ç¡®ï¼š

*   è¾“å…¥ï¼šæ¥è‡ªé¢„å®šä¹‰ç®—å­é›†åˆçš„è®¡ç®—å›¾å­å›¾ï¼ˆå¦‚ GQA æ³¨æ„åŠ›è®¡ç®—å­å›¾ï¼‰ï¼Œç¡®ä¿è¾“å…¥é€»è¾‘çš„è§„èŒƒæ€§ä¸å¯ä¼˜åŒ–æ€§ï¼›
*   æ ¸å¿ƒä¼˜åŒ–æ­¥éª¤ï¼šåŒ…å«å›¾é‡å†™ï¼ˆGraph Rewriteï¼Œè°ƒæ•´å›¾ç»“æ„ä»¥é€‚é… GPU æ¶æ„ï¼‰ã€ç®—å­èåˆï¼ˆOperator Fusionï¼Œå‡å°‘å†…å­˜è®¿é—®æ¬¡æ•°ï¼‰ç­‰ï¼Œæ‰€æœ‰ä¼˜åŒ–å‡åŸºäº Î¼Graphs çš„è·¨å±‚çº§è¡¨ç¤ºå±•å¼€ï¼›
*   è¾“å‡ºï¼šä¼˜åŒ–åçš„ CUDA ç¨‹åºï¼Œç›´æ¥é€‚é… GPU ç¡¬ä»¶æ‰§è¡Œï¼Œå¯ç›´æ¥JITåµŒå…¥pytorchã€‚

#### 1.2.1 Î¼Graphsï¼šå¤šå±‚æ¬¡è®¡ç®—å›¾è¡¨ç¤º

MPK ç¼–è¯‘å™¨å°† LLM è®¡ç®—å›¾è‡ªåŠ¨è½¬åŒ–ä¸ºç»†ç²’åº¦ä»»åŠ¡å›¾ï¼Œæœ€å¤§åŒ–æš´éœ²å¹¶è¡Œæ€§ã€‚è¯¥ä»»åŠ¡å›¾åœ¨å­å†…æ ¸çº§åˆ«æ˜¾å¼æ•è·ä¾èµ–å…³ç³»ï¼Œå®ç°æ›´æ¿€è¿›çš„è·¨å±‚æµæ°´çº¿ä¼˜åŒ–ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨ MPK ä»»åŠ¡å›¾ä¸­ï¼ˆå‚è§ä¸Šå›¾ï¼‰ï¼š

*   ä»»åŠ¡ï¼ˆçŸ©å½¢è¡¨ç¤ºï¼‰ï¼šä»£è¡¨åˆ†é…ç»™å•ä¸ª GPU æµå¼å¤šå¤„ç†å™¨ï¼ˆSMï¼‰çš„è®¡ç®—æˆ–é€šä¿¡å•å…ƒã€‚
*   äº‹ä»¶ï¼ˆåœ†å½¢è¡¨ç¤ºï¼‰ï¼šè¡¨ç¤ºä»»åŠ¡é—´çš„åŒæ­¥ç‚¹ã€‚
*   è§¦å‘æœºåˆ¶ï¼šæ¯ä¸ªä»»åŠ¡å‘å‡ºæŒ‡å‘è§¦å‘äº‹ä»¶çš„è¾¹ï¼Œè¯¥äº‹ä»¶åœ¨å…³è”ä»»åŠ¡å…¨éƒ¨å®Œæˆåæ¿€æ´»ã€‚
*   ä¾èµ–æœºåˆ¶ï¼šæ¯ä¸ªä»»åŠ¡æ¥æ”¶æ¥è‡ªä¾èµ–äº‹ä»¶çš„è¾¹ï¼Œè¡¨æ˜äº‹ä»¶æ¿€æ´»åä»»åŠ¡ç«‹å³å¯åŠ¨ã€‚

ä»»åŠ¡å›¾ä½¿ MPK èƒ½å¤Ÿå‘æ˜è®¡ç®—å›¾ä¸­æ— æ³•å®ç°çš„ pipeline ä¼˜åŒ–æœºä¼šã€‚ä¾‹å¦‚ï¼ŒMPK å¯ä»¥æ„å»ºä¼˜åŒ–ä»»åŠ¡å›¾ â€”â€” å…¶ä¸­æ¯ä¸ª all-reduce ä»»åŠ¡ä»…ä¾èµ–äºç”Ÿæˆå…¶è¾“å…¥çš„å¯¹åº” matmul ä»»åŠ¡ï¼Œä»è€Œå®ç°åˆ†å—æ‰§è¡Œä¸è®¡ç®—é€šä¿¡é‡å ã€‚

é™¤ç”Ÿæˆä¼˜åŒ–ä»»åŠ¡å›¾å¤–ï¼ŒMPK è¿˜é€šè¿‡ Mirage å†…æ ¸è¶…ä¼˜åŒ–å™¨è‡ªåŠ¨ä¸ºæ¯ä¸ªä»»åŠ¡ç”Ÿæˆé«˜æ€§èƒ½ CUDA å®ç°ï¼Œç¡®ä¿ä»»åŠ¡åœ¨ GPU æµå¼å¤šå¤„ç†å™¨ï¼ˆSMï¼‰ä¸Šé«˜æ•ˆæ‰§è¡Œã€‚

#### 1.2.2 å½’çº³å¼ç¨‹åºåˆæˆï¼šä¼˜åŒ–èŒƒå¼

å½’çº³å¼ç¨‹åºåˆæˆæ˜¯Mirageçš„å¦ä¸€å¤§æ ¸å¿ƒæœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„æ¼”ç»å¼ç¨‹åºåˆæˆï¼ˆå¦‚åŸºäºè§„åˆ™çš„é‡å†™ç³»ç»Ÿï¼‰ä¸åŒï¼Œå½’çº³å¼ç¨‹åºåˆæˆç›´æ¥ä»è¯­æ³•å‡ºå‘æ„é€ ç¨‹åºï¼Œå¹¶å€ŸåŠ©SMTæ±‚è§£å™¨éªŒè¯æ„é€ ç¨‹åºä¸åŸç¨‹åºçš„ç­‰ä»·æ€§ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿçªç ´ä¼ ç»Ÿä¼˜åŒ–æ–¹æ³•çš„å±€é™ï¼Œå‘ç°å°†ä»£æ•°å˜æ¢ã€è°ƒåº¦å˜æ¢å’Œæ–°è‡ªå®šä¹‰å†…æ ¸ç”Ÿæˆç›¸ç»“åˆçš„åˆ›æ–°ä¼˜åŒ–è·¯å¾„ã€‚

é€šè¿‡å½’çº³å¼ç¨‹åºåˆæˆï¼ŒMirageèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆé«˜æ€§èƒ½çš„GPUå†…æ ¸ä»£ç ï¼Œä¸ä»…ç®€åŒ–äº†å¼€å‘æµç¨‹ï¼Œè¿˜æå‡äº†ç¨‹åºçš„è¿è¡Œæ•ˆç‡ï¼Œä½¿å¾—å¼€å‘è€…èƒ½å¤Ÿæ›´ä¸“æ³¨äºé«˜å±‚é€»è¾‘çš„è®¾è®¡ï¼Œè€Œæ— éœ€æ·±å…¥åº•å±‚ç¡¬ä»¶ç»†èŠ‚ã€‚

ä¼ ç»Ÿæœºå™¨å­¦ä¹ ç¼–è¯‘å™¨ï¼ˆå¦‚ TVMã€TensorRTï¼‰é‡‡ç”¨æ¼”ç»å¼ç¨‹åºåˆæˆï¼ˆDeductive Program Synthesisï¼Œåˆç§° Term Rewriteï¼‰ ï¼šä»åŸå§‹ç¨‹åºå‡ºå‘ï¼Œé€šè¿‡ç­‰ä»·é‡å†™è§„åˆ™ï¼ˆå¦‚å›¾æ¨¡å¼åŒ¹é…ã€å¾ªç¯è°ƒåº¦åŸè¯­ï¼‰é€æ­¥å˜æ¢ï¼Œå§‹ç»ˆåœ¨ â€œç¨‹åºç­‰ä»·ç±»â€ å†…æœç´¢æ›´ä¼˜å®ç° â€”â€” è¿™ç§æ–¹å¼ä¾èµ–æ‰‹å·¥è®¾è®¡è§„åˆ™ï¼Œéš¾ä»¥çªç ´ç°æœ‰ç­‰ä»·ç±»çš„æ€§èƒ½ä¸Šé™ã€‚

Mirage åˆ™é‡‡ç”¨å½’çº³å¼ç¨‹åºåˆæˆï¼šä¸ä¾èµ–åŸå§‹ç¨‹åºçš„é€æ­¥å˜æ¢ï¼Œè€Œæ˜¯ç›´æ¥åŸºäºç®—å­è¯­æ³•æ„é€ å…¨æ–°å€™é€‰ç¨‹åºï¼Œå†é€šè¿‡ â€œÎ¼Graphs è¯­ä¹‰æ ¡éªŒ + æ¦‚ç‡ç­‰ä»·éªŒè¯â€ï¼ˆå¦‚æœ‰é™åŸŸéšæœºæµ‹è¯•ï¼‰ç¡®è®¤å€™é€‰ç¨‹åºä¸åŸå§‹ç¨‹åºçš„åŠŸèƒ½ä¸€è‡´æ€§ã€‚è¿™ç§èŒƒå¼æ— éœ€å—é™äºç­‰ä»·é‡å†™è§„åˆ™ï¼Œå¯æ¢ç´¢æ›´çµæ´»çš„è·¨å±‚çº§ä¼˜åŒ–æ–¹æ¡ˆï¼ˆå¦‚ Kernel-Graph åˆæˆç®—å­ä¸ Block-Graph å…±äº«å†…å­˜å¤ç”¨çš„ååŒï¼‰ï¼ŒåŒæ—¶é€šè¿‡æ¦‚ç‡éªŒè¯ä¿éšœæ­£ç¡®æ€§ã€‚

ä¸‹å›¾æ˜¯Mirageæ‰¾å‡ºçš„æœ€ä½³Î¼Graphsã€‚

0x02 å¤šå±‚æ¬¡è®¡ç®—å›¾è¡¨ç¤º
-------------

Mirage å®ç°äº†å¤šå±‚æ¬¡è®¡ç®—å›¾è¡¨ç¤ºï¼ˆÎ¼Graphsï¼‰ï¼Œé€šè¿‡ kernel-graphï¼ˆå†…æ ¸å›¾ï¼‰ã€block-graphï¼ˆå—å›¾ï¼‰å’Œ thread-graphï¼ˆçº¿ç¨‹å›¾ï¼‰è¿™ä¸‰å±‚ç»“æ„åŒ–å›¾æ¨¡å‹ï¼Œç²¾ç¡®æ˜ å°„ GPU ç¨‹åºä»å†…æ ¸åˆ°çº¿ç¨‹çš„æ‰§è¡Œé€»è¾‘ä¸å­˜å‚¨å±‚çº§ã€‚è¿™ç§ä¸‰å±‚ç»“æ„ä¸ CUDA ç¨‹åºçš„æ‰§è¡Œå±‚çº§åŠ GPU çš„å­˜å‚¨ä½“ç³»ç´§å¯†å¯¹åº”ï¼Œæ¯å±‚å‡æ¸…æ™°å®šä¹‰äº† â€œç®—å­ç±»å‹ â€” å¼ é‡å­˜å‚¨ â€” æ ¸å¿ƒåŠŸèƒ½â€ çš„å…³è”å…³ç³»ã€‚

### 2.1 æ¦‚å¿µ

ä¸‰å±‚çš„æ¦‚å¿µå¦‚ä¸‹ï¼š

1.  kernel-graphï¼ˆå†…æ ¸å›¾ï¼‰ï¼šå±äºé«˜å±‚æ¬¡æŠ½è±¡ï¼Œç”¨äºè¡¨ç¤ºæ•´ä¸ªè®¡ç®—å›¾ï¼ˆå³å®Œæ•´çš„è®¡ç®—ä»»åŠ¡ï¼‰ï¼ŒåŒ…å«ç²—ç²’åº¦çš„é«˜å±‚æ“ä½œï¼ˆå¦‚å®Œæ•´çš„çŸ©é˜µä¹˜æ³•ã€è§„çº¦è¿ç®—ç­‰ï¼‰ä¸å¯¹åº”æ•°æ®ã€‚è¯¥å±‚è´Ÿè´£å…¨å±€è°ƒåº¦ï¼Œé‡ç‚¹å…³æ³¨æ•°æ®æµä¸ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»ï¼Œå¯¹åº” GPU çš„å…¨å±€å†…å­˜ï¼Œä¸»è¦å¤„ç†å®è§‚å±‚é¢çš„ä»»åŠ¡åˆ†é…ä¸ååŒã€‚å…¶åŒ…å«çš„ç®—å­ï¼ˆä¸¾ä¾‹ï¼‰ç±»å‹æœ‰ï¼š
    1.  é«˜å±‚æ“ä½œï¼šKN\_INPUT\_OPï¼ˆè¾“å…¥ç®—å­ï¼‰ã€KN\_OUTPUT\_OPï¼ˆè¾“å‡ºç®—å­ï¼‰ã€KN\_MATMUL\_OPï¼ˆçŸ©é˜µä¹˜æ³•ç®—å­ï¼‰ï¼›
    2.  æ•°å­¦æ“ä½œï¼šKN\_EXP\_OPï¼ˆæŒ‡æ•°è¿ç®—ç®—å­ï¼‰ã€KN\_ADD\_OPï¼ˆåŠ æ³•ç®—å­ï¼‰ã€KN\_MUL\_OPï¼ˆä¹˜æ³•ç®—å­ï¼‰ï¼›
    3.  è§„çº¦æ“ä½œï¼šKN\_REDUCTION\_0\_OPï¼ˆé›¶é˜¶è§„çº¦ç®—å­ï¼‰ç­‰ï¼›
    4.  è‡ªå®šä¹‰æ“ä½œï¼šKN\_CUSTOMIZED\_OPï¼ˆè‡ªå®šä¹‰ç®—å­ï¼‰ç­‰ã€‚
2.  block-graphï¼ˆå—å›¾ï¼‰ï¼šå±äºä¸­ç­‰å±‚æ¬¡æŠ½è±¡ï¼ŒåµŒå¥—åœ¨ KN\_CUSTOMIZED\_OPï¼ˆè‡ªå®šä¹‰å†…æ ¸ç®—å­ï¼‰ä¸­ï¼Œå®šä¹‰ threadblockï¼ˆçº¿ç¨‹å—ï¼‰çº§åˆ«çš„è®¡ç®—é€»è¾‘ã€‚è¯¥å±‚åŒ…å«ç»†ç²’åº¦æ“ä½œï¼Œè´Ÿè´£ç®¡ç†çº¿ç¨‹å—çº§åˆ«çš„å¹¶è¡Œè®¡ç®—ï¼Œé‡ç‚¹å…³æ³¨å†…å­˜è®¿é—®æ¨¡å¼ã€å¾ªç¯ç»“æ„ç­‰ä¸­è§‚ç»†èŠ‚ï¼Œå¯¹åº” GPU çš„å…±äº«å†…å­˜ï¼Œæ ¸å¿ƒç›®æ ‡æ˜¯ä¼˜åŒ–ä¸­è§‚å±‚é¢çš„èµ„æºåˆ©ç”¨ä¸æ•°æ®å…±äº«æ•ˆç‡ã€‚å…¶åŒ…å«çš„ç®—å­ç±»å‹ï¼ˆä¸¾ä¾‹ï¼‰æœ‰ï¼š
    1.  è¾“å…¥æ“ä½œï¼šTB\_INPUT\_OPï¼ˆçº¿ç¨‹å—è¾“å…¥ç®—å­ï¼‰ï¼›
    2.  å†…å­˜æ“ä½œï¼šTB\_MATMUL\_OPï¼ˆçº¿ç¨‹å—çŸ©é˜µä¹˜æ³•ç®—å­ï¼‰ã€TB\_EXP\_OPï¼ˆçº¿ç¨‹å—æŒ‡æ•°è¿ç®—ç®—å­ï¼‰ï¼›
    3.  ç‰¹æ®Šæ“ä½œï¼šTB\_FORLOOP\_ACCUM\_NO\_RED\_OPï¼ˆçº¿ç¨‹å—å¾ªç¯ç´¯åŠ æ— è§„çº¦ç®—å­ï¼‰ã€TB\_RMS\_NORM\_OPï¼ˆçº¿ç¨‹å— RMS å½’ä¸€åŒ–ç®—å­ï¼‰ã€‚
3.  thread-graphï¼ˆçº¿ç¨‹å›¾ï¼‰ï¼šåœ¨ block-graph çš„å…·ä½“æ“ä½œä¸­ä½“ç°ï¼Œå®šä¹‰çº¿ç¨‹çº§åˆ«çš„æ‰§è¡Œç»†èŠ‚ã€‚è¯¥å±‚ä¸“æ³¨äºçº¿ç¨‹çº§åˆ«çš„å¾®è§‚è®¡ç®—é€»è¾‘ï¼Œå¯¹åº” GPU çš„å¯„å­˜å™¨ï¼Œæ ¸å¿ƒä½œç”¨æ˜¯ç¡®ä¿æ¯ä¸ªçº¿ç¨‹çš„é«˜æ•ˆæ‰§è¡Œï¼Œæœ€å¤§åŒ–å•çº¿ç¨‹çš„è®¡ç®—ååé‡ã€‚

è¿™ç§ä¸‰å±‚ç»“æ„æ”¯æŒç³»ç»Ÿåœ¨ä¸åŒæŠ½è±¡å±‚çº§å¼€å±•é’ˆå¯¹æ€§ä¼˜åŒ–ï¼š

*   åœ¨ kernel-graph å±‚ï¼Œä¸»è¦è¿›è¡Œå…¨å±€ä»»åŠ¡è°ƒåº¦ä¸æ•°æ®æµä¼˜åŒ–ï¼Œæ˜ç¡®æ•´ä½“è®¡ç®—æµç¨‹ä¸èµ„æºåˆ†é…æ–¹å‘ï¼›
*   åœ¨ block-graph å±‚ï¼Œä¾§é‡çº¿ç¨‹å—çº§åˆ«çš„å¹¶è¡Œç­–ç•¥ä¼˜åŒ–ï¼Œæå‡ä¸­è§‚å±‚é¢çš„å¹¶è¡Œæ•ˆç‡ä¸æ•°æ®å…±äº«èƒ½åŠ›ï¼›
*   åœ¨ thread-graph å±‚ï¼Œèšç„¦å…·ä½“çš„å†…å­˜è®¿é—®æ¨¡å¼ä¼˜åŒ–ä¸è®¡ç®—æŒ‡ä»¤è°ƒåº¦ï¼Œç¡®ä¿å¾®è§‚æ‰§è¡Œçš„é«˜æ•ˆæ€§ã€‚

è‹¥ç”¨é€šä¿—è¯­è¨€æ¦‚æ‹¬ä¸‰å±‚ç»“æ„çš„åˆ†å·¥ï¼škernel-graph å†³å®š â€œè¦åšä»€ä¹ˆâ€ï¼ˆæ˜ç¡®æ•´ä½“è®¡ç®—ä»»åŠ¡ä¸ç›®æ ‡ï¼‰ï¼Œblock-graph å†³å®š â€œè¯¥æ€ä¹ˆåšâ€ï¼ˆè§„åˆ’çº¿ç¨‹å—çº§çš„æ‰§è¡Œæ–¹æ¡ˆï¼‰ï¼Œthread-graph è´Ÿè´£ â€œå…·ä½“æ‰§è¡Œâ€ï¼ˆå®Œæˆçº¿ç¨‹çº§çš„å¾®è§‚è®¡ç®—ï¼‰ã€‚

è¿™ç§ä»å®è§‚åˆ°å¾®è§‚çš„å±‚æ¬¡åŒ–è®¾è®¡ï¼Œä½¿ Î¼Graphs èƒ½å¤Ÿå®ç°ä»å…¨å±€è°ƒåº¦åˆ°å±€éƒ¨æ‰§è¡Œçš„å…¨é“¾è·¯ä¼˜åŒ–ï¼Œæœ‰æ•ˆå‡å°‘è®¡ç®—å†—ä½™ä¸èµ„æºæµªè´¹ï¼Œç¡®ä¿ GPU è®¡ç®—èµ„æºçš„é«˜æ•ˆåˆ©ç”¨ã€‚

### 2.2 å±‚çº§å…³ç³»

ä¸‰çº§å›¾ç»“æ„çš„å…³ç³»å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

      muGraph(Kernel Graph)                                    
      â”‚                                                        
      â”œâ”€â”€â”€â”€â–º KNOperator(å„ç§æ ‡å‡†æ“ä½œ)                                       
      â”‚                                   
      â”‚                                                        
      â””â”€â”€â”€â”€â–º KNCustomizeOp(è‡ªå®šä¹‰æ“ä½œ)                                   
                â”‚                                              
                â””â”€â”€â”€â–º block-graph(Threadblock Graph)           
                       â”‚                                       
                       â”œâ”€â”€â”€â”€â–º TBOperator(å„ç§çº¿ç¨‹å—æ“ä½œ)                     
                       â”‚                                       
                       â””â”€â”€â”€â”€â–º TBInputOp(è¿æ¥åˆ°muGraphçš„å¼ é‡)                      
                                 â”‚                             
                                 â””â”€â”€â”€â–º thread-level execution(çº¿ç¨‹çº§æ‰§è¡Œ)
    

### 2.3 å¯¹æ¯”

ä¸‰å±‚çš„å¯¹æ¯”å¦‚ä¸‹ã€‚

è®¡ç®—å›¾å±‚çº§

å¯¹åº” CUDA æ‰§è¡Œå±‚çº§

å¼ é‡å­˜å‚¨ä½ç½®

ç®—å­ç±»å‹ä¸åŠŸèƒ½

æ ¸å¿ƒå±æ€§ / é€»è¾‘

Kernel-Graph

æ•´ä¸ª GPU å†…æ ¸ï¼ˆå¤šæµå¤„ç†å™¨ SM ååŒï¼‰

è®¾å¤‡å…¨å±€å†…å­˜ï¼ˆDevice DRAMï¼‰

1\. **é¢„å®šä¹‰ç®—å­**ï¼šç›´æ¥è°ƒç”¨å‚å•†åº“å†…æ ¸ï¼ˆå¦‚ cuBLAS çš„ GEMM çŸ©é˜µä¹˜ã€cuDNN çš„å·ç§¯ï¼‰ï¼› 2. **åˆæˆç®—å­**ï¼šéœ€é€šè¿‡æ›´ä½å±‚çº§çš„ Block-Graph æè¿°ï¼Œæ‰¿è½½ç®—å­èåˆã€è‡ªå®šä¹‰ç®—æ³•ç­‰å¤æ‚é€»è¾‘

æ— é¢å¤–å±æ€§ï¼Œæ ¸å¿ƒæ˜¯ â€œè°ƒåº¦å¤š SM ååŒâ€ï¼Œé€šè¿‡é¢„å®šä¹‰ç®—å­å¤ç”¨æˆç†Ÿåº“æ€§èƒ½ï¼Œåˆæˆç®—å­æ”¯æŒçµæ´»ä¼˜åŒ–

Block-Graph

å•ä¸ªæµå¤„ç†å™¨ SMï¼ˆçº¿ç¨‹å—åä½œï¼‰

å…±äº«å†…å­˜ï¼ˆShared Memoryï¼‰

1\. **é¢„å®šä¹‰ç®—å­**ï¼šè°ƒç”¨ CUTLASSã€ThunderKittens ç­‰åº“çš„å…±äº«å†…å­˜æ“ä½œï¼ˆå¦‚å—å†…çŸ©é˜µä¹˜ã€ç´¯åŠ ï¼‰ï¼› 2. **åˆæˆç®—å­**ï¼šç”± Thread-Graph æè¿°ï¼Œå®ç°çº¿ç¨‹å—å†…ç»†ç²’åº¦è®¡ç®—

1\. **å¹¶è¡Œåˆ‡åˆ†å±æ€§**ï¼šimapï¼ˆè¾“å…¥åˆ†å—ï¼Œæ˜ å°„ Grid ç»´åº¦åˆ°è¾“å…¥å¼ é‡ç»´åº¦ï¼‰ã€omapï¼ˆè¾“å‡ºæ‹¼æ¥ï¼Œæ˜ å°„ Grid ç»´åº¦åˆ°è¾“å‡ºå¼ é‡ç»´åº¦ï¼‰ã€fmapï¼ˆå¾ªç¯è¿­ä»£ï¼Œæ˜ å°„ For-Loop ç»´åº¦åˆ°æ•°æ®è¿­ä»£å™¨ / ç´¯åŠ å™¨ç»´åº¦ï¼‰ï¼› 2. **æ‰§è¡Œé€»è¾‘**ï¼šæ”¯æŒçº¿ç¨‹å—å¾ªç¯è¿­ä»£ï¼Œé€šè¿‡å…±äº«å†…å­˜å¤ç”¨ä¸ â€œè®¡ç®— - è®¿å­˜é‡å â€ï¼Œå°†å…¨å±€å†…å­˜è¯»å†™å»¶è¿Ÿéšè—åœ¨è®¡ç®—è¿‡ç¨‹ä¸­

Thread-Graph

å•ä¸ªçº¿ç¨‹ï¼ˆå¯„å­˜å™¨æ“ä½œï¼‰

çº¿ç¨‹ç§æœ‰å¯„å­˜å™¨ï¼ˆRegister Fileï¼‰

ä»…å«**é¢„å®šä¹‰ç®—å­**ï¼Œæè¿°å•ä¸ªçº¿ç¨‹å†…çš„å¯„å­˜å™¨çº§æµæ°´æ“ä½œï¼ˆå¦‚ load æ•°æ®â†’å…ƒç´ çº§è®¡ç®—â†’store ç»“æœï¼‰ï¼Œæ”¯æŒå¾ªç¯è¿­ä»£ä¸å¯„å­˜å™¨ç´¯åŠ ï¼›é»˜è®¤é€šè¿‡ â€œè§„åˆ™åŒ–èåˆâ€ å¿«é€Ÿç”Ÿæˆï¼Œé¿å…ç»†ç²’åº¦å±‚çº§çš„å†—ä½™æœç´¢

æ ¸å¿ƒæ˜¯ â€œå•çº¿ç¨‹é«˜æ•ˆæµæ°´â€ï¼Œé€šè¿‡å¯„å­˜å™¨æ“ä½œæœ€å°åŒ–å†…å­˜è®¿é—®ï¼Œæå‡è®¡ç®—å¯†åº¦

### 2.4 æ‰§è¡Œå…³ç³»

persistent\_kernel.pyæ˜¯ Persistent Kernelçš„Pythonæ¥å£ï¼Œæœ¬è´¨æ˜¯Pythonåˆ°CUDAæŒä¹…åŒ–å†…æ ¸ç³»ç»Ÿçš„æ¡¥æ¢ï¼Œå…è®¸ç”¨æˆ·ç”¨pythonå®šä¹‰å¤æ‚çš„è®¡ç®—å›¾ï¼Œç„¶ååœ¨GPUä¸Šé«˜æ•ˆæ‰§è¡Œã€‚

persistent\_kernel.pyä¸ä¸‰å±‚è®¡ç®—å›¾çš„å…³ç³»å¦‚ä¸‹ï¼š

1.  Persistent Kernel åˆ›å»ºå¹¶ç®¡ç† Kernel Graph
2.  Kernel Graph é€šè¿‡ KN\_CUSTOMIZED\_OP åŒ…å«å¤šä¸ª Block Graph
3.  æ¯ä¸ª Block Graph å®šä¹‰çº¿ç¨‹å—å†…çš„æ“ä½œåºåˆ—
4.  Kernel Graph è½¬æ¢ä¸º Task Graph ç”¨äºæ‰§è¡Œ
5.  Task Execution Engine åœ¨ Persistent Kernel ä¸­æ‰§è¡Œä»»åŠ¡
6.  Event System ç®¡ç†ä»»åŠ¡é—´çš„ä¾èµ–å’ŒåŒæ­¥
7.  Thread Graph åœ¨å®é™…GPUçº¿ç¨‹ä¸­æ‰§è¡Œå…·ä½“æ“ä½œ

0x03 å†…æ ¸å›¾
--------

æ¯ä¸ªå¼ é‡ç¨‹åºå¯¹åº”ä¸€ä¸ªå†…æ ¸å›¾ï¼Œå…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨åœ¨æ•´å€‹ GPU ä¸Šè¿è¡Œçš„å†…æ ¸ï¼Œæ¯æ¡è¾¹æ˜¯å†…æ ¸ä¹‹é—´å…±äº«çš„å¼ é‡ã€‚å†…æ ¸å›¾ä¸­çš„æ‰€æœ‰å¼ é‡éƒ½å­˜å‚¨åœ¨ GPU è®¾å¤‡å†…å­˜ä¸­ï¼Œå› ä¸ºä¸åŒçš„å†…æ ¸ä¸èƒ½åœ¨å¯„å­˜å™¨æ–‡ä»¶æˆ–å…±äº«å†…å­˜ä¸­å…±äº«æ•°æ®ã€‚å†…æ ¸å›¾ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½å¯ä»¥æ˜¯ç°æœ‰å†…æ ¸åº“ï¼ˆå¦‚ cuDNN çš„å·ç§¯å’Œ cuBLAS çš„çŸ©é˜µä¹˜æ³•ï¼‰æ”¯æŒçš„é¢„å®šä¹‰å†…æ ¸æ“ä½œç¬¦ã€‚æ­¤å¤–ï¼Œä¸ºäº†å¯ç”¨ç»†ç²’åº¦çš„å†…æ ¸é—´ä¼˜åŒ–ï¼ˆå¦‚å†…æ ¸èåˆï¼‰ï¼Œå†…æ ¸å›¾ä¸­çš„èŠ‚ç‚¹ä¹Ÿå¯ä»¥æ˜¯å›¾å®šä¹‰çš„å†…æ ¸æ“ä½œç¬¦ï¼Œå…¶è¯­ä¹‰å’Œè¡Œä¸ºç”±è¾ƒä½çº§åˆ«çš„ï¼ˆå³å—ï¼‰å›¾å®šä¹‰ã€‚ä¸‹å›¾ä¸­çš„ä¸¤ä¸ªå†…æ ¸æ“ä½œç¬¦éƒ½æ˜¯å›¾å®šä¹‰çš„æ“ä½œç¬¦ï¼Œæ¯ä¸ªéƒ½ç”±å—å›¾æŒ‡å®šã€‚

### 3.1 PersistentKernelè°ƒç”¨

åœ¨PersistentKernelå†…éƒ¨ï¼Œkn\_graphè´Ÿè´£å®é™…çš„è®¡ç®—å›¾æ„å»ºã€‚

    self.kn_graph = KNGraph(CyKNGraph(disable_fingerprint=True))
    

æ¯ä¸ªattach\_inputå’Œnew\_tensorè°ƒç”¨éƒ½ä¼šåœ¨kn\_graphä¸­åˆ›å»ºå¼ é‡èŠ‚ç‚¹ã€‚æ¯ä¸ªlayerè°ƒç”¨ä¹Ÿä¼šåœ¨kn\_graphä¸­æ·»åŠ ç›¸åº”çš„è®¡ç®—èŠ‚ç‚¹ã€‚æœ€åcompile()è°ƒç”¨self.kn\_graph.generate\_task\_graphç”Ÿæˆä»»åŠ¡å›¾ã€‚

### 3.2 Python ä»£ç 

å†…æ ¸å›¾åœ¨Pythonä¸­çš„ç±»æ˜¯KNGraphã€‚KNGraphç”¨äºæ„å»ºå’Œç®¡ç†å†…æ ¸è®¡ç®—å›¾ã€‚æ¯”å¦‚ï¼Œnew\_inputä¼šåˆ›å»ºæ–°çš„è¾“å…¥å˜é‡ã€‚attach\_torch\_tensorç®¡ç†PyTorchå˜é‡ã€‚attach\_cuda\_tensorå…³è”CUDAå˜é‡ã€‚compileä¼šç”Ÿæˆæœ€ç»ˆçš„æ‰§è¡Œä»£ç ã€‚

KNGraphçš„ç‰¹ç‚¹å¦‚ä¸‹ï¼š

*   Kernel graphçš„èŠ‚ç‚¹æ˜¯ï¼š
    
    *   é¢„å®šä¹‰ç®—å­ï¼ˆpre-defined operatorï¼‰ï¼Œæ¯”å¦‚cuBLAS GEMMã€cuDNN Conv
    *   åˆæˆç®—å­ï¼ˆgraph-defined operatorï¼‰ï¼Œç”¨æ›´ä½ä¸€å±‚çš„block graphæè¿°ï¼Œå¯æ‰¿è½½fusion/æ–°ç®—æ³•ã€‚
*   Kernel graphçš„è¾¹æ˜¯ï¼šä½äºå…¨å±€å†…å­˜ï¼ˆDevice DRAMï¼‰çš„Tensorã€‚
    

KNGraph ä»£ç ä¸¾ä¾‹å¦‚ä¸‹ï¼š

    class KNGraph:
        def __init__(self, graph):
            self.cygraph = graph
            self._is_compiled = False
            self.run = None
            self._valid_cuda_kernels = False
            self._cached_results = None
            self.visualizer = None
    
            self.backend = "cuda"
            
        def new_input(
            self, dims: tuple, strides: tuple = None, dtype: dtype = float16
        ) -> DTensor:
            # use the default strided layout if strides = None
            if strides is None:
                total_elements = 1
                strides = []
                for d in reversed(dims):
                    strides.append(total_elements)
                    total_elements *= d
                strides = reversed(strides)
            return self.cygraph.new_input(dims, tuple(strides), dtype)      
        
    
        def compile(self, async_=False, **kwargs):
            if self._is_compiled:
                return self._cached_results
            input_tensors = kwargs.get("inputs", [])
            input_strides = []
    
            for i in range(len(dtensors)):
                dims, strides = self.cygraph.get_input_dtensor_shape_and_stride(dtensors[i])
                input_strides.append(strides)
            target_cc = kwargs.get(
                "target_cc",
                torch.cuda.get_device_properties(0).major * 10
                + torch.cuda.get_device_properties(0).minor,
            )
            num_warp_groups = kwargs.get("num_warp_groups", 2)
            pipeline_stages = kwargs.get("pipeline_stages", 2)
            enable_online_softmax = kwargs.get("enable_online_softmax", False)
    
            result = generate_cuda_program(
                self.cygraph,
                target_cc=target_cc,
                input_strides=input_strides,
                num_warp_groups=num_warp_groups,
                pipeline_stages=pipeline_stages,
                profiling=profiling,
                enable_online_softmax=enable_online_softmax,
            )
            if result["max_smem_size"] > get_shared_memory_capacity(target_cc):
                self._is_compiled = True
                self._valid_cuda_kernels = False
                self._error_message = "shared memory usage exceed limit"
    
                if async_:
                    return Handle([], None)
                else:
                    return None
    
            MIRAGE_ROOT, INCLUDE_PATH, DEPS_PATH = get_key_paths()
            tempdir_obj = tempfile.TemporaryDirectory()
            tempdir = tempdir_obj.name
            saved_addr = ""
            file_id = kwargs.get("file_id", -1)
            if file_id != -1:
                print(f"file_id: {file_id}")
                saved_addr = f"./generated_codes/{file_id}/"
            FILE_NAME = os.path.join(tempdir, "test.cu")
            so_path = os.path.join(tempdir, "test.cpython-38-x86_64-linux-gnu.so")
    
            with open(FILE_NAME, "w") as f:
                f.write(result["code"] + HARD_CODE)
                if saved_addr != "":
                    print(f"saved_addr: {saved_addr}")
                    os.makedirs(saved_addr, exist_ok=True)
                    with open(saved_addr + "test" + str(file_id) + ".cu", "w") as f:
                        f.write(result["code"] + HARD_CODE)
    
            cc = shutil.which("nvcc")
            # This function was renamed and made public in Python 3.10
            if hasattr(sysconfig, "get_default_scheme"):
                scheme = sysconfig.get_default_scheme()
            else:
                scheme = sysconfig._get_default_scheme()
            if scheme == "posix_local":
                scheme = "posix_prefix"
            py_include_dir = sysconfig.get_paths(scheme=scheme)["include"]
            cc_cmd = get_cc_cmd(
                target_cc,
                cc,
                FILE_NAME,
                py_include_dir,
                INCLUDE_PATH,
                DEPS_PATH,
                so_path,
                profiling,
            )
    
            def remain_op():
                import importlib.util
    
                try:
                    spec = importlib.util.spec_from_file_location(
                        "__mirage_launcher", so_path
                    )
                    mod = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(mod)
                    self.run = getattr(mod, "launch")
                    self._is_compiled = True
                    self._valid_cuda_kernels = True
                    self._cached_results = result
                    self._error_message = "No error"
                    tempdir_obj.cleanup()
                    return self._cached_results
                except ImportError:
                    self._is_compiled = True
                    self._valid_cuda_kernels = False
                    self._cached_results = None
                    self._error_message = "CUDA compilation error"
                    return None
    
            if async_:
                if global_config.bypass_compile_errors:
                    ret = subprocess.Popen(
                        cc_cmd, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT
                    )
                else:
                    ret = subprocess.Popen(cc_cmd)
                return Handle([ret], remain_op)
            else:
                ret = subprocess.check_call(cc_cmd)
                return remain_op()
    

### 3.3 æ¡¥æ¢

PersistentKernel ä¸­ï¼Œé€šè¿‡å¦‚ä¸‹æ–¹å¼è¿›è¡Œè®¾ç½® Kernel Graphã€‚

    self.kn_graph = KNGraph(CyKNGraph(disable_fingerprint=True))
    

åœ¨python\\mirage\_cython\\core.pyx æ–‡ä»¶ä¸­ï¼ŒCyKNGraph ä¸­æœ‰å®šä¹‰ CppKNGraphã€‚

    cdef class CyKNGraph:
        cdef CppKNGraph *p_kgraph #Hold a CppKNGraph instance
    
        def __cinit__(self, graph = None, bool disable_fingerprint = False):
            cdef unsigned long long ptr
            cdef dim3 c_gpu_dim
            if graph is None:
                c_gpu_dim.x = 1
                c_gpu_dim.y = 1
                c_gpu_dim.z = 1
                self.p_kgraph = new CppKNGraph(c_gpu_dim, disable_fingerprint)
            else:
                ptr = ctypes.cast(graph, ctypes.c_void_p).value
                self.p_kgraph = <CppKNGraph*>(ptr)
    

åœ¨ python\\mirage\_cython\\CCore.pxd æ–‡ä»¶ä¸­ï¼ŒæŒ‡æ˜ CppKNGraph å¯¹åº”äº† "mirage::kernel::Graph"ï¼Œè¿™ä¾¿æ˜¯C++ä»£ç ä¸­ï¼ŒKernel Graph çš„å®ç°ã€‚

        cdef cppclass CppKNGraph "mirage::kernel::Graph":
            CppKNGraph(dim3 gpu_dim, bool disable_fingerprint)
            CppDTensor* new_input_ptr(vector[int] dims,
                                      vector[size_t] strides,
                                      DataType data_type,
                                      DmemLayout layout)
            void mark_output(const CppDTensor* A, vector[size_t] strides)
            CppDTensor* matmul(const CppDTensor* A, const CppDTensor* B)
            CppDTensor* reduction(const CppDTensor* input, int dim, int size)
            CppDTensor* rms_norm(const CppDTensor* input, vector[int])
            CppDTensor* exp(const CppDTensor* input)
            CppDTensor* silu(const CppDTensor* input)
            CppDTensor* gelu(const CppDTensor* input)
            CppDTensor* relu(const CppDTensor* input)
            CppDTensor* clamp(const CppDTensor* input, float min_val, float max_val)
            CppDTensor* sqrt(const CppDTensor* input)
            CppDTensor* square(const CppDTensor* input)
            CppDTensor* add(const CppDTensor* op1, const CppDTensor* op2)
            CppDTensor* mul(const CppDTensor* op1, const CppDTensor* op2)
            CppDTensor* div(const CppDTensor* op1, const CppDTensor* op2)
            CppDTensor* pow(const CppDTensor* op1, const CppDTensor* op2)
            int customized(vector[const CppDTensor*] inputs,
                           CppDTensor** outputs,
                           CppTBGraph* bgraph)
            int get_num_input_dtensors()
            int get_num_output_dtensors()
            int get_input_dtensors(CppDTensor** cinputs)
            int get_input_dtensor_shape_and_stride(const CppDTensor *input, int *strides, int *dims)
            void generate_triton_program(const char *filepath)
            void generate_cuda_program(const char *filepath)
            size_t get_owner_independent_hash() const
            # Persistent kernel functions
            void attach_torch_tensor(const CppDTensor *input,
                                     void *torch_data_ptr,
                                     const char *name)
            void attach_cuda_tensor(const CppDTensor *input,
                                    const char *name)
            void attach_nvshmem_tensor(const CppDTensor *input,
                                       const char *name)
            CppDTensor* fuse_tensors(vector[const CppDTensor*] inputs,
                                     int fused_dim,
                                     int num_groups,
                                     const char *name)
            void register_task(const char *task_type,
                               vector[int] params)
            TaskGraphResult generate_task_graph(int num_gpus, int my_gpu_id)
    
            vector[CppKNOperator*] operators
    

### 3.4 C++ ä»£ç 

muGraphåœ¨c++ä»£ç ä¸­ä½“ç°ä¸ºmirage::kernel::Graphç±»ï¼Œè¿™æ˜¯æœ€é«˜å±‚æ¬¡çš„è®¡ç®—å›¾ã€‚

    namespace mirage {
    namespace kernel {
    
    class Graph {
    private:
      struct pair_hash {
        size_t operator()(std::pair<int, int> const &p) const;
      };
    
    public:
      Graph(dim3 gpu_dim = {1, 1, 1}, bool disable_fingerprint = false);
      ~Graph();
      Graph(Graph const &) = delete;
      Graph &operator=(Graph const &) = delete;
      // input operator
      DTensor new_input(std::vector<int> const &dims,
                        std::vector<size_t> const &strides,
                        mirage::type::DataType data_type,
                        mirage::layout::DmemLayout layout);
      DTensor elementunary(DTensor const &input,
                           mirage::type::KNOperatorType _type);
      // å¿½ç•¥å…¶å®ƒå‡½æ•°  
    
    public:
      std::vector<mirage::kernel::KNOperator *> operators; // æ“ä½œç¬¦åˆ—è¡¨
      dim3 gpu_dim;
      off_t dmem_data_offset, dmem_fp_offset;
      std::vector<std::pair<off_t, size_t>> allocated_data_tensors,
          allocated_fp_tensors;
      // Fields for persistent kernels
      std::map<mirage::type::GuidType, mirage::runtime::IODesc> io_config;
      std::unordered_map<mirage::kernel::KNOperator const *,
                         std::tuple<int, int, runtime::TaskType, int>>
          task_config;
    
      using OpType = KNOperator;
      using TensorType = DTensor;
    };  
    

mirage::kernel::Graphçš„ä¸»è¦ç‰¹å¾æ˜¯ï¼š

*   æ“ä½œç¬¦ç±»å‹ï¼šä½¿ç”¨KNOperatorType æšä¸¾å®šä¹‰æ“ä½œç±»å‹ã€‚
*   å¼ é‡è¡¨ç¤ºï¼šä½¿ç”¨DTensorï¼ˆDevice Tensorï¼‰è¡¨ç¤ºæ•°æ®ã€‚
*   æ“ä½œèŠ‚ç‚¹ï¼šåŒ…æ‹¬è¾“å…¥ï¼ˆKN\_INPUT\_OPï¼‰ï¼Œè¾“å‡ºï¼ˆKN\_OUTPUT\_OPï¼‰ï¼ŒçŸ©é˜µä¹˜æ³•ï¼ˆKN\_MATMUL\_OPï¼‰ç­‰ã€‚

mirage::kernel::Graphçš„æˆå‘˜å‡½æ•°ä»¥ elementunar ä¸ºä¾‹ï¼Œä»£ç å¦‚ä¸‹ï¼š

    DTensor Graph::elementunary(DTensor const &input,
                                mirage::type::KNOperatorType type) {
      KNOperator *op = create_elementunary_op(input, type);
      assert(op != nullptr);
      operators.push_back(op);
      assert(op->output_tensors.size() == 1);
      DTensor output = op->output_tensors[0];
      return output;
    }
    

### 3.5 KNOperator

GraphåŒ…å«å¤šä¸ªKNOperatorå¯¹è±¡ã€‚

KNOperatoræ˜¯å†…æ ¸çº§åˆ«çš„æ“ä½œç¬¦åŸºç±»ï¼Œç”¨äºè¡¨ç¤ºè®¡ç®—å›¾ä¸­çš„èŠ‚ç‚¹ã€‚ä½œä¸ºè®¡ç®—å›¾ä¸­æ¯ä¸ªæ“ä½œçš„åŸºæœ¬å•å…ƒï¼Œå¯ä»¥ç»´æŠ¤è¾“å…¥å’Œè¾“å‡ºå¼ é‡çš„ä¿¡æ¯ï¼Œæä¾›æ“ä½œç±»å‹è¡¨ç¤ºã€‚è€Œä¸”ï¼Œé€šè¿‡è¾“å…¥è¾“å‡ºå¼ é‡çš„è¿æ¥å…³ç³»ï¼Œå¯ä»¥å»ºç«‹æ“ä½œé—´çš„ä¾èµ–å…³ç³»ï¼Œä¸ºåç»­çš„ä»»åŠ¡è°ƒåº¦å’Œäº‹ä»¶ç®¡ç†æä¾›åŸºç¡€ã€‚

åœ¨runtime.ccä¸­ï¼Œç³»ç»Ÿé€šè¿‡éå†Graphä¸­çš„operatorsæ¥ç”Ÿæˆä»»åŠ¡å›¾ã€‚

    class KNOperator {
    public:
      KNOperator(Graph *graph, mirage::type::KNOperatorType _type);
      KNOperator(Graph *graph,
                 mirage::type::KNOperatorType _type,
                 DTensor const &input1);
      KNOperator(Graph *graph,
                 mirage::type::KNOperatorType _type,
                 DTensor const &input1,
                 DTensor const &input2);
      KNOperator(Graph *graph,
                 mirage::type::KNOperatorType _type,
                 std::vector<DTensor> const &inputs);
      int get_input_dtensors(DTensor **inputs);
      int get_output_dtensors(DTensor **inputs);
    
      virtual ~KNOperator();
      virtual bool fingerprint(void) = 0;
      virtual operator json() const = 0; // å°†æ“ä½œåºåˆ—è½¬æ¢ä¸ºJSONæ ¼å¼
    
      // hash related functions
      virtual size_t get_owner_independent_hash() const;
    
    public:
      Graph *kgraph; // é€šè¿‡è¯¥æŒ‡é’ˆç»´æŠ¤ä¸æ‰€å±è®¡ç®—å›¾çš„å…³è”
      mirage::type::KNOperatorType op_type; // æ ‡è¯†æ“ä½œç±»å‹
      std::vector<DTensor> input_tensors; // å­˜å‚¨æ“ä½œçš„è¾“å…¥å¼ é‡
      std::vector<DTensor> output_tensors; // å­˜å‚¨æ“ä½œçš„è¾“å‡ºå¼ é‡
    };
    

KNCustomizedOpï¼ŒKNInputOpï¼ŒKNOutputOpæ˜¯KNOperatorçš„æ´¾ç”Ÿç±»ã€‚KNOperatorçš„æ´¾ç”Ÿç±»ä¸¾ä¾‹ã€‚

    class KNInputOp : public KNOperator {
    public:
      KNInputOp(Graph *_graph,
                std::vector<int> const &dims,
                std::vector<size_t> const &strides,
                mirage::type::DataType data_type,
                mirage::layout::DmemLayout layout,
                int3 input_map = {-1, -1, -1});
      ~KNInputOp();
      bool fingerprint(void);
    
      operator json() const override;
    
    public:
      std::vector<size_t> input_strides;
      int3 input_map;
    };
    
    class KNOutputOp : public KNOperator {
    public:
      KNOutputOp(Graph *_graph,
                 DTensor const &A,
                 std::vector<size_t> const &strides,
                 int3 output_map = {-1, -1, -1});
      ~KNOutputOp();
      bool fingerprint(void);
    
      operator json() const override;
    
    public:
      std::vector<size_t> output_strides;
      int3 output_map;
    };
    
    class KNCustomizedOp : public mirage::kernel::KNOperator {
    public:
      KNCustomizedOp(Graph *_kgraph,
                     std::vector<DTensor> const &inputs,
                     mirage::threadblock::Graph const &_graph);
      virtual ~KNCustomizedOp();
      bool fingerprint(void);
      size_t get_owner_independent_hash() const override;
    
      operator json() const override;
    
    public:
      mirage::threadblock::Graph bgraph;
      void get_bgraph(mirage::threadblock::Graph **bgraph);
    };
    

KNOperatorType çš„å…¨é‡ä¸ºï¼š

    enum KNOperatorType {
      KN_UNKOWN = 1000,
      KN_INPUT_OP = 1001,
      KN_OUTPUT_OP = 1002,
      KN_MATMUL_OP = 1003,
      // ElementUnary
      KN_EXP_OP = 1100,
      KN_SQUARE_OP = 1101,
      KN_SQRT_OP = 1102,
      KN_MUL_SCALAR_OP = 1103,
      KN_SILU_OP = 1104,
      KN_SIGMOID_OP = 1105,
      KN_GELU_OP = 1106,
      // non-lax elementunary ops
      KN_RELU_OP = 1150,
      KN_CLAMP_OP = 1151,
      KN_LOG_OP = 1160,
      // ElementBinary
      KN_ADD_OP = 1200,
      KN_MUL_OP = 1201,
      KN_DIV_OP = 1202,
      KN_POW_OP = 1203,
      // Reduction & Normalization
      KN_REDUCTION_0_OP = 1300,
      KN_REDUCTION_1_OP = 1301,
      KN_REDUCTION_2_OP = 1302,
      KN_RMS_NORM_OP = 1350,
      // Concat & Split
      KN_CONCAT_FIRST_OP_ID = 1400,
      KN_CONCAT_0_OP = 1400,
      KN_CONCAT_1_OP = 1401,
      KN_CONCAT_2_OP = 1402,
      KN_CONCAT_LAST_OP_ID = 1409,
      KN_SPLIT_FIRST_OP_ID = 1420,
      KN_SPLIT_0_OP = 1420,
      KN_SPLIT_1_OP = 1421,
      KN_SPLIT_2_OP = 1422,
      KN_CHUNK_0_OP = 1423,
      KN_CHUNK_1_OP = 1424,
      KN_CHUNK_2_OP = 1425,
      KN_SPLIT_LAST_OP_ID = 1429,
      // Communication
      KN_ALLREDUCE_OP = 1900,
      KN_CUSTOMIZED_OP = 1999,
    };
    

### 3.6 ç”Ÿæˆæ ·ä¾‹

Kernel & blockå›¾çš„ç”Ÿæˆé€»è¾‘å¦‚ä¸‹ï¼š

*   ä»è¾“å…¥èŠ‚ç‚¹å‡ºå‘ï¼Œä»¥xï¼Œyï¼Œzè¾“å…¥å¼ é‡ä¸ºèµ·ç‚¹ï¼Œåˆå§‹åŒ–ä¸€ä¸ªç©ºå‰ç¼€ã€‚
*   è¿­ä»£å¢é•¿ï¼Œæšä¸¾ç®—å­æ¥æ„é€ æ–°èŠ‚ç‚¹ï¼Œæ¯æ¬¡æšä¸¾ä¸€ä¸ªç®—å­åŠ å…¥ï¼ˆæšä¸¾matmulã€addã€exp...ï¼Œåˆæˆç®—å­ï¼‰ï¼Œå½“æšä¸¾åˆ°åˆæˆç®—å­ï¼Œé©¬ä¸Šè¿›å…¥block graphçš„synthesisï¼Œæ¯æ¬¡æ‰©å¼ ä¼šæ£€æŸ¥åˆæ³•æ€§ï¼šå½¢çŠ¶ã€æ˜¾å­˜/SMEMå®¹é‡ã€è·¯å¾„çº¦æŸã€‚
*   æŠ½è±¡å‰ªæï¼Œè®¡ç®—å½“å‰å‰ç¼€çš„æŠ½è±¡è¡¨è¾¾å¼Eï¼Œå½“å’Œcanonical form E0ä¸ä¸€è‡´æ—¶å‰ªæï¼Œç”Ÿæˆç»“æŸåä¼šå¾—åˆ°æ²¡æœ‰thread graphçš„kernel/blockå›¾å€™é€‰é›†åˆã€‚

ä¸‹é¢ä»£ç ä¸­ç»™å‡ºäº†kernel graphå’Œblock graphçš„ç”Ÿæˆæ ·ä¾‹ã€‚

    import mirage as mi
    
    def new_kernel_graph():
        kgraph = core.CyKNGraph()
        return KNGraph(kgraph)
    
    def get_rms_linear():
        graph = mi.new_kernel_graph() # kernel graph
        X = graph.new_input(dims=(num_tokens, 4096), dtype=mi.float16)
        W = graph.new_input(dims=(4096, n_local_heads * head_dim + 2 * n_local_kv_heads * head_dim), dtype=mi.float16)
        # block graph
        tb_graph = mi.new_threadblock_graph(grid_dim=(384,1,1), block_dim=(128,1,1), forloop_range=32, reduction_dimx=64)
        tX = tb_graph.new_input(dtensor=X, input_map=(-1, -1, -1), forloop_dim=1)
        tW = tb_graph.new_input(dtensor=W, input_map=(1, -1, -1), forloop_dim=0)
        tM = tb_graph.matmul(tX, tW)
        tAccX = tb_graph.forloop_accum(tX, "rms")
        tAccM = tb_graph.forloop_accum(tM)
        tO = tb_graph.div(tAccM, tAccX)
        tb_graph.new_output(stensor=tO, output_map=(1, -1, -1))
        O = graph.customized([X, W], tb_graph)
        return graph, O
        
    def mirage_llama(X, Wqkv, Wo, W13, W2, Kcache, Vcache, kernels):
        func = kernels[0]
        outputs = func(inputs=[X, Wqkv])
        Xqkv = outputs[0]
        Xq = Xqkv[:, : (n_local_heads * head_dim)]
        output_shape = Xq.shape
        Xkv = Xqkv[:, (n_local_heads * head_dim) :]
        Xk, Xv = Xkv.chunk(2, 1)
        Xq = Xq.view(Xq.shape[0], n_local_heads, head_dim)
        Xk = Xk.view(Xk.shape[0], n_local_kv_heads, head_dim)
        Xv = Xv.view(Xv.shape[0], n_local_kv_heads, head_dim)
        output = flashinfer.single_prefill_with_kv_cache(Xq, Kcache, Vcache, causal=True)
        output = torch.matmul(output.reshape(output_shape), Wo)
        X = output
        func = kernels[1]
        outputs = func(inputs=[X, W13])
        X13 = outputs[0]
        X1, X3 = X13.chunk(2, -1)
        output = torch.matmul(X1, W2)
        return output    
     
    if __name__ == "__main__":
        X = torch.randn(num_tokens, 4096, dtype=torch.float16, device='cuda:0')
        Wqkv = torch.randn(4096, n_local_heads * head_dim + 2 * n_local_kv_heads * head_dim, dtype=torch.float16, device='cuda:0')
        Wo = torch.randn(n_local_heads * head_dim, 4096, dtype=torch.float16, device='cuda:0')
        W13 = torch.randn(4096, intermediate_size * 2, dtype=torch.float16, device='cuda:0')
        W2 = torch.rand(14336, 4096, dtype=torch.float16, device='cuda:0')
        Kcache = torch.rand(num_kv_tokens, n_local_kv_heads, head_dim, dtype=torch.float16, device='cuda:0')
        Vcache = torch.rand(num_kv_tokens, n_local_kv_heads, head_dim, dtype=torch.float16, device='cuda:0')
    
        k1 = get_rms_linear() # æ­¤å¤„ç”Ÿæˆè®¡ç®—å›¾
        k2 = get_rms_linear2() # æ­¤å¤„ç”Ÿæˆè®¡ç®—å›¾
        kernels = [k1, k2]
    
        for _ in range(16):
            mirage_llama(X, Wqkv, Wo, W13, W2, Kcache, Vcache, kernels)
        torch.cuda.synchronize()
    

from\_json()å‡½æ•°ä¹Ÿä¼šç”Ÿæˆã€‚ä»¥ä¸‹æ˜¯åˆ›å»ºæ“ä½œã€‚gæ˜¯å†…æ ¸å›¾ã€‚

    void from_json(json const &j, Graph &g) {
        switch (op_type) {
          case type::KNOperatorType::KN_INPUT_OP: {
            int num_dim, dim[mirage::config::MAX_TENSOR_DIMS];
            type::DataType data_type;
            layout::DmemLayout layout;
            std::vector<size_t> input_strides;
            size_t guidO;
            jop.at("output_tensors")[0].at("num_dims").get_to(num_dim);
            jop.at("output_tensors")[0].at("dim").get_to(dim);
            jop.at("input_strides").get_to(input_strides);
            jop.at("output_tensors")[0].at("data_type").get_to(data_type);
            jop.at("output_tensors")[0].at("layout").get_to(layout);
            jop.at("output_tensors")[0].at("guid").get_to(guidO);
            std::vector<int> dims = to_vector(num_dim, dim);
            // è°ƒç”¨KNGraphçš„å‡½æ•°
            DTensor const &output =
                g.new_input(dims, input_strides, data_type, layout);
            guid_mapping[output.guid] = guidO;
            break;
          }
    

new\_inputæ˜¯KNGraphçš„å‡½æ•°ã€‚

    class KNGraph:
        def new_input(
            self, dims: tuple, strides: tuple = None, dtype: dtype = float16
        ) -> DTensor:
            # use the default strided layout if strides = None
            if strides is None:
                total_elements = 1
                strides = []
                for d in reversed(dims):
                    strides.append(total_elements)
                    total_elements *= d
                strides = reversed(strides)
            return self.cygraph.new_input(dims, tuple(strides), dtype)
    

æœ€ç»ˆåˆ°CyTBGraph

    cdef class CyTBGraph:
        cdef CppTBGraph *p_bgraph #Hold a CppTBGraph instance
    
        def __cinit__(self, tuple grid_dim = (), tuple block_dim = (), int forloop_range = -1, int dimx = -1, bgraph = None):
            cdef unsigned long long ptr
            cdef dim3 c_grid_dim
            cdef dim3 c_block_dim
            if bgraph is None:
                c_grid_dim.x = grid_dim[0]
                c_grid_dim.y = grid_dim[1]
                c_grid_dim.z = grid_dim[2]
                c_block_dim.x = block_dim[0]
                c_block_dim.y = block_dim[1]
                c_block_dim.z = block_dim[2]
                self.p_bgraph = new CppTBGraph(c_grid_dim, c_block_dim, forloop_range, dimx)
            else:
                ptr = ctypes.cast(bgraph, ctypes.c_void_p).value
                if isinstance(bgraph, int):
                    self.p_bgraph = <CppTBGraph*>(ptr)
                elif isinstance(bgraph, ctypes.c_void_p):
                    self.p_bgraph = <CppTBGraph*>(ptr)
        
        def new_input(self, DTensor dtensor, tuple input_map, int forloop_dim, bool store_in_dmem = False):
    
            cdef int3 c_input_map
            c_input_map.x = input_map[0]
            c_input_map.y = input_map[1]
            c_input_map.z = input_map[2]
            cdef CppDTensor* dtensor_cptr = NULL
            if dtensor is not None:
                dtensor_cptr = dtensor.c_ptr
            cdef CppSTensor* ptr = self.p_bgraph.new_input(dtensor_cptr, c_input_map, forloop_dim, SmemRowMajor, store_in_dmem)
            t = ctypes.cast(<unsigned long long>ptr, ctypes.c_void_p)
            return STensor(t)
    
        def new_output(self, STensor stensor, tuple output_map, int forloop_dim, str epilogue = None):
            cdef int3 c_output_map
            c_output_map.x = output_map[0]
            c_output_map.y = output_map[1]
            c_output_map.z = output_map[2]
            epilogue_type = string_to_tbepilogue(epilogue)
            self.p_bgraph.new_output(stensor.c_ptr, c_output_map, forloop_dim, epilogue_type)  
    
        def matmul(self, STensor A, STensor B):
            cdef CppSTensor* ptr = self.p_bgraph.matmul(A.c_ptr, B.c_ptr)
            t = ctypes.cast(<unsigned long long>ptr, ctypes.c_void_p)
            return STensor(t)
    
        def exp(self, STensor A):
            cdef CppSTensor* ptr = self.p_bgraph.exp(A.c_ptr)
            t = ctypes.cast(<unsigned long long>ptr, ctypes.c_void_p)
            return STensor(t)
    
        def silu(self, STensor A):
            cdef CppSTensor* ptr = self.p_bgraph.silu(A.c_ptr)
            t = ctypes.cast(<unsigned long long>ptr, ctypes.c_void_p)
            return STensor(t)
    

0x04 çº¿ç¨‹å—å›¾
---------

kernel graph ç®¡ç†æ•´ä½“è®¡ç®—æµï¼Œblock\_graph ç®¡ç†çº¿ç¨‹å—çº§åˆ«çš„å¹¶è¡Œè®¡ç®—ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„ GPU æ‰§è¡Œã€‚

å—å›¾æŒ‡å®šä¸çº¿ç¨‹å—ç›¸å…³çš„è®¡ç®—ï¼Œå…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹è¡¨ç¤ºä¸€ä¸ªå—æ“ä½œç¬¦ï¼ŒæŒ‡å®šçº¿ç¨‹å—å†…çš„è®¡ç®—ï¼Œæ¯æ¡è¾¹æ˜¯çº¿ç¨‹å—æ“ä½œç¬¦ä¹‹é—´å…±äº«çš„å¼ é‡ã€‚Mirage å°†å—å›¾ä¸­çš„æ‰€æœ‰ä¸­é—´å¼ é‡ä¿å­˜åœ¨ GPU å…±äº«å†…å­˜ä¸­ï¼Œæœ‰ä¸¤ä¸ªè€ƒè™‘ã€‚é¦–å…ˆï¼ŒGPU å…±äº«å†…å­˜æä¾›çš„å¸¦å®½è¿œé«˜äºè®¾å¤‡å†…å­˜ï¼Œè¿™ç§è®¾è®¡å…è®¸ Mirage é€šè¿‡æœ€å¤§é™åº¦åœ°å°†ä¸­é—´ç»“æœä¿å­˜åœ¨å…±äº«å†…å­˜ä¸­æ¥å‡å°‘è®¾å¤‡å†…å­˜è®¿é—®ã€‚å…¶æ¬¡ï¼Œå¯¹äºå¤§å°è¶…è¿‡å…±äº«å†…å­˜å®¹é‡ä¸”å¿…é¡»å­˜å‚¨åœ¨è®¾å¤‡å†…å­˜ä¸­çš„å¼ é‡ï¼ŒMirage ä½¿ç”¨è¿™äº›å¼ é‡å°†è®¡ç®—åˆ†å‰²æˆå¤šä¸ªå—å›¾ï¼Œæ¯ä¸ªå—å›¾ä»…åŒ…å«å…±äº«å†…å­˜ä¸­çš„å¼ é‡ã€‚è¿™ç§åˆ†ç¦»ä¸ä¼šå¼•å…¥å¯¹è®¾å¤‡å†…å­˜çš„é¢å¤–è®¿é—®ã€‚

### 4.1 å±æ€§

æ¯ä¸ªå—å›¾è¿˜ä¸ä¸€äº›å±æ€§ç›¸å…³è”ï¼Œä»¥æŒ‡å®šå…¶æ‰§è¡Œã€‚

#### 4.1.1 ç½‘æ ¼å°ºå¯¸

å†…æ ¸ä¸­çš„æ‰€æœ‰çº¿ç¨‹å—éƒ½ç”±æœ€å¤š 3 ç»´çš„ç½‘æ ¼ç»„ç»‡ï¼Œæ ‡è¯†ä¸º xã€y å’Œ zã€‚ç›¸åº”åœ°ï¼Œå—å›¾ä¸æœ€å¤šä¸‰ä¸ªç½‘æ ¼å°ºå¯¸ç›¸å…³è”ï¼ŒæŒ‡å®šæ²¿ xã€y å’Œ z å°ºå¯¸çš„å—æ•°ã€‚ä¸Šå›¾ä¸­çš„ä¸¤ä¸ªå—å›¾å¯åŠ¨äº† 80ï¼ˆå³ 8 Ã— 10ï¼‰å’Œ 64ï¼ˆå³ 8 Ã— 8ï¼‰ä¸ªå—ã€‚

é¦–å…ˆï¼Œå¯¹äºå›¾å®šä¹‰çš„å†…æ ¸æ“ä½œç¬¦ï¼ˆä¾‹å¦‚å†…æ ¸å›¾ä¸­çš„ Qã€K å’Œ Vï¼‰çš„æ¯ä¸ªè¾“å…¥å¼ é‡ï¼Œç›¸å…³çš„å—å›¾åŒ…å«ä¸€ä¸ª imapï¼Œå®ƒæŒ‡å®šå¦‚ä½•å°†è¾“å…¥å¼ é‡åˆ’åˆ†ä¸ºå„ä¸ªå—çš„å­å¼ é‡ã€‚å¯¹äºæ¯ä¸ªç½‘æ ¼å°ºå¯¸ï¼ˆå³ xã€y æˆ– zï¼‰ï¼Œimap å°†å…¶æ˜ å°„åˆ°ï¼ˆ1ï¼‰è¾“å…¥å¼ é‡çš„æ•°æ®ç»´åº¦æˆ–ï¼ˆ2ï¼‰ç‰¹æ®Šçš„å‰¯æœ¬ç»´åº¦ ğœ™ã€‚å¯¹äºï¼ˆ1ï¼‰ï¼Œæ˜ å°„çš„æ•°æ®ç»´åº¦åœ¨ç½‘æ ¼å°ºå¯¸ä¸Šçš„å—ä¹‹é—´å‡åŒ€åˆ’åˆ†ã€‚å¯¹äºï¼ˆ2ï¼‰ï¼Œè¾“å…¥å¼ é‡åœ¨è¿™äº›çº¿ç¨‹å—ä¹‹é—´å¤åˆ¶ã€‚

å…¶æ¬¡ï¼Œå¯¹äºå—å›¾çš„æ¯ä¸ªè¾“å‡ºå¼ é‡ï¼Œå—å›¾åŒ…æ‹¬ä¸€ä¸ª omapï¼Œå®ƒæŒ‡å®šæ‰€æœ‰å—çš„è¾“å‡ºå¦‚ä½•è¿æ¥ä»¥æ„å»ºå†…æ ¸æ“ä½œç¬¦çš„æœ€ç»ˆè¾“å‡ºã€‚åœ¨ omap ä¸­ï¼Œæ¯ä¸ªç½‘æ ¼å°ºå¯¸å¿…é¡»æ˜ å°„åˆ°è¾“å‡ºå¼ é‡çš„æ•°æ®ç»´åº¦ï¼Œå› ä¸ºä¸åŒçš„å—å¿…é¡»ä¿å­˜åˆ°è®¾å¤‡å†…å­˜ä¸­çš„ä¸ç›¸äº¤å¼ é‡ã€‚å¯¹äºä¸Šå›¾ä¸­å½¢çŠ¶ä¸º \[h=1, s=8, d=64\] çš„ Bï¼Œå…¶ omap={x<->h, y<->d} è¡¨ç¤ºå…·æœ‰ç›¸åŒ x ç´¢å¼•çš„å—æ²¿ h ç»´åº¦è¿æ¥ï¼Œå…·æœ‰ç›¸åŒ y ç´¢å¼•çš„å—æ²¿ d ç»´åº¦è¿æ¥ï¼Œä»è€Œå¾—åˆ°å½¢çŠ¶ä¸º \[h=8, s=8, d=640\] çš„å¼ é‡ Bã€‚

#### 4.1.2 For-loop å°ºå¯¸

ä¸ºäº†é€‚åº”å¤§è¾“å…¥å¼ é‡åœ¨å…±äº«å†…å­˜ä¸­å¹¶å…è®¸ç¼“å­˜é‡ç”¨ï¼Œä¸æ¯ä¸ªå—å›¾ç›¸å…³çš„ç¬¬äºŒä¸ªå±æ€§æ˜¯ for-loop å°ºå¯¸ï¼Œå®ƒä»¬å…±åŒæŒ‡å®šå—å›¾æ‰§è¡Œå¤šå°‘æ¬¡ä»¥å®Œæˆå†…æ ¸ã€‚ç›¸åº”åœ°ï¼Œæ¯ä¸ªè¾“å…¥å¼ é‡é¦–å…ˆè¢«å‘é€åˆ°è¾“å…¥è¿­ä»£å™¨ï¼Œè¯¥è¿­ä»£å™¨ä»è®¾å¤‡å†…å­˜åŠ è½½å¼ é‡çš„ä¸€éƒ¨åˆ†åˆ°å…±äº«å†…å­˜ã€‚æ¯ä¸ªè¾“å…¥è¿­ä»£å™¨éƒ½ä¸ fmap å…³è”ï¼Œä»¥æŒ‡å®šæ¯æ¬¡è¿­ä»£åŠ è½½è¾“å…¥å¼ é‡çš„å“ªä¸€éƒ¨åˆ†ã€‚å½¢å¼ä¸Šï¼Œfmap å°†æ¯ä¸ª for-loop ç»´åº¦æ˜ å°„åˆ°ï¼ˆ1ï¼‰è¾“å…¥å¼ é‡çš„æ•°æ®ç»´åº¦æˆ–ï¼ˆ2ï¼‰å‰¯æœ¬ç»´åº¦ ğœ™ã€‚ä¸ imap çš„è¯­ä¹‰ç±»ä¼¼ï¼Œè¾“å…¥å¼ é‡æ²¿è¯¥ç»´åº¦å‡åŒ€åˆ’åˆ†ä¸ºï¼ˆ1ï¼‰å¹¶åœ¨ï¼ˆ2ï¼‰ä¸­å¤åˆ¶ã€‚

æ­¤å¤–ï¼Œå—å›¾åŒ…å«è¾“å‡ºç´¯åŠ å™¨ï¼Œä»¥åœ¨å…±äº«å†…å­˜ä¸­è·¨è¿­ä»£ç´¯ç§¯å…¶è¾“å‡ºï¼Œå¹¶å°†æœ€ç»ˆç»“æœä¿å­˜å›è®¾å¤‡å†…å­˜ã€‚ä¸è¾“å…¥è¿­ä»£å™¨ç±»ä¼¼ï¼Œè¾“å‡ºç´¯åŠ å™¨ä¹Ÿä¸ fmap å…³è”ï¼Œä»¥æŒ‡å®šä¸åŒè¿­ä»£çš„è¾“å‡ºå¼ é‡å¦‚ä½•ç»„åˆä»¥äº§ç”Ÿæœ€ç»ˆç»“æœã€‚å…·ä½“æ¥è¯´ï¼Œfmap å°†æ¯ä¸ª for-loop ç»´åº¦æ˜ å°„åˆ°æ•°æ®ç»´åº¦ï¼Œè¿™å¯¼è‡´è¾“å‡ºæ²¿è¯¥ç»´åº¦è¿æ¥ï¼Œæˆ–å‰¯æœ¬ç»´åº¦ ğœ™ï¼Œè¿™å¯¼è‡´è¾“å‡ºåœ¨å…±äº«å†…å­˜ä¸­ç´¯ç§¯ã€‚

### 4.2 Python ä»£ç 

TBGraph æ˜¯å—å›¾çš„å®ç°ã€‚æ¯ä¸ªè‡ªå®šä¹‰æ“ä½œï¼ˆembeddingï¼Œattentionï¼ŒMLPï¼‰éƒ½ä¼šåˆ›å»ºå¯¹åº”çš„thread blockï¼Œç”¨äºå®šä¹‰è¯¥çº§åˆ«çš„å…·ä½“æ‰§è¡Œæ–¹å¼ï¼Œè¿™äº›thread block è¢«ç¼–è¯‘ä¸ºCUDA å†…æ ¸ï¼Œåœ¨GPUä¸Šä»¥warpå’Œçº¿ç¨‹æ–¹å¼å¹¶è¡Œæ‰§è¡Œã€‚

TBGraphçš„ç‰¹ç‚¹å¦‚ä¸‹ï¼š

*   èŠ‚ç‚¹åˆ†ç±»å¦‚ä¸‹ï¼š
    
    *   é¢„å®šä¹‰ç®—å­ï¼Œå¯¹åº”CUTLASSæˆ–è€…ThunderKittensç­‰CUDAç»„ä»¶åº“ä¸­å°è£…å¥½çš„å…±äº«å†…å­˜ä¸Šçš„ä¸€äº›æ“ä½œï¼ˆä¾‹å¦‚MatMulã€Mulã€Accumç­‰block opsï¼‰
    *   åˆæˆç®—å­ï¼ŒåŒ…å«ä¸€ä¸ªthread graph
*   è¾¹çš„ç‰¹ç‚¹æ˜¯ï¼š
    
    *   Tensorï¼ŒSEME tensorï¼Œæ‰€æœ‰æš‚å­˜tensoré»˜è®¤æ”¾åœ¨å…±äº«å†…å­˜ï¼Œå‡å°‘DRAMè®¿é—®

    class TBGraph:
        def __init__(self, graph):
            self.cygraph = graph
    
        def new_input(
            self,
            dtensor: DTensor,
            input_map: tuple,
            forloop_dim: int,
            store_in_dmem: bool = False,
        ):
            return self.cygraph.new_input(dtensor, input_map, forloop_dim, store_in_dmem)
    
        def new_output(self, stensor: STensor, output_map: tuple, forloop_dim: int = -1):
            return self.cygraph.new_output(stensor, output_map, forloop_dim)
    
        def matmul(self, A: STensor, B: STensor):
            return self.cygraph.matmul(A, B)
    
        def exp(self, A: STensor):
            return self.cygraph.exp(A)
    
        def silu(self, A: STensor):
            return self.cygraph.silu(A)
    
        def gelu(self, A: STensor):
            return self.cygraph.gelu(A)
    
        def relu(self, A: STensor):
            return self.cygraph.relu(A)
    
        def clamp(self, A: STensor, min_val: float, max_val: float):
            return self.cygraph.clamp(A, min_val, max_val)
    
        def square(self, A: STensor):
            return self.cygraph.square(A)
    
        def sqrt(self, A: STensor):
            return self.cygraph.sqrt(A)
    
        def mul_scalar(self, A: STensor, scalar: float):
            return self.cygraph.mul_scalar(A, scalar)
    
        def add(self, A: STensor, B: STensor):
            return self.cygraph.add(A, B)
    
        def mul(self, A: STensor, B: STensor):
            return self.cygraph.mul(A, B)
    
        def div(self, A: STensor, B: STensor):
            return self.cygraph.div(A, B)
    
        def sub(self, A: STensor, B: STensor):
            return self.cygraph.sub(A, B)
    
        def reduction(self, A: STensor, dim: int):
            return self.cygraph.reduction(A, dim)
    
        def reduction_max(self, A: STensor, dim: int):
            return self.cygraph.reduction_max(A, dim)
    
        def rms_norm(self, A: STensor):
            return self.cygraph.rms_norm(A)
    
        def concat(self, A: STensor, B: STensor, dim: int):
            return self.cygraph.concat(A, B, dim)
    
        def forloop_accum(self, A: STensor, acc: str = None):
            return self.cygraph.forloop_accum(A, acc)
    
        def forloop_accum_rescale(self, A: STensor, B: STensor, acc: str = None):
            return self.cygraph.forloop_accum_rescale(A, B, acc)
    
        def forloop_accum_max(self, A: STensor):
            return self.cygraph.forloop_accum_max(A)
    

TBGraph æ„é€ å‡½æ•°ä¼ å‚ graph æ˜¯ CyTBGraph ç±»å‹ã€‚å› æ­¤ï¼ŒTBGraph çš„æ‰€æœ‰æ“ä½œéƒ½è½¬äº¤ç»™ CyTBGraph è¿›è¡Œå¤„ç†ã€‚

    TBGraph(CyTBGraph(grid_dim, block_dim, 1, 64))
    

ç”Ÿæˆæ—¶å€™TBGraphï¼Œä¼ å…¥

    grid_dim=(X,Y,Z) // çº¿ç¨‹å—ç½‘æ ¼ç»´åº¦
    
    block_dim=(128,1,1) // çº¿ç¨‹å—å†…çº¿ç¨‹ç»´åº¦
    

è¿™è¡¨æ˜æ¯ä¸ªthread blockåŒ…å«128ä¸ªçº¿ç¨‹ï¼ŒæŒ‰ä¸€ç»´æ–¹å¼ç»„ç»‡ã€‚

grid\_dimå’Œblock\_dimè¿™ä¸¤ä¸ªå‚æ•°è¢«CyTBGraphä½¿ç”¨ã€‚

### 4.3 æ¡¥æ¢

new\_threadblock\_graphå‡½æ•°ä¸­ï¼Œä¼šçœ‹åˆ°CyTBGraphã€‚

    def new_threadblock_graph(
        grid_dim: tuple, block_dim: tuple, forloop_range: int, reduction_dimx: int
    ):
        bgraph = core.CyTBGraph(grid_dim, block_dim, forloop_range, reduction_dimx)
        return TBGraph(bgraph)
    
    

CyTBGraphä¼šè°ƒç”¨åˆ°CppTBGraphã€‚

    cdef class CyTBGraph:
        cdef CppTBGraph *p_bgraph #Hold a CppTBGraph instance
    
        def __cinit__(self, tuple grid_dim = (), tuple block_dim = (), int forloop_range = -1, int dimx = -1, bgraph = None):
            cdef unsigned long long ptr
            cdef dim3 c_grid_dim
            cdef dim3 c_block_dim
            if bgraph is None:
                c_grid_dim.x = grid_dim[0]
                c_grid_dim.y = grid_dim[1]
                c_grid_dim.z = grid_dim[2]
                c_block_dim.x = block_dim[0]
                c_block_dim.y = block_dim[1]
                c_block_dim.z = block_dim[2]
                self.p_bgraph = new CppTBGraph(c_grid_dim, c_block_dim, forloop_range, dimx)
            else:
                ptr = ctypes.cast(bgraph, ctypes.c_void_p).value
                if isinstance(bgraph, int):
                    self.p_bgraph = <CppTBGraph*>(ptr)
                elif isinstance(bgraph, ctypes.c_void_p):
                    self.p_bgraph = <CppTBGraph*>(ptr)
                else:
                    assert False, "bgraph must be an integer or ctypes.c_void_p, but got " + str(type(bgraph))
    

CppTBGraph å¯¹åº” "mirage::threadblock::Graph"ï¼Œè¿™å°±æ˜¯ C++çš„å®ç°ã€‚

    cdef cppclass CppTBGraph "mirage::threadblock::Graph"
    

### 4.4 C++ä»£ç 

å—å›¾åœ¨ä»£ç ä¸­æ˜¯mirage::threadblock::Graphç±»ï¼Œè¿™æ˜¯ä¸­é—´å±‚æ¬¡çš„è®¡ç®—å›¾ã€‚ä¸‹é¢æ˜¯ç²¾ç®€ç‰ˆä»£ç ã€‚

Block graphä¸»è¦åŒ…å«ä»¥ä¸‹å±æ€§æ¥è¡¨ç¤ºç¨‹åºå¹¶è¡Œåˆ‡åˆ†çš„ä¿¡æ¯

*   Grid Dims(x, y, z)ï¼škernelå¯åŠ¨å¤šå°‘block
*   imapï¼šä½œç”¨æ˜¯è¾“å…¥åˆ†å—ï¼Œgrid-dimsåˆ°input tensor dimsçš„æ˜ å°„
*   omapï¼šä½œç”¨æ˜¯è¾“å‡ºæ‹¼æ¥ï¼Œgrid-dimsåˆ°output tensor dimsçš„æ˜ å°„
*   For-loop bodyï¼šå…è®¸blockå¤šæ¬¡è¿­ä»£æ¥å¤ç”¨SMEMï¼Œæµæ°´çº¿å½¢å¼æ¥å……åˆ†è®¡ç®—å’Œè®¿å­˜é‡å ï¼ŒæŠŠDRAMè¯»å†™å®Œå…¨éšè—åˆ°è®¡ç®—æ—¶é—´é‡Œï¼ŒåŒæ—¶ä¹Ÿå……åˆ†æœç”¨SMEMï¼Œå½¢å¦‚InputIterator->...->Accum->...->OutputSaver
*   fmapï¼šå†³å®šæ¯æ¬¡è¿­ä»£å–å“ªä¸€å—æ•°æ®ï¼Œæ¯”å¦‚ fmap={iâ†”h} æ²¿ h ç»´æ»‘çª—ã€‚

    namespace mirage {
    namespace threadblock {
    
    class Graph {
    private:
      struct pair_hash {
        size_t operator()(std::pair<int, int> const &p) const;
      };
    
    public:
      Graph();
      Graph(dim3 grid_dim, dim3 block_dim, int forloop_range, int reduction_dimx);
      ~Graph();
      Graph(Graph const &) = delete;
      Graph &operator=(Graph const &) = delete;
      // input operator
    
      STensor new_input(mirage::kernel::DTensor const &dtensor,
                        int3 input_map,
                        int forloop_dim,
                        mirage::layout::SmemLayout layout,
                        bool store_in_dmem = false);
      STensor *new_input(mirage::kernel::DTensor const *dtensor,
                         int3 input_map,
                         int forloop_dim,
                         mirage::layout::SmemLayout layout,
                         bool store_in_dmem = false);
      TBOperator *create_input_op(mirage::kernel::DTensor const &dtensor,
                                  int3 input_map,
                                  int forloop_dim,
                                  mirage::layout::SmemLayout layout,
                                  bool store_in_dmem = false);
      // matmul operator
      STensor matmul(STensor const &A, STensor const &B);
      STensor *matmul(STensor const *A, STensor const *B);
      TBOperator *create_matmul_op(STensor const &A, STensor const &B);
      // element unary operator
      STensor exp(STensor const &A);
      STensor *exp(STensor const *A);
      STensor square(STensor const &A);
      STensor *square(STensor const *A);
      STensor sqrt(STensor const &A);
      STensor *sqrt(STensor const *A);
      STensor silu(STensor const &A);
      STensor *silu(STensor const *A);
      STensor gelu(STensor const &A);
      STensor *gelu(STensor const *A);
      STensor relu(STensor const &A);
      STensor *relu(STensor const *A);
    
      // element binary operators
      STensor add(STensor const &A, STensor const &B);
      STensor *add(STensor const *A, STensor const *B);
      STensor mul(STensor const &A, STensor const &B);
      STensor *mul(STensor const *A, STensor const *B);
      STensor div(STensor const &A, STensor const &B);
      STensor *div(STensor const *A, STensor const *B);
      STensor sub(STensor const &A, STensor const &B);
      STensor *sub(STensor const *A, STensor const *B);
      STensor pow(STensor const &A, STensor const &B);
      STensor *pow(STensor const *A, STensor const *B);
    
      // reduction operator
      STensor reduction(STensor const &A, int dim);
      STensor *reduction(STensor const *A, int dim);
      TBOperator *create_reduction_op(STensor const &A, int dim);
    
      // reduction_to_dimx operator
      STensor reduction_to_dimx(STensor const &A, int dim);
      TBOperator *create_reduction_to_dimx_op(STensor const &A, int dim);
    
      // reduction_max operator
      std::vector<STensor> reduction_max(STensor const &A, int dim);
      std::vector<STensor *> reduction_max(STensor const *A, int dim);
      TBOperator *create_reduction_max_op(STensor const &A, int dim);
    
      // rms_norm operator
      STensor rms_norm(STensor const &A);
      STensor *rms_norm(STensor const *A);
      TBOperator *create_rms_norm_op(STensor const &A);
    
    public:
      dim3 grid_dim, block_dim, cluster_dim{4, 4, 1};
      int forloop_range;
      int reduction_dimx;
      std::vector<mirage::threadblock::TBOperator *> operators;
      // memory allocator
      off_t smem_offset;
      std::vector<std::pair<off_t, size_t>> allocated_tensors;
    
      using OpType = TBOperator;
      using TensorType = STensor;
    };
    
    void from_json(json const &j, Graph &g);
    
    } // namespace threadblock
    } // namespace mirage
    

ä»¥ reduction\_max ä¸ºä¾‹ï¼Œä»£ç å¦‚ä¸‹ï¼š

    std::vector<STensor *> Graph::reduction_max(STensor const *input, int dim) {
      TBOperator *op = create_reduction_max_op(*input, dim);
      assert(op != nullptr);
      operators.push_back(op);
      return std::vector<STensor *>{&op->output_tensors[0], &op->output_tensors[1]};
    }
    
    TBOperator *Graph::create_reduction_max_op(STensor const &input, int dim) {
      TBOperator *op =
          new TBReductionOp(this, input, dim, -1 /*size = -1 for max*/);
      // Check shmem usage
      size_t smem_usage = calculate_shared_memory_usage(op);
      if (smem_usage > mirage::config::MAX_SMEM_SIZE) {
        delete op;
        return nullptr;
      } else {
        return op;
      }
    }
    

### 4.5 TBOperator

å—å›¾åœ¨CUDA thread blockçº§åˆ«æ‰§è¡Œï¼Œä½¿ç”¨TBOperatoræ¥è¡¨ç¤ºæ‰€åŒ…å«çš„æ“ä½œã€‚ä¹Ÿä½¿ç”¨TBInputOpè¿æ¥åˆ°ä¸Šå±‚çš„mu'Graphçš„å¼ é‡ã€‚

ä»¥ Attention å±‚ä¸ºä¾‹ï¼Œå…¶ thread block å¯èƒ½åŒ…å«å¦‚ä¸‹ç»“æ„ï¼š

    Thread Block for Attention:
    TB_INPUT_OPï¼ˆè¾“å…¥QKVå¼ é‡ï¼‰
        â†“
    TB_MATMUL_OPï¼ˆè®¡ç®—QK^Tï¼‰
        â†“
    TB_REDUCTION_OPï¼ˆSoftmaxå½’ä¸€åŒ–ï¼‰
        â†“
    TB_MATMUL_OPï¼ˆè®¡ç®—Attentionè¾“å‡ºï¼‰
        â†“
    TB_FORLOOP_ACCUM_NO_RED_OPï¼ˆç´¯ç§¯è®¡ç®—ï¼‰
    

TBOperatorçš„å®šä¹‰å¦‚ä¸‹ï¼š

    namespace mirage {
    namespace threadblock {
    
    class Graph;
    
    class TBOperator {
    public:
      TBOperator(Graph *graph, mirage::type::TBOperatorType);
      TBOperator(Graph *graph, mirage::type::TBOperatorType, STensor const &input1);
      TBOperator(Graph *graph,
                 mirage::type::TBOperatorType,
                 STensor const &input1,
                 STensor const &input2);
      TBOperator(Graph *graph,
                 mirage::type::TBOperatorType,
                 std::vector<STensor> const &inputs);
      int get_input_stensors(STensor **inputs);
      int get_output_stensors(STensor **inputs);
    
      virtual ~TBOperator();
    
      virtual operator json() const = 0;
    
    public:
      Graph *bgraph;
      mirage::type::TBOperatorType op_type;
      std::vector<STensor> input_tensors;
      std::vector<STensor> output_tensors;
    };
    

TBOperator çš„æ´¾ç”Ÿç±»ä¸¾ä¾‹ã€‚

    class TBInputOp : public TBOperator {
    public:
      TBInputOp(Graph *_graph,
                mirage::kernel::DTensor const &dtensor,
                int3 input_map,
                int forloop_dim,
                mirage::layout::SmemLayout layout,
                bool store_in_dmem);
      ~TBInputOp();
    
      operator json() const override;
      size_t get_dtensor_guid();
    
    public:
      mirage::kernel::DTensor dtensor;
      int3 input_map;
      int forloop_dim;
    };
    
    class TBOutputOp : public TBOperator {
    public:
      TBOutputOp(Graph *_graph,
                 STensor const &stensor,
                 int3 output_map,
                 int forloop_dim,
                 mirage::type::TBEpilogueType allreduce);
      ~TBOutputOp();
    
      operator json() const override;
      size_t get_dtensor_guid();
    
    public:
      mirage::kernel::DTensor dtensor;
      int3 output_map;
      int forloop_dim;
      mirage::type::TBEpilogueType epilogue;
    };
    
    

TBOperatorTypeçš„ç±»å‹ä¸ºï¼š

    enum TBOperatorType {
      TB_UNKOWN = 2000,
      TB_INPUT_OP = 2001,
      TB_OUTPUT_OP = 2002,
      TB_MATMUL_OP = 2003,
      // ElementUnary
      TB_EXP_OP = 2100,
      TB_SQUARE_OP = 2101,
      TB_SQRT_OP = 2102,
      TB_MUL_SCALAR_OP = 2103,
      TB_SILU_OP = 2104,
      TB_SIGMOID_OP = 2105,
      TB_GELU_OP = 2106,
      // non-lax elementunary ops
      TB_RELU_OP = 2150,
      TB_CLAMP_OP = 2151,
      TB_LOG_OP = 2160,
      // ElementBinary
      TB_ADD_OP = 2200,
      TB_MUL_OP = 2201,
      TB_DIV_OP = 2202,
      TB_SUB_OP = 2203,
      TB_POW_OP = 2204,
      // Reduction and Normalization
      TB_REDUCTION_FIRST_OP_ID = 2300,
      TB_REDUCTION_0_OP = 2301,
      TB_REDUCTION_1_OP = 2302,
      TB_REDUCTION_2_OP = 2303,
      TB_REDUCTION_0_TO_DIMX_OP = 2304,
      TB_REDUCTION_1_TO_DIMX_OP = 2305,
      TB_REDUCTION_2_TO_DIMX_OP = 2306,
      TB_REDUCTION_0_MAX_OP = 2307,
      TB_REDUCTION_1_MAX_OP = 2308,
      TB_REDUCTION_2_MAX_OP = 2309,
      TB_REDUCTION_LAST_OP_ID = 2349,
      TB_RMS_NORM_OP = 2350,
      // Concat & Split
      TB_CONCAT_FIRST_OP_ID = 2400,
      TB_CONCAT_0_OP = 2400,
      TB_CONCAT_1_OP = 2401,
      TB_CONCAT_2_OP = 2402,
      TB_CONCAT_LAST_OP_ID = 2409,
      TB_CONCAT_THEN_MATMUL_OP = 2411,
      TB_SPLIT_FIRST_OP_ID = 2420,
      TB_SPLIT_0_OP = 2420,
      TB_SPLIT_1_OP = 2421,
      TB_SPLIT_2_OP = 2422,
      TB_SPLIT_LAST_OP_ID = 2429,
      // Forloop Accum
      // LD indicates last dimension
      TB_FORLOOP_ACCUM_FIRST_OP = 2500,
      TB_FORLOOP_ACCUM_NO_RED_OP = 2500,
      TB_FORLOOP_ACCUM_RED_LD_SUM_OP = 2501,
      TB_FORLOOP_ACCUM_RED_LD_MEAN_OP = 2502,
      TB_FORLOOP_ACCUM_RED_LD_RMS_OP = 2503,
      TB_FORLOOP_ACCUM_REDTOX_LD_SUM_OP = 2504,
      TB_FORLOOP_ACCUM_NO_RED_RESCALE_OP = 2505,
      TB_FORLOOP_ACCUM_RED_LD_SUM_RESCALE_OP = 2506,
      TB_FORLOOP_ACCUM_MAX_OP = 2507,
      TB_FORLOOP_ACCUM_LAST_OP = 2599,
      TB_CUSTOMIZED_OP = 2999
    };
    

æˆ‘ä»¬ç”¨ TBReductionOp æ¥çœ‹çœ‹å…·ä½“å®ç°ã€‚

    class TBReductionOp : public TBOperator {
    public:
      TBReductionOp(Graph *graph,
                    STensor const &_input,
                    int reduce_dim,
                    int reduce_size);
      ~TBReductionOp();
    
      operator json() const override;
    
    public:
      int reduce_dim, reduce_size;
    };
    
    TBReductionOp::TBReductionOp(Graph *bgraph,
                                 STensor const &input,
                                 int dim,
                                 int size)
        : TBOperator(bgraph,
                     size == 1 ? (mirage::type::TBOperatorType)(
                                     mirage::type::TB_REDUCTION_0_OP + dim)
                     : size == -1
                         ? (mirage::type::TBOperatorType)(
                               mirage::type::TB_REDUCTION_0_MAX_OP + dim)
                         : (mirage::type::TBOperatorType)(
                               mirage::type::TB_REDUCTION_0_TO_DIMX_OP + dim),
                     input),
          reduce_dim(dim), reduce_size(size) {
      STensor output = input;
      assert(output.num_dims > reduce_dim);
      assert(output.layout == mirage::layout::SmemRowMajor);
      output.dim[reduce_dim] = reduce_size == -1 ? 1 : reduce_size;
      output.owner_op = this;
      output.owner_ts_idx = 0;
      output.guid = STensor::next_guid++;
      output.after_accum = input.after_accum;
      output.smem_offset = bgraph->allocate_fingerprint(output);
      output_tensors.push_back(output);
      if (reduce_size == -1) {
        // For max reduction, we need to allocate another tensor for difference
        STensor diff = output;
        diff.owner_ts_idx = 1;
        diff.guid = STensor::next_guid++;
        diff.smem_offset = bgraph->allocate_fingerprint(diff);
        output_tensors.push_back(diff);
      }
    }
    

### 4.6 ç”Ÿæˆæ ·ä¾‹

åœ¨Mirageé¡¹ç›®ä¸­ï¼Œblock\_graphæ˜¯åœ¨åˆ›å»ºè‡ªå®šä¹‰æ“ä½œæ—¶æ’å…¥å¾—ã€‚

*   å¯ä»¥åœ¨Pythonä»£ç ç›´æ¥é€šè¿‡mi.new\_threadblock\_graph()ç›´æ¥æ„å»ºã€‚
*   åœ¨ demo.py ä¸­é€å±‚æ„å»ºæ¨¡å‹æ—¶ï¼Œæ¯ä¸€å±‚éƒ½ä¼šæ’å…¥ç›¸åº”çš„ block\_graph æ¥å®šä¹‰è¯¥å±‚åœ¨çº¿ç¨‹å—çº§åˆ«çš„å…·ä½“æ‰§è¡Œæ–¹å¼ã€‚å³ï¼Œæ¯ä¸ªè‡ªå®šä¹‰æ“ä½œçš„åˆ›å»ºè¿‡ç¨‹ä¸­ï¼šæ¯å½“è°ƒç”¨ PersistentKernel çš„ layer æ–¹æ³•æ—¶ï¼Œéƒ½ä¼šåœ¨å†…éƒ¨åˆ›å»ºä¸€ä¸ªåŒ…å«å…·ä½“çº¿ç¨‹å—çº§è®¡ç®—çš„ block\_graphã€‚æ¯”å¦‚ï¼Œattention\_layer()ï¼Œrmsnorm\_linear\_layer()ï¼Œ def embed\_layer()å†…éƒ¨éƒ½ä¼šæ„å»ºblock\_graphã€‚
*   ä¹Ÿå¯ä»¥åœ¨C++ä»£ç ç›´æ¥æ„å»ºã€‚

#### 4.6.1 Pythonä»£ç ç›´æ¥æ„å»º

åŸå§‹çš„rms\_linearå…¬å¼ä¸ºï¼š

\\\[ y\_i = \\frac{ x\_i \* g\_i }{ \\sqrt{\\frac{1}{n} \\sum\_{i=1}^{n}{x\_i^2}} } \\\]

é€»è¾‘å¦‚ä¸‹ï¼š

é’ˆå¯¹rms\_linearï¼ŒMPKçš„è½¬æ¢ä»£ç å¦‚ä¸‹ï¼š

    def get_rms_linear():
        graph = mi.new_kernel_graph() # kernel graph
        X = graph.new_input(dims=(num_tokens, 4096), dtype=mi.float16)
        W = graph.new_input(dims=(4096, n_local_heads * head_dim + 2 * n_local_kv_heads * head_dim), dtype=mi.float16)
        # block graph
        tb_graph = mi.new_threadblock_graph(grid_dim=(384,1,1), block_dim=(128,1,1), forloop_range=32, reduction_dimx=64)
        tX = tb_graph.new_input(dtensor=X, input_map=(-1, -1, -1), forloop_dim=1)
        tW = tb_graph.new_input(dtensor=W, input_map=(1, -1, -1), forloop_dim=0)
        tM = tb_graph.matmul(tX, tW)
        tAccX = tb_graph.forloop_accum(tX, "rms")
        tAccM = tb_graph.forloop_accum(tM)
        tO = tb_graph.div(tAccM, tAccX)
        tb_graph.new_output(stensor=tO, output_map=(1, -1, -1))
        O = graph.customized([X, W], tb_graph)
        return graph, O
    

å…¶ä¸­ï¼Œnew\_threadblock\_graph()å†…éƒ¨ä¼šç›´æ¥æ„å»ºTBGraph(bgraph)ã€‚

    def new_threadblock_graph(
        grid_dim: tuple, block_dim: tuple, forloop_range: int, reduction_dimx: int
    ):
        bgraph = core.CyTBGraph(grid_dim, block_dim, forloop_range, reduction_dimx)
        return TBGraph(bgraph)
    

è°ƒæ•´ä¹‹åï¼Œå…¶å¯¹åº”çš„é€»è¾‘å¦‚ä¸‹ï¼š

#### 4.6.2 PersistentKernel çš„ layer æ–¹æ³•é—´æ¥æ„å»º

æ¯”å¦‚ï¼šrmsnorm\_linear\_layer()ï¼Œattention\_layer()ç­‰å‡½æ•°ä¸­ï¼Œéƒ½æ„å»ºäº†TBGrapattach\_inputh(CyTBGraph(grid\_dim, block\_dim, 1, 64))ã€‚

    mpk.embed_layer(input=x, weight=w_embed, output=embed_out, grid_dim=(1, 1, 1), block_dim=(128, 1, 1))
    mpk.rmsnorm_linear_layer(input=x, weight_norm=w_norm_attn, weight_linear=w_qkv, output=attn_in, grid_dim=(96, 1, 1), block_dim=(128, 1, 1))
    
    

åœ¨embed\_layerå‡½æ•°å†…éƒ¨ï¼Œä¼šæ„å»º TBGraph(bgraph)ã€‚

        def embed_layer(
            self,
            input: DTensor, # [batch_size, num_spec_tokens]
            weight: DTensor, # [vocab_size, hidden_size]
            output: DTensor, # [batch_size, hidden_size]
            grid_dim: tuple,
            block_dim: tuple,
            input_source: int = 0, # 0: all_tokens, 1: input_token
        ):
            tb_graph = TBGraph(CyTBGraph(grid_dim, block_dim, 1, 64))
            tb_graph.new_input(input, (-1, 1, -1), -1, True)
            tb_graph.new_input(weight, (1, -1, -1), -1, True)
            tb_graph.new_input(output, (1, 0, -1), -1, True)
            self.kn_graph.customized([input, weight, output], tb_graph)
            self.kn_graph.register_task(tb_graph, "embedding", [input_source])
    

#### 4.6.3 C++ä»£ç ç›´æ¥æ„å»º

åœ¨graph.ccï¼Œè‡ªå®šä¹‰æ“ä½œä¹Ÿä¼šæ„å»ºblock graphã€‚è¿™ä¸ªæ˜¯æŠŠpythonå®šä¹‰çš„å›¾è¿›è¡Œè½¬æ¢åˆ°c++ã€‚

    void from_json(json const &j, Graph &g) {
          case type::KNOperatorType::KN_CUSTOMIZED_OP: {
            std::vector<DTensor> inputs;
            for (auto const &jinput : jop.at("input_tensors")) {
              size_t guid;
              jinput.at("guid").get_to(guid);
              inputs.push_back(get_tensor_from_guid(guid));
            }
            threadblock::Graph bgraph;
            from_json(jop.at("bgraph"), bgraph);
            // å°†muGraphçš„å¼ é‡è¿æ¥åˆ°block-graphçš„è¾“å…¥
            for (size_t i = 0; i < bgraph.operators.size(); ++i) {
              if (bgraph.operators[i]->op_type == type::TB_INPUT_OP) {
                static_cast<threadblock::TBInputOp *>(bgraph.operators[i])
                    ->dtensor = inputs[i];
              }
            }
            std::vector<DTensor> outputs = g.customized(inputs, bgraph);
            for (size_t i = 0; i < outputs.size(); ++i) {
              size_t guidO;
              jop.at("output_tensors")[i].at("guid").get_to(guidO);
              guid_mapping[outputs[i].guid] = guidO;
            }
    
            break;
          }
    

0x05 çº¿ç¨‹å›¾
--------

çº¿ç¨‹å›¾è¿›ä¸€æ­¥å°†è®¡ç®—èŒƒå›´ä»å—ç¼©å°åˆ°å•ä¸ªçº¿ç¨‹ã€‚ä¸å—å›¾ç±»ä¼¼ï¼Œæ¯ä¸ªçº¿ç¨‹å›¾ä¹Ÿä¸å—å°ºå¯¸ç›¸å…³è”ï¼ŒæŒ‡å®šå—å†…çº¿ç¨‹çš„ç»„ç»‡ï¼Œä»¥åŠ for-loop å°ºå¯¸ï¼Œå®šä¹‰å®Œæˆå®šä¹‰è®¡ç®—çš„æ€»è¿­ä»£æ¬¡æ•°ã€‚æ¯ä¸ªçº¿ç¨‹å›¾åŒ…æ‹¬è¾“å…¥è¿­ä»£å™¨ï¼Œæ¯ä¸ªè¿­ä»£å™¨ä» GPU å…±äº«å†…å­˜åŠ è½½è¾“å…¥å¼ é‡åˆ°å¯„å­˜å™¨æ–‡ä»¶ï¼Œä»¥åŠè¾“å‡ºç´¯åŠ å™¨ï¼Œæ¯ä¸ªç´¯åŠ å™¨ä»å¯„å­˜å™¨æ–‡ä»¶ä¿å­˜è¾“å‡ºå¼ é‡å›åˆ°å…±äº«å†…å­˜ã€‚çº¿ç¨‹å›¾æ˜¯ uGraph ä¸­çš„æœ€ä½çº§åˆ«å›¾ï¼Œä»…åŒ…å«é¢„å®šä¹‰çš„çº¿ç¨‹æ“ä½œç¬¦ã€‚

çº¿ç¨‹å›¾æ˜¯æœ€åº•å±‚çš„è®¡ç®—å›¾ï¼Œåœ¨ä»£ç ä¸­æ²¡æœ‰æ˜¾å¼å®šä¹‰ä¸ºç‹¬ç«‹çš„å›¾ç»“æ„ï¼Œè€Œæ˜¯åœ¨block-graphçš„æ“ä½œä¸­ä½“ç°ã€‚

ä¸»è¦ç‰¹å¾ï¼š

*   æ‰§è¡Œå•ä½ï¼šåœ¨CUDA thread warpæˆ–è€…å•ä¸ªthreadçº§åˆ«æ‰§è¡Œ
*   æ“ä½œç»†èŠ‚ï¼šåŒ…å«å…·ä½“çš„çº¿ç¨‹çº§åˆ«è®¡ç®—å’Œå†…å­˜è®¿é—®æ¨¡å¼

*   Thread graph
    
*   *   è¾¹ï¼šTensorï¼Œthread graphçš„å¼ é‡ä½äºå¯„å­˜å™¨
        
    *   èŠ‚ç‚¹ï¼šæè¿°å•ä¸ªthreadå†…å¯„å­˜å™¨ä¸Šçš„æµæ°´ï¼Œload->emelent-wise->storeã€‚åªåŒ…å«é¢„å®šä¹‰ç®—å­ï¼Œå¯¹åº”å°è£…å¥½çš„å¯„å­˜å™¨ä¸Šçš„ä¸€äº›æ“ä½œï¼Œä¹Ÿæ”¯æŒfor loopç»´+å¯„å­˜å™¨ç´¯åŠ ï¼Œä¸è¿‡mirageé»˜è®¤ç”¨è§„åˆ™åŒ–èåˆå¿«é€Ÿåˆæˆï¼Œé¿å…åœ¨æœ€ç»†å±‚å†åšå¤§æœç´¢
        
*   å¯¹æ¯ä¸ªå€™é€‰å†…çš„blockå›¾ï¼Œæ‰¾å‡ºç¬¦åˆformçš„å­å›¾ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸²element-wise+reduceï¼‰ï¼ŒæŠŠå®ƒä»¬èæˆthread graphèŠ‚ç‚¹ï¼Œè¡¨ç¤ºè¿™æ®µè®¡ç®—å¯ä»¥æ”¾åœ¨å¯„å­˜å™¨é‡Œå®Œæˆ
    
*   è§„åˆ™åŒ–ã€æ— éœ€å¤§æœç´¢ã€‚threadåªåšå±€éƒ¨èåˆå’Œå›ºå®šæ¨¡å¼çš„for-loopï¼Œé¿å…æœç´¢æŒ‡æ•°çˆ†ç‚¸ï¼Œè¿™æ ·ä»èƒ½è®©å¤§å¤šæ•°é€å…ƒç´ ç®—å­ç•™åœ¨å¯„å­˜å™¨ä¸­ï¼Œå‡å°‘shared-memoryè®¿é—®
    

0xFF å‚è€ƒ
-------

[å¦‚ä½•è¯„ä»·CMUå°†LLMè½¬åŒ–ä¸ºå·¨å‹å†…æ ¸çš„Mirage Persistent Kernel(MPK)å·¥ä½œï¼Ÿ](https://www.zhihu.com/question/1927927257713849225/answer/1928955491515602157)

[Mirage: A Multi-Level Superoptimizer for Tensor Programs ç®€è®°](https://zhuanlan.zhihu.com/p/1490006494) [å°˜ä¼Šå…‰](https://www.zhihu.com/people/yi-guang-99-48)

[OSDI2025è®ºæ–‡ç¬”è®°ï¼šMirage: A Multi-Level Superoptimizer for Tensor Programs](https://zhuanlan.zhihu.com/p/1929963179133338885) [ç”»é¥¼å……é¥¥](https://www.zhihu.com/people/tu-ling-92-25)

Mirage: A Compiler for High-Performance Tensor Programs on GPUs

[https://mirage-project.readthedocs.io/en/latest/mugraph.html](https://mirage-project.readthedocs.io/en/latest/mugraph.html)

[https://mirage-project.readthedocs.io/en/latest/transpiler.html](https://mirage-project.readthedocs.io/en/latest/transpiler.html)

[https://zhihaojia.medium.com/compiling-llms-into-a-megakernel-a-path-to-low-latency-inference-cf7840913c17](https://zhihaojia.medium.com/compiling-llms-into-a-megakernel-a-path-to-low-latency-inference-cf7840913c17)

[èˆå¼ƒCUDAç¼–ç¨‹ï¼CMUç­‰ç”¨ä»£ç å°†LLMç¼–è¯‘æˆå·¨å‹å†…æ ¸ï¼Œæ¨ç†å»¶è¿Ÿé™6.7å€](https://baijiahao.baidu.com/s?id=1835685949555398711) [æœºå™¨ä¹‹å¿ƒPro](https://author.baidu.com/home?from=bjh_article&app_id=1536769991067070)