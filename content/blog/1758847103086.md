---
layout: post
title: '向量那点事儿'
date: "2025-09-26T00:38:23Z"
---
向量那点事儿
======

目录

*   [一、向量](#一向量)
    *   [坐标表示](#坐标表示)
*   [二、加减法](#二加减法)
    *   [向量加法](#向量加法)
        *   [应用示例](#应用示例)
    *   [向量减法](#向量减法)
        *   [应用示例](#应用示例-1)
*   [三、向量内积](#三向量内积)
    *   *   [应用示例](#应用示例-2)
*   [四、向量外积](#四向量外积)
    *   *   [应用示例](#应用示例-3)
*   [五、小试牛刀](#五小试牛刀)
    *   *   [代码示例](#代码示例)
*   [六、小结](#六小结)

### 一、向量

这次我们继续聊一下向量。

**向量**可以理解为一个**有方向的量**。

它既有**大小**（长度），又有**方向**（指向哪里）。

生活中很多东西都可以用向量描述，比如：

*   🚗 速度（你开车 60 km/h 向东）
*   🌬️ 风（风速 5 m/s 向北）
*   📦 力（用 10 牛顿的力推箱子向右）

![image-20250910182531731](https://img2024.cnblogs.com/blog/242916/202509/242916-20250925101929961-604011422.png)

#### 坐标表示

在数学里，我们通常用坐标来表示向量；而在几何空间中，常常用箭头来表示向量，箭头的长度表示大小（模），方向表示向量的方向。

*   在二维空间中，一个向量表示如下：

\\\[\\vec{v} = (x, y) \\\]

其中 x 表示水平方向分量，y 表示竖直方向分量。  
向量的模长为：\\(|\\vec{v}| = \\sqrt{x^2 + y^2}\\)

![image-20250910183206403](https://img2024.cnblogs.com/blog/242916/202509/242916-20250925102008519-1041448016.png)

*   在三维空间中，一个向量表示如下：

\\\[\\vec{v} = (x, y, z) \\\]

其中 x, y, z 分别是沿三个坐标轴的分量。  
向量的模长为：\\(|\\vec{v}| = \\sqrt{x^2 + y^2 + z^2}\\)

![](https://img2024.cnblogs.com/blog/242916/202509/242916-20250925102051000-579755143.png)

*   在N维空间中，一个向量表示如下：

\\\[\\vec{v} = (x\_1, x\_2.. x\_n) \\\]

其中 x1...xn 分别是各个维度的分量。  
向量的模长为：\\(|\\vec{v}| = \\sqrt{x\_1^2 + x\_2^2 + \\dots + x\_n^2} \\\\\\)

### 二、加减法

#### 向量加法

设定：

\\\[\\vec{a} = (x\_1, y\_1), \\quad \\vec{b} = (x\_2, y\_2) \\\]

那么有：

\\\[\\vec{a} + \\vec{b} = (x\_1 + x\_2, \\; y\_1 + y\_2) \\\]

加法的几何意义，可以使用三角形法则或平行四边形法则来说明：

![image-20250910095714904](https://img2024.cnblogs.com/blog/242916/202509/242916-20250925102140695-144651475.png)

简单的可以理解为，\\(\\vec{a}+\\vec{b}\\) 就是从坐标原点沿着\\(\\vec{a}\\)行进后，再沿着\\(\\vec{b}\\)行进。

##### 应用示例

![image-20250910102403901](https://img2024.cnblogs.com/blog/242916/202509/242916-20250925102213814-383196884.png)

假定有两股方向的力，如下：

\\(\\vec{F\_1} = (3, 4), \\quad \\vec{F\_2} = (1, 2)\\)

那么这两股力的合力为：

\\(\\vec{F} = \\vec{F\_1} + \\vec{F\_2} = (3+1, 4+2) = (4, 6)\\)

#### 向量减法

设定：

\\\[\\vec{a} = (x\_1, y\_1), \\quad \\vec{b} = (x\_2, y\_2) \\\]

那么有：

\\\[\\vec{a} - \\vec{b} = (x\_1 - x\_2, \\; y\_1 - y\_2) \\\]

加法的几何意义，可以使用三角形法则或平行四边形法则来说明：

![image-20250910102038003](https://img2024.cnblogs.com/blog/242916/202509/242916-20250925102307238-792440316.png)

简单的可以理解为，\\(\\vec{a}-\\vec{b}\\) 就是从b的终点开始，朝着\\(\\vec{a}\\)的终点行进的向量。

##### 应用示例

在船的航行过程中，可以利用向量的减法来获得船和水流的相对速度。

![image-20250910111156495](https://img2024.cnblogs.com/blog/242916/202509/242916-20250925102338337-906244789.png)

假定船的速度向量为：

\\(\\vec{v}\_{船} = (8, 0) \\quad (\\text{向东 8 m/s})\\)

水流速度向量为：

\\(\\vec{v}\_{水} = (3, 1) \\quad (\\text{向东 3 m/s，向北 1 m/s})\\)

那么船相对水流的速度向量为：

\\(\\vec{v}\_{相对} = (8-3, 0-1) = (5, -1)\\)

表示向东 5 m/s、向南 1 m/s。

### 三、向量内积

向量的内积又称为点积（Dot Product），内积是两个向量对应**分量相乘后求和的一个标量值**。

设定：

\\\[\\vec{a} = (x\_1, y\_1), \\quad \\vec{b} = (x\_2, y\_2) \\\]

那么有：

\\\[\\vec{a} \\cdot \\vec{b} = x\_1x\_2 + y\_1y\_2 \\\]

从几何意义上讲，向量的内积还可以表示如下：

\\\[\\vec{a} \\cdot \\vec{b} = |\\vec{a}| |\\vec{b}| \\cos\\theta \\\]

具体的证明可以参考下图，将坐标系进行旋转后，可完成推理：

![](https://img2024.cnblogs.com/blog/242916/202509/242916-20250925102453088-107902074.png)

其中 ⁡θ 表示两个向量的夹角，根据余弦定理可以得出：

*   假定模长不变，夹角越小，内积则越大
*   当夹角为90度时（两个向量垂直），此时内积为0
*   内积的本质等同于向量的投影和模长的乘积
*   坐标旋转时，内积保持不变

##### 应用示例

我们在电商平台上浏览产品详情时，经常会看到"相似产品"这样的页签，其中会给我们推荐相关的产品。

这种商品推荐的场景便可以基于**"余弦相似度"**来实现，余弦相似度的核心是**仅考虑向量的方向一致，忽略模长的影响**。具体实现如下：

1.  将商品信息特征化表述，包括：
    
    *   类目
    *   品牌
    *   价格区间
    *   颜色 / 尺寸 / 材质
    *   商品标题/描述
    *   图片特征
2.  特征向量归一化
    
    上述的商品特征可以基于Embedding、CNN等算法来提取为特征值。
    
    这些特征值拼接后形成一个统一的商品向量，如下：
    
    \\\[\\vec{g} = \[x\_{类目}, x\_{品牌},x\_{价格},x\_{尺寸},x\_{颜色},x\_{图谱特征}..\] \\\]
    
    由于不同维度的特征值其模长无法统一，我们需要将其进行归一化（L2归一）：
    
    对于其中的 \\(x\_k\\)，其归一后的值为：
    
    \\\[X\_k = \\frac{x\_k}{\\sqrt{x\_1^2 + x\_2^2 + \\cdots + x\_n^2}} \\\]
    
    L2归一化使用欧几里得范数来计算，最终得到特征向量为：
    
    \\\[\\vec{G} = \[X\_{类目}, X\_{品牌},X\_{价格},X\_{尺寸},X\_{颜色},X\_{图谱特征}..\] \\\]
    
    > 归一化后，∥G∥=1，余弦相似度就简化成两个单位向量的点积，只比较方向（特征分布模式），消除了特征值大小的影响。
    
3.  计算商品特征向量的相似度，获得最相似的N个商品
    
    通过计算向量的点积来比较相似度：$ simulaty = \\vec{G} \\cdot \\vec{G2}$
    

> 向量点积在机器学习中常用于评估特征的方向相似性

### 四、向量外积

向量的外积又称为叉积（Cross Product），两个**向量的外积是一个同时垂直于两者的向量**。

设定：

\\\[\\vec{a} = (x\_1, y\_1), \\quad \\vec{b} = (x\_2, y\_2) \\\]

那么有：

\\\[\\vec{a} × \\vec{b} = \\vec{c} \\\]

*   向量 \\(\\vec{c}\\)的模长：$\\vec{c} = ∣\\vec{a}∣∣\\vec{b}∣sin⁡θ $，在几何意义上等同与两个向量为边的平行四边形的面积。
    
*   向量 \\(\\vec{c}\\)的方向：垂直于两个向量构成的平面。
    

如下图所示：

![image-20250910113835076](https://img2024.cnblogs.com/blog/242916/202509/242916-20250925102614058-715180077.png)

向量 \\(\\vec{c}\\)的方向除了垂直之外，还需要遵循**右手螺旋定则**，也就是对于 \\(\\vec{a} × \\vec{b} = \\vec{c}\\) 来说，右手四指方向从 a 转向 b，大拇指所指方向就是 c 的方向。所以， \\(\\vec{a} × \\vec{b}\\) 和 \\(\\vec{b} × \\vec{a}\\) 的结果是相反的，即向量外积不满足交换律。

![](https://img2024.cnblogs.com/blog/242916/202509/242916-20250925102743902-1166170910.jpg)

从几何图形上看，向量的外积可以垂直于两个向量组成的平面，当向量平行（共线）时，向量的外积为0。

> 需要注意的是，向量的外积仅适用于三维图形，在四维及更高维空间中，垂直于两个向量的方向不唯一，而是一个高维子空间，因此无法用一个单一向量来表示。

##### 应用示例

物理学上，我们通过力矩（Torque）来描述一种"让物体转起来的能力"。

![](https://img2024.cnblogs.com/blog/242916/202509/242916-20250925102834093-370196.png)

比如：

你用扳手拧螺丝，用力的大小、角度和离螺丝中心的距离都会影响拧动的效果。

同样的力，扳手越长（离中心越远），越容易拧动——因为力矩更大。

**力矩的公式**如下：

\\\[\\vec{𝜏}=\\vec{𝑟}×\\vec{𝐹} \\\]

*   r 是从旋转中心到施力点的位置向量
    
*   𝐹：施加的作用力
    

力矩是向量 r 和向量 F的外积向量：

*   力矩的方向：由右手定则决定，表示旋转轴的方向
    
*   力矩的大小：等于 \\(|\\vec{r}| \\cdot |\\vec{F}| \\cdot \\sin\\theta\\)，也就是力度、垂直距离、和角度三者叠加的结果。
    

### 五、小试牛刀

下面使用 numpy 来实现本文提到的向量加减法、向量内积和外积计算。

##### 代码示例

    import numpy as np
    
    # 定义两个三维向量
    a = np.array([3, 4, 0])
    b = np.array([4, 0, 3])
    
    # 1️⃣ 向量加法
    add = a + b
    print("加法 a + b =", add)
    
    # 2️⃣ 向量减法
    sub = a - b
    print("减法 a - b =", sub)
    
    # 3️⃣ 向量内积（点积）
    dot = np.dot(a, b)
    print("内积 a · b =", dot)
    
    # 4️⃣ 特征归一化（L2归一）
    a_norm = a / np.linalg.norm(a)
    b_norm = b / np.linalg.norm(b)
    print("归一化后的 a =", a_norm)
    print("归一化后的 b =", b_norm)
    
    # 5️⃣ 归一后的余弦相似度
    cos_sim = np.dot(a_norm, b_norm)
    print("归一后的余弦相似度 =", cos_sim)
    
    # 6️⃣ 向量外积（叉积）
    cross = np.cross(a, b)
    print("外积 a × b =", cross)
    
    

执行上述程序，输出结果如下：

    加法 a + b = [7 4 3]
    减法 a - b = [-1  4 -3]
    内积 a · b = 12
    归一化后的 a = [0.6 0.8 0. ]
    归一化后的 b = [0.8 0.  0.6]
    归一后的余弦相似度 = 0.48
    外积 a × b = [ 12  -9 -16]
    

### 六、小结

向量的概念早在中学数学、物理学中就已经能接触到了，理解向量和空间几何的结合非常重要。从最简单的加减法就能体会到基本相对量的价值；向量内积更是各种推荐算法、特征相似度计算的基础范式，向量外积在机械工程学中大行其道等等，这些无一证明了向量在现实的数学应用中的重要地位。

![](https://images.cnblogs.com/cnblogs_com/littleatp/1241412/o_qrcode_for_gh_b2cf486409a0_258.jpg)

作者： [美码师(zale)](http://www.cnblogs.com/littleatp/)

出处： [http://www.cnblogs.com/littleatp/](http://www.cnblogs.com/littleatp/), 如果喜欢我的文章，请**关注我的公众号**

本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出 [原文链接](#)  如有问题， 可留言咨询.