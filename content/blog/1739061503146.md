---
layout: post
title: 'DeepSeek部署本地知识库'
date: "2025-02-09T00:38:23Z"
---
DeepSeek部署本地知识库
===============

![DeepSeek部署本地知识库](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208151543985-1121092440.png) 大模型之大，可以训练我们所有人日常生活学习工作可能使用到的所有知识。但是完整的大模型，要实现一个本地化的部署，可能是有点困难，因此才有了大模型的蒸馏技术。蒸馏之后大模型可能会损失大多数的行业知识，而我们可以通过本地知识库构建的方法，在本地构建一个私有的专业大模型。

技术背景
====

在前面的两篇文章中，分别介绍过[Ubuntu上关于DeepSeek的部署](https://www.cnblogs.com/dechinphy/p/18699554/deepseek)以及[Windows平台关于DeepSeek的部署](https://www.cnblogs.com/dechinphy/p/18702523/deepseek2)。其中内容包含了Ollama的下载安装和基本使用、DeepSeek模型文件的下载，以及使用ChatBox导入Ollama本地模型进行本地对话的方法。这里再介绍一个使用AnythingLLM构建本地知识库的方法，本地知识库跟ChatBox两种对话模式的主要不同点在于，ChatBox对话中输入给大模型的其实是上下N条对话的内容，而本地知识库是先给大模型输入本地一系列的文件内容，然后再进行对话，这就是大模型领域专业化的一个重要应用。

下载安装AnythingLLM
===============

这里我们仅介绍Windows平台的方案，首先访问[AnythingLLM官网](https://anythingllm.com/desktop)，找到一个适合自己本地环境的版本下载，Windows系统就直接安装就可以了：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208111040848-219354428.png)

由于安装过程中有可能要联网下载一些库，所以不能离线安装，而且要耗费一些时间。

AnythingLLM本地工作区配置
==================

安装完成后打开界面是这样的：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121638853-1352550404.png)

选择第一个，点击`->`进入下一步：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121646571-1406565187.png)

中间可能还要填一些邮箱用途之类的，没什么影响，按情况填写然后继续点击`->`进入下一步：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121652822-396699820.png)

输入工作区名称，就创建完成了：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121721725-1982836044.png)

我感觉这个对话框还是比ChatBox简洁很多，看个人吧，喜欢哪个就用哪个。

AnythingLLM模型配置
===============

点击左下角的扳手图标，先配置一些基本参数：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121732672-1989581721.png)

模型配置在`LLM首选项`里边：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121738372-1339279207.png)

选择Ollama，然后剩下的按照自己的本地情况进行配置：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121745421-172576660.png)

这里稍有点不同的是，ChatBox里面配置远程IP的时候，可以直接用`xxx.xxx.xxx.xxx:11434`这样的形式。但是在AnythingLLM里面配置远程ip的话，需要加上http，也就是`http://xxx.xxx.xxx.xxx:11434`这样的形式。然后就可以进入到聊天窗口，这里再修改一下工作区的模型配置：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121806171-1635148468.png)

这里就可以看到对应IP下的所有本地模型，配置完成后就可以开始对话了：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121811348-1554255832.png)

工作区上传知识库文档
==========

在工作区那里有两个按钮，一个是上面一个章节用到的模型配置按钮，还有一个就是上传知识库文档的按钮了，点击可以进入这样的一个界面：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121816643-1032203090.png)

可以本地打开一个文件夹，把相应的文件拖到左下角那朵云上面，就上传到临时交换区了。这里还可以把网页链接输进去，也是直接同步到交换区。在传完文件之后，在交换区选择需要传输到工作区里面的文件，点击`Move To Workspace`就可以把所有选中的文件传到工作区里面了。这里还没结束，需要再点击一个`Save and Embed`同步到工作区中，这需要一点点解析的时间。传输完成后，可以在右侧工作区的文件面板上看到传输过来的文件，包含网页内容：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208121820539-1923037228.png)

这样就可以构建属于自己专业领域的本地知识库了，相当于让DeepSeek的模型学习一遍这些传进去的文档。

应用场景
====

这里只是做一个简单的演示。我先在一个空白的工作区里面提问：“什么是mindsponge”。这个问题对于模型来说可能会有点陌生，因为它学习到的数据里面可能没有这个工具，所以它的回答也是不知所云：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208144907225-578319532.png)

但是当我把之前写过的一些[关于mindsponge的博客](https://www.cnblogs.com/dechinphy/collections/5620)传上去之后，再问一遍“什么是mindsponge”，它的回答是这样的：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250208141747295-2104397942.png)

相对来说信息就准确了很多，可以认为大模型从本地的知识库里面学习到了行业相关内容，这就完成了一个大模型+专业领域知识库的构建。

提示
==

这里提供2条可能有用的提示：

1.  载入新的知识库文件之后，最好reset一下对话，发送一个`/reset`即可。
2.  如果用户仅需要回复定制化的内容，可以在聊天设置中把`聊天`模式改为`查询`模式。

总结概要
====

大模型之大，可以训练我们所有人日常生活学习工作可能使用到的所有知识。但是完整的大模型，要实现一个本地化的部署，可能是有点困难，因此才有了大模型的蒸馏技术。蒸馏之后大模型可能会损失大多数的行业知识，而我们可以通过本地知识库构建的方法，在本地构建一个私有的专业大模型。

版权声明
====

本文首发链接为：[https://www.cnblogs.com/dechinphy/p/deepseek3.html](https://www.cnblogs.com/dechinphy/p/deepseek3.html)

作者ID：DechinPhy

更多原著文章：[https://www.cnblogs.com/dechinphy/](https://www.cnblogs.com/dechinphy/)

请博主喝咖啡：[https://www.cnblogs.com/dechinphy/gallery/image/379634.html](https://www.cnblogs.com/dechinphy/gallery/image/379634.html)

参考链接
====

1.  [https://readdevdocs.com/blog/ai/如何用DeepSeek R1搭建个人知识库？.html#前言](https://readdevdocs.com/blog/ai/%E5%A6%82%E4%BD%95%E7%94%A8DeepSeek%20R1%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E5%BA%93%EF%BC%9F.html#%E5%89%8D%E8%A8%80)