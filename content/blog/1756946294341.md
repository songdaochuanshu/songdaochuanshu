---
layout: post
title: 'ã€LangGraphã€‘Human-in-the-loopç¤ºä¾‹ä¹‹äººå·¥å¹²é¢„shellå‘½ä»¤æ‰§è¡Œ'
date: "2025-09-04T00:38:14Z"
---
ã€LangGraphã€‘Human-in-the-loopç¤ºä¾‹ä¹‹äººå·¥å¹²é¢„shellå‘½ä»¤æ‰§è¡Œ
============================================

å€ŸåŠ©LangGraphçš„Human in the loopï¼Œå®ç°ä¸€ä¸ªå‘½ä»¤è¡Œäº¤äº’çš„ç¨‹åºï¼ŒAIæ‰§è¡Œshellå‘½ä»¤å‰éƒ½è¦ç”¨æˆ·åŒæ„ã€‚

å‰è¨€
--

çœ‹langgraphå®˜æ–¹æ–‡æ¡£æ„Ÿè§‰human in the loopè²Œä¼¼è¿˜æŒºç®€å•çš„ï¼Œä½†å®é™…ä¸Šæ‰‹æ—¶ï¼Œé‚£æ–‡æ¡£çœ‹å¾—æˆ‘äº‘é‡Œé›¾é‡Œçš„ã€‚æ›´è¯¦ç»†çš„Guideså’ŒReferenceï¼Œæ•æˆ‘èƒ½åŠ›æœ‰é™ï¼Œæ‚²æ‘§çš„ä¹Ÿæ²¡çœ‹æ‡‚ã€‚ä½œä¸ºè¯•éªŒï¼Œæˆ‘æƒ³åšä¸€ä¸ªåŠŸèƒ½ï¼šæœ¬åœ°æ‰§è¡Œshellå‘½ä»¤ï¼Œæ¯æ¬¡æ‰§è¡Œå‰éƒ½è¦ç”¨æˆ·ç¡®è®¤ã€‚å·¦çœ‹å®˜æ–¹æ–‡æ¡£ï¼Œ å³å»è¥¿å¤©è¯·ChatGPTè€ç¥–ã€‚ChatGPTè¯´å¾—å¤´å¤´æ˜¯é“ï¼ŒCopilotä¹Ÿåå¤è°ƒè¯•ï¼Œä½†å°±æ˜¯ä¸èƒ½ç”¨ã€‚å°±è¿™ã€‚ã€‚ã€‚çœ‹æ¥ç¢°åˆ°æ–°ä¸œè¥¿AIå°±ååˆ†æ‹‰èƒ¯ã€‚æœ€ç»ˆï¼Œè®¤çœŸçœ‹äº†åŠå¤©æ–‡æ¡£ï¼Œæ²¡å€ŸåŠ©GPTï¼Œæ€»ç®—æ£é¼“å‡ºæ¥ä¸€ä¸ªæœ€ç®€ç‰ˆã€‚

> è‡ªä»AIèƒ½åŠ›è¶Šæ¥è¶Šå¼ºï¼Œå¤§å¤šæ—¶å€™è‡ªå·±æ›´ä¹ æƒ¯ç›´æ¥è®©AIå¸®å¿™è§£å†³é—®é¢˜ï¼Œè¶Šæ¥è¶Šæ‡’å¾—çœ‹æ–‡æ¡£ã€‚è‡ªå·±æ‰¾é¥­åƒçš„èƒ½åŠ›è¿˜æ˜¯å¾—ç•™ç€ï¼Œä¸èƒ½å…‰é AIå–‚é¥­ã€‚

è¿è¡Œæ•ˆæœ
----

è¯•éªŒå˜›ï¼Œäº¤äº’å°±æ˜¯å‘½ä»¤è¡Œäº†ã€‚æ•ˆæœå¤§æ¦‚è¿™æ ·

    $ python custom_workflow.py
    AIåŠ©æ‰‹å·²å¯åŠ¨ï¼Œè¾“å…¥ 'quit'ã€'exit' æˆ– 'q' é€€å‡ºç¨‹åº
    User: ä»Šå¤©çš„æ—¥æœŸæ˜¯ä»€ä¹ˆ
    Assistant: ä»Šå¤©çš„æ—¥æœŸæ˜¯ 2025-09-03ã€‚
    User: åˆè‚¥çš„å¤©æ°”æ€ä¹ˆæ ·
    Assistant: åˆè‚¥çš„å¤©æ°”æ€»æ˜¯é˜³å…‰æ˜åªšï¼
    User: æŸ¥çœ‹ä¸‹æœ¬åœ°å†…å­˜å ç”¨
    Assistant: Do you approve executing this command: free -h? Please answer 'yes' or 'no'.
    User: yes
    Assistant: å½“å‰æœ¬åœ°å†…å­˜å ç”¨æƒ…å†µå¦‚ä¸‹
    
    total        used        free      shared  buff/cache   available
    å†…å­˜ï¼š          62Gi        10Gi        46Gi       157Mi       6.5Gi        52Gi
    äº¤æ¢ï¼š         3.8Gi          0B       3.8Gi
    
    User: diskå‘¢ï¼Ÿ
    Assistant: Do you approve executing this command: df -h? Please answer 'yes' or 'no'.
    User: yes
    Assistant: å½“å‰ç£ç›˜ä½¿ç”¨æƒ…å†µå¦‚ä¸‹ï¼š
    
    æ–‡ä»¶ç³»ç»Ÿ                 å¤§å°  å·²ç”¨  å¯ç”¨ å·²ç”¨% æŒ‚è½½ç‚¹
    udev                      32G     0   32G    0% /dev
    tmpfs                    6.3G  1.8M  6.3G    1% /run
    /dev/mapper/debian-root  234G   29G  194G   13% /
    tmpfs                     32G   37M   32G    1% /dev/shm
    efivarfs                 128K   40K   84K   32% /sys/firmware/efi/efivars
    tmpfs                    5.0M   12K  5.0M    1% /run/lock
    tmpfs                    1.0M     0  1.0M    0% /run/credentials/systemd-journald.service
    tmpfs                     32G   49M   32G    1% /tmp
    /dev/nvme1n1p1           989M  256M  666M   28% /boot
    /dev/mapper/debian-home  676G  196G  446G   31% /home
    /dev/nvme0n1p1           300M   39M  262M   13% /boot/efi
    tmpfs                    6.3G  4.1M  6.3G    1% /run/user/1000
    
    User: éå¸¸å¥½
    Assistant: è°¢è°¢ï¼å¦‚æœæ‚¨æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦è¿›ä¸€æ­¥çš„å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚ğŸ˜Š
    User: quit
    Goodbye!
    

Code
----

æ³¨é‡Šå†™å¾—å¤Ÿè¯¦ç»†çš„äº†ï¼Œå…·ä½“å¯ä»¥ç›´æ¥çœ‹æ³¨é‡Šã€‚LLMç”¨çš„æ˜¯é˜¿é‡Œåƒé—®ï¼Œæ³¨æ„æ›¿æ¢æˆè‡ªå·±çš„ã€‚

checkpointerç”¨çš„æ˜¯å†…å­˜ï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒï¼Œå¯ä»¥æŠŠcheckpointeræ¢æˆsqliteã€postgresã€redisç­‰ã€‚

logå°±æ˜¯ä¸ªå†™æ—¥å¿—æ–‡ä»¶çš„æ¨¡å—ï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°ï¼Œä¹‹å‰è°ƒè¯•çš„æ—¶å€™ç”¨æ¥å‘ç»™LLMåšè¯Šæ–­ï¼Œæ¯”è¾ƒç®€å•å°±ä¸è´´äº†ã€‚

åœ¨pythonå‘½ä»¤è¡Œäº¤äº’ç¨‹åºä¸­ï¼Œæœ€å¥½å¼•ç”¨ä¸‹`readline`æ¨¡å—ï¼Œä¸ç„¶è¾“å…¥ä¸­æ–‡ä¼šç¢°åˆ°é€€æ ¼é”®æ²¡æ³•æ­£å¸¸ç”¨çš„é—®é¢˜ï¼Œè€Œä¸”æ–¹å‘é”®ä¹Ÿæ²¡æ³•ç”¨ã€‚

    """
    Human in the loop ç¤ºä¾‹, æ¯å½“AIéœ€è¦æ‰§è¡Œshellå‘½ä»¤æ—¶, éƒ½éœ€è¦ç»è¿‡ç”¨æˆ·ç¡®è®¤
    """
    
    import os
    import readline  # å¼•å…¥readlintæ¨¡å—ä»¥å¢å¼ºå‘½ä»¤è¡Œè¾“å…¥ä½“éªŒã€‚Linuxç¯å¢ƒçš„Pythonæ ‡å‡†åº“å†…ç½®
    from datetime import datetime
    import subprocess
    import traceback
    
    from langchain_core.runnables import RunnableConfig
    from langchain_core.tools import tool
    from langchain_core.messages import HumanMessage
    from langchain_openai import ChatOpenAI
    
    from langgraph.checkpoint.memory import InMemorySaver
    from langgraph.graph import END, START, StateGraph, MessagesState
    from langgraph.graph.state import CompiledStateGraph
    from langgraph.prebuilt import ToolNode, tools_condition
    from langgraph.types import Command, interrupt
    from langgraph.prebuilt import create_react_agent
    
    # è‡ªå®šä¹‰ä¸€ä¸ªç®€å•çš„æ–‡ä»¶å‹æ—¥å¿—è®°å½•å™¨
    from log import logger
    
    
    # è®¾ç½®APIå¯†é’¥
    os.environ["OPENAI_API_KEY"] = ""
    
    # åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
    llm = ChatOpenAI(
        model="qwen-plus",
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )
    
    
    # å®šä¹‰å·¥å…·å‡½æ•°
    
    @tool
    def get_date() -> str:
        """è·å–ä»Šå¤©çš„æ—¥æœŸã€‚
        
        Returns:
            str: å½“å‰æ—¥æœŸï¼Œæ ¼å¼ä¸º YYYY-MM-DD
        """
        logger.info("Getting date")
        return datetime.now().strftime("%Y-%m-%d")
    
    @tool
    def get_weather(city: str) -> str:
        """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯ã€‚
        
        Args:
            city (str): åŸå¸‚åç§°
            
        Returns:
            str: å¤©æ°”ä¿¡æ¯æè¿°
        """
        logger.info("Getting weather")
        return f"It's always sunny in {city}!"
    
    @tool
    def execute_command(command: str) -> str:
        """æœ¬åœ°æ‰§è¡Œshellå‘½ä»¤, æ¯æ¬¡æ‰§è¡Œå‰éœ€è¦ç”¨æˆ·ç¡®è®¤
        
        Args:
            command (str): è¦æ‰§è¡Œçš„å‘½ä»¤
    
        Returns:
            str: å‘½ä»¤æ‰§è¡Œç»“æœæˆ–æ‹’ç»ä¿¡æ¯
        """
        # ä½¿ç”¨interruptå‡½æ•°æš‚åœæ‰§è¡Œå¹¶è¯·æ±‚ç”¨æˆ·ç¡®è®¤
        # interruptä¼šå°†æ§åˆ¶æƒäº¤è¿˜ç»™ç”¨æˆ·ï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥
        decision = interrupt({"query": f"Do you approve executing this command: {command}? Please answer 'yes' or 'no'."})
        logger.info(f"Decision: {decision}")
        
        # æ ¹æ®ç”¨æˆ·å†³ç­–å†³å®šæ˜¯å¦æ‰§è¡Œå‘½ä»¤
        if decision == "yes":
            logger.info(f"Executing command, {command}")
            try:
                # æ‰§è¡Œå‘½ä»¤å¹¶è·å–ç»“æœ
                result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=10)
                result = result.stdout or result.stderr
                return result
            except subprocess.TimeoutExpired:
                return "Command timed out"
            except Exception as e:
                return f"Error executing command: {str(e)}"
        else:
            logger.info("Command execution denied by user")
            return "Command execution denied by user"
    
    # å®šä¹‰å¯ç”¨å·¥å…·åˆ—è¡¨
    tools = [get_weather, get_date, execute_command]
    
    # åˆ›å»ºReActä»£ç†ï¼Œå®ƒå¯ä»¥æ ¹æ®éœ€è¦è‡ªåŠ¨è°ƒç”¨å·¥å…·
    agent = create_react_agent(
        model=llm,
        tools=tools,
        prompt="You are a helpful assistant."
    )
    
    # åˆ›å»ºå·¥å…·èŠ‚ç‚¹ï¼Œç”¨äºæ‰§è¡Œå·¥å…·è°ƒç”¨
    tool_node = ToolNode(tools=tools)
    
    # åˆ›å»ºå†…å­˜æ£€æŸ¥ç‚¹ä¿å­˜å™¨ï¼Œç”¨äºä¿å­˜å¯¹è¯çŠ¶æ€
    memory = InMemorySaver()
    
    # é…ç½®è¿è¡Œæ—¶å‚æ•°ï¼Œä½¿ç”¨å›ºå®šçš„çº¿ç¨‹ID
    config = RunnableConfig(configurable={"thread_id": "1"})
    
    def create_graph() -> CompiledStateGraph:
        """åˆ›å»ºå¹¶è¿”å›å·¥ä½œæµå›¾ã€‚
        
        Returns:
            CompiledStateGraph: ç¼–è¯‘åçš„å·¥ä½œæµå›¾
        """
        # åˆ›å»ºçŠ¶æ€å›¾ï¼Œä½¿ç”¨MessagesStateä½œä¸ºçŠ¶æ€ç±»å‹
        graph_builder = StateGraph(MessagesState)
        
        # æ·»åŠ èŠ‚ç‚¹
        graph_builder.add_node("agent", agent)  # AIä»£ç†èŠ‚ç‚¹
        graph_builder.add_node("tools", tool_node)  # å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹
        
        # æ·»åŠ è¾¹
        graph_builder.add_edge(START, "agent")  # ä»å¼€å§‹èŠ‚ç‚¹è¿æ¥åˆ°ä»£ç†èŠ‚ç‚¹
        graph_builder.add_edge("tools", "agent")  # ä»å·¥å…·èŠ‚ç‚¹è¿æ¥å›ä»£ç†èŠ‚ç‚¹
        
        # æ·»åŠ æ¡ä»¶è¾¹ï¼Œæ ¹æ®ä»£ç†çš„å†³ç­–å†³å®šä¸‹ä¸€æ­¥
        graph_builder.add_conditional_edges(
            "agent",
            tools_condition,  # æ¡ä»¶å‡½æ•°ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            {"tools": "tools", END: END}  # æ˜ å°„ï¼šéœ€è¦å·¥å…·æ—¶è½¬åˆ°å·¥å…·èŠ‚ç‚¹ï¼Œå¦åˆ™ç»“æŸ
        )
    
        # ç¼–è¯‘å›¾å¹¶è¿”å›ï¼Œä½¿ç”¨å†…å­˜ä¿å­˜å™¨æ¥ä¿å­˜çŠ¶æ€
        return graph_builder.compile(checkpointer=memory)
    
    def handle_user_decision(user_input: str) -> bool:
        """å¤„ç†ç”¨æˆ·å¯¹ä¸­æ–­çš„å“åº”ã€‚
        
        Args:
            user_input (str): ç”¨æˆ·çš„è¾“å…¥
            
        Returns:
            bool: å¦‚æœå¤„ç†äº†ä¸­æ–­è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        # åˆ›å»ºå›¾å®ä¾‹
        graph = create_graph()
        
        # è·å–å½“å‰çŠ¶æ€
        current_state = graph.get_state(config)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„ä¸­æ–­
        if not current_state.next:
            logger.warning("No pending interrupts to handle.")
            return False  # æ²¡æœ‰å¾…å¤„ç†çš„ä¸­æ–­
        
        # æ ¹æ®ç”¨æˆ·è¾“å…¥å†³å®šå¦‚ä½•å“åº”ä¸­æ–­
        if user_input.lower() == "yes":
            # ç”¨æˆ·ç¡®è®¤ï¼Œç»§ç»­æ‰§è¡Œ
            graph.invoke(Command(resume="yes"), config=config)
        else:
            # ç”¨æˆ·æ‹’ç»ï¼Œå–æ¶ˆæ‰§è¡Œ
            graph.invoke(Command(resume="no"), config=config)
            
        return True  # å¤„ç†äº†ä¸­æ–­
    
    def graph_invoke(user_input: str):
        """å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶æ‰§è¡Œç›¸åº”æ“ä½œã€‚
        
        Args:
            user_input (str): ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬
        """
        # é¦–å…ˆå°è¯•å¤„ç†ç”¨æˆ·å¯¹ä¸­æ–­çš„å“åº”
        interrupt_handled = handle_user_decision(user_input)
    
        # å¦‚æœå·²ç»å¤„ç†äº†ä¸­æ–­ï¼Œåˆ™ä¸å†ç»§ç»­å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œè€Œæ˜¯æ˜¾ç¤ºç»“æœ
        if interrupt_handled:
            # è·å–å¤„ç†åçš„çŠ¶æ€å¹¶æ˜¾ç¤ºç»“æœ
            graph = create_graph()
            current_state = graph.get_state(config)
            if current_state.values and 'messages' in current_state.values:
                # æ˜¾ç¤ºæœ€æ–°çš„æ¶ˆæ¯å†…å®¹
                messages = current_state.values['messages']
                if messages:
                    last_message = messages[-1]
                    if hasattr(last_message, 'content'):
                        print("Assistant:", last_message.content)
            return
    
        # å¦‚æœæ²¡æœ‰å¾…å¤„ç†çš„ä¸­æ–­ï¼Œåˆ™æ­£å¸¸å¤„ç†ç”¨æˆ·è¾“å…¥
        graph = create_graph()
        resp = graph.invoke({"messages": [HumanMessage(content=user_input)]}, config=config)
        
        logger.debug(f"response: {resp}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–­éœ€è¦å¤„ç†
        if "__interrupt__" in resp:
            interrupt_data = resp["__interrupt__"]
            interrupt = interrupt_data[0] if interrupt_data else None
    
            if not interrupt or not hasattr(interrupt, "value"):
                logger.error("Invalid interrupt data")
                return
                
            interrupt_value = interrupt.value
            # æ˜¾ç¤ºä¸­æ–­è¯·æ±‚ç»™ç”¨æˆ·
            print(f"Assistant: {interrupt_value['query']}")
        else:
            # ç›´æ¥æ˜¾ç¤ºAIçš„å“åº”
            print("Assistant:", resp["messages"][-1].content)
            
        logger.debug(f"Snapshot state: {graph.get_state(config)}")
        logger.debug(f"Snapshot next: {graph.get_state(config).next}")
    
    # ç¨‹åºå…¥å£ç‚¹
    if __name__ == "__main__":
        """ä¸»ç¨‹åºå¾ªç¯ï¼Œå¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆå“åº”ã€‚"""
        
        print("AIåŠ©æ‰‹å·²å¯åŠ¨ï¼Œè¾“å…¥ 'quit'ã€'exit' æˆ– 'q' é€€å‡ºç¨‹åº")
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("User: ").strip()
                logger.info(f"User input: {user_input}")
                
                # æ£€æŸ¥é€€å‡ºå‘½ä»¤
                if user_input.lower() in ["quit", "exit", "q"]:
                    print("Goodbye!")
                    break
                    
                # å¤„ç†ç”¨æˆ·è¾“å…¥
                graph_invoke(user_input)
                
            except KeyboardInterrupt:
                # å¤„ç†Ctrl+Cä¸­æ–­
                print("\nGoodbye!")
                break
            except Exception as e:
                # è®°å½•å¹¶æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                logger.error(f"Error occurred: {traceback.format_exc()}")
                print(f"Error: {traceback.format_exc()}")
                break
    

æœ¬æ–‡æ¥è‡ªåšå®¢å›­ï¼Œä½œè€…ï¼š[èŠ±é…’é”„ä½œç”°](https://www.cnblogs.com/XY-Heruo/)ï¼Œè½¬è½½è¯·æ³¨æ˜åŸæ–‡é“¾æ¥ï¼š[https://www.cnblogs.com/XY-Heruo/p/19071001/human-in-the-loop-of-langgraph](https://www.cnblogs.com/XY-Heruo/p/19071001/human-in-the-loop-of-langgraph)