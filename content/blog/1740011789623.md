---
layout: post
title: 'DeepSeek智能编程'
date: "2025-02-20T00:36:29Z"
---
DeepSeek智能编程
============

![DeepSeek智能编程](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219165749241-1240120630.png) 本文介绍了两种智能编程的方案，一种是使用Cursor结合远程API形式的智能化自动编程，另一种方案是VSCode插件结合本地部署的Ollama模型来进行智能编程。用户可以根据自己的需求来选择一种合适的交互方案，总体来说智能化、自动化的编程已经近在眼前了。

技术背景
====

DeepSeek开源之后，让大家意识到了即时是在自己硬件性能一般的本地环境，也能够部署和使用大语言模型，真正实现了大模型的“私有化”。而私有化大模型之后，自然是考虑生产力的私有化。例如，如何使用大模型作为一个工具来进行编程？本文将要介绍两种不同的人工智能编程方法。

Cursor的安装与使用
============

第一种方法，是使用Cursor来进行编程，是一个跟VSCode很像的IDE，优点是支持了很多模型的api，例如deepseek和o1-mini、o3这些，原生的为人工智能编程而设计。

Cursor安装
--------

首先访问[Cursor官网](https://www.cursor.com/cn/downloads)，下载适合自己本地平台的版本。我这里下载的是Windows版本，可以直接安装：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250218165638692-1171875313.png)

没有太多可以配置的选项：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250218170112465-1284951421.png)

按照自己的需求进行设置就好了：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250218170119035-214418707.png)

Cursor基本使用
----------

打开一个文件夹作为workspace：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250218170312175-1897405025.png)

创建一个测试py脚本，只需要输入一行注释：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250218171541925-2105856241.png)

这个时候下面的代码还是灰色的，只需要按一下TAB，就可以插入AI生成的代码：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250218171750360-1397487231.png)

也可以选择生成一些函数：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250218171856046-2128321716.png)

这里因为输入的指令可能不是很明确，导致函数没有输出，我们可以要求它输出一个排序之后的列表：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250218171956900-1892227677.png)

这样就有输出了，然后一样的，点击TAB键，就可以自动填入生成的代码：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250218172108970-1089242160.png)

甚至还自动生成了两个测试案例，这个对于需要单元测试的项目来说非常的友好。除了可以写代码之外，可以把项目作为输入的知识库，进行Chat，只需要使用快捷键`ctrl+L`即可：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250218172045626-1736318125.png)

可以看到这里的代码解读还是比较准确的，即使是作为一个源码阅读的辅助工具也是很棒的。

另外除了使用注释生成代码之外，我们还可以直接用`ctrl+K`快捷键，弹出代码需求窗口，直接把需求输入，就可以生成代码：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250218172509898-315376230.png)

点击这个绿色按钮，代码就填入到光标位置了：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250218172533436-2147047297.png)

这里因为光标前有一个缩进，所以生成的代码块前默认加了一个缩进，自己根据需求调整下位置就可以了。

小结
--

Cursor的智能编程体验还是不错的，而且使用远程的API对于本地环境要求也不高。但是有个问题是似乎比较难配置本地的Ollama环境，找了一圈也没有找到相关的文档。所以如果是本地已经部署了Ollama环境的，可以优先查看下面章节要介绍的VSCode插件。

VSCode插件Continue
================

第二个要介绍的工具是VSCode里面的一个智能编程插件Continue。

安装与配置
-----

直接在VSCode的插件商城里面搜Continue：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219153949821-205859659.png)

点击安装，然后就能在左侧显示一个Continue的图标：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219154006720-158588759.png)

可以在对话选项里面选择添加一个Chat Model：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219154020350-1788171457.png)

如果配置了Ollama的环境，会显示出本地的相关模型：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219154028608-2087216007.png)

运行前可以查看本地Ollama运行情况：

    $ ollama ps
    NAME    ID    SIZE    PROCESSOR    UNTIL 
    

随便发送一个问题过去：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219154429283-2128166427.png)

再次查看：

    $ ollama ps
    NAME               ID              SIZE     PROCESSOR    UNTIL               
    deepseek-r1:14b    ea35dfe18182    12 GB    100% GPU     29 minutes from now
    

这里就是加载Ollama模型对话成功了。然后就会收到回复：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219154456499-1095958266.png)

但是这里只是临时会话的配置，真正要做到DeepSeek智能编程，我们要找到Local with Ollama做一些额外的设置：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219155442000-1260079523.png)

点击config file，进行配置，默认是这样的：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219155512860-1961900351.png)

或者也可以从continue的设置里面找到配置文件的位置：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219160828530-2001212369.png)

按照自己本地模型修改下代码：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219163221988-2053373062.png)

这里关于Ollama的请求格式，可以参考其[官网文档](https://github.com/ollama/ollama/blob/main/docs/api.md)。

关于Continue插件的快捷键使用方法，点击设置按钮右边的三个点的按钮，可以查看：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219160345554-1310657956.png)

接下来开始智能编程。

Continue与DeepSeek
-----------------

我们可以先输入一个注释：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219163447213-1052324809.png)

选中注释：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219163355525-719492482.png)

这里会提示你快捷键该怎么用，例如我们使用`ctrl+L`快捷键进入Chat模式，并告诉它我们需要生成代码：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219163559449-347343583.png)

点击接受：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219163633349-1630955021.png)

新的代码就更新进来了。这次我们选中刚才生成的代码，快捷键使用`ctrl+I`启用编辑模式，然后告诉他我们要修改的内容：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219163940230-828058287.png)

自动生成的函数效果：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219163905890-1733627654.png)

再补充一个Chat模式随机字符串生成的函数（要在对话框里面@你所需要修改的文件）：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219165103646-1488532617.png)

chat模式下生成的代码块有一个三角形，可以直接apply到你的python文件中：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250219165644506-2024792909.png)

测试AI生成代码的本地运行：

    $ python3 test_chat.py 
    s!
    

小结
--

这里Continue插件使用的完全是本地Ollama环境中的DeepSeek开源蒸馏模型，可以很好的把本地LLM和Embedding模型应用到人工智能编程中。不过这样虽然隐私性较好，但效率和质量也会受限于本地的硬件条件。

总结概要
====

本文介绍了两种智能编程的方案，一种是使用Cursor结合远程API形式的智能化自动编程，另一种方案是VSCode插件结合本地部署的Ollama模型来进行智能编程。用户可以根据自己的需求来选择一种合适的交互方案，总体来说智能化、自动化的编程已经近在眼前了。

版权声明
====

本文首发链接为：[https://www.cnblogs.com/dechinphy/p/cursor.html](https://www.cnblogs.com/dechinphy/p/cursor.html)

作者ID：DechinPhy

更多原著文章：[https://www.cnblogs.com/dechinphy/](https://www.cnblogs.com/dechinphy/)

请博主喝咖啡：[https://www.cnblogs.com/dechinphy/gallery/image/379634.html](https://www.cnblogs.com/dechinphy/gallery/image/379634.html)

参考链接
====

1.  [https://www.5dzone.com/posts/visual-studio-code中continue插件连接ollama的配置方法.html](https://www.5dzone.com/posts/visual-studio-code%E4%B8%ADcontinue%E6%8F%92%E4%BB%B6%E8%BF%9E%E6%8E%A5ollama%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%B9%E6%B3%95.html)
2.  [https://github.com/continuedev/continue/issues/3752](https://github.com/continuedev/continue/issues/3752)