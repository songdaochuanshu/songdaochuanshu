---
layout: post
title: 'âœ¨ç”Ÿç‰©å¤§è¯­è¨€æ¨¡å‹Evo2â€”â€”è§£ç åŸºå› å¯†ç çš„AIé©å‘½'
date: "2025-05-20T00:42:29Z"
---
âœ¨ç”Ÿç‰©å¤§è¯­è¨€æ¨¡å‹Evo2â€”â€”è§£ç åŸºå› å¯†ç çš„AIé©å‘½ğŸš€
===========================

æœ¬æ–‡æ·±å…¥è§£æç”Ÿç‰©å¤§è¯­è¨€æ¨¡å‹Evo2çš„Embeddingé­”æ³•â€”â€”é€šè¿‡æå–åŸºå› åºåˆ—çš„è¯­ä¹‰ç‰¹å¾ï¼Œç»“åˆæ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰ï¼ŒæˆåŠŸå°†BRCA1å•æ ¸è‹·é…¸çªå˜æ•ˆåº”é¢„æµ‹çš„AUROCä»0.7å·¦å³æå‡è‡³0.9å·¦å³ã€‚ä»NVIDIA NIMäº‘ç«¯éƒ¨ç½²åˆ°Auto-dlæœ¬åœ°ç¯å¢ƒæ­å»ºï¼Œä»Embeddingæ‰¹é‡æå–åˆ°DNNæ¨¡å‹ä¼˜åŒ–ï¼Œæä¾›å¼€ç®±å³ç”¨çš„ä»£ç ä¸é¿å‘æŒ‡å—ï¼Œä¸ºç”Ÿç‰©è®¡ç®—ç ”ç©¶è€…æ‰“å¼€"AI+åŸºå› "çš„åˆ›æ–°åº”ç”¨èŒƒå¼ã€‚

### ğŸŒŸ 2025ï¼šç”Ÿç‰©AIçš„"DeepSeekæ—¶åˆ»"

å½“æ•´ä¸ªä¸­æ–‡äº’è”ç½‘ä¸ºå›½äº§å¤§è¯­è¨€æ¨¡å‹DeepSeekæ¬¢å‘¼æ—¶ï¼Œç”Ÿå‘½ç§‘å­¦ç•Œæ­£æ‚„ç„¶æ€èµ·ä¸€åœºé™é»˜é©å‘½â€”â€”ç”±Arc Instituteé¢†è¡”ï¼Œæ–¯å¦ç¦ã€UC Berkeleyã€å“¥å¤§ã€UCSFæºæ‰‹è‹±ä¼Ÿè¾¾ç­‰é¡¶å°–AIä¼ä¸šï¼Œå…±åŒæ¨å‡ºç™¾äº¿å‚æ•°çº§ç”Ÿç‰©è¯­ä¹‰ç†è§£å¼•æ“Evo2ï¼è¿™ä¸ªèƒ½ç›´æ¥"è¯»æ‡‚"æ ¸è‹·é…¸è¯­è¨€çš„ç¥å¥‡æ¨¡å‹ï¼Œæ­£åœ¨é‡æ–°å®šä¹‰æˆ‘ä»¬å¯¹åŸºå› å¯†ç çš„è®¤çŸ¥æ–¹å¼ğŸ§¬

ğŸŒŸæ¨¡å‹äº®ç‚¹é€Ÿè§ˆï¼š

*   ğŸ§¬ ç›´æ¥è§£ææ ¸è‹·é…¸åºåˆ—çš„"ç”Ÿç‰©è¯­è¨€"
    
*   ğŸš€ æ”¯æŒ8192é•¿åº¦ï¼ˆbaseæ¨¡å‹ï¼‰1 ç™¾ä¸‡ï¼ˆå®Œæ•´æ¨¡å‹ï¼‰è¶…é•¿åŸºå› ç‰‡æ®µå¤„ç†
    
*   ğŸŒ è·¨ç‰©ç§åŸºå› ç†è§£èƒ½åŠ›å‡çº§
    
*   ğŸ”“ å®Œå…¨å¼€æºï¼æ”¯æŒNVIDIA NIMäº‘ç«¯éƒ¨ç½²å’Œæœ¬åœ°è¿è¡Œ
    

ï¼ˆğŸ‘‰å°è´´å£«ï¼šæƒ³äº†è§£Evo1åˆ°Evo2çš„æ¶æ„é©å‘½ï¼Ÿå¿«åœ¨è¯„è®ºåŒºå‚¬æ›´æŠ€æœ¯è§£æä¸“é¢˜ï¼ï¼‰

ğŸ”æœ¬æœŸå®æˆ˜ç›®æ ‡ï¼š

ã€€ã€€ğŸ› ï¸ ä»é›¶å¼€å§‹çš„ä¿å§†çº§æ•™ç¨‹

ã€€ã€€ğŸš€ç”¨Embedding+DNNå®ç°BRCA1çªå˜æ•ˆåº”é¢„æµ‹

ã€€ã€€ğŸ“Šæ€§èƒ½é£è·ƒï¼šç›¸è¾ƒäºä»…ç”¨scoreå‡½æ•°å·®å€¼é¢„æµ‹çš„0.7 AUROCï¼ˆFairçº§ï¼‰ï¼ŒEmbedding+DNNæ–¹æ¡ˆç›´å†²0.9 AUROCï¼ˆGoodçº§ï¼‰ğŸ“ˆ

Â âœ¨ å°è´´å£«ï¼š

æˆ‘ä»é›¶å¼€å§‹ï¼Œç§Ÿç”¨æ–°çš„Auto-dlæœåŠ¡å™¨ï¼Œæ­å»ºç¯å¢ƒï¼Œé‡è·‘codeï¼Œä»¥ä¿è¯æ¯ä¸ªæ–°æ‰‹å°ç™½éƒ½èƒ½æœ‰æˆåŠŸæ„Ÿåœ°ä¸€æ¬¡æ€§è¿è¡ŒæˆåŠŸï¼Œä¸äº§ç”Ÿä»»ä½•æŠ¥é”™ã€‚å·²å‡†å¤‡å¥½å¼€ç®±å³ç”¨çš„Auto-dlé•œåƒï¼Œè¯„è®ºåŒº@zylAKï¼ˆæˆ‘çš„åšå®¢å›­æ˜µç§°ï¼‰å³åˆ»è·å–ğŸš€ å¦‚æœè§‰å¾—å¸–å­ä¸é”™æ¬¢è¿è½¬å‘zylAKçš„å¸–å­ç»™å°ä¼™ä¼´ä»¬ï¼Œä½ ä»¬çš„æ”¯æŒæ˜¯æˆ‘æ›´æ–°çš„åŠ¨åŠ›ã€‚å¦‚æœè¿˜æƒ³äº†è§£Evo2æ›´å¤šçš„åº”ç”¨ï¼Œä¾‹å¦‚å¦‚ä½•è®¾è®¡æ–°çš„æ ¸é…¸åºåˆ—ã€å¦‚ä½•è·å¾—å¯è§£é‡Šçš„å¤§è¯­è¨€æ¨¡å‹ç†è§£ç­‰ï¼Œéƒ½å¯ä»¥åœ¨è¯„è®ºåŒºå‚¬æ›´ã€‚

åºŸè¯ä¸å¤šè¯´ï¼Œä»¥Auto-dläº‘æœåŠ¡å™¨ä¸ºä¾‹ï¼Œç›´æ¥ä¸Šä»£ç ï¼š

ä¸€ã€å‰æœŸå‡†å¤‡ï¼š  
1.1 äº‘æœåŠ¡å™¨é…ç½®ï¼š

![](https://img2024.cnblogs.com/blog/1463277/202505/1463277-20250519153719421-699431769.png)

1.2 å¼€å¯Auto-dlçš„å­¦æœ¯åŠ é€Ÿå¹¶ä»githubä¸Šä¸‹è½½Evo2é¡¹ç›®æ–‡ä»¶ï¼Œæ¿€æ´»ï¼š  
å‘½ä»¤è¡Œæ˜¯ï¼š

1 source /etc/network\_turbo #å¼€å¯å­¦æœ¯åŠ é€Ÿ
2 git clone https://github.com/ArcInstitute/evo2.git #ä¸‹è½½Evo2é¡¹ç›®æ–‡ä»¶  
3 cd evo2 #è¿›å…¥é¡¹ç›®è·¯å¾„  

4 git clone https://github.com/Zymrael/vortex.git #æ‰‹åŠ¨å®‰è£…vortexä¾èµ–

5 python setup.py install #é¡¹ç›®æ¿€æ´»

1.3 ä»hugging faceé•œåƒç«™hf-mirrorä¸Šä¸‹è½½å¯¹åº”Evo2æ¨¡å‹ï¼Œå¹¶å­˜å‚¨åœ¨æœ¬åœ°ï¼Œä»¥ä¾›åç»­è°ƒç”¨ã€‚ç›®å‰4090æœºå™¨çš„é…ç½®å¯ä»¥è¿è¡Œ1bå’Œ7bçš„æ¨¡å‹ï¼ˆå®Œæ•´å’Œbaseç‰ˆå‡å¯ï¼‰ï¼Œ40bæ¨¡å‹å¯èƒ½éœ€è¦å†…å­˜æ›´é«˜çš„æœºå™¨ä¸”éœ€è¦å¤šå¡GPUéƒ¨ç½²ï¼Œè¿™ä¸€æœŸæš‚ä¸è®¨è®ºã€‚ä¸‰ç§å‚æ•°é‡çš„æ¨¡å‹æ•ˆæœç›¸å·®ä¸é‚£ä¹ˆæ˜æ˜¾ã€‚  
å‘½ä»¤è¡Œæ˜¯ï¼š

1 cd /root/autodl-tmp/evo2/evo2\_models #åœ¨é¡¹ç›®æ–‡ä»¶å¤¹ä¸­å•ç‹¬åˆ›å»ºä¸€ä¸ªevo2\_modelæ–‡ä»¶å¤¹ç”¨äºä¿å­˜ä¸‹è½½çš„æ¨¡å‹ï¼Œè¿™æ ·å°±ä¸ç”¨æ¯æ¬¡è°ƒç”¨æ—¶é‡æ–°ä¸‹è½½äº†
2 
3 #è®¾ç½®huggingface-cliä¸‹è½½çš„é•œåƒç½‘å€
4 export HF\_ENDPOINT=https://hf-mirror.com
5 
6 #ä¸‹è½½evo2\_1b\_baseæ¨¡å‹ä¸ºä¾‹
7 huggingface-cli download --resume-download arcinstitute/evo2\_1b\_base --local-dir /root/autodl-tmp/evo2/evo2\_models

æ­£ç¡®çš„ä¸‹è½½è¿è¡Œæ—¶ä¼šæœ‰å¦‚ä¸‹çš„è¾“å‡ºï¼ˆè¿›åº¦æ¡é€æ¸å¢åŠ ï¼‰

![](https://img2024.cnblogs.com/blog/1463277/202505/1463277-20250519161115806-813906910.png)

äºŒã€æ¨¡å‹åŠ è½½ä¸Embeddingsæå–

2.1 å¯¼å…¥é¡¹ç›®éœ€è¦ç”¨åˆ°çš„æ‰€æœ‰packages

 1 from Bio import SeqIO 2 import gzip 3 import matplotlib.pyplot as plt 4 import numpy as np 5 import pandas as pd 6 import os 7 import seaborn as sns 8 from sklearn.metrics import roc\_auc\_score 9 import numpy as np
10 import torch
11 import torch.nn as nn
12 from torch.utils.data import DataLoader, TensorDataset
13 from sklearn.model\_selection import train\_test\_split
14 from sklearn.metrics import roc\_auc\_score
15 from torch.optim.lr\_scheduler import ReduceLROnPlateau
16 from pathlib import Path
17 from tqdm.notebook import tqdm
18 import transformer\_engine.pytorch as te
19 from transformer\_engine.common import recipe

Â å¯èƒ½ä¼šå‡ºç°æŠ¥é”™ï¼š

![](https://img2024.cnblogs.com/blog/1463277/202505/1463277-20250519162030634-373452541.png)

Â ä½†å®Œå…¨ä¸å½±å“åç»­ä»£ç è¿è¡Œã€‚å¦‚æœåæœŸflash-attnåŒ…å‡çº§é€ æˆå†²çªï¼Œå¯ä»¥æŒ‡å®šå®‰è£…2.7.4ç‰ˆæœ¬ã€‚

2.2 åŠ è½½æ¨¡å‹

os.chdir('/root/autodl-tmp/evo2/evo2')
model\_path \= "/root/autodl-tmp/evo2/evo2\_models/evo2\_1b\_base/evo2\_1b\_base.pt"
from evo2.models import Evo2
model \= Evo2(model\_name='evo2\_1b\_base',local\_path=model\_path)

2.3 åŠ è½½å¹¶è§£æè¾“å…¥æ•°æ®â€”â€”BRCA1æ•°æ®ï¼ŒåŒ…æ‹¬åºåˆ—æ•°æ®ï¼Œçªå˜ä½ç‚¹ï¼Œçªå˜æ•ˆåº”åˆ†ç±»ã€‚è¯¦ç»†è¯´æ˜è¯·è§Evo2é¡¹ç›®æ¡ˆä¾‹ä»‹ç»ï¼šhttps://github.com/ArcInstitute/evo2/tree/main/notebooks/brca1

 1 os.chdir('/root/autodl-tmp/evo2')  
   brca1\_df = pd.read\_excel(

 2     os.path.join('notebooks', 'brca1', '41586\_2018\_461\_MOESM3\_ESM.xlsx'),
 3     header=2,
 4 )
 5 brca1\_df = brca1\_df\[\[ 6     'chromosome', 'position (hg19)', 'reference', 'alt', 'function.score.mean', 'func.class',
 7 \]\]
 8 
 9 # å¯¹åˆ—åé‡å‘½å
10 brca1\_df.rename(columns={
11     'chromosome': 'chrom',
12     'position (hg19)': 'pos',
13     'reference': 'ref',
14     'alt': 'alt',
15     'function.score.mean': 'score',
16     'func.class': 'class',
17 }, inplace=True)
18 
19 # å°†çªå˜æ•ˆåº”å‘½åä¸ºäºŒåˆ†ç±»æ ‡ç­¾
20 brca1\_df\['class'\] = brca1\_df\['class'\].replace(\['FUNC', 'INT'\], 'FUNC/INT')
21 
22 WINDOW\_SIZE = 8192
23 
24 # è¯»å–17å·æŸ“è‰²ä½“å‚è€ƒåŸºå› ç»„åºåˆ—
25 with gzip.open(os.path.join('notebooks', 'brca1', 'GRCh37.p13\_chr17.fna.gz'), "rt") as handle:
26     for record in SeqIO.parse(handle, "fasta"):
27         seq\_chr17 = str(record.seq)
28         break
29 
30 def parse\_sequences(pos, ref, alt):
31     """
32 è§£æå‚è€ƒåºåˆ—ï¼ˆæœªçªå˜åºåˆ—ï¼‰å’Œçªå˜åºåˆ—
33     """
34     p = pos - 1 # Convert to 0-indexed position
35     full\_seq = seq\_chr17
36 
37     ref\_seq\_start = max(0, p - WINDOW\_SIZE//2)
38     ref\_seq\_end = min(len(full\_seq), p + WINDOW\_SIZE//2)
39     ref\_seq = seq\_chr17\[ref\_seq\_start:ref\_seq\_end\]
40     snv\_pos\_in\_ref = min(WINDOW\_SIZE//2, p)
41     var\_seq = ref\_seq\[:snv\_pos\_in\_ref\] + alt + ref\_seq\[snv\_pos\_in\_ref+1:\]
42 
43     # æ•°æ®åˆç†æ€§æ£€æŸ¥
44     assert len(var\_seq) == len(ref\_seq)
45     assert ref\_seq\[snv\_pos\_in\_ref\] == ref
46     assert var\_seq\[snv\_pos\_in\_ref\] == alt
47 
48     return ref\_seq, var\_seq
49 
50 # ç»™å‚è€ƒåºåˆ—ä¸€ä¸ªç´¢å¼•å€¼
51 ref\_seqs = \[\]
52 ref\_seq\_to\_index = {}
53 
54 # è§£æåºåˆ—å¹¶å­˜å‚¨ç´¢å¼•å€¼
55 ref\_seq\_indexes = \[\]
56 var\_seqs = \[\]
57 
58 for \_, row in brca1\_df.iterrows():
59     ref\_seq, var\_seq = parse\_sequences(row\['pos'\], row\['ref'\], row\['alt'\])
60 
61     # ç»™å½“å‰å¾ªç¯åˆ°çš„å‚è€ƒåºåˆ—è·å–/åˆ›å»ºç´¢å¼•
62     if ref\_seq not in ref\_seq\_to\_index:
63         ref\_seq\_to\_index\[ref\_seq\] = len(ref\_seqs)
64 ref\_seqs.append(ref\_seq)
65     
66 ref\_seq\_indexes.append(ref\_seq\_to\_index\[ref\_seq\])
67 var\_seqs.append(var\_seq)
68 
69 ref\_seq\_indexes = np.array(ref\_seq\_indexes)

2.4 ä»¥BCRA1åºåˆ—ä¸ºè¾“å…¥ï¼Œæå–å…¨éƒ¨å…¨éƒ¨å±‚çš„Embeddingå¹¶ä¿å­˜ä¸‹æ¥

 1 # ========== é…ç½®å‚æ•° ==========
 2 device = next(model.model.parameters()).device 3 candidate\_layers = \[f"blocks.{i}.pre\_norm" for i in range(25)\]
 4 batch\_size = 8  # æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´
 5 save\_dir = "extract\_embeddings"
 6 os.makedirs(save\_dir, exist\_ok=True)
 7 
 8 # ========== æ‰¹é‡åµŒå…¥æå–  ==========
 9 def process\_sequences(seq\_list, layer\_name, desc, prefix="ref"):
10     """æ‰¹é‡å¤„ç†åºåˆ—åµŒå…¥å¹¶ç¡®ä¿æ–‡ä»¶ä¿å­˜"""
11     # ç”Ÿæˆæ ‡å‡†åŒ–æ–‡ä»¶å
12     sanitized\_layer = layer\_name.replace('.', '\_')
13     memmap\_path = os.path.join(save\_dir, f"{prefix}\_{sanitized\_layer}.npy")
14     
15     # åˆ›å»ºå†…å­˜æ˜ å°„æ–‡ä»¶å¹¶ç«‹å³ä¿å­˜å¤´ä¿¡æ¯
16     emb\_mmap = np.lib.format.open\_memmap(
17 memmap\_path, 
18         dtype=np.float32,
19         mode='w+',
20         shape=(len(seq\_list), 1920)
21 )
22     
23     try:
24         # åˆ†æ‰¹å¤„ç†
25         for i in tqdm(range(0, len(seq\_list), batch\_size), desc=desc, leave=False):
26             batch\_seqs = seq\_list\[i:i+batch\_size\]
27             
28             # Tokenizeå¹¶å¡«å……
29             batch\_tokens = \[\]
30             for seq in batch\_seqs:
31                 tokens = model.tokenizer.tokenize(seq)
32                 batch\_tokens.append(torch.tensor(tokens, dtype=torch.long))
33             
34             max\_len = max(len(t) for t in batch\_tokens)
35             padded\_tokens = torch.stack(\[
36                 torch.nn.functional.pad(t, (0, max\_len - len(t))) for t in batch\_tokens
37 \]).to(device)
38             
39             # å‰å‘ä¼ æ’­
40 with torch.no\_grad():
41                 \_, emb\_dict = model.forward(
42 padded\_tokens,
43                     return\_embeddings=True,
44                     layer\_names=\[layer\_name\]
45 )
46             
47             # å†™å…¥å†…å­˜æ˜ å°„æ–‡ä»¶
48             batch\_emb = emb\_dict\[layer\_name\].float().mean(dim=1).cpu().numpy()
49             emb\_mmap\[i:i+len(batch\_emb)\] = batch\_emb
50             
51             # ç«‹å³åˆ·æ–°å†™å…¥ç£ç›˜
52 emb\_mmap.flush()
53             
54     finally:
55         # ç¡®ä¿æ–‡ä»¶å…³é—­
56         del emb\_mmap
57     
58     return memmap\_path
59 
60 # ========== ä¸»æµç¨‹ ==========
61 # é¢„å…ˆç”Ÿæˆå…¨å±€ç´¢å¼•æ–‡ä»¶ (åªéœ€ä¿å­˜ä¸€æ¬¡)
62 np.save(os.path.join(save\_dir, "ref\_idx.npy"), ref\_seq\_indexes)
63 
64 for layer\_name in tqdm(candidate\_layers, desc="ğŸ” Processing Layers"):
65     # å¤„ç†å‚è€ƒåºåˆ— (ç”Ÿæˆ ref\_blocks\_0\_pre\_norm.npy)
66     \_ = process\_sequences(
67 ref\_seqs, 
68 layer\_name,
69         f"ğŸ§¬ Ref {layer\_name}",
70         prefix="ref"
71 )
72     
73     # å¤„ç†å˜å¼‚åºåˆ— (ç”Ÿæˆ var\_blocks\_0\_pre\_norm.npy)
74     \_ = process\_sequences(
75 var\_seqs,
76 layer\_name,
77         f"ğŸ§¬ Var {layer\_name}",
78         prefix="var"
79     )

æ­£ç¡®è¿è¡Œåæœ‰å¦‚ä¸‹è¾“å‡ºæ˜¾ç¤ºï¼š

![](https://img2024.cnblogs.com/blog/1463277/202505/1463277-20250519170247866-509314315.png)

ä¸‰ã€åŸºäºä¿å­˜çš„Embeddingså¼€å‘ä¸‹æ¸¸çš„çªå˜æ•ˆåº”é¢„æµ‹å™¨ï¼š

3.1 Embeddingæ•°æ®åŠ è½½å‡½æ•°çš„å®šä¹‰

 1 # ========== æ–°å¢é…ç½®å‚æ•° ==========
 2 embed\_dir = Path("extract\_embeddings")
 3 layers\_to\_train = \[f"blocks.{i}.pre\_norm" for i in range(25)\]  # éœ€è¦è®­ç»ƒçš„å±‚åˆ—è¡¨ï¼Œå…¨éƒ¨çš„25å±‚
 4 results\_dir = Path("training\_results")
 5 results\_dir.mkdir(exist\_ok=True)
 6 
 7 # ========== æ•°æ®åŠ è½½å‡½æ•° ==========
 8 def load\_layer\_data(layer\_name): 9     """åŠ è½½æŒ‡å®šå±‚çš„åµŒå…¥æ•°æ®å’Œæ ‡ç­¾"""
10     sanitized = layer\_name.replace('.', '\_')
11     
12     # åŠ è½½åµŒå…¥æ•°æ®ï¼ˆå†…å­˜æ˜ å°„æ¨¡å¼ï¼‰
13     ref\_emb = np.load(embed\_dir/f"ref\_{sanitized}.npy", mmap\_mode='r')
14     var\_emb = np.load(embed\_dir/f"var\_{sanitized}.npy", mmap\_mode='r')
15     ref\_idx = np.load(embed\_dir/"ref\_idx.npy")
16     
17     # æ‹¼æ¥ç‰¹å¾
18     X = np.concatenate(\[ref\_emb\[ref\_idx\], var\_emb\], axis=1)
19     
20     # è·å–æ ‡ç­¾ï¼ˆä»åŸå§‹æ•°æ®æ¡†ï¼‰
21     y = brca1\_df\['class'\].map({'FUNC/INT':0, 'LOF':1}).values
22     
23     return X, y

3.2 Embeddingsæ•°æ®æ­£ç¡®æ€§æ£€éªŒã€‚ä¸»è¦æ˜¯éªŒè¯æ•°æ®æ˜¯å¦å­˜åœ¨ï¼Œä»¥åŠæ˜¯å¦ç¬¦åˆEvo2\_1b\_baseæ¨¡å‹ä¸­é—´å±‚çš„ç»´åº¦ï¼ˆ1920ç»´ï¼‰

 1 # ç¤ºä¾‹ï¼Œæ£€æŸ¥ç¬¬24å±‚æ–‡ä»¶æ˜¯å¦å­˜åœ¨
 2 assert os.path.exists("extract\_embeddings/ref\_blocks\_24\_pre\_norm.npy")
 3 assert os.path.exists("extract\_embeddings/var\_blocks\_24\_pre\_norm.npy")
 4 
 5 # éªŒè¯åµŒå…¥ç»´åº¦
 6 ref\_emb = np.load("extract\_embeddings/ref\_blocks\_24\_pre\_norm.npy", mmap\_mode='r')
 7 var\_emb = np.load("extract\_embeddings/var\_blocks\_24\_pre\_norm.npy", mmap\_mode='r')
 8 print(f"å‚è€ƒåºåˆ—åµŒå…¥ç»´åº¦: {ref\_emb.shape}")  # åº”ä¸º (N\_ref, 1920)
 9 print(f"å˜å¼‚åºåˆ—åµŒå…¥ç»´åº¦: {var\_emb.shape}")  # åº”ä¸º (N\_ref, 1920)
10 
11 for layer\_name in layers\_to\_train:
12     print(layer\_name)
13     X, y = load\_layer\_data(layer\_name)
14     print(X.shape)

**3.3 ï¼ˆé‡è¦ï¼‰å®šä¹‰åˆ†ç¦»å™¨DNNçš„ç»“æ„ï¼ˆä»¿ç…§åŸæ–‡ä¸­çš„DNNç»“æ„ï¼‰**

 1 # ========== æ¨¡å‹æ¶æ„ ==========
 2 class BRCA1Classifier(nn.Module): 3     def \_\_init\_\_(self, input\_dim):
 4         super().\_\_init\_\_()
 5         self.net = nn.Sequential( 6             nn.Linear(input\_dim, 512),
 7             nn.ReLU(),
 8             nn.BatchNorm1d(512),
 9             nn.Dropout(0.3),
10             
11             nn.Linear(512, 128),
12 nn.ReLU(),
13             nn.BatchNorm1d(128),
14             nn.Dropout(0.3),
15             
16             nn.Linear(128, 32),
17 nn.ReLU(),
18             nn.BatchNorm1d(32),
19             
20             nn.Linear(32, 1),
21 nn.Sigmoid()
22 )
23         
24     def forward(self, x):
25         return self.net(x)

**3.4 ï¼ˆé‡è¦ï¼‰è®­ç»ƒæµç¨‹å®šä¹‰**

  1 # ========== è®­ç»ƒæµç¨‹ ==========
  2 def train\_for\_layer(layer\_name):  3     """å•å±‚è®­ç»ƒæµç¨‹"""
  4     print(f"\\n=== å¼€å§‹è®­ç»ƒå±‚ {layer\_name} ===")
  5     
  6     # åŠ è½½æ•°æ®
  7     X, y = load\_layer\_data(layer\_name)  8     
  9     # æ•°æ®åˆ’åˆ†
 10     X\_temp, X\_test, y\_temp, y\_test = train\_test\_split( 11         X, y, test\_size=0.2, random\_state=42, stratify=y
 12     )
 13     X\_train, X\_val, y\_train, y\_val = train\_test\_split( 14         X\_temp, y\_temp, test\_size=0.25, random\_state=42, stratify=y\_temp
 15     )
 16     
 17     # è½¬æ¢ä¸ºPyTorch Dataset
 18     train\_dataset = TensorDataset(torch.FloatTensor(X\_train), torch.FloatTensor(y\_train).unsqueeze(1))
 19     val\_dataset = TensorDataset(torch.FloatTensor(X\_val), torch.FloatTensor(y\_val).unsqueeze(1))
 20     test\_dataset = TensorDataset(torch.FloatTensor(X\_test), torch.FloatTensor(y\_test).unsqueeze(1))
 21     
 22     # ========== è®­ç»ƒé…ç½® ==========
 23     device = torch.device("cuda" if torch.cuda.is\_available() else "cpu")
 24     model = BRCA1Classifier(X.shape\[1\]).to(device)
 25 
 26     # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
 27     optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)
 28     criterion = nn.BCELoss() 29 
 30     # å­¦ä¹ ç‡è°ƒåº¦å™¨
 31     scheduler = ReduceLROnPlateau( 32         optimizer, 
 33         mode='max', 
 34         factor=0.5, 
 35         patience=20, 
 36         min\_lr=1e-6
 37     )
 38     
 39     # æ•°æ®åŠ è½½å™¨
 40     train\_loader = DataLoader(train\_dataset, batch\_size=128, shuffle=True)
 41     val\_loader = DataLoader(val\_dataset, batch\_size=128)
 42     test\_loader = DataLoader(test\_dataset, batch\_size=128)
 43 
 44     # ========== è®­ç»ƒå¾ªç¯ ==========
 45     best\_auc = 0 46     patience\_counter = 0 47     max\_patience = 100
 48 
 49     for epoch in range(500):
 50         # è®­ç»ƒé˜¶æ®µ
 51         model.train()
 52         train\_loss = 0 53         for inputs, labels in train\_loader: 54             inputs, labels = inputs.to(device), labels.to(device) 55             
 56             optimizer.zero\_grad()
 57             outputs = model(inputs) 58             loss = criterion(outputs, labels) 59         
 60             # æ¢¯åº¦è£å‰ª
 61             torch.nn.utils.clip\_grad\_norm\_(model.parameters(), max\_norm=1.0)
 62         
 63             loss.backward()
 64             optimizer.step()
 65             train\_loss += loss.item() \* inputs.size(0) 66     
 67         # éªŒè¯é˜¶æ®µ
 68         model.eval()
 69         val\_loss = 0 70         y\_true, y\_pred = \[\], \[\] 71         with torch.no\_grad():
 72             for inputs, labels in val\_loader: 73                 inputs, labels = inputs.to(device), labels.to(device) 74                 outputs = model(inputs) 75                 val\_loss += criterion(outputs, labels).item() \* inputs.size(0) 76                 y\_true.extend(labels.cpu().numpy())
 77                 y\_pred.extend(outputs.cpu().numpy())
 78     
 79         # è®¡ç®—æŒ‡æ ‡
 80         train\_loss /= len(train\_loader.dataset) 81         val\_loss /= len(val\_loader.dataset) 82         val\_auc = roc\_auc\_score(y\_true, y\_pred) 83     
 84         # å­¦ä¹ ç‡è°ƒæ•´
 85         scheduler.step(val\_auc)
 86     
 87         # æ—©åœæœºåˆ¶
 88         if val\_auc > best\_auc: 89             best\_auc = val\_auc 90             patience\_counter = 0 91             torch.save(model.state\_dict(), 'best\_model.pth')
 92         else:
 93             patience\_counter += 1
 94             if patience\_counter >= max\_patience: 95                 print(f"æ—©åœè§¦å‘äºç¬¬{epoch}è½®")
 96                 break
 97     
 98         # æ‰“å°è¿›åº¦
 99         print(f"Epoch {epoch+1}: "
100               f"Train Loss: {train\_loss:.4f} | "
101               f"Val Loss: {val\_loss:.4f} | "
102               f"Val AUROC: {val\_auc:.4f}")
103         
104     # ========== æœ€ç»ˆè¯„ä¼° ==========
105     model.load\_state\_dict(torch.load('best\_model.pth'))
106 model.eval()
107     y\_test\_true, y\_test\_pred = \[\], \[\]
108 with torch.no\_grad():
109         for inputs, labels in test\_loader:
110             inputs, labels = inputs.to(device), labels.to(device)
111             outputs = model(inputs)
112 y\_test\_true.extend(labels.cpu().numpy())
113 y\_test\_pred.extend(outputs.cpu().numpy())
114 
115     test\_auc = roc\_auc\_score(y\_test\_true, y\_test\_pred)
116     print(f"\\næœ€ç»ˆæµ‹è¯•é›†AUROC: {test\_auc:.4f}")
117     
118     # ä¿å­˜ç»“æœ
119     sanitized = layer\_name.replace('.', '\_')
120     torch.save(model.state\_dict(), results\_dir/f"best\_model\_{sanitized}.pth")
121     np.save(results\_dir/f"test\_pred\_{sanitized}.npy", y\_test\_pred)
122     
123     return test\_auc

3.5 æ‰§è¡Œè®­ç»ƒæµç¨‹

 1 # ========== ä¸»æ‰§è¡Œæµç¨‹ ==========
 2 if \_\_name\_\_ == "\_\_main\_\_":
 3     results = {} 4     for layer in tqdm(layers\_to\_train, desc="Training Layers"):
 5         try:
 6             auc = train\_for\_layer(layer) 7             results\[layer\] = auc 8         except Exception as e: 9             print(f"è®­ç»ƒå±‚ {layer} æ—¶å‡ºé”™: {str(e)}")
10             results\[layer\] = None
11     
12     # ä¿å­˜æœ€ç»ˆç»“æœ
13     with open(results\_dir/"summary.txt", "w") as f:
14         for layer, auc in results.items():
15             f.write(f"{layer}: {auc:.4f}\\n")

è¿è¡ŒæˆåŠŸåä¼šæœ‰ç±»ä¼¼å¦‚ä¸‹è¾“å‡ºï¼š

![](https://img2024.cnblogs.com/blog/1463277/202505/1463277-20250519171121782-2028203774.png)

Â æœ€åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ£€æŸ¥summary.txtè·å–è®­ç»ƒæœ€ä¼˜çš„è®­ç»ƒç»“æœæ˜¯åˆ©ç”¨å“ªä¸€å±‚Embeddingã€‚æˆ‘è®­ç»ƒçš„ç»“æœæ˜¾ç¤ºç¬¬12å±‚embeddingè®­ç»ƒå¾—åˆ°çš„DNNé¢„æµ‹å™¨æ•ˆæœæœ€å¥½ï¼Œå°ä¼™ä¼´ä¼´ä»¬ä¹Ÿå¯ä»¥è‡ªå·±å°è¯•ä¸åŒçš„æ¨¡å‹ä¸‹ï¼Œä¸åŒçš„DNNç»“æ„ï¼Œå“ªä¸€å±‚èƒ½è·å¾—æœ€å¥½çš„é¢„æµ‹æ•ˆæœã€‚

![](https://img2024.cnblogs.com/blog/1463277/202505/1463277-20250519172442978-1111004721.png)