---
layout: post
title: '从春晚舞台到全球赛场：中国人形机器人，到底走到了哪一步？'
date: "2026-02-22T00:58:35Z"
---
从春晚舞台到全球赛场：中国人形机器人，到底走到了哪一步？
============================

2026年春晚的机器人表演，并非单纯的舞台炫技，而是中国人形机器人产业的一次国家级路演。四家企业分别在\*\*高动态运动控制、多机集群协同、仿生情感交互、具身智能落地\*\*四大核心方向，展现了中国在人形机器人领域从跟跑到并跑、部分领域领跑的产业格局。相较于海外企业聚焦实验室参数、军事场景、长期测试的技术路线，中国企业更注重场景落地、成本控制、规模化量产，形成了差异化的竞争优势，推动人形机器人从实验室走向工业、商业、家庭等真实场景，2026年也被业内视为人形机器人规模化应用的元年。

前言
==

2026年央视春节联欢晚会创下春晚历史上机器人参与规模的新纪录，共有**宇树科技、魔法原子、松延动力、银河通用**四家核心国产人形机器人企业，携超200台机器人深度融入四大核心节目，覆盖武术、小品、歌舞、微电影全品类，全方位展现了中国人形机器人产业的技术突破与商业化落地能力。以下为各企业的详细拆解：

一、宇树科技（Unitree Robotics）
========================

1\. 春晚节目表现
----------

作为春晚“三朝元老”，宇树科技是武术节目《武BOT》的核心技术方，携20余台H2、G1系列人形机器人，与河南塔沟武术学校学员同台，完成**全球首次全自主人形机器人集群武术表演**。

节目中实现了3米弹射空翻、单脚连续空翻、蹬墙后空翻、Airflare大回旋七周半、4m/s集群快速跑位等高难度动作，同时完成挥剑、耍双节棍、醉拳等武术招式，集群动作同步误差小于0.1秒，全程零失误完成直播演出；同时在义乌分会场以“齐天大圣”造型机器人刷屏全网。

2\. 公司核心业务与实力
-------------

*   企业基础：2016年成立，总部位于杭州，国家级专精特新“小巨人”企业，**全球足式机器人绝对龙头**，四足机器人全球市占率超69.75%；2025年人形机器人出货量超5500台，位列全球第一。
*   技术壁垒：实现从电机、减速器、控制器、运动控制算法到具身大模型的全栈自研，核心部件自研率超95%，国产化率超85%，累计拥有180余项授权专利。
*   商业化落地：产品矩阵覆盖四足机器人Go/B2系列、人形机器人H/G/R三大系列，售价从3.99万元到65万元不等，已落地工业巡检、电力作业、科研教育、应急救援等场景；2024年营收突破10亿元，C轮融资后估值超120亿元，已完成IPO辅导，拟登陆科创板。

3\. 节目核心技术实现原理
--------------

### （0）概述

*   **硬件底层**：主力机型H2全身自由度从19个提升至31个（单臂7个、单腿6个、3自由度腰部、2自由度颈部），动作精度达毫米级；自研内转子永磁同步电机扭矩密度达180Nm/kg，伺服响应速度0.001秒级，单臂峰值负载达21kg，支撑高爆发武术动作；搭载自研128线激光雷达与全新灵巧手，实现武术道具的稳定抓持与快速更换。
*   **算法与集群控制**：采用模型预测控制（MPC）+深度强化学习融合框架，机器人在仿真环境中完成上亿次动作迭代，自主习得复杂武术技巧与平衡控制；自研高并发集群控制系统与AI融合定位算法，通过3D激光雷达每秒上百次扫描舞台环境，实现无外部定位的全自主协同，攻克长序列表演的运动误差累计难题；依托5G专网+边缘计算，将集群指令传输延迟压缩至毫秒级，保障动作同步性。
*   **直播容错机制**：搭载全自主容错系统，机器人实时监测自身状态，跑偏后可快速归位；主控节点故障时0.3秒内切换备用主机，并有备用机器人待命，保障直播零失误。

**《武BOT》节目中，机器人的所有动作可拆解为三大核心技术模块，每个模块都对应着全球性的技术难题，我们逐一拆解：**

### （1）单机极限武术动作：从“能站稳”到“会打拳”的核心突破

**节目里做了什么**：机器人完成了弹射空翻、Airflare大回旋、双节棍挥舞、醉拳倒地起身等连专业武术演员都需要长期训练的动作，甚至在3米弹射落地后，能瞬间调整平衡，无缝衔接下一个武术招式。

**核心难点**：这类高爆发动作的核心挑战，是机器人在重心剧烈变化、全身关节高速联动时，始终保持平衡，同时精准控制每一个动作的力度、角度和节奏——哪怕一个关节的扭矩输出偏差0.1%，就会导致机器人摔倒、表演失败。

**底层实现原理**：

*   **硬件底座：“肌肉骨骼”的极致性能**  
    主力机型H2全身自由度从19个提升至31个（单臂7个、单腿6个、3自由度腰部、2自由度颈部），相当于给机器人装上了能精准控制的“全身关节”；自研内转子永磁同步电机，扭矩密度达180Nm/kg，伺服响应速度达到0.001秒级，比人类神经反射速度快100倍，单臂峰值负载达21kg，能支撑高爆发的空翻、挥棍动作。  
    通俗类比：这就像给武术运动员装上了反应速度快100倍、力量控制精准到克的肌肉，既能爆发出空翻的爆发力，又能精准控制双节棍的轨迹，不伤到自己和搭档。
    
*   **算法核心：“肌肉记忆”的AI训练**  
    采用**模型预测控制（MPC）+深度强化学习**的融合框架，这是机器人能完成复杂武术动作的核心。  
    通俗解释：团队先在数字仿真世界里，给机器人搭建了1:1的虚拟舞台，让AI控制的机器人在里面完成**上亿次的动作训练**——就像武术运动员在武馆里反复练习，摔倒了就调整参数重新来，最终让机器人自主习得复杂武术技巧和平衡控制能力。  
    其中，MPC算法相当于“实时教练”，每秒会对上百次机器人的重心、速度、关节状态进行预判，提前调整每个关节的扭矩输出，确保机器人在空翻、落地的全过程中，重心始终落在安全区间；而深度强化学习训练出的“肌肉记忆”，能让机器人在舞台地面有轻微打滑、重心出现偏差时，瞬间自主调整动作，就像武术运动员临场应变一样。
    
*   **道具操作：“手眼协同”的精准控制**  
    机器人能稳定挥舞双节棍、长剑，核心在于搭载了自研128线激光雷达+视觉相机，配合全新灵巧手，每秒对道具的位置、自身的姿态进行上百次扫描校准，实现道具的稳定抓持与轨迹控制，确保双节棍的挥舞轨迹精准贴合武术动作设计，不会出现甩飞、节奏错位的问题。
    

### （2）20余台机器人集群协同：从“单机跳”到“群体演”的全球突破

**节目里做了什么**：20余台机器人在没有外部定位设备的情况下，完成了4m/s高速跑位、复杂队形变换、与真人演员的实时对练，全程没有出现碰撞、跑偏，动作同步误差小于0.1秒，实现了全球首次全自主人形机器人集群武术表演。

**核心难点**：传统机器人集群表演，大多依赖舞台地面的二维码、外部动捕设备进行定位，相当于“开了外挂”；而宇树的机器人全程只靠自身机载传感器，在高速运动、舞台灯光复杂、真人演员动态移动的环境下，实现精准定位和协同，还要解决长序列表演中，每台机器人的动作误差累计问题——一旦一台机器人慢了0.05秒，整个集群的表演就会乱套。

**底层实现原理**：

*   **全自主定位：不依赖外挂的“环境感知”**  
    自研AI融合定位算法，通过机器人自带的3D激光雷达，每秒上百次扫描舞台环境，实时构建三维地图，同时匹配预存的舞台模型，计算出自身在舞台上的精准位置，定位精度达到毫米级，完全不需要外部动捕、二维码等辅助设备。  
    通俗类比：这就像你蒙着眼睛，但是你脑子里时刻知道自己在房间里的位置以及周围的情况，就能在熟悉的房间里精准走到指定位置，而且跑步前进也不会撞墙，精度还能达到毫米级。
    
*   **高并发集群控制：零误差的“团队指挥”**  
    自研分布式集群控制系统，采用“统一时间基准+分布式轨迹规划”架构：首先通过5G专网+边缘计算，给所有机器人同步一个精准到微秒级的统一时间轴，确保每台机器人的动作“在同一个节拍上”，指令传输延迟压缩至毫秒级；  
    同时，主控系统只给机器人下发“目标位置、动作节拍”的核心指令，每台机器人自主规划自己的跑位路径、动作执行细节，还能实时感知周边机器人的位置，动态调整自己的路线，避免碰撞；哪怕某台机器人出现轻微跑偏，也能在0.2秒内自主调整归位，不影响整个集群的表演。
    
*   **误差消除：长序列表演的“防跑偏机制”**  
    团队针对长序列武术表演，设计了“分段闭环校准”机制：把整个3分钟的节目，拆解成数十个关键动作节点，每完成一个节点的动作，所有机器人都会自动校准自身位置、动作节奏，把累计的误差清零，确保从节目开头到结尾，同步精度始终保持在0.1秒以内。
    

### （3）直播零失误：国家级舞台的“容错保障”

**节目里做了什么**：在春晚全球直播的高压场景下，20余台机器人全程零失误，没有出现一台故障、摔倒，完美完成表演。

**底层实现原理**：  
搭载了全自主容错系统，每台机器人都会实时监测自身的电机温度、关节状态、电池电量、定位精度，一旦出现轻微异常，会自动调整动作参数，优先保障平衡和核心动作执行；如果出现主控节点故障，会在0.3秒内自动切换备用主机，同时舞台侧方还有待命的备用机器人，可在节目间隙无缝替换故障设备，彻底杜绝直播事故。

4\. 国内外技术对比
-----------

维度

核心优势

现存差距

运动性能

高动态运动控制能力全球领先，完成了波士顿动力Atlas尚未实现的连续花式翻桌跑酷、集群协同武术表演等动作，单机极限动作参数跻身全球第一梯队

在工业场景的长期稳定作业能力、复杂非结构化环境的泛化能力上，与波士顿动力、Agility Robotics仍有一定差距

量产能力

2025年出货量远超特斯拉Optimus（小批量测试阶段）、波士顿动力Atlas（非量产），是全球唯一实现高性能人形机器人万台级量产规划的企业

\-

成本与供应链

整机成本仅为Atlas的千分之一、Optimus的约1/3，核心部件成本仅为进口产品的1/10，全栈自研供应链摆脱海外技术依赖

\-

智能能力

\-

具身大模型的通用任务处理能力，相较于特斯拉Optimus的端到端大模型仍有提升空间

5\. 未来发展方向
----------

*   2026年目标人形机器人出货量1万-2万台，持续扩大全球市场份额；
*   深化工业巡检、电力作业、应急救援等B端场景的规模化落地，实现单台机器人替代3人工作量；
*   持续迭代具身智能大模型，提升机器人的通用任务处理能力与自主决策能力；
*   推进消费级人形机器人的普及，以低价产品打开C端市场。

二、魔法原子（MagicLab）
================

1\. 春晚节目表现
----------

作为春晚智能机器人战略合作伙伴，魔法原子是本届春晚首家亮相的机器人企业。主会场歌曲《智造未来》中，携6台MagicBot Z1高动态小人形机器人、2台MagicBot Gen1全尺寸人形机器人，与易烊千玺、陈小春等艺人同台，完成360°托马斯回旋、侧空翻、同步舞蹈等高难度动作；宜宾分会场，上百台MagicDog四足机器人以“熊猫”造型完成**全球首次百台级四足机器人公开舞台同步演绎**；同时在贺岁短片中完成捞面、送餐等生活化操作。

2\. 公司核心业务与实力
-------------

*   企业基础：2024年1月成立，总部无锡，由追觅科技孵化，核心研发人员占比超70%；成立两年完成多轮融资，累计融资超5亿元，估值达35亿元。
*   技术壁垒：核心硬件自研率超90%，覆盖关节模组、灵巧手、伺服电机、谐波减速器等23类核心部件，自研关节峰值扭矩最高达525N·m，跻身行业第一梯队；软件层面打造“**原子万象”具身智能大模型**，采用“大脑+小脑”双模架构。
*   商业化落地：产品矩阵包括人形机器人MagicBot Gen1/Z1、四足机器人MagicDog系列，覆盖工业巡检、商业服务、家庭陪伴、文旅演艺、教育娱乐等场景，已在27个国家建立本地化团队。

3\. 节目核心技术实现原理
--------------

魔法原子在春晚的表演，覆盖了“高动态街舞、百台级集群同步、生活化精细操作”三大完全不同的技术方向，我们逐一拆解每个动作的实现逻辑：

### （0）概述

*   **硬件底层**：MagicBot Z1奔跑速度突破4m/s，搭载自研高功率密度关节模组，支撑高动态舞蹈与空翻动作；Gen1全尺寸人形机器人双臂最大负载达50kg，搭载自研6自由度灵巧手，实现捞面、端餐等精细操作。
*   **集群控制**：采用分布式集群控制系统，通过时间同步算法与多智能体轨迹规划，实现上百台四足机器人的毫秒级动作同步，同步误差小于0.01秒；通过纯视觉SLAM定位，实现无外部辅助的自主编队与动态避障。
*   **智能算法**：“原子万象”具身大模型采用快慢双模协同架构，“大脑”负责任务规划与场景理解，“小脑”负责实时运动控制与平衡调节，通过数百万条工业场景真实数据训练，实现任务的自主泛化。

### （1）主会场街舞表演：托马斯全旋与同步舞蹈的技术突破

**节目里做了什么**：6台MagicBot Z1小人形机器人，与真人艺人同台完成了360°托马斯回旋、侧空翻、连续街舞动作，同时与音乐节拍、艺人动作完美同步，转身、摆臂、重心迁移全程连贯流畅，多机动作同步误差小于0.01秒。

**核心难点**：托马斯全旋这类街舞动作，需要机器人在单臂支撑全身重量的同时，完成腰部、腿部的高速圆周摆动，重心全程在快速变化，对关节的负载能力、扭矩控制精度、平衡调节速度提出了极致要求；同时多机协同舞蹈，需要每台机器人的每一个动作，都精准贴合音乐节拍，差0.01秒就会出现“抢拍、慢拍”的问题。

**底层实现原理**：

*   **硬件支撑：高功率密度的“关节心脏”**  
    MagicBot Z1搭载了自研的高功率密度一体化关节模组，在小尺寸机身内实现了超高扭矩输出，奔跑速度突破4m/s，单臂能稳定支撑整机8kg的重量，同时完成高速摆动，这是实现托马斯全旋的物理基础。  
    团队针对街舞动作的高频次、高负载特性，优化了关节的散热结构与电流管理策略，确保机器人在连续3分钟的高动态舞蹈中，不会因为关节过热触发保护机制，保证动作全程稳定输出。
    
*   **平衡控制：动态重心的实时调节**  
    采用**零力矩点（ZMP）平衡控制算法**，配合全身力控技术，在托马斯全旋的全过程中，每秒数百次计算机器人的重心位置、支撑区域，实时调整手臂、腰部、腿部的关节角度和扭矩输出，确保重心始终落在支撑臂的安全范围内，不会出现侧翻、摔倒的问题。  
    通俗类比：这就像你单臂撑在地上做圆周摆腿，大脑需要全程感知自己的重心，随时调整手臂的发力、腰腹的扭转、腿部的摆动，确保自己不会摔倒——而机器人的“大脑”，每秒能做数百次这样的调整，精度比人类高上千倍。
    
*   **节拍同步：零误差的“音乐卡点”**  
    团队给所有机器人搭建了统一的高精度时间同步系统，以音乐的音频波形为基准，把每一个舞蹈动作都精准对应到音乐的节拍点上，每台机器人的动作启动时间、执行时长，都精准锁定到毫秒级，确保6台机器人的动作完全同步，与艺人的表演、音乐的节奏完美契合。
    

### （2）宜宾分会场：百台熊猫机器狗的集群表演

**节目里做了什么**：上百台MagicDog四足机器人，以熊猫造型亮相，在宜宾分会场的城市广场上，完成了奔跑、列阵、队形变换、同步舞蹈，甚至实现了自然的歪头、点头等拟人化动作，全程动作整齐划一，没有出现一台掉队、碰撞。

**核心难点**：百台级四足机器人的户外集群表演，核心挑战有三个：一是户外广场地面不平整、灯光环境复杂，机器人的自主定位难度远高于室内舞台；二是百台机器人的动作同步，需要解决大规模集群的指令传输延迟、误差累计问题；三是熊猫外皮包裹后，机身散热空间被压缩，需要解决高负载连续运行的稳定性问题。

**底层实现原理**：

*   **分布式集群控制系统：百台机器人的“统一指挥”**  
    采用“主站+分布式从站”的集群控制架构，主站系统只负责下发整体的表演序列、队形变换指令，每台机器狗自主完成动作执行、路径规划、定位校准；通过时间敏感网络（TSN）技术，给所有机器人同步统一的时间基准，确保百台机器人的动作启动时间误差小于0.01秒，实现“整齐划一”的表演效果。
    
*   **纯视觉SLAM定位：户外场景的精准导航**  
    每台机器狗都搭载了双目视觉相机+IMU惯性测量单元，通过纯视觉SLAM技术，实时构建户外场景的三维地图，匹配自身位置，同时感知周边其他机器人的位置，动态调整行进路线，避免碰撞；哪怕户外地面不平整、出现轻微打滑，也能自主调整步态，快速回到预定位置，完成队形变换。
    
*   **散热与功率优化：外皮包裹下的稳定运行**  
    针对熊猫外皮压缩散热空间的问题，团队优化了整机的电流管理与功率控制策略，在不影响动作表现力的前提下，降低了连续运动状态下的关节发热量，同时优化了机身的散热结构，确保机器人在长达数分钟的连续表演中，不会因为过热触发保护，稳定完成所有动作。
    

### （3）贺岁短片：捞面、倒酒的精细操作

**节目里做了什么**：MagicBot Gen1全尺寸人形机器人，在短片中完成了捞面、端餐、倒酒等生活化操作，面条捞取、汤汁倾倒的力度控制精准，没有出现洒漏、面条断裂的问题。

**核心难点**：这类精细操作的核心挑战，是机器人对柔性物体（面条）、易碎容器（碗、酒杯）的力控精度——力度太大，会夹断面条、捏碎杯子；力度太小，会夹不住面条、端不稳碗；同时还要精准控制倾倒的角度和速度，确保汤汁、酒水不会洒漏。

**底层实现原理**：

*   **6自由度灵巧手：微米级的力控精度**  
    Gen1搭载了自研6自由度灵巧手，指尖搭载了高精度力传感器，力控精度达到0.5N，能精准感知抓取物体的反馈力度，实现“柔性抓取”——捞面条时，能精准控制指尖的夹持力，既牢牢夹住面条，又不会把面条夹断；端碗时，能根据碗的重量、重心变化，实时调整手臂的姿态，确保碗始终保持水平，汤汁不会洒漏。
    
*   **“大脑+小脑”双架构：从任务规划到精准执行**  
    自研的“原子万象”具身智能大模型，采用“大脑+小脑”的快慢双模协同架构：“大脑”负责任务规划与场景理解，比如接收到“捞面”的指令后，会自动拆解成“移动到锅前-张开手-伸入锅中-夹住面条-抬起-放入碗中”的分步动作；“小脑”负责实时运动控制与力控调节，在每一步动作执行中，实时调整手臂的位置、指尖的力度，应对面条的柔性变化、碗的重量变化，确保任务精准完成。
    

4\. 国内外技术对比
-----------

维度

核心优势

现存差距

集群协同

多机协同群控能力全球领先，完成全球首次百台级四足机器人公开舞台同步表演，分布式控制技术跻身行业第一梯队

\-

产品性价比

依托追觅科技的供应链优势，实现高自研率下的极致成本控制，产品性价比远超海外同级别产品

\-

落地速度

成立仅两年即实现多场景商业化落地，落地速度行业领先

全尺寸人形机器人的长期稳定运行能力、复杂场景的泛化能力，相较于宇树科技、波士顿动力仍有差距

智能能力

\-

具身大模型的训练数据量与通用能力，相较于银河通用、特斯拉仍有提升空间

5\. 未来发展方向
----------

*   2026年工业场景计划千台级规模部署，在追觅工厂等场景落地物料搬运、点胶检测等工序；
*   加速无人咖啡、无人药房等零售解决方案的推广，目标1-2年覆盖全球10000家门店；
*   推进四足机器人导盲犬项目“光引001”的落地，切入助残普惠场景；
*   持续拓展海外市场，提升全球化营收占比。

三、松延动力（Noetix Robotics）
=======================

1\. 春晚节目表现
----------

作为春晚**仿生人形机器人独家合作伙伴**，松延动力携5款机器人参演小品《奶奶的最爱》，成为首个登上春晚语言类节目的机器人企业。其中1:1复刻蔡明的仿生机器人，以近乎真人的面部神态、口型同步、微表情动作，与真人演员完成对戏；同时4台双足人形机器人完成端茶、互动等生活化动作。

2\. 公司核心业务与实力
-------------

*   企业基础：2023年9月成立，总部北京，创始团队来自清华、浙大；2025年一年内完成5轮融资，估值约20亿元。
*   技术壁垒：核心技术覆盖仿生人脸驱动、多模态交互大模型、双足运动控制，是国内少数实现仿生人形机器人批量生产的企业；自研D2P数字人映射技术，实现虚拟数字人到实体机器人的精准映射。
*   商业化落地：构建了N系列、E系列、轮式机器人W1、“小布米”系列的产品矩阵；旗下万元级消费级双足机器人“小布米”（定价9998元），2025年10月发售即斩获数千台订单，是**全球首款万元级消费级双足人形机器人**，产品已落地商业导览、教育科研、家庭陪伴等场景。

3\. 节目核心技术实现原理
--------------

松延动力在小品中的表演，核心分为两大技术方向，也是仿生人形机器人最核心的两个难题：**“长得像、演得真”的仿生交互**，以及**“走得稳、做得准”的生活化动作**，我们逐一拆解：

### （0）概述

*   **仿生人脸核心技术**：通过铂金硅胶添加高分子材料，提升面部拉伸自然度与耐久性；采用高紧凑型驱动设计，在仿生人脸内部集成32-40个微型电机，实现表情、口型、眼神的精准控制；自研D2P数字人映射技术，将虚拟数字人的表情、口型数据，实时映射到真实机器人的电机转角上，实现语音与口型的1:1同步。
*   **多模态交互**：自研多模态交互大模型，实现语音、表情、眼神、肢体动作的协同表达，比如对话时的呼吸起伏、颈部与手臂的配合动作，大幅提升拟人交互体验。
*   **运动控制**：自研双足运动控制算法，实现机器人在家庭场景的稳定行走、端茶、搀扶等高精度动作，适配非结构化的家庭环境。

### （1）蔡明仿生机器人：真人级复刻与实时对戏的核心技术

**节目里做了什么**：1:1复刻蔡明老师的仿生机器人，在小品中与真人演员完成实时对戏，说话时口型与台词完全同步，同时配合台词做出眨眼、微笑、撇嘴、头部微动作等真人级微表情，甚至能根据对手演员的台词，实时做出对应的神态反馈，仿真度极高，在后台被多位演员误认成真人。

**核心难点**：语言类节目对仿生机器人的要求，远高于歌舞表演——不仅要“长得像”，更要“演得真”：口型要与台词1:1同步，差一帧就会出现“对口型穿帮”；微表情要贴合人物情绪，僵硬一点就会显得很“假”；同时还要在狭小的人脸空间内，放下足够多的驱动电机，还要保证上镜效果，团队甚至需要把仿生人头整体缩小30%，对结构设计提出了极致挑战。

**底层实现原理**：

*   **仿生人脸硬件：真人级的“皮肤与肌肉”**  
    首先在外观上，团队通过3D扫描，1:1复刻了蔡明老师的面部轮廓、五官细节，采用添加了高分子材料的铂金硅胶制作仿生皮肤，不仅在视觉上无限接近真人皮肤的质感，还提升了皮肤的拉伸自然度与耐久性，在做出表情时，皮肤的拉伸、褶皱都与真人完全一致，不会出现“塑料感”。  
    最核心的突破，是高紧凑型驱动设计：团队在缩小30%的仿生人脸内部，集成了**32个微型驱动电机**，分别对应人脸的眉、眼、口、鼻等核心表情区域，相当于给机器人装上了“人工面部肌肉”，每个电机都能精准控制对应区域的皮肤位移，实现微笑、撇嘴、眨眼、抬眉等数十种真人微表情，最小动作幅度可达0.1毫米，完全还原真人的面部神态。
    
*   **D2P数字人映射技术：口型与表情的1:1同步**  
    这是实现真人级对戏的核心技术，自研的D2P（数字人到物理人）映射技术，能把虚拟数字人的表情、口型数据，实时、精准地映射到实体机器人的电机上。  
    通俗解释：团队先提前采集了蔡明老师说台词时的面部动作、口型变化数据，制作了1:1的虚拟数字人；当机器人需要说台词时，系统会先把语音台词转化为虚拟数字人的口型、表情动作，再通过D2P技术，把这些动作转化为32个微型电机的转动角度、速度指令，实时驱动电机动作，最终实现语音与口型的1:1同步，表情与台词情绪的完美契合，哪怕是台词里的气口、重音，都能对应到口型的细微变化上。
    
*   **多模态交互大模型：实时对戏的“灵性反馈”**  
    自研多模态交互大模型，能实时识别对手演员的台词、语气、甚至面部表情，快速理解对话语境，输出对应的台词、表情和肢体动作；同时还能实现语音、表情、眼神、肢体动作的协同表达，比如说话时配合自然的头部转动、呼吸起伏，甚至是说话间隙的眼神互动，完全还原真人对话的状态，彻底摆脱了传统机器人“念台词”的僵硬感。
    

### （2）“小布米”双足机器人：家庭场景的生活化动作

**节目里做了什么**：4台“小布米”消费级双足机器人，在小品中完成了稳定行走、端茶、敬礼、与演员互动挥手等动作，在客厅的非结构化环境中，全程行走稳定，端茶时没有出现洒漏，动作流畅自然。

**核心难点**：消费级双足机器人，受限于成本和尺寸，硬件性能无法和工业级大机型相比，要在家庭的瓷砖、地毯等不同地面上，实现稳定行走，还要完成端茶等精细操作，对算法的轻量化、平衡控制能力提出了极高要求。

**底层实现原理**：

*   **轻量化双足运动控制算法：小机身的稳定行走**  
    “小布米”身高94厘米，体重仅12公斤，全身21个自由度，团队针对小尺寸双足机器人，自研了轻量化的模型预测控制算法，能在算力有限的主控芯片上，实现每秒上百次的步态规划与平衡调节，在瓷砖、地毯等不同地面上，都能自主调整步幅、步速和关节角度，实现稳定行走，哪怕被轻微触碰，也能快速调整重心，不会摔倒。
    
*   **力控抓取：端茶不洒的精细操作**  
    机器人的手部搭载了微型力传感器，端茶时，能精准控制夹持杯子的力度，既牢牢握住杯子，又不会捏碎纸杯；同时在行走过程中，手臂会实时调整姿态，抵消行走带来的晃动，确保杯子始终保持水平，杯里的水不会洒漏，完美适配家庭场景的服务需求。
    

4\. 国内外技术对比
-----------

维度

核心优势

现存差距

仿生交互

仿生人脸的高集成度驱动技术、多模态情感交互能力处于国内第一梯队，打破了海外企业在高端仿生机器人领域的垄断

高动态运动控制能力，相较于宇树科技、波士顿动力有明显差距

消费级普及

率先实现消费级双足机器人的万元级定价，打开了C端市场的普及路径，差异化避开工业赛道红海竞争，商业化落地速度领先

工业场景的落地能力与技术积累，弱于银河通用、魔法原子

量产能力

实现了仿生人形机器人的批量生产，量产能力远超海外同类型高端仿生产品

\-

5\. 未来发展方向
----------

*   持续深化仿生人形机器人的技术迭代，推动产品在商业导览、康养陪护场景的规模化落地；
*   推进消费级机器人“小布米”的量产与普及，拓展教育娱乐、家庭陪伴C端市场；
*   深化与高校、科研院所的合作，推动人形机器人教学平台的落地；
*   持续优化成本，推动人形机器人进入普通家庭。

四、银河通用（GALBOT）
==============

1\. 春晚节目表现
----------

作为春晚**指定具身大模型机器人**，银河通用在贺岁微电影《我最难忘的今宵》中，携Galbot G1轮式双臂机器人亮相，与沈腾、马丽搭档，完成盘核桃、捡玻璃碎片、叠衣服、货架取物、串烤肠等生活化任务，实现了**春晚舞台首次无预设脚本的机器人自主决策作业**，无需提前编程，即可根据场景实时完成任务规划与执行。

2\. 公司核心业务与实力
-------------

*   企业基础：2023年5月成立，总部北京，由北大王鹤博士、前ABB高管姚腾洲联合创立，核心成员来自华为天才少年计划、百度、微软等企业；2025年12月完成超3亿美元融资，估值达30亿美元。
*   技术壁垒：国内极少数实现“百亿数据集—具身大模型—机器人本体—场景规模化落地”全链条闭环的企业；自研“银河星脑AstraBrain”具身大模型体系，首创虚实结合的训练范式，构建了百亿级机器人干活数据集，是全球具身机器人大模型数据量最大的公司之一。
*   商业化落地：产品主打Galbot系列轮式双臂通用机器人，采用“轮式底盘+折叠腿”复合结构，已实现千台级规模化落地，覆盖工业制造、智慧零售、医疗康养、城市服务等六大领域，合作客户包括宁德时代、德国博世、丰田汽车、北汽、宣武医院等龙头企业，2025年工业订单突破千台，创下具身智能领域商业化订单纪录。

3\. 节目核心技术实现原理（通俗专业版）
---------------------

银河通用的表演，和其他三家企业最大的区别，是**完全没有预设的固定脚本**——其他机器人的表演，哪怕动作再复杂，也是提前编排好的固定程序；而银河通用的机器人，是根据现场场景和任务指令，自主思考、自主规划、自主执行，这也是具身智能最核心的能力。我们以节目中几个典型任务为例，拆解其底层实现原理：

### 概述

*   **具身大模型核心**：首创“合成仿真数据为主、真机采集数据为辅”的虚实结合训练管线，解决了全球机器人干活数据匮乏的行业难题；自研GraspVLA、GroceryVLA、NavFoM等端到端具身大模型，对透明、高光、不规则物体的抓取成功率稳定在95%以上，实现了任务的自主规划、动态避障、长程导航。
*   **硬件架构**：采用“轮式底盘+折叠腿+双臂”的复合结构，兼顾高速移动与越障能力，身高173cm、臂展190cm、升降行程65cm，双臂最大负载达50kg，搭载自研6自由度灵巧手，实现毫米级精细操作。
*   **一体化控制系统**：采用“大脑-小脑-神经控制”一体化系统，“大脑”（具身大模型）负责场景理解与任务规划，“小脑”负责运动控制与平衡调节，“神经控制”负责关节的实时伺服响应，实现端到端的任务执行，无需预设脚本。

### 核心任务逻辑：无脚本自主作业的全链路流程

不管是盘核桃、捡玻璃碎片，还是叠衣服、串烤肠，机器人执行所有任务，都遵循着**“感知-决策-执行-反馈优化”**的端到端全链路，这也是它能实现无脚本作业的核心，我们逐层拆解：

#### 第一步：感知——“看懂”眼前的场景和物体

**节目里的挑战**：机器人需要识别出核桃、玻璃碎片、衣服、烤肠、签子等完全不同的物体，尤其是透明的玻璃碎片，在浅色桌面上几乎“隐形”，传统视觉系统很容易识别失败；同时还要适应舞台复杂的灯光变化，准确判断每个物体的位置、形状、大小、材质。

**底层实现原理**：

*   机器人搭载了多模态感知系统，包括双目深度相机、激光雷达、触觉传感器，能同时获取场景的视觉、深度、触觉信息；
*   自研的视觉大模型，在训练阶段见过了数十亿张真实场景图片，能精准识别上万种日常物体，哪怕是形状不规则的碎玻璃、褶皱的衣服，也能快速识别并分割出物体轮廓；
*   针对透明物体识别的行业难题，团队通过仿真环境生成了海量的透明物体数据——不同厚度、不同碎裂形状、不同光照条件下的玻璃碎片，让机器人在虚拟世界中“见过”各种可能的透明形态，理解了透明物体的反光、折射规律，最终实现对玻璃碎片的识别成功率稳定在99%以上，哪怕是只有几毫米的玻璃渣，也能精准定位。

#### 第二步：决策——“想清楚”任务该怎么做

**节目里的挑战**：比如“捡玻璃碎片”这个任务，没有提前编程告诉机器人“先捡大的、再捡小的，用夹子夹，放到垃圾桶里”，机器人需要自主理解任务目标，把大任务拆解成可执行的小步骤，还要应对突发情况——比如玻璃碎片滚到了桌子底下，要自主规划路线，调整手臂姿态去捡。

**底层实现原理**：

*   核心是自研的“银河星脑AstraBrain”具身大模型，它就像机器人的“大脑”，通过百亿级的机器人操作数据训练，已经学会了上千种日常任务的执行逻辑，能根据任务指令，自主拆解动作步骤。  
    通俗类比：就像你让一个人“把地上的玻璃碎片捡干净”，他不用你一步步教，就会自己去找垃圾桶、拿工具，先捡大块再捡小块，还会注意不被划伤——银河通用的具身大模型，就是让机器人具备了这样的自主思考能力。
*   针对春晚的场景，团队还对大模型进行了轻量化微调，让它能快速适配舞台场景，针对不同任务快速输出最优的动作规划，同时具备容错能力——如果第一次捡玻璃没夹住，会自主调整夹子的开合角度、夹持位置，重新尝试，直到任务完成。

#### 第三步：执行——“精准完成”精细操作

**节目里的挑战**：不同任务对操作的要求完全不同：盘核桃需要双手配合，力度既要足够转动核桃，又不能捏碎；串烤肠需要精准把烤肠穿到签子上，偏差1毫米就会穿歪；叠衣服需要抓住衣服的边角，精准完成折叠动作，这些都对机器人的动作精度、力控能力提出了极高要求。

**底层实现原理**：

*   **硬件基础：灵活又精准的“手臂和手”**  
    Galbot G1采用“轮式底盘+折叠腿+双臂”的复合结构，双臂最大负载达50kg，重复定位精度可达±0.02毫米，比头发丝还细；搭载自研6自由度灵巧手，指尖配备高精度力传感器，力控精度可达0.3N，既能实现串烤肠的毫米级精准定位，又能实现盘核桃、叠衣服的柔性力控。
    
*   **“大脑-小脑-神经”一体化控制系统**  
    采用三级控制架构，实现端到端的精准执行：“大脑”（具身大模型）输出任务规划和动作指令；“小脑”（运动控制算法）负责把指令拆解成每个关节的转动角度、扭矩参数，实时调节手臂的运动轨迹和力度；“神经控制”（伺服系统）负责0.001秒级的实时响应，确保每个关节都精准执行指令，最终实现任务的完美执行。
    
*   **虚实结合的训练范式：让机器人提前“练会”所有动作**  
    团队首创“合成仿真数据为主、真机采集数据为辅”的训练管线，解决了全球机器人干活数据匮乏的行业难题。通俗解释：在数字仿真世界里，生成了数百万种不同大小、材质、形状的虚拟物体，还有各种不同的场景，让机器人在虚拟世界里完成上千亿次的操作训练，练出了一套适应性极强的“通用操作能力”；再用少量真实世界的数据做微调，就能让机器人在真实场景里，轻松完成各种没见过的任务，这也是它能在春晚舞台上，无脚本完成多种生活化任务的核心原因。
    

### 4\. 国内外技术对比

维度

核心优势

现存差距

场景落地

具身大模型的场景落地能力全球领先，实现了全球首个百台级机器人7×24小时自主运营的零售店，工业、零售场景的规模化落地能力，远超特斯拉Optimus、波士顿动力等海外企业

双足人形机器人的高动态运动控制能力，相较于宇树科技、波士顿动力有差距

技术创新

首创的虚实结合训练范式，解决了全球机器人干活数据匮乏的行业难题，具身大模型的操作泛化能力跻身全球第一梯队

消费级市场的布局与产品，相较于松延动力较为滞后

工业能力

轮式双臂机器人的重载操作、精细操作能力处于行业第一梯队，已获得头部制造企业的千台级订单，商业化落地规模全球领先

\-

### 5\. 未来发展方向

*   2026年加大“银河太空舱”无人零售解决方案在全国的推广力度，实现千店级规模部署；
*   深化与宁德时代、博世等工业客户的合作，扩大工业场景的千台级部署规模；
*   持续迭代具身大模型，提升机器人的通用任务泛化能力，拓展医疗康养、城市服务等场景；
*   推进IPO进程，提升资本市场影响力，巩固具身智能领域的龙头地位。  
    

整体总结
====

2026年春晚的机器人表演，并非单纯的舞台炫技，而是中国人形机器人产业的一次国家级路演。四家企业分别在**高动态运动控制、多机集群协同、仿生情感交互、具身智能落地**四大核心方向，展现了中国在人形机器人领域从跟跑到并跑、部分领域领跑的产业格局。

相较于海外企业聚焦实验室参数、军事场景、长期测试的技术路线，中国企业更注重场景落地、成本控制、规模化量产，形成了差异化的竞争优势，推动人形机器人从实验室走向工业、商业、家庭等真实场景，2026年也被业内视为人形机器人规模化应用的元年。