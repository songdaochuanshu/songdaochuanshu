---
layout: post
title: '机器学习中的数据表示'
date: "2025-09-04T00:38:13Z"
---
机器学习中的数据表示
==========

目录

*   [数据概念](#数据概念)
    *   [标量 Scalar](#标量-scalar)
    *   [向量 Vector](#向量-vector)
    *   [矩阵 Matrix](#矩阵-matrix)
    *   [张量 Tensor](#张量-tensor)
*   [小试牛刀](#小试牛刀)
*   [小结](#小结)

### 数据概念

标量、向量、矩阵、张量  
这几个概念是机器学习中数据表示的基础，简单的科普下。

#### 标量 Scalar

标量是最基本、最简单的量，只有大小，没有方向。

例如：一个人的年龄25岁、房间的温度30度、物体的质量15KG，在机器学习中，误差值、学习率等指标都是一个标量。

标量的数学表示为：\\(x \\in \\mathbb{R}\\)，其中 R 是包含所有实数标量的空间。

#### 向量 Vector

向量是一个有顺序的数字（标量）列表，用来表示一个事物的多个特征。

向量既有大小，也有方向。向量在物理中，经常用来描述 速度和方向的叠加，如果仅描述一个人的行进速度，那么就是标量。但如果需要描述这个人的行进特征，那就要考虑他的速度和方向。

如下图所示，一个人爬山的速度，由水平方向的速度和垂直方向的速度组成。

![](https://img2024.cnblogs.com/blog/242916/202509/242916-20250903142846009-1046752989.png)

那么假设水平方向移动的速度是 \[0, 3\], 垂直方向易懂的速度是 \[4, 0\]， 那么这个速度向量就是 \[4, 3\]，其中的标量 4和3 就代表了在水平和垂直方向上的分量。

不难看出，向量在数学上的表示就是一维数组，在机器学习中可以用来表示数据点的一组特征。数组中每个元素代表了在每个方向上的分量（特征值），例如一个房子的价格是 300万，这个房子的特征可以包括 房龄(10年)、面积(100平方)、楼层(16F)等，它的特征向量可以表示为 \[10, 100, 16\]。

向量的数学表示为\\(x \\in \\mathbb{R}^n\\)，其中 R 是包含所有实数标量的空间，n 代表了向量的维度（或者长度）。

#### 矩阵 Matrix

矩阵可以看做是向量的维度延伸，在前面的例子中，我们用向量描述了一个房子的多个特征。那么如何描述100个房子的这些特征呢，答案应该很容易想到，通过将多个向量组合成一个二维数组，每一行代表一个房子的向量，如下：

\\\[A = \\begin{bmatrix} 7 & 14 & 2 \\\\ 19 & 5 & 11 \\\\ 8 & 17 & 20 \\end{bmatrix} \\\]

矩阵的数学表示为\\(x \\in \\mathbb{R}^{m\*n}\\)，其中m和n分别代表行和列。将其展开为二维数组的形式，如下：

\\\[A = \\begin{bmatrix} a\_{11} & a\_{12} & \\cdots & a\_{1n} \\\\ a\_{21} & a\_{22} & \\cdots & a\_{2n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a\_{m1} & a\_{m2} & \\cdots & a\_{mn} \\end{bmatrix} \\\]

#### 张量 Tensor

张量可以看做是矩阵向更高维度的扩展，可以有三个或以上的维度。实际上在机器学习中，数据都是以张量为单位进行称呼的，可以这么认为：

    标量是0维张量
    
    向量是1维张量
    
    矩阵是2维张量
    
    ...
    

其中，一个三维张量可以表示为 \\(x \\in \\mathbb{R}^{i\*j\*k}\\), 其中i、j、k分别是三个维度上的特征数量。

为了更形象一些，我们可以从几何的角度做如下的类比：

![](https://img2024.cnblogs.com/blog/242916/202509/242916-20250903142904598-1707423103.png)

很多人会觉得，数学到了矩阵这里已经开始变得很复杂了，为什么还需要张量呢？原因就在于我们的世界元素构成是非常复杂的，为了更好的表示和处理这些不同维度的特征数据，我们不得不用高维的手段来描述它们，例如：

*   彩色图像：不仅有高和宽，还有颜色通道（RGB） → 三维
    
*   视频：图像帧序列 + 时间维度 → 四维
    
*   自然语言处理：词嵌入 + 句子结构 + 批量输入 → 三维或四维
    
*   神经网络权重：每层的连接结构可能是四维甚至更高维
    

而实际上，张量已经是深度学习框架（如 PyTorch、TensorFlow）中的核心数据结构，并用于支持高效的数据处理和多种维度运算。

### 小试牛刀

接下来，我们尝试在代码中实现这几个数据结构，我们所用的代码会用到 numpy 组件，numpy 是python机器学习的基础组件，提供了对各类数据操作的封装。

示例代码：

    import numpy as np
    
    # 向量
    x1 = np.arange(3)
    print("向量\n", x1)
    
    # 矩阵
    x11 = np.arange(6).reshape(2, 3)
    print("矩阵\n", x11)
    
    # 三维张量
    x111 = np.arange(24).reshape(2, 3, 4)
    print("三维张量\n", x111)
    

> arrange(x) 表示生成一个x长度的数组序列，按数字逐个递增排列
> 
> reshape是一个重组函数，用于将数组重新组合为新的维度结构

执行这段程序，可以分别看到向量、矩阵、三维张量的表示。

    向量
     [0 1 2]
    矩阵
     [[0 1 2]
     [3 4 5]]
    三维张量
     [[[ 0  1  2  3]
      [ 4  5  6  7]
      [ 8  9 10 11]]
    
     [[12 13 14 15]
      [16 17 18 19]
      [20 21 22 23]]]
    

### 小结

正如向量/矩阵是线性代数的基础一样，在AI领域，张量是深度学习的"语言基础"，大名鼎鼎的 Tensorflow 也因此命名。张量统一了不同类型的数据表示（标量、向量、矩阵、高维数组），在数学和物理领域广泛用于描述复杂结构。

![](https://images.cnblogs.com/cnblogs_com/littleatp/1241412/o_qrcode_for_gh_b2cf486409a0_258.jpg)

作者： [美码师(zale)](http://www.cnblogs.com/littleatp/)

出处： [http://www.cnblogs.com/littleatp/](http://www.cnblogs.com/littleatp/), 如果喜欢我的文章，请**关注我的公众号**

本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出 [原文链接](#)  如有问题， 可留言咨询.