---
layout: post
title: 'DeepSeek+Zotero'
date: "2025-02-12T00:36:13Z"
---
DeepSeek+Zotero
===============

![DeepSeek+Zotero](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250211141916063-1823987832.png) 这篇文章介绍了一种在Zotero科研文献阅读管理软件中，使用Awesome GPT插件配置Ollama-DeepSeek文本生成模型+BAAI-bgeM3嵌入模型，来解析和理解科研论文的一种方法。借此可以简化一部分繁杂的论文学习过程，也许可以提升科学研究的效率。

技术背景
====

在[DeepSeek](https://www.cnblogs.com/dechinphy/collections/25319)系列文章中，我们已经分别介绍过关于DeepSeek在Ubuntu Linux平台和Windows平台上的本地部署方案，以及Ollama、ChatBox和AnythingLLM等辅助工具的使用。即使不使用DeepSeek-R1的全量模型，在DeepSeek的本地部署的蒸馏模型，结合AnythingLLM已经可以构建本地化的知识库。但是如果在科研过程中要专注于使用PDFChat这样的功能的时候，可能还是需要一个更加场景细化的应用。

Zotero原本经常被用来当作论文数据库，可以导入自己关注的各个领域的文章，还可以云同步到其他设备上。而且因为Zotero强大的PDF处理能力，有时候也会被拿来当科研论文的PDF阅读器。那么如果在读论文的时候直接导入一个大模型AI助手，那么可能会大大提升论文阅读的速度。本文介绍在Zotero中使用DeepSeek进行理解和辅助的方法。

Zotero插件安装
==========

我们需要一个[Awesome GPT](https://zotero-chinese.com/user-guide/plugins/zotero-gpt.html)插件来导入Ollama的本地模型，或者是一些服务商提供的API。下载完成后再Zotero中打开`工具-插件-Install From Plugin`选项，导入我们下载好的插件：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250210105030891-447329224.png)

这样插件就安装完成了。

配置Awesome GPT
=============

在Zotero中找到`编辑-设置-GPT`：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250210105034479-547008793.png)

General部分改为本地Ollama的参数，API Key随便填几个数字。Custom Embedding这个部分建议选中，然后去[硅基流动](https://cloud.siliconflow.cn/models?types=embedding)弄一个免费的API，推荐bge-m3：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250210105041413-1232145091.png)

点击这个API文档：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250210105048703-646801530.png)

复制框里面的url路径，作为插件的Full API使用，然后再注册一个硅基流动的账号，在`账户管理-API密钥`新建一个密钥：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250211140413733-1656040090.png)

点击前面的密钥即可复制，作为插件中的`Key`使用，模型就选择`BAAI/bge-m3`：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250210105108541-1884744393.png)

这样就配置完成了，点击TEST会出现成功POST的字样，没有报错即为配置成功。

使用Awesome GPT
=============

在Zotero中随便打开一个PDF文档，使用快捷键`ctrl+/`打开Awesome GPT界面，就会弹出这样的一个面板：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250211141004909-1665802560.png)

然后就可以在面板上直接输入问题，按Enter或者点击Ask PDF向DeepSeek提问，这里解析PDF使用的就是我们导入的Embedding模型。如下是一个示例：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250211141258883-1176603224.png)

由于本地使用的是一个7B的模型，还没有展现出比较强大的智能。按照经验来说，32B会有一个显著的提升，很勉强能用，70B开始有一些智能，真要使用的话还是建议上全量模型，现在API其实也不贵。

关于插件里面还有一些其他的操作，可以通过输入`/`调出来：

![](https://img2024.cnblogs.com/blog/2277440/202502/2277440-20250211142128332-411557969.png)

例如说，这里就可以输入clear清空屏幕输出。

总结概要
====

这篇文章介绍了一种在Zotero科研文献阅读管理软件中，使用Awesome GPT插件配置Ollama-DeepSeek文本生成模型+BAAI-bgeM3嵌入模型，来解析和理解科研论文的一种方法。借此可以简化一部分繁杂的论文学习过程，也许可以提升科学研究的效率。

版权声明
====

本文首发链接为：[https://www.cnblogs.com/dechinphy/p/ds-zotero.html](https://www.cnblogs.com/dechinphy/p/ds-zotero.html)

作者ID：DechinPhy

更多原著文章：[https://www.cnblogs.com/dechinphy/](https://www.cnblogs.com/dechinphy/)

请博主喝咖啡：[https://www.cnblogs.com/dechinphy/gallery/image/379634.html](https://www.cnblogs.com/dechinphy/gallery/image/379634.html)

参考链接
====

1.  [https://zhuanlan.zhihu.com/p/20850142386](https://zhuanlan.zhihu.com/p/20850142386)