---
layout: post
title: '基于深度学习的安全帽检测系统演示与介绍(YOLOv12/v11/v8/v5模型+Pyqt5界面+训练代码+数据集)'
date: "2025-11-30T00:48:16Z"
---
基于深度学习的安全帽检测系统演示与介绍(YOLOv12/v11/v8/v5模型+Pyqt5界面+训练代码+数据集)
=========================================================

![基于深度学习的安全帽检测系统演示与介绍(YOLOv12/v11/v8/v5模型+Pyqt5界面+训练代码+数据集)](https://img2024.cnblogs.com/blog/3687401/202511/3687401-20251129214842532-1823499571.png) 本文介绍了一套基于YOLO系列算法的智能安全帽检测系统。系统采用YOLOv5/v8/v11/v12等多种模型，支持图片、视频和实时摄像头的安全帽检测，具备用户管理、多模型切换等功能。通过对比实验显示，YOLO12n模型表现最优（mAP40.6%），YOLO11n速度最快（56.1ms）。系统训练数据集包含7000余张图片，最终实现安全帽识别准确率达90-93%，综合mAP@0.5达到94.6%。该系统为工业生产安全监管提供了高效可靠的智能化解决方案。

视频演示
====

[基于深度学习的安全帽检测系统演示与介绍](https://www.bilibili.com/video/BV1tD1QBuEiP "基于深度学习的安全帽检测系统演示与介绍")

1\. 前言
------

随着工业生产安全意识的日益增强，安全帽作为保护作业人员头部安全的基础装备，其规范佩戴已成为施工现场、工厂车间等区域强制性的管理要求。然而，传统的人工监督方式存在效率低、覆盖面有限、易产生疏漏等问题。为了提升安全监管的智能化与自动化水平，我们开发了这套基于YOLO目标检测算法的安全帽检测系统。

本系统旨在利用先进的计算机视觉技术，实时、准确地检测和识别人员是否佩戴安全帽。系统核心基于YOLO系列算法（包括YOLOv5、v8、v11、v12），构建了一个功能完备的软件平台。它不仅支持对图片、视频文件、批量图片进行离线检测，还能通过摄像头进行实时视频流分析，并即时统计“戴安全帽”与“未戴安全帽”的人员数量，为安全管理提供直观的数据支持。

此外，系统还集成了用户登录认证、个人中心、模型训练与评估等辅助模块，形成了一个集检测、管理、分析与扩展于一体的综合性解决方案。通过本项目，我们期望能为安全生产管理提供一种高效、可靠的技术工具，有效预防因未佩戴安全帽而引发的安全事故，具有重要的现实应用价值。

2\. 项目演示
--------

### 2.1 **用户登录界面**

界面设计简洁直观，左侧突出系统主题，用户需验证用户名、密码及动态验证码后方可进入系统。

### 2.2 **新用户注册**

新用户可设置用户名与密码，并支持自定义头像上传；如未选择，系统将自动分配默认头像完成注册。

### 2.3 **主界面布局**

主界面采用三栏式设计，涵盖左侧功能操作区、中央视觉结果展示区与右侧目标详细信息面板，结构清晰，操作流畅。

### 2.4 **个人信息管理**

用户可在此模块随时更新个人密码与头像，支持信息灵活修改。

### 2.5 **多模态检测展示**

系统支持图片、视频及实时摄像头的安全帽识别。检测结果除在图像中直接标出外，也会在列表中逐项显示。点击任一目标，即可在右侧面板中查看其详细识别信息与坐标位置。

### 2.6 **多模型切换**

用户可根据需要，灵活切换使用不同版本的已训练模型进行检测，便于比较性能或适配不同场景。

3.模型训练核心代码
----------

本脚本是YOLO模型批量训练工具，可自动修正数据集路径为绝对路径，从pretrained文件夹加载预训练模型，按设定参数（100轮/640尺寸/批次8）一键批量训练YOLOv5nu/v8n/v11n/v12n模型。

    # -*- coding: utf-8 -*-
    """
    该脚本用于执行YOLO模型的训练。
    
    它会自动处理以下任务：
    1. 动态修改数据集配置文件 (data.yaml)，将相对路径更新为绝对路径，以确保训练时能正确找到数据。
    2. 从 'pretrained' 文件夹加载指定的预训练模型。
    3. 使用预设的参数（如epochs, imgsz, batch）启动训练过程。
    
    要开始训练，只需直接运行此脚本。
    """
    import os
    import yaml
    from pathlib import Path
    from ultralytics import YOLO
    
    def main():
        """
        主训练函数。
        
        该函数负责执行YOLO模型的训练流程，包括：
        1. 配置预训练模型。
        2. 动态修改数据集的YAML配置文件，确保路径为绝对路径。
        3. 加载预训练模型。
        4. 使用指定参数开始训练。
        """
        # --- 1. 配置模型和路径 ---
        
        # 要训练的模型列表
        models_to_train = [
            {'name': 'yolov5nu.pt', 'train_name': 'train_yolov5nu'},
            {'name': 'yolov8n.pt', 'train_name': 'train_yolov8n'},
            {'name': 'yolo11n.pt', 'train_name': 'train_yolo11n'},
            {'name': 'yolo12n.pt', 'train_name': 'train_yolo12n'}
        ]
        
        # 获取当前工作目录的绝对路径，以避免相对路径带来的问题
        current_dir = os.path.abspath(os.getcwd())
        
        # --- 2. 动态配置数据集YAML文件 ---
        
        # 构建数据集yaml文件的绝对路径
        data_yaml_path = os.path.join(current_dir, 'train_data', 'data.yaml')
        
        # 读取原始yaml文件内容
        with open(data_yaml_path, 'r', encoding='utf-8') as f:
            data_config = yaml.safe_load(f)
        
        # 将yaml文件中的 'path' 字段修改为数据集目录的绝对路径
        # 这是为了确保ultralytics库能正确定位到训练、验证和测试集
        data_config['path'] = os.path.join(current_dir, 'train_data')
        
        # 将修改后的配置写回yaml文件
        with open(data_yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(data_config, f, default_flow_style=False, allow_unicode=True)
        
        # --- 3. 循环训练每个模型 ---
        
        for model_info in models_to_train:
            model_name = model_info['name']
            train_name = model_info['train_name']
            
            print(f"\n{'='*60}")
            print(f"开始训练模型: {model_name}")
            print(f"训练名称: {train_name}")
            print(f"{'='*60}")
            
            # 构建预训练模型的完整路径
            pretrained_model_path = os.path.join(current_dir, 'pretrained', model_name)
            if not os.path.exists(pretrained_model_path):
                print(f"警告: 预训练模型文件不存在: {pretrained_model_path}")
                print(f"跳过模型 {model_name} 的训练")
                continue
            
            try:
                # 加载指定的预训练模型
                model = YOLO(pretrained_model_path)
                
                # --- 4. 开始训练 ---
                
                print(f"开始训练 {model_name}...")
                # 调用train方法开始训练
                model.train(
                    data=data_yaml_path,  # 数据集配置文件
                    epochs=100,           # 训练轮次
                    imgsz=640,            # 输入图像尺寸
                    batch=8,             # 每批次的图像数量
                    name=train_name,      # 模型名称
                )
                
                print(f"{model_name} 训练完成！")
                
            except Exception as e:
                print(f"训练 {model_name} 时出现错误: {str(e)}")
                print(f"跳过模型 {model_name}，继续训练下一个模型")
                continue
        
        print(f"\n{'='*60}")
        print("所有模型训练完成！")
        print(f"{'='*60}")
    
    if __name__ == "__main__":
        # 当该脚本被直接执行时，调用main函数
        main()

4\. 技术栈
-------

*   语言：Python 3.10
    
*   前端界面：PyQt5
    
*   数据库：SQLite（存储用户信息）
    
*   模型：YOLOv5、YOLOv8、YOLOv11、YOLOv12
    

5\. YOLO模型对比与识别效果解析
-------------------

### 5.1 YOLOv5/YOLOv8/YOLOv11/YOLOv12模型对比

基于Ultralytics官方COCO数据集训练结果：

模型

尺寸(像素)

mAPval 50-95

速度(CPU ONNX/毫秒)

参数(M)

FLOPs(B)

YOLO12n

640

40.6

\-

2.6

6.5

YOLO11n

640

39.5

56.1 ± 0.8

2.6

6.5

YOLOv8n

640

37.3

80.4

3.2

8.7

YOLOv5nu

640

34.3

73.6

2.6

7.7

**关键结论**：

1.  **精度最高**：YOLO12n（mAP 40.6%），显著领先其他模型（较YOLOv5nu高约6.3个百分点）；
    
2.  **速度最优**：YOLO11n（CPU推理56.1ms），比YOLOv8n快42%，适合实时轻量部署；
    
3.  **效率均衡**：YOLO12n/YOLO11n/YOLOv8n/YOLOv5nu参数量均为2.6M，FLOPs较低（YOLO12n/11n仅6.5B）；YOLOv8n参数量（3.2M）与计算量（8.7B）最高，但精度优势不明显。
    

**综合推荐**：

*   追求高精度：优先选YOLO12n（精度与效率兼顾）；
    
*   需高速低耗：选YOLO11n（速度最快且精度接近YOLO12n）；
    
*   YOLOv5nu/YOLOv8n因性能劣势，无特殊需求时不建议首选。
    

### 5.2 数据集分析

数据集中训练集和验证集一共大概7000多张，数据集目标类别两类：有安全帽，无安全帽。数据集配置代码如下：

    names:
    - Helmet
    - NoHelmet
    nc: 2
    path: D:\project\python\01Finished\yolo_Hard_Hat\train_data
    test: ../test/images
    train: ../train/images
    val: ../valid/images

上面的图片就是部分样本集训练中经过数据增强后的效果标注。

### 5.3 训练结果

混淆矩阵显示中，有安全帽和无安全帽的识别准确度分别是:90%，93%。

F1指数（F1 Score）是统计学和机器学习中用于评估分类模型性能的核心指标，综合了模型的精确率（Precision）和召回率（Recall），通过调和平均数平衡两者的表现。 

当置信度为0.377时，所有类别的综合F1值达到了0.91（蓝色曲线）。

mAP@0.5：是目标检测任务中常用的评估指标，表示在交并比（IoU）阈值为0.5时计算的平均精度均值（mAP）。其核心含义是：只有当预测框与真实框的重叠面积（IoU）≥50%时，才认为检测结果正确。

图中可以看到综合mAP@0.5达到了0.946（94.6%），准确率非常高。

6\. 源码获取方式
----------

[源码获取方式：https://www.bilibili.com/video/BV1tD1QBuEiP](https://www.bilibili.com/video/BV1tD1QBuEiP "源码获取方式：https://www.bilibili.com/video/BV1tD1QBuEiP")

​