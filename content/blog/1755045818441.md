---
layout: post
title: '从纳秒到毫秒的“时空之旅”：CPU是如何看待内存与硬盘的？'
date: "2025-08-13T00:43:38Z"
---
从纳秒到毫秒的“时空之旅”：CPU是如何看待内存与硬盘的？
-----------------------------

在数据暴涨时代，如何高效存储和管理海量数据已成为应用系统的核心挑战。这不仅关乎读写性能，更涉及并发场景下性能与持久化之间的平衡。要应对这一挑战，既需要理解不同存储介质的物理特性与性能边界，也需通过数据结构、存储模型与操作系统机制的协同设计，达成技术上的最优平衡。  
本文将从计算机系统的分层存储体系这一基础视角出发，阐述B+树如何为关系型数据库（如MySQL）的优化复杂查询效率，LSM树如何为NoSQL数据库（如RocksDB）实现高吞吐写入，以及Kafka的日志结构如何借助顺序存储特性突破传统消息队列的性能瓶颈。

**计算机存储设计**  

现代计算机的存储器设计地采用了一种分层次的结构。从塔尖的寄存器、高速缓存，到塔身的内存（主存），再到塔基的外部存储（硬盘/SSD），存储器的访问速度逐级递减，而容量逐级递增，单位存储成本也随之显著降低。

**寄存器**  
寄存器（Register）是集成在处理器内部的、数量极少但速度最快的高速存储单元。处理器的算术逻辑单元（Arithmetic And Logic Unit，ALU）直接通过指令集对其进行读写，几乎没有延迟。然而，其制造成本极为高昂，导致容量非常有限。  
1）通用寄存器（General-Purpose Registers）：用于暂存参与运算的数据、中间结果或地址。其位数（如32位、64位）与处理器的字长相匹配。  
2）特殊目的寄存器（Special-Purpose Registers）：承载特定控制或状态信息，如程序计数器（PC，指向下一条待执行指令）、堆栈指针（SP）、指令寄存器（IR）、状态寄存器（Flags）等。  
3）浮点寄存器（Floating-Point Registers）：专用于存储和处理浮点数，支持高精度的科学计算。通常是几个或几十个字节，取决于浮点数的精度和计算需求。

**高速缓存**  
高速缓存是介于处理器与主存之间的一道屏障，用以弥合两者巨大的速度差异。它通常采用静态随机存取存储器（Static Random-Access Memory，SRAM），SRAM由触发器构成，只要供电，数据就能保持，无需刷新电路，因此访问速度极快，接近寄存器，但成本和功耗也较高。  
现代处理器普遍集成L1、L2、L3三层高速缓存。  
1）L1 Cache：每个处理器核心独享，容量最小（如几十KB），速度最快。通常进一步划分为指令缓存（Instruction Cache）和数据缓存（Data Cache），以支持指令预取和数据读写的并行。  
2）L2 Cache：容量和速度介于L1和L3之间。早期设计为核心独享，现代多核处理器中，部分架构（如Intel的一些型号）采用共享L2，而另一些（如AMD的一些型号）仍为核心独享或小组共享。  
3）L3 Cache：通常为多核心共享，容量最大（如几MB到几十MB），速度相对最慢，但仍远快于主存。作为主存前最后一道高速防线。

**内存**  
内存，即主存，是计算机运行程序和数据的主要工作区域。它主要采用动态随机存取存储器（Dynamic Random Access Memory，DRAM），DRAM利用电容存储电荷来表示数据位，电容会漏电，因此需要周期性刷新（Refresh）电路来维持数据，这使其速度慢于SRAM，但存储密度更高，单位容量成本更低。  
内存用于存放当前正在执行的操作系统、应用程序代码、运行时数据栈、堆等。CPU通过内存总线直接寻址访问内存中的数据。其容量通常以GB或TB计。

**外部存储**  
机械硬盘（Hard Disk Drive、HDD）和固态硬盘（Solid State Drive、SSD）是两种最常见的硬盘，作为计算机的外部存储，处理器想要访问它们存储的数据需要很长时间，如下表所示，在 SSD 中随机访问 4KB 数据需要的时间是访问内存的1500 倍，机械硬盘的寻道时间是访问内存的100000倍。  
硬盘是计算机主要的非易失性（断电后数据不丢失）大容量存储设备，用于长期保存用户数据和程序。常见的有机械硬盘（Hard Disk Drive、HDD）和固态硬盘（Solid State Drive、SSD）。处理器访问外部存储数据需通过I/O总线，其速度远慢于内存。  
1）机械硬盘：通过磁头在旋转的盘片上读写数据。其访问时间主要由寻道时间（磁头移动到目标磁道）、旋转延迟（盘片旋转到目标扇区）和数据传输时间构成。随机访问性能差，顺序访问性能尚可。  
2）固态硬盘 ：基于NAND闪存芯片存储数据，无机械部件，随机读写性能远超HDD，延迟极低。但其写入操作（尤其随机写）涉及擦除再写入的特性，存在写放大问题和寿命限制。  

**I/O操作**  
I/O（Input/Output）是计算机系统与外部世界（包括外设、网络、其他系统）进行数据交换的核心过程。它既包括从键盘、鼠标、磁盘、网络等输入源读取数据，也包括将数据输出到显示器、打印机、磁盘、网络等目标。  

**I/O 模式**  
在计算机体系结构中，硬盘属于一种常见的输入输出设备，处理器想要访问硬盘中的数据要先通过 I/O 将硬盘中的数据读入到内存中，再访问存储在内存中的数据。计算机中包含三种比较常见的 I/O 模式： 程序控制 I/O（Programmed I/O）、中断驱动 I/O（Interrupt-driven I/O）和直接内存访问（Direct Memory Access，DMA)。

**程序控制 I/O**  
程序控制I/O是最简单的一种 I/O 模式。比如发起系统调用write，处理器会向I/O设备写入数据，写入后会一直轮询I/O设备的状态等待它完成。这个过程涉及到一个内核态和用户态的切换。这种方式虽然简单，但是它会占用全部的处理器资源，在某些复杂的系统中会造成计算资源的严重浪费。  

**中断驱动 I/O**  
由于程序控制I/O让处理器处于不必要的繁忙之中，所以出现了中断驱动I/O，通过中断功能和特殊命令来通知接口，只要I/O设备有了需要的数据，便会发出中断请求信号。同时处理器可以继续执行其他程序。与程序控制I/O 相比，中断驱动 I/O 将一部分工作交给了 I/O 设备，所以能够提高资源的利用率。  
然而以上两种I/O模式的数据传输都需要处理器干预，并且都有两个缺点：  
1）I/O传输速率受处理器的速度限制。  
2）每次I/O传输必须执行许多指令。  

**DMA**  
为解决处理器参与数据传输的瓶颈，引入DMA控制器（Direct Memory Acess Controller， DMAC）。处理器只需向DMAC下达指令（源地址、目标地址、数据长度等），DMAC便能直接在I/O设备和内存之间开辟通路，独立完成数据传输，传输结束后再通过中断通知处理器。处理器在此期间可以并行执行其他任务，仅在传输开始和结束时介入。现代计算机系统默认广泛采用DMA进行I/O操作。  
尽管DMA大幅提升效率，但I/O操作（涉及总线仲裁、上下文切换、中断处理等）仍是程序中相对耗时和复杂的操作。  

**未完待续**

**很高兴与你相遇！如果你喜欢本文内容，记得关注哦！！！**

本文来自博客园，作者：[poemyang](https://www.cnblogs.com/poemyang/)，转载请注明原文链接：[https://www.cnblogs.com/poemyang/p/19033086](https://www.cnblogs.com/poemyang/p/19033086)

posted on 2025-08-12 08:18  [poemyang](https://www.cnblogs.com/poemyang)  阅读(312)  评论(0)    [收藏](javascript:void\(0\))  [举报](javascript:void\(0\))