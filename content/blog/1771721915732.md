---
layout: post
title: 'RankMixer: Scaling Up Ranking Models in  Industrial Recommenders'
date: "2026-02-22T00:58:35Z"
---
RankMixer: Scaling Up Ranking Models in Industrial Recommenders
---------------------------------------------------------------

RankMixer：在工业级推荐系统中扩展排序模型
=========================

摘要
--

近年来，大语言模型（LLMs）的快速发展激发了将推荐系统进行大规模扩展的研究兴趣，但在工业实践中仍面临两项关键挑战。第一，工业级推荐系统在训练和在线推理阶段必须满足严格的时延约束和高并发（QPS）需求，计算与服务成本受到强约束。第二，现有排序模型中大量由人工设计的特征交叉模块源自 CPU 时代，难以充分利用现代 GPU 的计算特性，导致模型计算利用率（Model FLOPs Utilization，MFU）较低，系统扩展性受限。

为此，我们提出了 **RankMixer**，一种面向硬件感知（hardware-aware）的模型设计，旨在构建统一且具备良好扩展性的特征交互架构。RankMixer 在保留 Transformer 高度并行计算优势的同时，用多头 token mixing 模块替代了二次复杂度的自注意力机制，从而显著提升计算效率。此外，RankMixer 通过逐 token 的前馈网络（Per-token FFNs），同时建模不同特征子空间内部的表示能力以及跨特征子空间的交互关系。

在此基础上，我们进一步引入稀疏混合专家（Sparse-MoE）变体，将 RankMixer 扩展至十亿级参数规模，以实现更高的投入产出比（ROI）。针对专家训练不足和负载不均衡的问题，我们设计了一种动态路由策略以提升训练效率和稳定性。实验结果表明，RankMixer 在万亿级别的真实生产数据集上展现出卓越的扩展能力。

通过使用 RankMixer 替换以往多样化、低 MFU 的人工特征模块，我们将模型的 MFU 从 4.5% 提升至 45%，在保持推理时延基本不变的前提下，将在线排序模型的参数规模提升了两个数量级。我们还在两大核心应用场景（推荐与广告）中通过在线 A/B 实验验证了 RankMixer 的通用性。最终，我们在不增加线上服务成本的情况下，成功上线了参数规模为 10 亿的稠密 RankMixer 模型，带来了用户活跃天数提升 0.3%，应用内总使用时长提升 1.08%。

1 引言
----

推荐系统（Recommender System，RS）在信息分发过程中起着至关重要的作用。作为一个重要的机器学习应用场景，推荐系统基于大规模多字段特征数据来预测用户对物品的行为，这些特征包括数值型特征（如各类统计特征）、类别型特征（如用户 ID 和物品 ID）、用户行为特征以及内容特征等 \[19, 41\]。当前最先进的推荐方法主要基于深度学习推荐模型（Deep Learning Recommendation Models，DLRMs），其通过位于特征嵌入之上的稠密交互层，利用神经网络灵活地刻画特征之间的交互关系。稠密交互层是 DLRM 性能的关键组成部分，围绕该层已经提出了多种模型结构 \[7, 11, 33, 38, 42\]。

受益于大语言模型（LLMs）中“参数规模增长带来性能提升”的趋势 \[1, 14, 16\]，将 DLRMs 进行规模化以充分利用海量数据已成为迫切需求。早期关于 DLRM 扩展性的研究 \[2, 6, 40\] 主要通过简单地加宽或堆叠特征交互层，而不改变其结构形式，这种方式带来的收益有限，甚至在某些情况下会导致性能下降 \[18, 32\]。随后的一些工作，如 DHEN \[39\] 和 Wukong \[38\]，开始通过设计新的 DNN 结构来提升模型的可扩展性能。然而，在推荐系统中利用模型规模提升效果面临着独特的工程挑战。与 NLP 或视觉任务不同，工业级推荐系统必须严格满足极低的推理时延要求，并支持极高的 QPS（每秒查询数）。因此，核心问题在于如何在模型效果与计算效率之间找到一个最优平衡点。

从历史上看，推荐系统中排序模型的架构深受 CPU 时代设计理念的影响。这类模型通常通过组合多种异构、人工设计的特征交叉模块来建模特征交互，但其中许多核心算子在现代 GPU 上是内存受限（memory-bound）而非计算受限（compute-bound），导致 GPU 并行度不足，模型计算利用率（Model FLOPs Utilization，MFU）极低，往往只有个位数百分比。此外，由于 CPU 时代模型的计算成本与参数规模大致成正比，理论上由 scaling law 所暗示的“激进扩展带来的高 ROI”在实践中难以实现。

综上所述，关于 DLRM 的 scaling law 研究需要解决以下关键问题：  
• 架构设计应与硬件特性高度对齐，在现代 GPU 上最大化 MFU 和计算吞吐。  
• 模型设计必须充分利用推荐数据的特点，例如高度异构的特征空间，以及数百个字段之间的个性化跨特征交互。

为应对上述挑战，我们提出了一种硬件感知（hardware-aware）的模型设计方法——RankMixer。RankMixer 的核心设计基于两个可扩展组件：  
1）多头 token mixing，通过无参数（parameter-free）的算子实现跨 token 的特征交互，在性能和计算效率上均优于自注意力机制；  
2）逐 token 的前馈网络（Per-token FFNs），显著扩展模型容量，并通过为不同特征子空间分配独立参数，有效缓解跨特征空间建模中的主导（domination）问题。这种设计同时与推荐数据的分布特性高度契合，表现出更优的扩展行为。

为了进一步提升大规模模型的投入产出比（ROI），我们将逐 token 的 FFN 扩展为稀疏混合专家（Sparse Mixture-of-Experts，MoE）结构。通过对不同数据样本仅动态激活少量专家，可以在计算开销几乎不增加的情况下显著提升模型容量。RankMixer 采用了类似 Transformer 的高度并行架构，但克服了基于自注意力的特征交互在推荐场景中的若干关键局限性，包括训练效率低、跨特征空间 ID 相似性建模的组合爆炸问题，以及注意力权重矩阵带来的严重内存瓶颈。在相同 FLOPs 约束下，相比标准 Transformer，RankMixer 具备更大的模型容量和更强的学习能力。

在抖音推荐系统的生产部署中，我们验证了在保持推理时延不高于原有基线模型的前提下，将模型参数规模扩展超过 100 倍是可行的。这得益于 RankMixer 架构在参数规模与 FLOPs 之间的解耦能力，以及通过高 MFU 和工程优化将 FLOPs 增长与实际成本解耦。

本文的主要贡献总结如下：  
• 提出了一种遵循硬件感知模型设计理念的新型架构 RankMixer，通过多头 token mixing 和逐 token FFN 高效建模异构特征交互，并引入动态路由策略以提升 RankMixer 中 Sparse MoE 的可扩展性。  
• 借助高 MFU 和性能优化手段（包括 MFU 提升与量化），在不增加推理成本的前提下，将模型参数规模扩展至原来的 70 倍。  
• 在万亿级工业推荐数据集上进行了大量离线与在线实验，系统性研究了模型的 scaling law。RankMixer 已成功部署于抖音信息流推荐排序全量流量中，用户活跃天数和应用使用时长分别提升了 0.3% 和 1.08%。

2 相关工作
------

现代推荐系统主要建立在深度学习推荐模型（Deep Learning Recommendation Models，DLRMs）之上，而如何高效地建模特征交互是影响 DLRM 性能的关键因素之一 \[5, 11, 15, 22, 31, 33, 39\]。Wide & Deep \[5\] 是较早的代表性工作之一，它将逻辑回归（wide 部分）与深度神经网络（deep 部分）相结合，分别用于建模低阶和高阶特征交互。DeepFM \[11\] 则将因子分解机（Factorization Machine，FM）与 DNN 进行了统一建模。除此之外，DeepCross \[26\] 是残差网络 \[13\] 在推荐场景中的一种扩展，旨在通过残差结构隐式地学习特征交互关系。然而，研究表明，仅依赖 DNN 自动学习高阶特征交互本身是非常具有挑战性的 \[22, 25\]。

为此，大量工作采用显式特征交叉方法，通过设计不同算子来明确建模高阶特征交互，例如 PNN \[22\]、DCN \[32\] 及其改进版本 DCNv2 \[33\]、xDeepFM \[18\]、FGCNN \[20\] 以及 FiGNN \[17\]。AutoInt \[28\] 和 Hiformer \[10\] 则引入带残差连接的注意力机制来学习复杂的特征交互关系。DHEN \[39\] 提出将多种交互算子进行组合，以增强模型的表达能力。尽管这些新型架构在精度上取得了一定提升，但通常会显著增加模型的推理时延和内存开销，同时模型规模整体仍然较小，限制了进一步的扩展。

Scaling law 已成为深度学习领域的一个基础性主题，并在过去十年中推动了多项关键突破，尤其是在自然语言处理（NLP）\[14, 16\]、计算机视觉（CV）\[8, 37\] 以及多模态建模 \[23, 24\] 等方向。Scaling law 描述了模型性能与扩展因素（如模型参数规模、数据量和计算能力）之间的幂律关系 \[1, 16, 29, 30\]。近年来，推荐系统中的 scaling law 也逐渐受到研究者的广泛关注 \[12\]。已有工作从不同角度探索了推荐模型的扩展策略，包括用户行为序列的预训练 \[6\]、通用用户表征学习 \[27, 40\] 以及在线召回阶段的规模化建模 \[9, 34\]。例如，Wukong \[38\] 通过堆叠 FM 与 LCB 来学习特征交互；Zhang 等人 \[40\] 则将序列推荐模型的参数规模扩展至 8 亿（0.8B）。HSTU \[36\] 进一步增强了生成式推荐模型（Generative Recommenders，GRs）的 scaling 效果，该类模型更加侧重于序列建模能力。

3 方法
----

### 3.1 整体架构

RankMixer 的整体架构由 **T 个输入 token** 组成，这些 token 依次经过 **L 个 RankMixer Block** 处理，最后通过一个输出池化算子得到模型输出。每个 RankMixer Block 包含两个核心组件：（1）**多头 Token Mixing 层**，以及（2）**逐 token 前馈网络（Per-Token Feed-Forward Network，PFFN）层**，其结构如图 1 所示。

首先，将输入向量 \\(e\_{\\text{input}}\\) 进行 token 化，得到 ( T ) 个特征 token：$ x\_1, x\_2, \\ldots, x\_T $，其中每个 token 表示一个语义一致的特征向量。RankMixer 通过堆叠的 $ L $ 层对 token 表示进行逐层精炼，其计算过程为：

\\\[S\_{l-1} = \\mathrm{LN}\\big(\\mathrm{TokenMixing}(X\_{l-1}) + X\_{l-1}\\big), \\\]

\\\[X\_l = \\mathrm{LN}\\big(\\mathrm{PFFN}(S\_{l-1}) + S\_{l-1}\\big), \\tag{1} \\\]

其中，\\(\\mathrm{LN}(\\cdot)\\)表示层归一化（Layer Normalization），\\(\\mathrm{TokenMixing}(\\cdot)\\)和 \\(\\mathrm{PFFN}(\\cdot)\\)分别表示多头 Token Mixing 模块和逐 token FFN 模块；\\(X\_l \\in \\mathbb{R}^{T \\times d}\\)是第 (l) 个 RankMixer Block 的输出，\\(X\_0 \\in \\mathbb{R}^{T \\times d}\\) 由 \\(x\_1, x\_2, \\ldots, x\_T\\) 堆叠而成，(d) 为模型的隐藏维度。

最终输出表示 \\(o\_{\\text{output}}\\) 通过对最后一层输出 (X\_L) 进行 **均值池化（mean pooling）** 得到，并用于后续不同任务的预测计算。

* * *

### 3.2 输入层与特征 Token 化

构建大规模推荐模型的首要步骤是准备信息丰富的输入特征。这些特征通常包括：  
• **用户特征**，如用户 ID 及其他用户属性；  
• **候选内容特征**，如视频 ID、作者 ID 等；  
• **序列特征**，通过序列建模模块（Sequence Module）\[4, 42\] 处理，用于刻画用户的时序兴趣，生成对应的嵌入表示 (e\_s)；  
• **交叉特征**，即用户与候选内容之间的交互特征。

所有特征都会被映射为不同维度的 embedding。为了在后续阶段实现高效的并行计算，需要将这些维度不一致的 embedding 转换为维度对齐的向量，称为 **特征 token（feature tokens）**。我们将这一 embedding 对齐过程称为 **tokenization（token 化）**。

**最简单的 token 化策略是“一个特征对应一个 embedding”，但在通常包含数百个特征的推荐系统中，这种做法会带来多个问题。一方面，过多的 token 会导致每个 token 分配到的参数量和计算量过少，从而对重要特征建模不足，同时无法充分利用 GPU 的计算能力；另一方面，token 数量过少（例如仅使用单个 token）又会使模型退化为普通的深度神经网络（DNN），难以区分不同特征子空间，容易出现强特征主导、弱特征被淹没的问题**。

为了解决上述矛盾，我们提出了一种 **基于语义的 token 化方法**。该方法结合领域知识，将特征划分并聚合为若干语义一致的特征组。随后，将这些分组后的特征 embedding 按顺序拼接为一个整体向量：

\\\[e\_{\\text{input}} = \[e\_1; e\_2; \\ldots; e\_G\], \\\]

并进一步切分为若干个固定维度的 token。每个特征 token \\(x\_t \\in \\mathbb{R}^d\\) 表示一组具有相似语义的特征 embedding。

具体形式为：

\\\[x\_t = \\mathrm{Proj}\\Big(e\_{\\text{input}}\\big\[d \\cdot (t-1) : d \\cdot t\\big\]\\Big), \\quad t = 1, \\ldots, T, \\tag{2} \\\]

其中，\\(e\_{\\text{input}}\\) 为拼接后的 embedding 向量，(d) 为每个 token 的固定维度，(G) 为特征分组数量，(T) 为最终生成的 token 数目，\\(\\mathrm{Proj}(\\cdot)\\) 表示将切分后的 embedding 映射到 (d) 维空间的投影函数。

**个人理解：表征 Token 化的核心不仅将 embedding 维度对齐，而且引入语义组内融合这一中间建模层。通过将语义一致的特征先拼接，再经过线性投影或小型变换网络映射为固定维度的 token，模型能够在组内学习特征的重要性分配与组合关系。这相当于在进入全局网络之前，先完成一次局部建模，使相关特征在同一子空间内进行协同表达，而非在底层直接与其他语义特征混合。  
在训练过程中，损失函数的梯度会先作用于 token 表示，再反向传播至组内的投影层与各个基础 embedding，从而实现组内联合更新。这种机制带来的实际效果包括：1.为后续结构实现高效的并行计算、2.增强语义子空间的结构化表达、3.提高梯度信号的集中度、4.减少无关特征间的过早干扰，并使模型在保持计算可控的前提下具备更清晰的表达层级。**

### 3.3 RankMixer Block

#### 3.3.1 多头 Token Mixing

为了促进不同 token 之间的有效信息交换（这对于特征交叉和全局信息建模至关重要），我们引入了 **多头 Token Mixing（Multi-head Token Mixing）模块**。每个 token 会被均匀地划分为 \\(H\\) 个 head，第 \\(h\\) 个 head 对应 token \\(x\_i\\) 的子向量记为 \\(x\_i^{(h)}\\)：

\\\[x\_i^{(1)} ,|, x\_i^{(2)} ,|, \\ldots ,|, x\_i^{(H)} ;=; \\mathrm{SplitHead}(x\_i). \\tag{3} \\\]

这些 head 可以被视为将 token (x\_i) 投影到若干低维特征子空间中的结果，这是因为推荐任务本身需要从不同“视角”对信息进行建模。Token Mixing 的目标正是将这些子空间向量进行融合，从而实现全局范围内的特征交互。

形式化地，经过多头 Token Mixing 后，第 (h) 个 head 对应的混合 token (s^{(h)}) 构造为：

\\\[s^{(h)} = \\mathrm{Concat}\\big( x\_1^{(h)}, x\_2^{(h)}, \\ldots, x\_T^{(h)} \\big). \\\]

多头 Token Mixing 模块的输出记为

\\\[S \\in \\mathbb{R}^{T \\times \\frac{dH}{H}}, \\\]

该输出由所有混合后的 token \\(s\_1, s\_2, \\ldots, s\_T\\) 堆叠而成。在本文中，我们设置 **输出 token 数 (T) 与输入 token 数相同**，以便于与残差连接结构对齐。

在加入残差连接并经过归一化之后，得到最终的 Token Mixing 输出：

\\\[s\_1, s\_2, \\ldots, s\_T = \\mathrm{LN}\\big( \\mathrm{TokenMixing}(x\_1, x\_2, \\ldots, x\_T) + (x\_1, x\_2, \\ldots, x\_T) \\big). \\tag{5} \\\]

**尽管自注意力机制（self-attention）在大语言模型中已被证明极为有效，但我们发现其在推荐系统中并非最优选择。在自注意力中，注意力权重通过 token 之间的内积相似度来计算，这在 NLP 场景中是合理的，因为所有 token 共享统一的语义空间。然而在推荐任务中，特征空间天然是高度异构的：来自用户侧与物品侧的特征，其 ID 空间往往包含数以亿计的元素。在这样的异构语义空间中，直接计算内积相似度是极其困难的**。

因此，在推荐系统中，对这类多源异构输入使用自注意力机制，往往无法优于 **无参数（parameter-free）的多头 Token Mixing 方法**，反而会引入更多的计算量、内存 IO 开销以及 GPU 显存占用。

* * *

#### 3.3.2 逐 Token 前馈网络（Per-token FFN）

以往的 DLRM 以及 DHEN 等模型，通常在单一的交互模块中混合来自多种不同语义空间的特征，这容易导致高频特征主导训练过程，从而淹没低频或长尾信号，最终损害整体推荐效果。

为此，我们提出了一种 **参数隔离（parameter-isolated）的前馈网络结构**，称为 **逐 token FFN（Per-token FFN）**。在传统设计中，FFN 的参数在所有 token 之间是共享的；而在 RankMixer 中，每个 token 都通过一组独立的变换进行处理，从而实现 token 级别的参数隔离。

对于第 (i) 个 token (s\_i)，其逐 token FFN 表达为：

\\\[v\_i = \\mathrm{FFN}^{(i)}\_2\\Big( \\mathrm{Gelu}\\big( \\mathrm{FFN}^{(i)}\*1(s\_i) \\big) \\Big), \\tag{6} \\\]

其中

\\\[\\mathrm{FFN}^{(i)}\*k(x) = x W^{(i)}\*{\\text{pffn},k} + b^{(i)}\*{\\text{pffn},k}, \\tag{7} \\\]

表示逐 token FFN 中的第 (k) 层 MLP。具体而言：

*   \\(W^{(i)}\_{\\text{pffn},1} \\in \\mathbb{R}^{d \\times \\alpha d}\\)，
*   \\(b^{(i)}\_{\\text{pffn},1} \\in \\mathbb{R}^{\\alpha d}\\)，
*   \\(W^{(i)}\_{\\text{pffn},2} \\in \\mathbb{R}^{\\alpha d \\times d}\\)，
*   \\(b^{(i)}\_{\\text{pffn},2} \\in \\mathbb{R}^{d}\\)。

其中 (\\alpha) 是用于调节逐 token FFN 隐藏层维度的超参数，(\\mathrm{Gelu}(\\cdot)) 为 GELU 激活函数，(s\_i \\in \\mathbb{R}^{d}) 表示第 (i) 个 token。

整体的逐 token FFN 模块可以总结为：

\\\[v\_1, v\_2, \\ldots, v\_T = \\mathrm{PFFN}(s\_1, s\_2, \\ldots, s\_T), \\tag{8} \\\]

其中

\\\[\\mathrm{PFFN}(s\_1, s\_2, \\ldots, s\_T) = \\mathrm{FFN}^{(i)}\_2\\Big( \\mathrm{Gelu}\\big( \\mathrm{FFN}^{(i)}\_1(s\_1, s\_2, \\ldots, s\_T) \\big) \\Big). \\tag{9} \\\]

与所有 token 共享参数的 FFN 相比，逐 token FFN 在 **计算复杂度保持不变的前提下**，通过引入更多参数显著增强了模型的表达能力。

需要特别强调的是，逐 token FFN 与多任务学习中的 MMoE（Multi-gate Mixture-of-Experts）存在本质区别：在逐 token FFN 中，每个 FFN 接收的是 **不同的 token 输入**；而在 MMoE 中，所有专家通常处理的是 **同一个输入**。与 MMoE“多专家共享输入”以及 Transformer“多输入共享一个 FFN”不同，RankMixer 同时对 **输入和参数进行拆分**，这使其在不同特征子空间中能够学习到更加多样化、互补性的表示能力。

### 3.4 RankMixer 中的稀疏 MoE（Sparse MoE）

为了进一步提升模型扩展的投入产出比（ROI），我们可以将每个 token 对应的稠密 FFN 替换为 **稀疏混合专家（Sparse Mixture-of-Experts，MoE）模块**，从而在计算开销基本保持不变的情况下显著提升模型容量。然而，直接将标准的 Sparse-MoE 应用于 RankMixer 会出现性能退化，主要原因包括以下两点：

1）**均匀的 K 专家路由问题**。  
传统的 Top-K 专家选择机制对所有特征 token 一视同仁，这会导致有限的专家计算预算被浪费在信息量较低的 token 上，而对信息量更高、更加关键的 token 分配不足，从而削弱模型区分不同 token 重要性的能力。

2）**专家训练不足问题**。  
逐 token FFN 本身已经使参数规模随着 token 数量线性增长；若再为每个 token 引入不共享的专家集合，将导致专家总数急剧膨胀，进而引发严重的路由不均衡问题，使大量专家样本覆盖不足、训练不充分。

为了解决上述问题，我们结合了两种互补的训练策略。

#### ReLU 路由（ReLU Routing）

为了赋予不同 token 更灵活的专家激活数量，同时保持路由过程的可微性，我们将常见的 **Top-K + softmax** 路由方式替换为 **ReLU 门控（ReLU gate）结合自适应 ℓ1 正则项** 的方法 \[35\]。

具体而言，给定第 (i) 个 token \\(x\_i \\in \\mathbb{R}^{d\_h}\\)，以及其对应的路由函数 \\(h(\\cdot)\\) 和第 (k) 个专家 \\(f\_{i,k}(\\cdot)\\)，专家的路由权重定义为：

\\\[g\_{i,k} = \\mathrm{ReLU}\\big( h(x\_i)\_k \\big), \\\]

其中，ReLU 门控会自动将得分为负的专家权重置零，从而实现稀疏激活；同时，通过在训练过程中引入自适应的 ℓ1 正则约束，可以控制每个 token 实际激活的专家数量，使其根据 token 的信息复杂度自适应变化。

### 3.5 规模扩展方向

RankMixer 本质上是一种高度并行且可扩展的架构。其参数规模和计算成本可以沿着四个相互正交的维度进行扩展：

*   Token 数量 ( T )
*   模型宽度 ( D )
*   层数 ( L )
*   专家数量 ( E )

对于**全密集激活版本（full-dense-activated version）**，单条样本的参数量和前向计算量（FLOPs）近似为：

\\\[Param \\approx 2 k L T D^2 \\\]

\\\[FLOPs \\approx 4 k L T D^2 \\\]

其中：

*   ( k ) 是用于调节 FFN 隐藏层维度的放大比例（即 FFN 隐层维度通常为 ( kD )）。
*   ( L ) 是层数
*   ( T ) 是 token 数
*   ( D ) 是每个 token 的维度

可以看到，其规模增长规律与 Transformer 类似，主要呈现为对 ( D^2 ) 的二次依赖。

在 **Sparse-MoE 版本** 中，每个 token 的有效参数量和计算量还会额外受到稀疏比例的影响：

\\\[s = \\frac{Activated\_Param}{Total\_Param} \\\]

也就是说：

*   总参数量可能非常大（因为有大量专家）
*   但每次前向只激活其中一部分专家
*   实际计算成本约为 dense 版本乘以稀疏比例 ( s )

因此，通过增加专家数量 ( E ) 可以显著扩大模型容量，而计算开销保持相对可控。

整体而言，这一段强调的是：

RankMixer 的扩展方式是“结构正交”的——  
可以独立增加 token 数、宽度、深度或专家数，而每个方向对参数量和计算量的影响是可解析、可控的。

第 4 节 实验
--------

### 4.1 实验设置

#### 4.1.1 数据集与环境

离线实验使用的是来自 Douyin 推荐系统的训练数据。这些数据来源于 Douyin 的线上日志以及用户反馈标签。

训练数据包含 300 多种特征类型，包括：

*   数值特征
*   ID 特征
*   交叉特征
*   序列特征

数据规模非常庞大，涉及：

*   数十亿级别的用户 ID
*   数亿级别的视频 ID

上述 ID 均被转换为 embedding 表示。

数据规模达到每天万亿级别记录，实验基于连续两周的数据进行训练与评估。

#### 4.1.2 评估指标

性能指标分为两类：效果指标与效率指标。

效果指标包括：

AUC（Area Under the Curve）  
UAUC（User-level AUC）

评估目标为 Finish/Skip 标签：

*   finish = 1/0 表示用户是否完整观看视频
*   skip = 1/0 表示用户是否在短时间内滑走

实验报告的是该 finish 标签对应的 AUC 与 UAUC。

在该场景下，AUC 提升 0.0001 即可认为是具有统计显著性的提升。

效率指标包括：

Dense-Param  
仅统计 dense 部分参数量（不包括稀疏 embedding 参数）。

Training FLOPs / Batch  
单个 batch（大小为 512）前向与反向传播所需的浮点运算次数，用于衡量训练计算成本。

MFU（Model FLOPs Utilization）  
衡量模型对硬件浮点算力的利用率：

MFU = 实际使用 FLOPs / 硬件理论 FLOPs 上限

#### 4.1.3 对比方法

对比模型包括多个公认的 SOTA 方法：

DLRM-MLP  
作为基础 MLP 特征交叉模型。

DCNv2、RDCN  
典型的显式特征交叉模型。

MoE  
通过并行专家扩展模型容量。

AutoInt、Hiformer  
基于自注意力的特征交互方法，其中 Hiformer 结合了异构 self-attention 与低秩近似。

DHEN  
融合多种特征交叉模块（DCN / self-attention / FM / LR）的多层堆叠结构。

Wukong  
在 DHEN 框架基础上研究特征交互的 scaling law，引入 FMB 与 LCB 结构。

训练环境：

*   数百张 GPU
*   混合分布式训练
*   稀疏部分（embedding）异步更新
*   dense 部分同步更新

优化器设置统一：

*   dense 部分使用 RMSProp，学习率 0.01
*   sparse 部分使用 Adagrad

### 4.2 与 SOTA 方法对比

为了研究模型扩展能力，作者将模型参数规模控制在约 1 亿左右，在相近参数量下比较不同结构的效果与计算成本。

实验结果显示，RankMixer 在多个目标和指标上显著优于其他 SOTA 模型。

具体分析如下：

首先，简单将 DLRM 扩展到 1 亿参数，仅带来有限收益，说明推荐模型的 scaling 不能依赖简单堆参数，而需要结构设计与推荐数据特性匹配。

其次，与 DCN、RDCN、AutoInt、DHEN 等经典交叉结构相比，这些模型存在参数量与 FLOPs 不匹配的问题：

*   即便参数规模不大
*   计算量已经显著上升

说明其结构设计在计算效率上存在瓶颈，从而限制了进一步扩展能力。

RankMixer 在达到 1 亿参数规模时：

*   取得最优效果
*   FLOPs 处于相对中等水平

体现出模型容量与计算负载之间的平衡性。

此外，与 Hiformer 和 Wukong 等 scaling 模型相比，在相近参数规模下，RankMixer：

*   效果更优
*   计算需求更低

整体结论是：

RankMixer 在大规模推荐场景下，表现出更优的扩展效率（scaling efficiency），在参数增长时能够更有效地转化为性能提升，同时保持较合理的计算成本。

### 4.3 不同模型的 Scaling Law

图 2 展示了从参数规模和 FLOPs 两个维度观察到的 scaling law 曲线。

RankMixer 在参数规模和 FLOPs 两个坐标下都呈现出最陡峭的 scaling 曲线，意味着在参数或计算量增加时，其性能提升最为显著，整体始终优于其他模型。

Wukong 虽然在参数维度上曲线较陡，但其计算成本增长更快。因此，在 AUC–FLOPs 曲线上，与 RankMixer 和 Hiformer 的差距进一步拉大。

Hiformer 的性能略低于 RankMixer，反映出其依赖特征级 token 切分以及 Attention 机制，在效率上存在劣势。

DHEN 的 scaling 表现不理想，说明其特征交叉结构的可扩展性有限。

MoE 通过增加专家数进行扩展，但在专家负载均衡方面存在困难，导致扩展效率不佳。

具体到 RankMixer，本模型可通过三个方向进行扩展：

*   增加宽度 (D)
*   增加特征 token 数 (T)
*   增加层数 (L)

实验观察到一个与大语言模型 scaling law 相似的现象：

模型质量主要与总参数量相关，不同扩展方向（增加深度 L、宽度 D 或 token 数 T）带来的性能提升几乎一致。

从计算效率角度看：

*   增大隐藏维度 (D) 会产生更大的矩阵乘法规模
*   更容易获得较高的 MFU
*   比单纯增加层数更具硬件效率

因此最终配置为：

*   100M 模型：(D=768, T=16, L=2)
*   1B 模型：(D=1536, T=32, L=2)

可以看出，作者更偏向通过“加宽 + 增加 token 数”而非“加深层数”来扩展模型。

### 4.4 消融实验

表 2：RankMixer-100M 组件消融

*   去除 skip connection：AUC −0.07%
*   去除 Multi-Head Token-Mixing：AUC −0.50%
*   去除 LayerNorm：AUC −0.05%
*   将 per-token FFN 改为共享 FFN：AUC −0.31%

可以看到：

Multi-Head Token-Mixing 的影响最大。若去除该模块，则每个 FFN 只能建模局部特征，无法获得跨 token 的全局信息。

去除残差连接或 LayerNorm 会降低训练稳定性，更容易出现梯度爆炸或消失。

将 per-token 独立 FFN 改为共享 FFN 会削弱“特征子空间独立建模”的能力。

* * *

表 3：Token2FFN 路由策略对比

对比对象包括：

All-Concat-MLP  
将所有 token 拼接后通过一个大 MLP，再拆分回多个 token。  
AUC −0.18%，FLOPs 不变。  
性能下降说明大规模矩阵学习困难，同时削弱局部子空间建模能力。

All-Share  
不进行 token 划分，整体输入共享给所有 per-token FFN，类似 MoE。  
AUC −0.25%。  
性能明显下降，说明特征子空间划分与独立建模至关重要。

Self-Attention  
用自注意力进行 token 路由。  
AUC −0.03%，但 FLOPs +71.8%。  
性能略逊于 Multi-Head Token-Mixing，同时计算成本显著增加，表明在数百个特征子空间之间学习相似性非常困难且代价高昂。

整体结论是：

RankMixer 的核心优势来自于：

*   明确的特征子空间划分
*   轻量级、无参数的 token mixing
*   每个子空间独立的 FFN 建模

该设计在性能、计算效率与扩展能力之间取得了较优平衡。

### 4.5 Sparse-MoE 的可扩展性与专家均衡

可扩展性  

图 3 展示了离线 AUC 随 SMoE 稀疏度变化的曲线。实验表明，将 Dense-Training-Sparse-Inference（DTSI）与 ReLU 路由结合，对于在高稀疏率下保持模型精度至关重要。

该策略可以：

*   将模型参数容量（以及显存占用）扩展超过 8 倍
*   几乎不损失 AUC
*   推理吞吐提升约 50%

相比之下，传统（Vanilla）Sparse-MoE 随着激活专家数量减少，性能单调下降，验证了作者指出的两个问题：

*   专家负载不均
*   专家训练不足

引入 load-balancing loss 虽然缓解了性能下降，但仍不如 DTSI + ReLU 方案。原因在于问题核心并非路由器本身，而是专家训练不足。

因此，Sparse-MoE 被验证为将 RankMixer 从 1B 扩展到未来 10B 规模的可行路径，并且不会突破成本预算。

专家均衡与多样性

传统 Sparse-MoE 往往出现专家失衡：

*   部分专家几乎从不被激活（“死亡专家”）
*   少数专家长期高频激活

图 4 表明：

DTSI（密集训练、稀疏推理）+ ReLU 路由 可以有效解决该问题。

Dense training 确保大多数专家在训练阶段获得充分梯度更新，避免专家“饿死”。

ReLU 路由使不同 token 的激活比例动态变化——激活比例会根据 token 信息量自适应调整，这与推荐数据高度动态、分布多样的特性相匹配。

* * *

### 4.6 在线推理成本

问题：参数规模提升两个数量级，如何避免推理延迟爆炸？

在实际系统中：

*   延迟与吞吐成反比
*   延迟与机器资源成本成正比

与此前 1600 万参数（DLRM + DCN）模型相比，RankMixer 扩展至 1B 参数，约提升 70 倍。但推理延迟保持稳定。

延迟可分解为：

Latency = (Param × FLOPs/Param ratio) / (MFU × 硬件理论 FLOPs)

两数量级的参数增长，被以下因素逐步抵消：

*   FLOPs/Param ratio 降低 3.6 倍
*   MFU 提升 10 倍
*   量化带来 2 倍硬件 FLOPs 提升

(1) FLOPs/Param 比

RankMixer 参数增长 70 倍，但 FLOPs 仅增长约 20 倍。

其 FLOPs/Param 比仅为基线模型的三分之一，相当于 3.6 倍效率提升。

即在同等 FLOPs 预算下，可容纳三倍参数量。

(2) MFU（模型 FLOPs 利用率）

通过：

*   大规模 GEMM 形状
*   并行 per-token FFN 融合为单 kernel
*   减少内存带宽开销

MFU 提升约 10 倍，使模型从 memory-bound 转为 compute-bound。

(3) 量化

采用半精度（fp16）推理，使 GPU 理论峰值 FLOPs 提升 2 倍。

RankMixer 的主要计算为大矩阵乘法，非常适合 fp16。

* * *

### 4.7 在线效果

为验证 RankMixer 作为统一扩展推荐框架的泛化能力，作者在两个核心场景进行线上实验：

*   信息流推荐（Feed Recommendation）
*   广告推荐（Advertising）

指标包括：

Feed 推荐

*   Active Days：实验期内用户平均活跃天数（DAU 替代指标）
*   Duration：App 停留总时长
*   Finish / Like / Comment：播放完成数、点赞数、评论数

广告

*   ΔAUC
*   ADVV（广告主价值）

基线模型为 1600 万参数（DLRM + DCN）。

替换 dense 部分为 RankMixer-1B 后，AUC 提升 0.7%。

A/B 测试结果显示：

RankMixer 在所有关键业务指标上取得统计显著提升。

其中，低活跃用户群体提升最大：

Active Days 提升超过 1.7412%，表明模型具备较强泛化能力。

最终结论是：

RankMixer 作为统一骨干模型，在不同个性化排序场景中表现稳定且具扩展能力。

5 结论
----

本文提出的 RankMixer 已在 Douyin Feed 排序系统中全面部署。

其核心优势在于：

*   面向异构特征交互的结构设计
*   高度并行、硬件友好的架构

实验验证其性能优越且具有陡峭的 scaling law。

上线后，在 Douyin App 上实现：

*   Active Days 提升 0.3%
*   App 停留时长提升 1%

表明其在工业大规模推荐系统中的有效性与可扩展性。

posted on 2026-02-21 12:19  [GlenTt](https://www.cnblogs.com/GlenTt)  阅读(20)  评论(0)    [收藏](javascript:void\(0\))  [举报](javascript:void\(0\))