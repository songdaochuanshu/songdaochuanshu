---
layout: post
title: 'GPFS并行文件系统部署实践'
date: "2025-04-21T00:42:28Z"
---
GPFS并行文件系统部署实践
==============

### 环境

ubuntu22.04

试用版下载链接

    https://www.ibm.com/cn-zh/products/storage-scale
    

我的版本：Storage\_Scale\_Developer-5.2.2.1-x86\_64-Linux

    apt install -y build-essential linux-headers-$(uname -r)
    

hosts

    172.23.170.11 ubuntu1
    172.23.170.12 ubuntu2
    172.23.170.13 ubuntu3
    172.23.170.14 ubuntu4
     
    172.23.170.101 ces1.imalloc.cn ces1
    172.23.170.102 ces2.imalloc.cn ces2
    172.23.170.103 ces3.imalloc.cn ces3
    

### 安装

    # 解压后安装
    ./Storage_Scale_Developer-5.2.2.1-x86_64-Linux-install --text-only
    
    # 配置安装节点
    cd /usr/lpp/mmfs/5.2.2.1/ansible-toolkit/
    ./spectrumscale setup -s 172.23.170.101
    
    # 添加节点并查看配置
    ./spectrumscale node add ubuntu1 -a -g -n -m -q
    ./spectrumscale node add ubuntu2 -a -g -n -q
    ./spectrumscale node add ubuntu3 -n -q
    ./spectrumscale node list
    

**参数-a**、**\-g**、**\-n**、**\-m** 和 **\-q** 分别表示不同类型的节点，这些节点在 GPFS 集群中扮演不同的角色。以下是它们的具体作用：

1.  **\-a 表示 Admin 节点（管理节点）：**
    *   Admin 节点是 GPFS 集群的管理员节点，主要负责管理集群的配置、监控和维护任务。
    *   它通常用于运行 GPFS 管理命令，例如创建文件系统、添加或删除节点、配置策略等。
    *   Admin 节点可以有多台，但通常由系统管理员指定一台或几台节点作为主要的管理节点。
2.  **\-g 表示 GUI 节点（图形用户界面节点）：**
    *   GUI 节点用于运行 GPFS 的图形用户界面工具，方便管理员通过可视化界面管理集群。
    *   它提供了一个友好的界面来监控文件系统的性能、节点状态和执行管理任务，而无需使用命令行。
    *   并非所有 GPFS 部署都需要 GUI 节点，这取决于是否需要图形化管理。
3.  **\-n 表示 NSD 节点（Network Shared Disk 节点）：**
    *   NSD 节点负责管理 GPFS 的存储设备（磁盘）。它是 GPFS 数据存储和访问的核心节点。
    *   这些节点直接与物理存储（例如 SAN 或本地磁盘）交互，并确保数据在集群中的分布和冗余。
    *   每个 NSD 节点都可以为文件系统提供存储空间，并且多个 NSD 节点协作以提高性能和容错能力。
4.  **\-m 表示 Manager 节点（管理器节点）：**
    *   Manager 节点负责协调 GPFS 集群中的元数据操作。元数据包括文件系统结构、文件位置等信息。
    *   在 GPFS 中，Manager 节点确保所有节点对文件系统的元数据有一致的视图，并处理锁管理和数据一致性。
    *   通常会有多个 Manager 节点以提供高可用性，如果主 Manager 节点失败，备用 Manager 节点会接管。
5.  **\-q 表示 Quorum 节点（仲裁节点）：**
    *   Quorum 节点用于确保集群在节点失败或网络分区的情况下保持稳定。
    *   GPFS 使用仲裁机制来决定集群是否可以继续运行。例如，只有当大多数 Quorum 节点在线时，集群才能正常工作，这防止了数据不一致或“分裂脑”问题。
    *   Quorum 节点的数量和位置需要仔细规划，以保证高可用性和容错能力。

### 添加磁盘

    ./spectrumscale nsd add -p ubuntu1 -fs gpfs -fg 101 -po system -u dataAndMetadata "/dev/sdb"
    ./spectrumscale nsd add -p ubuntu1 -fs gpfs -fg 101 -po pool01 -u dataOnly "/dev/sdc"
    ./spectrumscale nsd add -p ubuntu1 -fs gpfs -fg 101 -po pool02 -u dataOnly "/dev/sdd"
    ./spectrumscale nsd add -p ubuntu2 -fs gpfs -fg 102 -po system -u dataAndMetadata "/dev/sdb"
    ./spectrumscale nsd add -p ubuntu2 -fs gpfs -fg 102 -po pool01 -u dataOnly "/dev/sdc"
    ./spectrumscale nsd add -p ubuntu2 -fs gpfs -fg 102 -po pool02 -u dataOnly "/dev/sdd"
    ./spectrumscale nsd add -p ubuntu3 -fs gpfs -fg 103 -po system -u dataAndMetadata "/dev/sda"
    ./spectrumscale nsd add -p ubuntu3 -fs gpfs -fg 103 -po pool01 -u dataOnly "/dev/sdb"
    ./spectrumscale nsd add -p ubuntu3 -fs gpfs -fg 103 -po pool02 -u dataOnly "/dev/sdc"
    ./spectrumscale nsd list
    

#### 命令结构和参数说明

基本命令是 **./spectrumscale nsd add**，用于向 GPFS 集群添加新的 NSD 设备。以下是每个参数的含义：

*   **\-p `<node>`**：指定 NSD 设备所在的节点。在你的例子中，节点分别是 **ubuntu1**、**ubuntu2** 和 **ubuntu3**。这表示这些 NSD 设备将挂载在指定的节点上。
*   **\-fs `<filesystem>`**：指定要添加 NSD 设备的文件系统名称。在所有命令中，文件系统名称都是 **gpfs**，意味着这些 NSD 设备都属于同一个 GPFS 文件系统。
*   **\-fg `<failure group>`**：指定故障组 (Failure Group)。故障组用于确保数据的高可用性和容错能力。如果一个故障组中的节点或磁盘失败，其他故障组的节点可以接管。命令中使用了三个不同的故障组：**101**（用于 **ubuntu1**）、**102**（用于 **ubuntu2**）和 **103**（用于 **ubuntu3**）。
*   **\-po `<pool>`**：指定存储池 (Storage Pool)。存储池是 GPFS 中用于组织和管理存储空间的逻辑分组。命令中使用了三个存储池：
    *   **system**：通常用于存储元数据和关键数据。
    *   **pool01** 和 **pool02**：用户数据存储池，可能用于不同的性能或容量需求。
*   **\-u `<usage>`**：指定 NSD 的使用类型：
    *   **dataAndMetadata**：该磁盘用于存储数据和元数据（适用于关键存储，如 **system** 存储池）。
    *   **dataOnly**：该磁盘仅用于存储数据，不存储元数据（适用于大规模数据存储，如 **pool01** 和 **pool02**）。
*   **"/dev/sdX"**：指定实际的物理设备或分区路径，例如 **/dev/sdb**、**/dev/sdc** 等。这些是将被用作 NSD 的底层存储设备。

### **副本数量与挂载点**

    ./spectrumscale filesystem list
    ./spectrumscale filesystem modify gpfs -mr 2 -MR 3 -r 2 -R 3 -m /gpfs
    ./spectrumscale filesystem list
    

**参数说明**

*   **\-r**
    
    指定每个数据块的文件副本数。该参数接受以下值：1、2、3。
    
*   **\-mr**
    
    指定inode和目录的副本数。该参数接受以下值：1、2、3。
    
*   **\-MR**
    
    指定inode和目录的默认最大副本数。该参数接受以下值：1、2、3。
    
*   **\-R**
    
    指定每个数据块的文件的默认最大副本数。该参数接受以下值：1、2、3。
    

**\-m `<mountpoint>`**：指定文件系统的挂载点。在这里，**\-m /gpfs** 表示文件系统 **gpfs** 将挂载在 **/gpfs** 目录下。这是客户端访问文件系统时使用的路径。

### 其他配置

    # 开启性能监控，默认已经打开
    ./spectrumscale config perfmon -r on
    
    # 通讯端口
    ./spectrumscale config gpfs -c gpfsdemo -e 60000-61000
    
    # Callhome 功能
    ./spectrumscale callhome disable
    

### GPFS集群部署

    # 检查配置
    ./spectrumscale install --precheck
    
    # 安装
    ./spectrumscale install
    

### GUI配置

    /usr/lpp/mmfs/gui/cli/mkuser admin -g Administrator,SecurityAdmin
    

### 部署CES服务（可选）

    echo "172.23.170.101 ces1.imalloc.cn ces1">>/etc/hosts
    echo "172.23.170.102 ces2.imalloc.cn ces2">>/etc/hosts
    echo "172.23.170.103 ces3.imalloc.cn ces3">>/etc/hosts
    
    ./spectrumscale node add ubuntu1 -p
    ./spectrumscale node add ubuntu2 -p
    ./spectrumscale node add ubuntu3 -p
    ./spectrumscale node list
    
    # 我的另外一张网卡，发布服务
    ./spectrumscale config protocols -e 172.23.170.101,172.23.170.102,172.23.170.103
    
    # 配置cesShareRoot
    ./spectrumscale config protocols -f gpfs -m /gpfs
    
    # 开启NFS和SMB服务协议
    ./spectrumscale enable nfs
    ./spectrumscale enable smb
    
    # 检查配置
    ./spectrumscale deploy --precheck
    # 部署
    ./spectrumscale deploy
    

### 配置CES（可选）

    # 认证方式本地认证
    /usr/lpp/mmfs/bin/mmuserauth service create --data-access-method file --type userdefined
    
    # 添加用户
    useradd cestest
    /usr/lpp/mmfs/bin/smbpasswd -a cestest
    
    # 发布SMB
    mkdir /gpfs/smbshare1
    chown cestest /gpfs/smbshare1
    /usr/lpp/mmfs/bin/mmsmb export add smbshare1 /gpfs/smbshare1
    
    #访问
    \\172.23.170.101\smbshare1
    

### 添加GPFS客户端

    ./spectrumscale node add FQDN
    ./spectrumscale callhome disable
    
    ./spectrumscale install --precheck
    ./spectrumscale install
    

![](https://img2024.cnblogs.com/blog/1639143/202504/1639143-20250420192141802-1136295584.png)

![](https://img2024.cnblogs.com/blog/1639143/202504/1639143-20250420192152096-1870762840.png)

![](https://img2024.cnblogs.com/blog/1639143/202504/1639143-20250420192159001-326129131.png)

### 命令参考

https://www.ibm.com/docs/en/storage-scale/5.2.2