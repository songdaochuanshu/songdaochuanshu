---
layout: post
title: '当Claude Code负责人说"编程已解决"，测试工程师该慌吗？'
date: "2026-02-23T00:58:49Z"
---
当Claude Code负责人说"编程已解决"，测试工程师该慌吗？
=================================

> Claude Code负责人Lenny Rachitsky抛出"Coding is solved"的观点，引发技术圈热议。作为测试工程师，我们该如何看待这场AI革命？是恐慌、抗拒，还是拥抱？

背景：一句话炸翻技术圈
-----------

前几天刷到Claude Code负责人Lenny Rachitsky的访谈，他说了句让整个技术圈炸锅的话：

**"Coding is solved"（编程已解决）**

这话什么意思？简单说就是：有了Claude Code这样的AI编程助手，写代码已经不是问题了，未来的开发者主要工作是"提出正确的问题"而不是"写代码"。

说实话，看到这句话的第一反应，我心里咯噔一下。

作为一名测试老兵，这些年一直在努力提升代码能力，为了更好地做自动化测试、看懂开发同事的代码、定位Bug的根因。现在告诉我"写代码不重要了"，那我这些年积累的技能是不是要废了？

但冷静下来想了一周，又实际试用了Claude Code，我发现事情没那么简单。

今天就从测试工程师的视角，聊聊我对"Coding is solved"这个观点的真实感受，以及我们这个职业在AI时代的真正价值。

* * *

核心内容
----

### Claude Code到底有多强？

先说体验。我用Claude Code帮我重构了一个单元测试模块，总共300多行代码。

**之前我的做法**：

1.  理解业务逻辑，画时序图
2.  设计测试用例，考虑边界条件
3.  手写Mock对象
4.  一行行写断言
5.  跑测试，修复失败的用例
6.  补充遗漏的场景
7.  整个过程大概4-5小时

**用Claude Code之后**：

1.  描述需求："帮我为这个UserService类写单元测试，覆盖正常、异常、边界场景，使用Mockito"
2.  Claude Code分析代码，自动生成测试
3.  检查生成的测试，补充几个特殊场景
4.  跑测试，全绿
5.  整个过程不到40分钟

这效率提升确实让人惊艳。从这个角度看，"Coding is solved"也不是完全没有道理——**常规的、套路化的编程工作，AI确实可以做得又快又好**。

但是（重点来了），真的就"解决"了吗？

* * *

### "Coding is solved"背后的真相

我觉得这句话只说对了一半。更准确的表述应该是：

**"Template coding is solved"（模板化编程已解决）**

但真正考验技术功力的"复杂编程"，AI还远没到"解决"的程度。

我试了几个场景，发现Claude Code的局限：

**场景1：业务逻辑复杂的测试用例**

我让Claude Code为一个涉及多状态流转的订单系统写集成测试。它生成了大概80%的代码，但缺失了几个关键场景：

*   订单在"待支付"状态下的超时取消逻辑
*   并发创建订单时的库存一致性校验
*   优惠券叠加使用的边界条件

这些场景都需要深入理解业务才能设计出来，AI只能看到代码，看不到业务背后的规则。

**场景2：性能测试的脚本设计**

我让Claude Code帮我写一个JMeter压测脚本。它能生成基本的HTTP请求配置，但对于以下问题束手无策：

*   如何根据线上流量分布设计TPS目标？
*   如何模拟真实用户的操作路径，而不是随机请求？
*   如何设计数据预热策略，避免冷启动影响测试结果？

这些都需要经验和判断，AI目前做不到。

**场景3：缺陷定位的深度分析**

我故意模拟了一个偶发的空指针异常，日志里只有堆栈信息，没有业务上下文。我让Claude Code帮忙分析，它给出了几个可能的"常见原因"，但都没抓住关键。

最后还是需要靠：

1.  梳理业务流程，找到可疑的代码路径
2.  在可疑位置加日志，重新复现
3.  通过日志对比，定位到真正的问题

这个过程需要推理、假设、验证，AI目前只能做到"基于已有模式的匹配"，做不到"基于业务理解的推理"。

* * *

### 测试工程师的真正价值在哪里？

"Coding is solved"这句话如果真成立，那测试工程师的价值在哪里？

我认为，**测试工程师的核心价值从来就不是"写代码"本身，而是"发现问题的能力"和"保证质量的思维"**。

代码只是工具，不是目的。

让我换个角度说：

**AI可以帮你写测试脚本，但它不能决定"测什么"**  
**AI可以帮你生成测试数据，但它不能判断"什么数据是有效的"**  
**AI可以帮你执行测试用例，但它不能设计"如何让系统崩溃"**

这些都需要测试工程师的专业判断。

* * *

### 实战案例：AI做不了的测试

分享一个朋友公司案例。去年他们公司上线了一个新的推荐系统，负责算法的团队信心满满，说准确率提升了15%。

但测试团队发现了几个严重问题：

**问题1：冷启动偏差**  
新用户第一次打开App，推荐结果全是热门内容，完全没有个性化。这说明推荐系统对"新用户"这个特殊场景考虑不足。

AI生成的测试用例都是基于正常用户行为设计的，想不到"刚注册的空白用户"这种边缘场景。

**问题2：时间衰减异常**  
晚上推荐的内容跟中午完全一样，没有考虑用户兴趣的时间变化。比如用户中午看美食，晚上看娱乐，但推荐系统没有捕捉到这个模式。

这需要对用户行为模式有深入理解，AI看不到业务背后的逻辑。

**问题3：长尾内容曝光异常**  
热门内容的曝光率超过90%，中长尾内容几乎没有机会。这会导致内容生态恶化，长期看对平台不利。

这需要从产品战略高度思考，AI做不到。

**这些问题都不是"写代码"能解决的，而是需要测试思维、业务理解、产品视角。**

AI能帮你快速写出测试脚本，但这些脚本"测什么"、"怎么测"、"测到什么程度"，必须由人来决定。

* * *

### 优缺点分析

#### Claude Code这类AI工具的优点

1.  **效率提升明显**
    
    *   常规测试脚本的编写速度提升5-10倍
    *   减少重复劳动，让人专注更重要的工作
2.  **降低技术门槛**
    
    *   新手测试工程师也能快速上手自动化测试
    *   不需要深入学习各种测试框架的细节
3.  **代码质量稳定**
    
    *   生成的代码符合最佳实践
    *   减少低级错误

#### 局限性

1.  **业务理解不足**
    
    *   看不到代码背后的业务逻辑
    *   难以设计针对业务漏洞的测试用例
2.  **边缘场景覆盖差**
    
    *   更倾向于测试"正常路径"
    *   对异常、边界、并发场景考虑不足
3.  **复杂推理能力弱**
    
    *   无法进行深度的缺陷根因分析
    *   难以设计复杂的测试策略

#### 适用场景

*   ✅ **单元测试**：生成基础测试用例效率很高
*   ✅ **API接口测试**：快速生成请求和断言
*   ✅ **UI自动化脚本**：录制回放场景效率提升明显

#### 不适用场景

*   ❌ **复杂业务场景的测试设计**：需要深入理解业务
*   ❌ **性能测试策略制定**：需要经验和判断
*   ❌ **安全测试**：需要攻击思维和漏洞知识

* * *

### 最佳实践/建议

基于我的使用经验，给测试工程师几个实用建议：

#### 1\. 把AI当助手，不是替代品

**正确用法**：

*   AI生成基础代码 → 你补充业务逻辑
*   AI提供测试用例 → 你设计边缘场景
*   AI执行自动化测试 → 你分析测试结果

**错误用法**：

*   AI生成什么就用什么，不检查
*   完全依赖AI设计测试策略
*   把AI的输出当成最终结果

#### 2\. 提升不可替代的核心能力

既然AI能帮你写代码，那你应该把精力放在AI做不了的事情上：

**业务理解能力**

*   深入了解产品背后的业务逻辑
*   能识别业务规则中的漏洞和风险点

**测试设计能力**

*   能设计出覆盖全面的测试策略
*   能想到AI想不到的边缘场景

**缺陷分析能力**

*   能从表面现象推导根本原因
*   能提供有价值的修复建议

**沟通协调能力**

*   能跟开发、产品、运维有效沟通
*   能推动质量问题的解决

#### 3\. 学会"提问"比"写代码"更重要

Claude Code负责人的观点有道理：未来更重要的是"提出正确的问题"。

对测试工程师来说，这意味着：

*   能清晰地描述测试需求
*   能给出充分的上下文信息
*   能对AI的输出进行有效反馈

比如，不要只说"帮我写个测试"，而要说：

    帮我为PaymentService的processPayment方法写单元测试，
    场景包括：
    1. 正常支付流程（成功扣款、订单状态更新）
    2. 余额不足（抛出InsufficientBalanceException）
    3. 支付超时（模拟第三方支付接口超时）
    4. 并发支付（同一订单多次支付）
    使用Mockito模拟依赖的PaymentGateway和OrderRepository，
    确保测试是独立的，不依赖外部系统。
    

这样AI才能生成真正有用的测试代码。

#### 4\. 保持学习，但不要焦虑

AI确实在改变这个行业，但不是在"消灭"这个职业，而是在"升级"这个职业。

历史上每一次技术革命都会引发恐慌：

*   计算器出现时，有人说会计会失业
*   Excel出现时，有人说统计员会失业
*   自动化测试出现时，有人说手工测试会失业

但结果呢？

*   会计转型为财务分析师
*   统计员转型为数据科学家
*   手工测试工程师转型为自动化测试工程师

**每一次技术革命，淘汰的不是职业，而是"只做重复劳动"的人。**

* * *

### 未来展望

**我的判断**：

未来3-5年，测试工程师这个职业不会消失，但会两极分化：

**低端测试**（重复执行、简单脚本）会被AI取代  
**高端测试**（测试设计、质量策略、风险控制）会更值钱

测试工程师的技能树会从：

*   编码能力 → 测试设计能力
*   工具使用 → 业务理解
*   执行测试 → 质量规划

**简单说：AI帮你写测试脚本，你来设计测什么、怎么测、测到什么程度。**

* * *

总结
--

回到开头的问题："当Claude Code负责人说'编程已解决'，测试工程师该慌吗？"

我的答案是：**不该慌，但该变。**

不该慌，因为测试工程师的核心价值从来就不是"写代码"，而是"保证质量"。AI能帮你写测试脚本，但它不能代替你设计测试策略、分析业务风险、发现隐藏缺陷。

该变，因为AI确实在改变这个行业的规则。如果你只会写简单的测试脚本、执行重复的测试用例，那确实该焦虑了。但如果你具备业务理解能力、测试设计能力、缺陷分析能力，AI反而会成为你的武器，让你更高效地工作。

**未来不属于会写代码的测试工程师，也不属于会用AI的测试工程师，而是属于"懂业务、会设计、善用AI"的测试工程师。**

所以，别慌，学起来。

* * *

参考资料
----

1.  [Claude Code Creator: "Coding is solved"访谈](https://www.lennysnewsletter.com/p/head-of-claude-code-what-happens)
2.  [Large Language Model Reasoning Failures论文](https://arxiv.org/abs/2602.06176)
3.  [Claude Code CLI资源消耗问题讨论](https://old.reddit.com/r/ClaudeCode/comments/1qazqq6/confirmed_claude_code_cli_burns_13_of_your_quota/)

**优秀不够，你是否无可替代**

**软件测试交流QQ群：721256703，期待你的加入！！**

**欢迎关注我的微信公众号：软件测试君**

![](https://www.cnblogs.com/images/cnblogs_com/longronglang/1061549/o_QQ%E6%88%AA%E5%9B%BE20190728134401.jpg)