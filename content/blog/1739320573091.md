---
layout: post
title: 'LangChain基础篇 (05)'
date: "2025-02-12T00:36:13Z"
---
LangChain基础篇 (05)
=================

LangChain 核心模块：Data Conneciton - Document Transformers
======================================================

一旦加载了文档，通常会希望对其进行转换以更好地适应您的应用程序。

最简单的例子是，您可能希望将长文档拆分为较小的块，以适应模型的上下文窗口。LangChain具有许多内置的文档转换器，可以轻松地拆分、合并、过滤和其他操作文档。

Text Splitters 文本分割器
--------------------

当你想处理长篇文本时，有必要将文本分成块。听起来很简单，但这里存在着潜在的复杂性。理想情况下，你希望将语义相关的文本片段放在一起。

从高层次上看，文本分割器的工作原理如下：

1.  将文本分成小而有意义的块（通常是句子）。
2.  开始将这些小块组合成较大的块，直到达到某个大小（通过某个函数进行测量）。
3.  一旦达到该大小，使该块成为自己独立的一部分，并开始创建一个具有一定重叠（以保持上下文关系）的新文本块。

这意味着您可以沿两个不同轴向定制您的文本分割器：

**1\. 如何拆分文字**  
**2\. 如何测量块大小**

### 使用 `RecursiveCharacterTextSplitter` 文本分割器

该文本分割器接受一个字符列表作为参数，根据第一个字符进行切块，但如果任何切块太大，则会继续移动到下一个字符，并以此类推。默认情况下，它尝试进行切割的字符包括 `["\n\n", "\n", " ", ""]`

除了控制可以进行切割的字符外，您还可以控制其他一些内容：

*   length\_function：用于计算切块长度的方法。默认只计算字符数，但通常在这里传递一个令牌计数器。
*   chunk\_size：您的切块的最大大小（由长度函数测量）。
*   chunk\_overlap：切块之间的最大重叠部分。保持一定程度的重叠可以使得各个切块之间保持连贯性（例如滑动窗口）。
*   add\_start\_index：是否在元数据中包含每个切块在原始文档中的起始位置。

LangChain 核心模块：Data Conneciton - Text Embedding Models
======================================================

Embeddings类是一个专门用于与文本嵌入模型进行交互的类。有许多嵌入模型提供者（OpenAI、Cohere、Hugging Face等）-这个类旨在为所有这些提供者提供一个标准接口。

嵌入将一段文本创建成向量表示。这非常有用，因为它意味着我们可以在向量空间中思考文本，并且可以执行语义搜索等操作，在向量空间中寻找最相似的文本片段。

LangChain中基础的Embeddings类公开了两种方法：**一种用于对文档进行嵌入，另一种用于对查询进行嵌入。**前者输入多个文本，而后者输入单个文本。之所以将它们作为两个独立的方法，是因为某些嵌入提供者针对要搜索的文件和查询（搜索查询本身）具有不同的嵌入方法。

使用 OpenAIEmbeddings 调用 OpenAI 嵌入模型
----------------------------------

### 使用 embed\_documents 方法嵌入文本列表

    from langchain_openai import OpenAIEmbeddings
    

    embeddings_model = OpenAIEmbeddings()
    

    embeddings = embeddings_model.embed_documents(
        [
            "Hi there!",
            "Oh, hello!",
            "What's your name?",
            "My friends call me World",
            "Hello World!"
        ]
    )
    

### 使用 embed\_query 方法嵌入问题

嵌入一段文本，以便与其他嵌入进行比较:

    embedded_query = embeddings_model.embed_query("What was the name mentioned in the conversation?")
    

LangChain 核心模块：Data Conneciton - Vector Stores
==============================================

存储和搜索非结构化数据最常见的方法之一是将其嵌入并存储生成的嵌入向量，然后在查询时将非结构化查询进行嵌入，并检索与嵌入查询“最相似”的嵌入向量。

向量存储库负责为您存储已经过嵌入处理的数据并执行向量搜索。

下面以 `Chroma` 为例展示功能和用法

    ## 使用 Chroma 作为向量数据库，实现语义搜索
    

    from langchain.document_loaders import TextLoader
    from langchain_openai import OpenAIEmbeddings
    from langchain.text_splitter import CharacterTextSplitter
    from langchain.vectorstores import Chroma
    
    # 加载长文本
    raw_documents = TextLoader('../tests/state_of_the_union.txt',encoding='utf-8').load()
    

    # 实例化文本分割器
    text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=0)
    

    # 分割文本
    documents = text_splitter.split_documents(raw_documents)
    

    embeddings_model = OpenAIEmbeddings()
    

    # 将分割后的文本，使用 OpenAI 嵌入模型获取嵌入向量，并存储在 Chroma 中
    db = Chroma.from_documents(documents, embeddings_model)
    

#### 使用文本进行语义相似度搜索

    query = "What did the president say about Ketanji Brown Jackson"
    docs = db.similarity_search(query)
    print(docs[0].page_content)
    

### 使用嵌入向量进行语义相似度搜索

    embedding_vector = embeddings_model.embed_query(query)
    docs = db.similarity_search_by_vector(embedding_vector)
    print(docs[0].page_content)
    

本文来自博客园，作者：[nmblr](https://www.cnblogs.com/nmblr/)，转载请注明原文链接：[https://www.cnblogs.com/nmblr/p/18710510](https://www.cnblogs.com/nmblr/p/18710510)