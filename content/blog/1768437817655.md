---
layout: post
title: '【开源自荐】为AI短视频打造一个分镜管理平台'
date: "2026-01-15T00:43:37Z"
---
【开源自荐】为AI短视频打造一个分镜管理平台
======================

> 吐槽：写这篇文章的时间，比我开发这个项目还要久。😂

从 2022 到 2026，我算是一路追着 AI 跑的那批程序员。

IDE 从 VS Studio 集成 Copilot、Cursor、Augment、Windsurf、Antigravity……折腾一圈，最后又回归 **VS Code + Copilot**。  
模型从 GPT-3.5，到 Claude Code、Grok、DeepSeek、Qwen；  
生图/视频从 Midjourney、Stable Diffusion，到 Veo、即梦、可灵、Banana Pro……一路追着体验更新。

（从疯狂白嫖到热衷付费，堕落了呀......）

面对 AI，我的心情一直是五味杂陈：

*   **酸：** 以前为了优化性能熬夜死磕源码、数据结构；现在 AI 给出的代码比我写的好多了，帮我干活的同时还给我情绪体验！ 有种“十年寒窗不如 AI 一瞬”的落差感，真是辛酸
    
*   **甜：** 效率贼高，以前要磨半天的功能，现在几分钟就能跑起来，爽歪歪
    
*   **苦：** AI 强归强，token也是真的贵，不够用根本不够用，公司还不给报销（命苦）
    
*   **辣：** 节奏越来越快，周期缩短、并行项目变多，脑子每天都在高负载运转
    
*   **咸：** 时代交替里，一个十年老兵不想掉队的眼泪
    

在这三四年最大的感受就是：**时间好快，时代变化更快，快的我都来不及拥抱变化😵💫**。

* * *

1）言归正传：24小时，0 手写代码，我做了个啥？
=========================

我做了一个本地客户端项目：**Storyboard：镜头管理板**。 目标很简单：面向短视频创作者与制作团队的本地分镜工作台：从爆款视频导入（模仿对象）、抽帧、模型切换、AI 分析、图像/视频生成，到批量任务与成片合成，一条链路完成管理与输出。

**我在这个项目开发中用到的工具/模型：**

*   Chat 模型：ChatGPT / Gemini / DeepSeek
    
*   UI 设计：Figma / 墨刀
    
*   编程模型：Claude Code 4.5 Sonnet / GPT-5.2 Codex
    
*   编程工具：VS Code Copilot / Codex
    

**技术栈：** Avalonia + SQLite + EF Core + .NET 8+ Semantic Kernel + Provider

> Talk is cheap. Show me the code.

*   项目地址：[GitHub 开源仓库（求个 Star ⭐️）](https://github.com/BroderQi/Storyboard)
    
*   在线体验：[Web Demo（仅 UI 展示）](http://47.100.163.84/)
    
*   客户端下载：[完整功能版本](https://github.com/BroderQi/Storyboard)
    

主页面：

![image](https://img2024.cnblogs.com/blog/1148127/202601/1148127-20260114191819902-1798076118.png)

* * *

2）项目背景：AI 短视频素材管理混乱
===================

最近 AI 漫剧、AI 视频火得离谱，我也去玩了几天。

实操中遇见问题：做一条“差不多”的视频，往往要几十上百个镜头图片，来回切模型、反复抽卡：

*   素材散落各处
    
*   提示词和成片分离，后续无法追溯
    
*   多个项目混在一起，管理混乱
    
*   一条视频下来，重复劳动占了大头
    

然后程序员的“职业病”就发作了： **能不能把它流程化、批量化、自动化？**

于是我想做一个“镜头管理软件”： 把 **爆款视频导入、智能抽帧、AI模型切换、AI 分析、批量任务、成片合成** 全部集成在本地。

* * *

3）需求整理：梳理操作流程
=============

一开始我的想法：

    对参考视频做全局理解，生成多个分镜脚本
    * 用户可以编辑分镜脚本
    * 每个分镜选择不同模型：首尾帧→图生视频→配音→合成
    * 最终形成一张“分镜表格”：镜头号、时长、首尾帧提示词、镜头类型、画面、动作、场景等
    

我把这套想法丢给 ChatGPT、Gemini、DeepSeek 来回拆台纠错。最后收敛成一条更现实的流程：

**最终确定的核心链路：**

    输入： 用户上传参考视频
    处理链：
        视频理解与分镜：传统 CV（镜头切换检测）切分 + 多模态模型辅助描述，生成初步分镜表
        分镜编辑：表格内所有字段都可编辑，重点是“画面描述/关键帧提示词”
        生成链：
            首尾帧：提示词 → SD / MJ 等生成关键帧
            动作：关键帧 + 动作描述 → 图生视频模型生成片段
            音频：抽取原音频或 TTS 生成新音频
    视频合成：片段 + 音频对齐 → 输出成片
    

* * *

4）核心功能清单
========

和AI继续敲定功能细节，让AI整理后给我完整功能文档（纯享版）。

**摘录简化后部分功能：**

*   项目管理：创建/打开/最近项目/资源目录
    
*   视频导入：元信息解析（时长/分辨率/帧率）
    
*   抽帧：定数抽帧 / 等时抽帧 / 关键帧抽取
    
*   分镜表格：镜头号/时长/画面/动作/场景/提示词/模型选择/状态
    
*   批量生成：任务队列/并发/失败重试/日志追踪
    
*   资源管理：图片/视频/提示词版本/可追溯
    
*   合成出片：片段拼接/音频对齐/导出
    

**详细文件地址:****[功能文档](https://github.com/BroderQi/Storyboard/blob/main/%E5%8A%9F%E8%83%BD%E6%96%87%E6%A1%A3.md)****。**

* * *

5）技术选型：为什么做客户端？
===============

我主要纠结了四个问题：

td {white-space:nowrap;border:0.5pt solid #dee0e3;font-size:10pt;font-style:normal;font-weight:normal;vertical-align:middle;word-break:normal;word-wrap:normal;}

我想要的目标

放弃原因（不选的坑）

最终选择

Web vs 客户端

快速出 UI + 本地高性能处理

Web 需要前后分离、部署繁琐；  
权限/存储/任务队列链路复杂，  
且 ffmpeg/OpenCV 本地吃资源更适合客户端

客户端

Python vs .NET

工程化、可维护、可扩展

Python 工具链强但客户端工程化、结构化维护成本更高；  
.NET本命+年度语言，必须打Call

.NET 8

WPF vs Avalonia

跨平台 + 学新技术

WPF 不跨平台，限制未来用户范围

Avalonia

WebView vs 原生复刻

UI 还原度 + 可维护性验证

WebView性能/体验不确定

Avalonia 原生复刻

* * *

6）UI 设计：先用 AI 做“能跑的设计稿”
=======================

拿到核心功能后，我直接在 **Figma / 墨刀** 走 vibe coding： 自然语言沟通需求 → 输出可运行的 React 项目 → 这就是“设计稿 + 交互稿 + 可运行原型”。

我就将功能贴到对话框，创建Web界面。就得到两个可运行原型：

![308b428a54192c39f3a168ab6be766b9](https://img2024.cnblogs.com/blog/1148127/202601/1148127-20260114192410233-2084263044.png)

墨刀最终成品截图：

![cf082781dc06dbf30dd3bd2035dccce6](https://img2024.cnblogs.com/blog/1148127/202601/1148127-20260114192546823-363850222.png)

figma：

![81eddd65cfffdb55090c6b74b092b95e](https://img2024.cnblogs.com/blog/1148127/202601/1148127-20260114192607008-1830546258.png)

导出成React项目文件  
![87865bc53fe5dcec2441f8152e60e864](https://img2024.cnblogs.com/blog/1148127/202601/1148127-20260114192624142-128403351.png)

* * *

7）代码实现：我的 0 手写代码流水线
===================

我基本按这个“AI协作流水线”跑：

1.  新建项目文件夹，把功能文档复制进来，把 React 原型项目拖进来

![b56a1adbf05d831de33c882281f1e395](https://img2024.cnblogs.com/blog/1148127/202601/1148127-20260114192743020-232735968.jpg)

2.  **UI** **复刻阶段：** 用 Avalonia 对照 React 逐页面 1:1 还原（不允许脑补，不允许简化）。 这个模块用Claude Code 4.5 Sonnet 还原度比较高。

![4044fbab3b46b72a769e966abc00d82a](https://img2024.cnblogs.com/blog/1148127/202601/1148127-20260114192801765-1251944392.jpg)

3.  进行局部UI修复。截图、引入相关文件，AI修复
    
4.  **数据贯通阶段：** 删除 React 项目，只保留 UI；要求 SQLite + EF Core，前后端字段一致，数据流转跑通
    
5.  切换另一个模型做全量 code review（结构、边界、错误处理、可维护性）
    
6.  修复 → 运行成功 → 打包 → 开源
    

* * *

8）个人感悟：
=======

> AI 拉平了写代码的门槛，但“把事做成”的能力依然稀缺。

对程序人来讲：编程能力失去了稀缺性，在AI面前逐渐消退。

但是对想做产品的人，黄金时代到了：

趁AI尚未完全自主、普通人还不能轻松驾驭的窗口期，

我们可以将灵感，快速做成能运行、能验证的原型。

抓住这个时代红利，从技术转向产品、转向市场。

我做 Storyboard，是想证明：当灵感闪现，我能以最快速度让它落地成真。

如果你也想快速落地产品。

如果你也想做AI视频/漫剧。

欢迎来提需求、交PR，一起把这个工具打磨得更趁手。

想法不值钱，做出来才值钱。

现在，正是动手的最好时候。