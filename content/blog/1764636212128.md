---
layout: post
title: 'DeepSeek 接入 Claude Code：从踩 CCR 坑到发现“协议才是本体”'
date: "2025-12-02T00:43:32Z"
---
DeepSeek 接入 Claude Code：从踩 CCR 坑到发现“协议才是本体”
===========================================

**阅读时间：10分钟｜字数：3000+**
----------------------

![图1：DeepSeek 接入 Claude Code 封面图](https://img2024.cnblogs.com/blog/2045416/202512/2045416-20251201202518261-225663460.png)

这篇文章想讲一件很具体、也很日常的小事：

> 作为一个想薅 AI 羊毛、又想少踩坑的普通开发者，我是怎么从「迷信 CCR 这种万能适配器」，一路绕弯路，最后回到一个更本质的答案：**协议才是本体**，并把 Qwen/DeepSeek 稳稳接到了 Claude Code 里。

不会有太多代码，因为代码可以随时让 AI 再帮我写一遍；  
我更想讲的是：**一个新手，是怎么从 0 折腾到 1 的。**

一、为什么我非要折腾「Claude Code + 国产模型」
------------------------------

故事要从「薅羊毛变难了」说起。

最开始，我是用 Cursor、Augment 这一类工具，配合各种「域名号池」的骚操作，勉强薅到一些算力。但随着各家风控收紧，这条路越来越难走：

*   要么需要更多维护成本；
*   要么就是今天能用、明天突然失效。

那段时间我在想：

> 与其天天琢磨怎么薅羊毛，不如直接把主力工具换成一个「体验好、上下文工程做得强」的产品。

于是 Claude Code 显然成了最顺眼的那个。

![图2：Claude Code 接入示意](https://img2024.cnblogs.com/blog/2045416/202512/2045416-20251201203610964-76402429.png)

Claude Code 是 Anthropic 在 2025 年 5 月正式发布的一款全新 AI 编码工具，一上线就成了 AI Coding 领域的现象级产品（它的上下文工程做的非常好！）

但是，用了你就会发现：它有一个非常明显的硬伤——

*   默认选择调用 Anthropic 自家的 Claude 模型（那我还怎么薅羊毛...）
*   想办法去注册难就算了，而且anthropic封号率极高

原因其实很简单：

*   Claude Code 说的是 **Anthropic API 协议**；
*   而很多国内外平台说的是 **OpenAI 风格协议**；
*   这两套在参数结构、请求路径上都不一样，根本不兼容。

你要是想系统对比 Anthropic 家和 OpenAI 家的 API 区别，可以看这篇总结：

> A 家和 O 家的格式区别参考：[https://zhuanlan.zhihu.com/p/1933112792816292424](https://zhuanlan.zhihu.com/p/1933112792816292424)

![图3：Anthropic 与 OpenAI API 协议对比示意图](https://img2024.cnblogs.com/blog/2045416/202512/2045416-20251201202835509-2097734280.png)

那问题就来了：

*   我既想用 Claude Code 这套开发体验；
*   又想用 Qwen、DeepSeek 这些在国内体验不错、还提供免费额度的模型。

当我看到魔搭社区提供了 Qwen 和 DeepSeek 的最新模型免费 API（每天 2000 次），那一刻的想法其实很简单：

> 如果我能把「魔搭的免费 Qwen/DeepSeek」接入到 Claude Code 里，那就太完美了。

只是，我一开始选的路径，有点走远了。

二、第一条路：被 CCR「万能适配器」忽悠的那些日子
--------------------------

![图4：CCR 开源项目示意图](https://img2024.cnblogs.com/blog/2045416/202512/2045416-20251201203716672-1949073924.png)

当时我看到一个开源项目：**CCR**。

它打出来的卖点大概是这样的：

> 让任意模型都能嵌入到 Claude Code。

对一个只是想「赶紧上手用」的开发者来说，这简直是天籁之音：

> 太好了，有人帮我把各种 API 格式的坑都填了，我只要学会怎么用 CCR 就行了。

于是我干了什么？

### 1\. 先把学习成本付出去再说

我开始认真啃 CCR 的文档，理解它大致是怎么干事的：

*   安装 CCR；
*   配置路由；
*   在 CCR 里把国产模型的地址和 Key 配进去；
*   再让 Claude Code 指向 CCR。

别看这里只是几行字，当时花的时间其实不少：

*   有些参数名一眼看不懂，还得翻 Issues；
*   某些版本的说明和代码又对不上；
*   新手基本处于「边查边试边踩坑」的状态。

那时候我的心态是：

> 没关系，开源项目嘛，多花点时间理解也是应该的。

### 2\. 好不容易跑起来，却被一次更新打回原形

在反复折腾之后，我终于让 CCR 和 Claude Code 跑起来了。

然而没多久，项目更新了。

更新之后，之前好不容易调通的配置——**直接失效了**。

*   Claude Code 连不上 CCR；
*   或者请求过去就报错；
*   日志一堆 warning 和 error，看得人心烦。

那一刻的心情大概是：

> 我到底是在用 Claude 写代码，还是在给 CCR 打工做测试？

![图5：CCR 配置报错与调试过程截图](https://img2024.cnblogs.com/blog/2045416/202512/2045416-20251201203750921-266530274.png)

### 3\. 论坛玄学自救：coding 居然靠成功率？

接下来就是典型的「开源项目自救流程」：

*   上论坛、刷 Issue、看评论区；
*   各种「邪修方案」纷纷出现：
    *   有人说改某个ccr的服务器端口就好；
    *   有人说锁定某个ccr旧版本最稳；
    *   还有人丢一段脚本截图，说「你先这样跑一下再试试」。

![图6：论坛中各种 CCR 玄学解决方案截图](https://img2024.cnblogs.com/blog/2045416/202512/2045416-20251201203202491-1173210144.png)

现实情况是：

*   有时候照做真的能成功；
*   但下一次就又挂了；
*   成功率完全看运气。

> 我这……coding 还需要看概率？

那几天的体验给了我一个很强的直觉：

*   **一个要天天依赖的开发工具，如果只能「看脸成功」，那它就不适合做生产力的底座。**

下面这张图，大概就是当时在论坛各种翻找解决方案时的场景：

![图7：论坛里寻找各种 CCR 玄学解法](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251115193039518-1359922155.png)

三、停下来想一想：我到底卡在哪？
----------------

在玄学尝试了一圈、成功率始终不稳定之后，我终于不再继续「评论区指哪儿我试哪儿」，而是决定停下来问自己三个问题：

![图8：思考 CCR 本质是翻译器的示意图](https://img2024.cnblogs.com/blog/2045416/202512/2045416-20251201203910354-127471205.png)

这时候我慢慢意识到：

*   Claude Code 出厂只认识 **Anthropic 自己那一套 API 协议**；
*   很多平台（包括不少国产云）提供的是 **OpenAI 风格协议**；
*   CCR、本质上就是一个「翻译器」，负责在这两种协议之间做转换。

翻译器本身会带来什么？

*   它也有版本；
*   它也会有 bug；
*   它也需要维护和测试。

于是问题变成：

> **我是真的需要这么一个「万能翻译器」，还是其实只需要找一个「本来就说同一种话」的平台？**

这个视角一旦转过来，后面的路就开始变得清晰了。

![图9：寻找原生支持 Anthropic 协议平台的思路转变](https://img2024.cnblogs.com/blog/2045416/202512/2045416-20251201203243158-1094285962.png)

四、惊喜发现：魔搭居然原生支持 Anthropic 协议
----------------------------

后来有一天，我在魔搭社区看模型接口文档的时候，突然看到这样一行说明——大意是：

> 某些模型接口，已经支持 Anthropic 格式。

当时的感觉只有一句：

> 我这……走了半天弯路，结果答案在文档里一直写着。

魔搭提供的 Qwen/DeepSeek 模型，本身就可以用 **Anthropic 协议** 调用。

这意味着什么？

*   我不需要 CCR 这种中间件了；
*   不需要在 OpenAI ↔ Anthropic 之间来回翻译；
*   只要让 Claude Code 以为它在和 Anthropic 官方对话，实际上请求发到了魔搭就行。

也就是说，只要做到两件事：

1.  把 Claude Code 指向魔搭的 Anthropics 兼容 API 地址；
2.  告诉它应该用哪个模型（例如 Qwen/DeepSeek）。

下面这张图，就是当时我在魔搭页面上看到「支持 Anthropic 接口格式」时的大概样子：

![图10：魔搭模型接口页面中对 Anthropic 协议的支持说明](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251115193056820-1005555324.png)

实际上DeepSeek官方也推出了一个满足[Claude Code](https://claude.ai/api)的接口格式，

![图11：DeepSeek 官方文档支持 Claude Code 接口格式说明](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251115193209381-1479538339.png)

看到这里，我心里的思路瞬间变成：

> 与其在各种中间件上赌运气，不如直接找一个**官方就讲 Anthropic 语言**的平台。

接下来就是「从 0 到 1 的配置过程」了。

五、真正实用的部分：我从 0 配好 Claude Code + 魔搭 API 的完整步骤
--------------------------------------------

下面这部分是你可以直接照抄的教程部分：

![图12：Claude Code 配置魔搭 API 步骤概览](https://img2024.cnblogs.com/blog/2045416/202512/2045416-20251201204047032-529911697.png)

*   先临时试跑：确认思路没问题；
*   再做永久配置：免得每次重启终端都得重配；
*   最后用一个 `.claude/settings.json` 帮你把配置收拢在一处。

### 5.1 准备工作：先在魔搭拿到 API Key

这一步很简单，官方文档也写得很清楚，这里只说关键点：

1.  注册/登录魔搭平台；
2.  进入「API Key」或「访问令牌」页面；
3.  生成一个新的 Key，并妥善保存。

注意：

*   这类 Key 只在你自己的本地配置中使用；

魔搭现在给的免费额度，大致是每天 2000 次调用，对我这种折腾+日常小规模使用的人来说已经够用。

### 5.2 在 PowerShell 里用一次性环境变量先跑通

在动系统级配置之前，我的习惯是：

> 先在当前终端用「一次性环境变量」跑通一遍，确认链路没问题再说。

在 Windows PowerShell 里，可以用这样的形式设置环境变量（注意：这些是一次性的，只在当前窗口有效）：

    $env:ANTHROPIC_BASE_URL = "https://api-inference.modelscope.cn"
    $env:ANTHROPIC_AUTH_TOKEN = "你的魔搭 API Key"
    $env:ANTHROPIC_MODEL = "Qwen/Qwen3-Coder-480B-A35B-Instruct"
    

这里有三个关键点：

1.  **ANTHROPIC\_BASE\_URL**：

*   指向魔搭的 Anthropics 兼容推理接口，比如：
*   `https://api-inference.modelscope.cn`

2.  **ANTHROPIC\_AUTH\_TOKEN**：

*   就是你刚刚从魔搭页面拿到的 API Key；

3.  **ANTHROPIC\_MODEL**：

*   告诉服务器你要用哪个模型，例如：
*   `Qwen/Qwen3-Coder-480B-A35B-Instruct`

![图13：PowerShell 设置一次性环境变量示例](https://img2024.cnblogs.com/blog/2045416/202512/2045416-20251201204135267-371314964.png)

设置完这三个环境变量之后，在**同一个 PowerShell 窗口**里，直接启动 Claude Code CLI：

    claude
    

进入对话界面后，我做的第一件事不是写代码，而是问它：

> 你是什么模型？

这一次，Claude 工具就会带着你配置好的 Qwen 模型名称去请求魔搭服务器，服务端能正确识别并返回信息。

成功时大概长这样：

![图14：Claude CLI 中询问「你是什么模型」并返回 Qwen 相关信息](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251115193326877-587890665.png)

那一刻的感觉有点像校招拿到第一封 offer：

> 哦，原来这个思路是真的通了。

后面我又实际跑了一下补全，确认在 Claude Code 里用 Qwen 模型写代码是没问题的：

![图15：成功在 Claude Code 中使用 Qwen 模型进行补全](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251115193217630-1690789979.png)

### 5.3 把一次性配置变成永久配置：Windows 系统环境变量

上面那种 `$env:...` 的方式，有一个典型的坑：

> **只在当前终端窗口有效。关掉窗口，一切归零。**

如果你每次开一个新终端都要重新打一遍这三行命令，很快就会崩溃。

所以更实用的做法，是通过 Windows 系统环境变量，把这三项配置成**用户级环境变量**。

#### 步骤如下：

1.  打开环境变量窗口

*   按 Win 键，在开始菜单中直接输入「环境变量」；
*   点击搜索结果里的「编辑系统环境变量」。

2.  进入环境变量设置

*   在弹出的「系统属性」窗口中，点击右下角的「环境变量…」。

3.  新建用户变量

*   在窗口上半部分「XXX 的用户变量」区域，点击「新建…」。
    
*   重复三次，新建以下三个变量：
    
*   变量 1：
    
    *   变量名：`ANTHROPIC_BASE_URL`
    *   变量值：`https://api-inference.modelscope.cn`
*   变量 2：
    
    *   变量名：`ANTHROPIC_AUTH_TOKEN`
    *   变量值：`你的魔搭 API Key`
*   变量 3：
    
    *   变量名：`ANTHROPIC_MODEL`
    *   变量值：`Qwen/Qwen3-Coder-480B-A35B-Instruct`

4.  保存并重启终端

*   创建完三个变量后，一路点击「确定」关闭所有窗口；
*   非常重要的一步：**关闭所有已打开的终端窗口，然后重新打开一个新的终端。**

只有在新开的终端里，这些环境变量才会真正生效。

整个过程大概会看到这样的界面：

![图16：Windows 环境变量配置示例](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251115193303739-825500175.png)

做完这些之后，以后你只要：

    claude
    

就可以直接在任何终端里调用到魔搭上的 Qwen/DeepSeek，而不需要重复配置。

### 5.4 进阶一点：用 `.claude/settings.json` 固化项目级配置

系统环境变量解决的是「这台机器上所有终端都能用」的问题。

但如果你像我一样：

*   偶尔会在其他机器上也用 Claude Code；
*   或者希望有一个地方集中记录「和 Claude 相关的所有配置」；

那再加一层配置会更安心：**`.claude/settings.json`**。

#### 步骤：

1.  找到当前用户的 `.claude` 目录

*   在 Windows 下，一般是：`C:\Users\%username%\.claude`
*   可以用 CMD 或资源管理器进入。

2.  创建或编辑 `settings.json`

*   使用 VS Code 或记事本打开/创建这个文件，填入类似这样的内容（示例值请替换成你自己的真实配置）：

    {
      "env": {
       "ANTHROPIC_BASE_URL": "https://api-inference.modelscope.cn",
       "ANTHROPIC_AUTH_TOKEN": "your-api-key",
       "ANTHROPIC_MODEL": "Qwen/Qwen3-Coder-480B-A35B-Instruct"
      }
    }
    

这一步的好处是：

*   就算你在某台机器上不方便配系统环境变量；
*   只要有这个 `.claude/settings.json` 文件，Claude Code 也能读到这些配置。

大概长这样：

![图17：.claude/settings.json 配置示例](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251115193319604-1928661991.png)

最后，切回到你的项目目录下，再次启动 Claude：

    claude
    

就可以顺畅地继续用 Qwen/DeepSeek 模型写代码了：

![图18：在项目目录中启动 Claude 并继续使用 Qwen 模型](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251115193326877-587890665.png)

六、回头看：这次折腾给我的三个反思
-----------------

写完这些，我回头看了一眼这整个从 0 到 1 的过程，最有感的其实是三件事：

### 1\. 别一上来就迷信「万能中间件」

一开始我特别迷信 CCR：

*   它看起来能统一所有模型；
*   能帮我搞定各种奇怪的 API 差异。

结果现实是：

*   我 80% 的时间都花在「如何喂饱 CCR」上；
*   每次它更新，我都得跟着重配、重查问题。

对一个只是想「赶紧写代码」的人来说，这显然是跑偏了。

### 2\. 协议才是本体，工具只是壳

真正解锁 Claude Code 的钥匙，不是 CCR，也不是某个具体脚本，而是：

> **有没有一个平台，本身就支持 Anthropic 协议。**

当我发现魔搭的 Qwen/DeepSeek 模型可以用 Anthropic 格式调用时，整件事一下子变得简单：

*   不需要中间代理；
*   不怕中间件版本乱飞；
*   Claude Code 只需要「以为」自己在和 Anthropic 官方聊天就行了。

工具可以换很多代，UI 也可以不停更新，但**协议选对了，你就不会被某一个中间层绑死**。

### 3\. 新手从 0 到 1 的关键，是敢停下来问一句「我到底在干嘛」

在最混乱的那时候，我其实就是：

*   论坛说啥我就试啥；
*   某个评论说改这个参数，我就改；
*   成功一次就暗爽，失败一次就继续玄学微调。

真正让事情回到正轨的，是那一刻我停下来问自己：

> 我到底想解决什么问题？

是用上 CCR，还是用上 Qwen/DeepSeek？

当我把这两个问题拆开之后，答案就变得很清晰：

*   用上哪种中间件，是「手段」；
*   能稳定用上自己想要的模型，才是「目的」。

![图19：从迷信中间件到回归协议本质的反思总结](https://img2024.cnblogs.com/blog/2045416/202512/2045416-20251201204824768-1933418171.png)

七、给后来者的一点小建议
------------

最后，用几条很实际的小建议收个尾：

*   想在 Claude Code 里用第三方模型，**先看对方支不支持 Anthropic 协议**，再考虑各种中间件。
*   能少用一个中间件，就少用一个中间件，特别是那种还在快速迭代、测试不太完善的项目。
*   真遇到搞不定的错误，多从「协议兼容性」和「官方文档」找原因，而不是只在评论区赌运气。
*   论坛和评论区当然有价值，但更大的价值有时候只是：
    *   让你知道**不是你一个人踩坑**，
    *   而不是让你把全部希望压在某条玄学指令上。

如果你也正好在折腾「Claude Code + 国产模型」，希望这篇从 0 到 1 的踩坑记录，能帮你少踩几次我已经踩过的坑。