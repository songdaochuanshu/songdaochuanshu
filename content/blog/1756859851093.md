---
layout: post
title: '谁说的YOLO只能目标检测？手把手教你解锁它隐藏的热力图视野！'
date: "2025-09-03T00:37:31Z"
---
谁说的YOLO只能目标检测？手把手教你解锁它隐藏的热力图视野！
===============================

![谁说的YOLO只能目标检测？手把手教你解锁它隐藏的热力图视野！](https://img2024.cnblogs.com/blog/3687401/202509/3687401-20250902191137992-1335252101.png) 今天，我们来探讨如何利用YOLO算法实现热力图的展示。YOLO算法最常见的应用是目标检测，但它其实隐藏着许多其他技能，比如热力图生成。这项功能可以帮助我们直观地分析视频或图像中目标物体的位置和趋势。

​

视频演示
====

* * *

引言
==

大家好！欢迎来到Coding茶水间。今天，我们来探讨如何利用YOLO算法实现热力图的展示。YOLO算法最常见的应用是目标检测，但它其实隐藏着许多其他技能，比如热力图生成。这项功能可以帮助我们直观地分析视频或图像中目标物体的位置和趋势。

热力图的最大特点在于，它像一个温度计一样，使用颜色的深浅来表示检测目标物体的核心区域和边界区域。

相比单纯的数字展示，颜色变化能更快速、直观地揭示视频中目标物体的分布和运动趋势。例如，在人群跟踪或车辆监测场景中，热力图能突出高密度区域，帮助我们快速识别关键信息。

在本教程中，我们将一步步讲解如何使用Ultralytics的YOLO框架来实现热力图生成。

我们会覆盖视频处理和图像处理的代码实现，并附上完整代码示例。如果你对YOLO的运行环境不熟悉，可以参考我之前的相关视频教程。

热力图的基本原理
--------

热力图的核心是通过颜色映射（colormap）来可视化检测结果。Ultralytics的solutions包提供了现成的热力图工具，它基于YOLO模型的预训练权重（如yolo12n.pt）来处理输入。

关于colormap，这里简单介绍一下：它决定了热力图的颜色渐变方式。常见的colormap包括JET（从蓝色冷调过渡到红色热调）、HOT、VIRIDIS等。选择不同的colormap会影响最终的视觉效果。例如，JET colormap适合突出密度差异，如下图所示

在本教程中，我们使用cv2.COLORMAP\_JET作为示例。你可以根据项目需求更换其他colormap。

热力图特别适用于目标跟踪领域，它能叠加在原图上，显示“热影”效果，帮助分析物体运动轨迹。

环境准备
----

*   Python环境：确保安装Ultralytics、OpenCV和NumPy。
*   YOLO模型：使用预训练权重文件，如yolo12n.pt（可从Ultralytics官网下载）。
*   测试文件：准备一个视频文件（如pedtracking.mp4，用于行人跟踪）和一张图像（如zidane.jpg）。

注意：如果使用自定义训练模型，可以替换权重文件以适应特定项目。

视频处理的实现步骤
=========

我们新建一个Python文件，命名为heatmap.py。代码主要分为以下步骤：

1.  **导入必要包**：
    *   从ultralytics导入solutions包（包含热力图功能）。
    *   导入cv2（OpenCV，用于视频读取和显示）。
    *   导入numpy（用于图像矩阵运算和拼接）。
2.  **读取视频文件**：
    *   使用cv2.VideoCapture打开视频。
3.  **初始化热力图对象**：
    *   调用solutions.Heatmap，传入colormap和模型权重。
4.  **循环处理视频帧**：
    *   读取每一帧图像。
    *   使用热力图对象处理帧，生成热力图。
    *   水平拼接原帧和热力图。
    *   显示拼接结果，并检查按键退出（q或ESC）。
5.  **释放资源**：
    *   关闭视频捕获并销毁窗口。

### 视频处理完整代码

    from ultralytics import solutions
    import cv2
    import numpy as np
    
    #读取视频文件
    cap = cv2.VideoCapture('pedtracking.mp4')
    
    #初始化热力图对象
    heatmap = solutions.Heatmap(colormap=cv2.COLORMAP_JET,model="yolo12n.pt")
    
    while cap.isOpened():
        success, img0 = cap.read()
        if not success:
            break
    
        #处理帧图像生成热力图对象
        results =  heatmap(img0)
    
        #拼接原图和热力图
        combined_frame = np.hstack((img0,results.plot_im))
    
        #展示拼接后的图像
        cv2.imshow('Original vs Heatmap',combined_frame)
    
        # 检查按键，按 'q' 或 ESC 退出
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q') or key == 27:
            break
    
    cap.release()
    cv2.destroyAllWindows()

运行后，你会看到原视频帧和热力图的拼接显示。例如，在行人跟踪视频中，检测到的行人区域会以深蓝色标注，背景为浅色。随着视频播放，热力图会显示“脱影”效果，突出运动轨迹。

另一个车辆视频示例：初始帧会标注检测到的车辆为深色，其他区域为浅蓝色。

图像处理的实现步骤
---------

图像处理与视频类似，但无需循环读取帧。直接使用cv2.imread加载图像，然后处理并显示。

### 图像处理完整代码

    import cv2
    import numpy as np  # 用于图像拼接
    from ultralytics import solutions
    
    # 打开图片
    img = cv2.imread('zidane.jpg')
    # 初始化热力图对象
    heatmap = solutions.Heatmap(colormap=cv2.COLORMAP_JET, model="yolo12n.pt")
    
    # 处理生成热力图
    results = heatmap(img)
    
    # ✅ 关键修改：水平拼接原视频帧和热力图结果
    combined_frame = np.hstack((img, results.plot_im))  # 水平拼接
    
    # ✅ 显示拼接后的双画面
    cv2.imshow('Original vs Heatmap', combined_frame)  # 窗口名称更明确
    cv2.waitKey(0)
    cv2.destroyAllWindows()

运行后，左侧显示原图，右侧显示热力图。使用yolo12n.pt模型，能有效检测图像中的目标并以颜色突出。

总结与扩展
=====

通过以上代码，我们实现了YOLO热力图在视频和图像上的应用。这项技术在目标跟踪、安防监控等领域有广泛用途。如果你有自定义模型，可以轻松替换权重文件来优化效果。

不知各位小伙伴学废了没有？欢迎在评论区分享你的实现经验或问题。如果本文对你有帮助，记得点赞和收藏哦！更多Coding茶水间教程，敬请关注。

​