---
layout: post
title: 'SpringBoot3 + LangChain4j + Redis 实现大模型多轮对话及工具调用'
date: "2025-07-11T00:44:05Z"
---
SpringBoot3 + LangChain4j + Redis 实现大模型多轮对话及工具调用
================================================

引言
--

在人工智能快速发展的当下，大语言模型（LLM）已成为构建智能应用的核心技术之一。LangChain4j 作为 Java 生态中领先的 LLM 应用开发框架，为开发者提供了强大的工具，助力构建基于大语言模型的各类应用。在 Java 领域，目前整合大语言模型的主流工具主要有 Spring AI 和 LangChain4j。许多 Java 开发者可能对 Spring AI 更为熟悉，但 LangChain4j 延续了 LangChain 框架的诸多优点，在 Java 中同样易于使用。  
不过，当前网络上关于 LangChain4j 的整合教程较少，官方文档的粒度也不够细致，导致将其集成到现有项目中并非易事。为此，我计划编写一个系列教程，帮助大家快速地将大语言模型集成到自己的项目中。目前已实现了多轮对话和工具调用功能，接下来的短期目标是支持多模态能力和知识库系统。

项目概述
----

本项目实现了一个基于SpringBoot3的智能对话系统，具有以下核心特性：

*   **流式响应**：支持实时流式输出，提供更好的用户体验
*   **多轮对话**：基于Redis实现对话历史持久化
*   **工具集成**：支持自定义工具函数扩展AI能力
*   **内存管理**：智能的对话历史管理，避免上下文过长

技术栈
---

*   **SpringBoot 3.5.3**：现代化的Java Web框架
*   **Java 21**：使用最新的LTS版本
*   **LangChain4j 1.1.0-beta7**：Java版LangChain框架
*   **Redis**：用于对话历史持久化存储
*   **Lombok**：简化Java代码编写

项目结构
----

    src/main/java/com/fengzeng/langchain4j/
    ├── chat/
    │   └── ChatController.java          # 聊天控制器
    ├── config/
    │   ├── AssistantConfiguration.java  # AI助手配置
    │   ├── PersistentChatMemoryStore.java # Redis持久化存储
    │   └── RedisTemplateConfig.java    # Redis配置
    ├── service/
    │   ├── Assistant.java              # 普通助手接口
    │   └── StreamingAssistant.java     # 流式助手接口
    ├── tool/
    │   └── AssistantTools.java         # 自定义工具
    └── listener/
        └── MyChatModelListener.java    # 聊天模型监听器
    

核心实现
----

### 1\. 依赖配置

首先在`pom.xml`中添加必要的依赖：

    <dependencies>
        <!-- SpringBoot Web -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        
        <!-- Redis支持 -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-redis</artifactId>
        </dependency>
        
        <!-- LangChain4j核心 -->
        <dependency>
            <groupId>dev.langchain4j</groupId>
            <artifactId>langchain4j-spring-boot-starter</artifactId>
            <version>1.1.0-beta7</version>
        </dependency>
        
        <!-- OpenAI集成 -->
        <dependency>
            <groupId>dev.langchain4j</groupId>
            <artifactId>langchain4j-open-ai-spring-boot-starter</artifactId>
            <version>1.1.0-beta7</version>
        </dependency>
        
        <!-- 响应式支持 -->
        <dependency>
            <groupId>dev.langchain4j</groupId>
            <artifactId>langchain4j-reactor</artifactId>
            <version>1.1.0-beta7</version>
        </dependency>
    </dependencies>
    

### 2\. 应用配置

在`application.yaml`中配置OpenAI和Redis：

    langchain4j:
      open-ai:
        streaming-chat-model:
          base-url: https://yunwu.ai/v1
          api-key: your-api-key
          model-name: gpt-4o-mini
          log-requests: true
          log-responses: true
    
    spring:
      data:
        redis:
          host: 10.0.5.55
          port: 6379
          database: 1
          password: your-password
    
    server:
      port: 8000
    

### 3\. Redis配置

创建Redis模板配置类：

    @Configuration
    public class RedisTemplateConfig {
        
        @Bean
        public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {
            RedisTemplate<String, Object> template = new RedisTemplate<>();
            template.setConnectionFactory(factory);
            template.setKeySerializer(new StringRedisSerializer());
            template.setHashKeySerializer(new StringRedisSerializer());
            template.setValueSerializer(new StringRedisSerializer());
            template.setHashValueSerializer(new GenericJackson2JsonRedisSerializer());
            template.afterPropertiesSet();
            return template;
        }
    }
    

### 4\. 持久化聊天存储

实现基于Redis的聊天历史持久化：

    @Component
    @Slf4j
    public class PersistentChatMemoryStore implements ChatMemoryStore {
        
        @Resource
        private RedisTemplate<String, Object> redisTemplate;
        
        @Override
        public List<ChatMessage> getMessages(Object memoryId) {
            Object raw = redisTemplate.opsForValue().get(String.valueOf(memoryId));
            if (raw == null) {
                // todo 从数据库中查询最近的历史消息记录
                return List.of(); // 返回空历史，表示是第一次对话
            }
            return messagesFromJson(raw.toString());
        }
        
        @Override
        public void updateMessages(Object memoryId, List<ChatMessage> messages) {
            String json = messagesToJson(messages);
            redisTemplate.opsForValue().set(String.valueOf(memoryId), json);
        }
        
        @Override
        public void deleteMessages(Object memoryId) {
            redisTemplate.delete(String.valueOf(memoryId));
        }
    }
    

### 5\. 流式助手接口

定义支持流式响应的AI助手：

    @AiService
    public interface StreamingAssistant {
        
        @SystemMessage("You are a helpful assistant")
        Flux<String> chat(@UserMessage String userMessage, @MemoryId int memoryId);
    }
    

### 6\. 自定义工具

扩展AI助手的能力：

    @Component
    public class AssistantTools {
        
        @Tool
        @Observed
        public String currentTime() {
            return LocalDateTime.now().toString();
        }
    }
    

### 7\. 聊天控制器

其实，核心步骤就在这里。由于引入了 langchain4j-starter 后，框架会根据配置文件中定义的 xxx-chat-model，自动为你注入对应的实例。因此，关键就在于如何正确获取 Assistant。官方文档给出的示例是直接通过注解注入 Assistant，但这种方式无法注入自定义的 memory（记忆）和 tools（工具），限制了更复杂场景的使用。

下面是一个通过显式方式构建 Assistant 的示例，并提供了一个简单的 REST API 接口：

    @RestController
    @RequestMapping("/api/v1/chat")
    public class ChatController {
        
        @Resource
        private OpenAiStreamingChatModel openAiChatModel;
        
        @Resource
        PersistentChatMemoryStore chatMemoryStore;
        
        @Resource
        AssistantTools assistantTools;
        
        @GetMapping(value = "/chat", produces = TEXT_EVENT_STREAM_VALUE)
        public Flux<String> model(@RequestParam(value = "message", defaultValue = "Hello") String message,
                                  @RequestParam(value = "memoryId") int memoryId) {
            
            StreamingAssistant assistant = getAssistant(memoryId);
            return assistant.chat(message, memoryId);
        }
        
        private StreamingAssistant getAssistant(int memoryId) {
            ChatMemoryProvider chatMemoryProvider = o -> MessageWindowChatMemory.builder()
                    .id(memoryId)
                    .maxMessages(10)
                    .chatMemoryStore(chatMemoryStore)
                    .build();
            
            return AiServices.builder(StreamingAssistant.class)
                    .streamingChatModel(openAiChatModel)
                    .chatMemoryProvider(chatMemoryProvider)
                    .tools(assistantTools)
                    .build();
        }
    }
    

核心特性解析
------

### 1\. 多轮对话支持

通过`@MemoryId`注解和Redis持久化存储，系统能够：

*   为每个用户会话分配唯一的memoryId
*   自动保存和恢复对话历史
*   支持最多10轮对话的上下文窗口

### 2\. 流式响应

使用`Flux<String>`和`TEXT_EVENT_STREAM_VALUE`实现：

*   实时流式输出，提升用户体验
*   减少等待时间，提供即时反馈
*   支持长文本的渐进式显示

### 3\. 工具集成

通过`@Tool`注解可以轻松扩展AI能力：

*   自定义工具函数
*   自动注入到AI助手中
*   支持复杂的业务逻辑

### 4\. 内存管理

智能的对话历史管理：

*   自动限制上下文长度
*   防止token超限
*   保持对话的连贯性

使用示例
----

### 启动应用

    mvn spring-boot:run
    

### API调用

    curl -N "http://localhost:8000/api/v1/chat/chat?message=你好&memoryId=123"
    

### 前端集成

    const eventSource = new EventSource('/api/v1/chat/chat?message=你好&memoryId=123');
    eventSource.onmessage = function(event) {
        console.log('收到流式响应:', event.data);
    };
    

总结
--

本项目展示了如何使用SpringBoot3和LangChain4j构建现代化的AI对话系统。通过Redis实现持久化存储，结合流式响应和工具集成，为开发者提供了一个完整的解决方案。

项目特点：

*   **简单易用**：基于SpringBoot的熟悉开发模式
*   **功能完整**：支持多轮对话、流式响应、工具集成
*   **可扩展性强**：模块化设计，易于扩展新功能
*   **生产就绪**：包含完整的配置和部署方案

相关资源
----

*   [项目地址(github)](https://github.com/fengzengfly/easy_langchain4sb)
*   [LangChain4j官方文档](https://docs.langchain4j.dev/)
*   [SpringBoot官方文档](https://spring.io/projects/spring-boot)
*   [Redis命令手册](https://www.redis.net.cn/order/)