---
layout: post
title: 'Kubernetes 知识梳理及集群搭建'
date: "2025-01-15T16:14:05Z"
---
Kubernetes 知识梳理及集群搭建
====================

### Kubernetes介绍

#### 应用部署方式演变

在部署应用程序的方式上，主要经历了三个时代：

*   **传统部署**：互联网早期，会直接将应用程序部署在物理机上
    
    > 优点：简单，不需要其它技术的参与
    > 
    > 缺点：不能为应用程序定义资源使用边界，很难合理地分配计算资源，而且程序之间容易产生影响
    
*   **虚拟化部署**：可以在一台物理机上运行多个虚拟机，每个虚拟机都是独立的一个环境
    
    > 优点：程序环境不会相互产生影响，提供了一定程度的安全性
    > 
    > 缺点：增加了操作系统，浪费了部分资源
    
*   **容器化部署**：与虚拟化类似，但是共享了操作系统
    
    > 优点：
    > 
    > 可以保证每个容器拥有自己的文件系统、CPU、内存、进程空间等
    > 
    > 运行应用程序所需要的资源都被容器包装，并和底层基础架构解耦
    > 
    > 容器化的应用程序可以跨云服务商、跨Linux操作系统发行版进行部署
    

![](https://img2024.cnblogs.com/blog/1080590/202501/1080590-20250115095145945-1716950576.png)

容器化部署方式给带来很多的便利，但是也会出现一些问题，比如说：

*   一个容器故障停机了，怎么样让另外一个容器立刻启动去替补停机的容器
*   当并发访问量变大的时候，怎么样做到横向扩展容器数量

这些容器管理的问题统称为**容器编排**问题，为了解决这些容器编排问题，就产生了一些容器编排的软件：

*   **Swarm**：Docker自己的容器编排工具
*   **Mesos**：Apache的一个资源统一管控的工具，需要和Marathon结合使用
*   **Kubernetes**：Google开源的的容器编排工具

#### kubernetes简介

kubernetes，是一个全新的基于容器技术的分布式架构领先方案，是谷歌严格保密十几年的秘密武器----Borg系统的一个开源版本，于2014年9月发布第一个版本，2015年7月发布第一个正式版本。

kubernetes的本质是**一组服务器集群**，它可以在集群的每个节点上运行特定的程序，来对节点中的容器进行管理。目的是实现资源管理的自动化，主要提供了如下的主要功能：

*   **自我修复**：一旦某一个容器崩溃，能够在1秒中左右迅速启动新的容器
*   **弹性伸缩**：可以根据需要，自动对集群中正在运行的容器数量进行调整
*   **服务发现**：服务可以通过自动发现的形式找到它所依赖的服务
*   **负载均衡**：如果一个服务起动了多个容器，能够自动实现请求的负载均衡
*   **版本回退**：如果发现新发布的程序版本有问题，可以立即回退到原来的版本
*   **存储编排**：可以根据容器自身的需求自动创建存储卷

#### kubernetes组件

一个kubernetes集群主要是由**控制节点(master)**、**工作节点(node)**构成，每个节点上都会安装不同的组件。

**master：集群的控制平面，负责集群的决策 ( 管理 )**

> **ApiServer** : 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制
> 
> **Scheduler** : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上
> 
> **ControllerManager** : 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等
> 
> **Etcd** ：负责存储集群中各种资源对象的信息

**node：集群的数据平面，负责为容器提供运行环境 ( 干活 )**

> **Kubelet** : 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器
> 
> **KubeProxy** : 负责提供集群内部的服务发现和负载均衡
> 
> **Docker** : 负责节点上容器的各种操作

![](https://img2024.cnblogs.com/blog/1080590/202501/1080590-20250115100511123-1703559542.png)

下面，以部署一个nginx服务来说明kubernetes系统各个组件调用关系：

1.  首先要明确，一旦kubernetes环境启动之后，master和node都会将自身的信息存储到etcd数据库中。
    
2.  一个nginx服务的安装请求会首先被发送到master节点的apiServer组件。
    
3.  apiServer组件会调用scheduler组件来决定到底应该把这个服务安装到哪个node节点上在此时，它会从etcd中读取各个node节点的信息，然后按照一定的算法进行选择，并将结果告知apiServer。
    
4.  apiServer调用controller-manager去调度Node节点安装nginx服务。
    
5.  kubelet接收到指令后，会通知docker，然后由docker来启动一个nginx的pod，pod是kubernetes的最小操作单元，容器必须跑在pod中至此。
    
6.  一个nginx服务就运行了，如果需要访问nginx，就需要通过kube-proxy来对pod产生访问的代理，这样外界用户就可以访问集群中的nginx服务了。
    

#### 1.4 kubernetes概念

**Master**：集群控制节点，每个集群需要至少一个master节点负责集群的管控

**Node**：工作负载节点，由master分配容器到这些node工作节点上，然后node节点上的docker负责容器的运行

**Pod**：kubernetes的最小控制单元，容器都是运行在pod中的，一个pod中可以有1个或者多个容器

**Controller**：控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等

**Service**：pod对外服务的统一入口，下面可以维护者同一类的多个pod

**Label**：标签，用于对pod进行分类，同一类pod会拥有相同的标签

**NameSpace**：命名空间，用来隔离pod的运行环境

### kubernetes集群环境搭建

#### 前置知识点

目前生产部署Kubernetes 集群主要有两种方式：

**kubeadm**

Kubeadm 是一个K8s 部署工具，提供kubeadm init 和kubeadm join，用于快速部署Kubernetes 集群。

官方地址：[https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/](https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/)

**二进制包**

从github 下载发行版的二进制包，手动部署每个组件，组成Kubernetes 集群。

Kubeadm 降低部署门槛，但屏蔽了很多细节，遇到问题很难排查。如果想更容易可控，推荐使用二进制包部署Kubernetes 集群，虽然手动部署麻烦点，期间可以学习很多工作原理，也利于后期维护。

#### kubeadm 部署方式介绍

kubeadm 是官方社区推出的一个用于快速部署kubernetes 集群的工具，这个工具能通过两条指令完成一个kubernetes 集群的部署：

*   创建一个Master 节点kubeadm init
*   将Node 节点加入到当前集群中$ kubeadm join <Master 节点的IP 和端口>

#### 安装要求

在开始之前，部署Kubernetes 集群机器需要满足以下几个条件：

*   一台或多台机器，操作系统CentOS7.x-86\_x64
*   硬件配置：2GB 或更多RAM，2 个CPU 或更多CPU，硬盘30GB 或更多
*   集群中所有机器之间网络互通
*   可以访问外网，需要拉取镜像
*   禁止swap 分区

#### 最终目标

*   在所有节点上安装Docker 和kubeadm
*   部署Kubernetes Master
*   部署容器网络插件
*   部署Kubernetes Node，将节点加入Kubernetes 集群中
*   部署Dashboard Web 页面，可视化查看Kubernetes 资源

#### 准备环境

角色

IP地址

组件

k8s-master01

172.16.5.3

docker，kubectl，kubeadm，kubelet

k8s-node01

172.16.5.4

docker，kubectl，kubeadm，kubelet

k8s-node02

172.16.5.5

docker，kubectl，kubeadm，kubelet

#### 系统初始化（所有节点都要操作）

    # 设置系统主机名以及 Host 文件的相互解析
    hostnamectl set-hostname k8s-master01 && bash
    hostnamectl set-hostname k8s-node01 && bash
    hostnamectl set-hostname k8s-node02 && bash
    
    cat > /etc/hosts <<EOF
    172.16.5.3     k8s-master01
    172.16.5.4     k8s-node01
    172.16.5.5     k8s-node02
    EOF
    
    scp /etc/hosts root@172.16.5.4:/etc/hosts 
    scp /etc/hosts root@172.16.5.5:/etc/hosts 
    
    # 安装依赖文件
    yum install -y conntrack ntpdate ntp ipvsadm ipset jq iptables curl sysstat libseccomp wget vim net-tools git
    
    # 设置防火墙为 Iptables 并设置空规则
    systemctl stop firewalld && systemctl disable firewalld
    
    yum -y install iptables-services && systemctl start iptables && systemctl enable iptables && iptables -F && service iptables save
    
    # 关闭 SELINUX
    swapoff -a && sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
    
    setenforce 0 && sed -i 's/^SELINUX=.*/SELINUX=disabled/' /etc/selinux/config
    
    # 调整内核参数，对于 K8S
    modprobe br_netfilter
    
    cat > /etc/sysctl.d/kubernetes.conf <<EOF
    net.bridge.bridge-nf-call-iptables=1
    net.bridge.bridge-nf-call-ip6tables=1
    net.ipv4.ip_forward=1
    net.ipv4.tcp_tw_recycle=0
    vm.swappiness=0 # 禁止使用 swap 空间，只有当系统 OOM 时才允许使用它
    vm.overcommit_memory=1 # 不检查物理内存是否够用
    vm.panic_on_oom=0 # 开启 OOM
    fs.inotify.max_user_instances=8192
    fs.inotify.max_user_watches=1048576
    fs.file-max=52706963
    fs.nr_open=52706963
    net.ipv6.conf.all.disable_ipv6=1
    net.netfilter.nf_conntrack_max=2310720
    EOF
    
    sysctl -p /etc/sysctl.d/kubernetes.conf
    
    # 调整系统时区
    # 设置系统时区为 中国/上海
    timedatectl set-timezone Asia/Shanghai
    # 将当前的 UTC 时间写入硬件时钟
    timedatectl set-local-rtc 0
    # 重启依赖于系统时间的服务
    systemctl restart rsyslog
    systemctl restart crond
    
    # 设置 rsyslogd 和 systemd journald
    # 持久化保存日志的目录
    mkdir /var/log/journal 
    mkdir /etc/systemd/journald.conf.d
    cat > /etc/systemd/journald.conf.d/99-prophet.conf <<EOF
    [Journal]
    # 持久化保存到磁盘
    Storage=persistent
    
    # 压缩历史日志
    Compress=yes
    
    SyncIntervalSec=5m
    RateLimitInterval=30s
    RateLimitBurst=1000
    
    # 最大占用空间 10G
    SystemMaxUse=10G
    
    # 单日志文件最大 200M
    SystemMaxFileSize=200M
    
    # 日志保存时间 2 周
    MaxRetentionSec=2week
    
    # 不将日志转发到 syslog
    ForwardToSyslog=no
    EOF
    
    systemctl restart systemd-journald
    
    
    # kube-proxy开启ipvs的前置条件
    cat > /etc/sysconfig/modules/ipvs.modules <<EOF
    #!/bin/bash
    modprobe -- ip_vs
    modprobe -- ip_vs_rr
    modprobe -- ip_vs_wrr
    modprobe -- ip_vs_sh
    modprobe -- nf_conntrack_ipv4
    EOF
    
    chmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep -e ip_vs -e nf_conntrack_ipv4
    
    
    # 安装 Docker 软件
    yum install -y yum-utils device-mapper-persistent-data lvm2
    
    yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
    
    yum install -y docker-ce
    
    ## 创建 /etc/docker 目录
    mkdir /etc/docker
    
    cat > /etc/docker/daemon.json <<EOF
    {
    "exec-opts": ["native.cgroupdriver=systemd"],
    "log-driver": "json-file",
    "log-opts": {
    "max-size": "100m"
    }
    }
    EOF
    
    ## 配置关闭 Docker 的 cgroups，修改 /etc/docker/daemon.json，加入以下内容
    "exec-opts": ["native.cgroupdriver=systemd"]
    
    mkdir -p /etc/systemd/system/docker.service.d
    # 重启docker服务
    systemctl daemon-reload && systemctl restart docker && systemctl enable docker
    
    
    # 安装 Kubeadm
    
    cat > /etc/yum.repos.d/kubernetes.repo <<EOF
    [kubernetes]
    name=Kubernetes
    baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
    enabled=1
    gpgcheck=0
    repo_gpgcheck=0
    gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
    http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
    EOF
    
    yum install -y kubelet kubeadm kubectl && systemctl enable kubelet
    

### 部署Kubernetes Master

#### 初始化主节点（主节点操作）

    kubeadm init --apiserver-advertise-address=172.16.5.3 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.21.1 --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16
    
    mkdir -p $HOME/.kube
    
    cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
    
    chown $(id -u):$(id -g) $HOME/.kube/config
    

#### 加入主节点以及其余工作节点

    kubeadm join 172.16.5.3:6443 --token h0uelc.l46qp29nxscke7f7 \
            --discovery-token-ca-cert-hash sha256:abc807778e24bff73362ceeb783cc7f6feec96f20b4fd707c3f8e8312294e28f 
    
    ## token 没有过期可以通过如下命令获取
    kubeadm token list
    ## 如果 token 已经过期，就重新申请
    kubeadm token create
    
    ## 获取 --discovery-token-ca-cert-hash 值，得到值后需要在前面拼接上 sha256:
    openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | \
    openssl dgst -sha256 -hex | sed 's/^.* //'
    

#### 部署网络

    kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
    

下面是文件内容

    ---
    apiVersion: policy/v1beta1
    kind: PodSecurityPolicy
    metadata:
      name: psp.flannel.unprivileged
      annotations:
        seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default
        seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default
        apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default
        apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default
    spec:
      privileged: false
      volumes:
      - configMap
      - secret
      - emptyDir
      - hostPath
      allowedHostPaths:
      - pathPrefix: "/etc/cni/net.d"
      - pathPrefix: "/etc/kube-flannel"
      - pathPrefix: "/run/flannel"
      readOnlyRootFilesystem: false
      # Users and groups
      runAsUser:
        rule: RunAsAny
      supplementalGroups:
        rule: RunAsAny
      fsGroup:
        rule: RunAsAny
      # Privilege Escalation
      allowPrivilegeEscalation: false
      defaultAllowPrivilegeEscalation: false
      # Capabilities
      allowedCapabilities: ['NET_ADMIN', 'NET_RAW']
      defaultAddCapabilities: []
      requiredDropCapabilities: []
      # Host namespaces
      hostPID: false
      hostIPC: false
      hostNetwork: true
      hostPorts:
      - min: 0
        max: 65535
      # SELinux
      seLinux:
        # SELinux is unused in CaaSP
        rule: 'RunAsAny'
    ---
    kind: ClusterRole
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: flannel
    rules:
    - apiGroups: ['extensions']
      resources: ['podsecuritypolicies']
      verbs: ['use']
      resourceNames: ['psp.flannel.unprivileged']
    - apiGroups:
      - ""
      resources:
      - pods
      verbs:
      - get
    - apiGroups:
      - ""
      resources:
      - nodes
      verbs:
      - list
      - watch
    - apiGroups:
      - ""
      resources:
      - nodes/status
      verbs:
      - patch
    ---
    kind: ClusterRoleBinding
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: flannel
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: flannel
    subjects:
    - kind: ServiceAccount
      name: flannel
      namespace: kube-system
    ---
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: flannel
      namespace: kube-system
    ---
    kind: ConfigMap
    apiVersion: v1
    metadata:
      name: kube-flannel-cfg
      namespace: kube-system
      labels:
        tier: node
        app: flannel
    data:
      cni-conf.json: |
        {
          "name": "cbr0",
          "cniVersion": "0.3.1",
          "plugins": [
            {
              "type": "flannel",
              "delegate": {
                "hairpinMode": true,
                "isDefaultGateway": true
              }
            },
            {
              "type": "portmap",
              "capabilities": {
                "portMappings": true
              }
            }
          ]
        }
      net-conf.json: |
        {
          "Network": "10.244.0.0/16",
          "Backend": {
            "Type": "vxlan"
          }
        }
    ---
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: kube-flannel-ds
      namespace: kube-system
      labels:
        tier: node
        app: flannel
    spec:
      selector:
        matchLabels:
          app: flannel
      template:
        metadata:
          labels:
            tier: node
            app: flannel
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                - matchExpressions:
                  - key: kubernetes.io/os
                    operator: In
                    values:
                    - linux
          hostNetwork: true
          priorityClassName: system-node-critical
          tolerations:
          - operator: Exists
            effect: NoSchedule
          serviceAccountName: flannel
          initContainers:
          - name: install-cni
            image: quay.io/coreos/flannel:v0.14.0
            command:
            - cp
            args:
            - -f
            - /etc/kube-flannel/cni-conf.json
            - /etc/cni/net.d/10-flannel.conflist
            volumeMounts:
            - name: cni
              mountPath: /etc/cni/net.d
            - name: flannel-cfg
              mountPath: /etc/kube-flannel/
          containers:
          - name: kube-flannel
            image: quay.io/coreos/flannel:v0.14.0
            command:
            - /opt/bin/flanneld
            args:
            - --ip-masq
            - --kube-subnet-mgr
            resources:
              requests:
                cpu: "100m"
                memory: "50Mi"
              limits:
                cpu: "100m"
                memory: "50Mi"
            securityContext:
              privileged: false
              capabilities:
                add: ["NET_ADMIN", "NET_RAW"]
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            volumeMounts:
            - name: run
              mountPath: /run/flannel
            - name: flannel-cfg
              mountPath: /etc/kube-flannel/
          volumes:
          - name: run
            hostPath:
              path: /run/flannel
          - name: cni
            hostPath:
              path: /etc/cni/net.d
          - name: flannel-cfg
            configMap:
              name: kube-flannel-cfg
    

### 测试kubernetes 集群

#### 部署nginx 测试

    kubectl create deployment nginx --image=nginx
    
    kubectl expose deployment nginx --port=80 --type=NodePort
    
    kubectl get pod,svc
    

\*\*\*\*\*\*\*\*\*\* 如果您认为这篇文章还不错或者有所收获，请点击右下角的【推荐】/【赞助】按钮，因为您的支持是我继续创作分享的最大动力！ \*\*\*\*\*\*\*\*\*\*

  

作者：[讲文张字](https://www.cnblogs.com/zhangwencheng)  
出处：[https://www.cnblogs.com/zhangwencheng](https://www.cnblogs.com/zhangwencheng)  
版权：本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出 [原文链接](#)