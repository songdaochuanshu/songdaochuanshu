---
layout: post
title: 'spark streamingæ¶ˆè´¹rocketmqçš„å‡ ç§æ–¹å¼'
date: "2025-09-05T00:39:13Z"
---
spark streamingæ¶ˆè´¹rocketmqçš„å‡ ç§æ–¹å¼
==============================

åœ¨ Spark é‡Œæ¥å…¥ **RocketMQ**ï¼Œä¸»è¦æœ‰ä¸¤å¤§ç±»æ–¹å¼ï¼š

* * *

ğŸ”¹ 1. åŸºäº **è€çš„ Spark Streaming (DStream API)**
---------------------------------------------

RocketMQ ç¤¾åŒºæä¾›è¿‡ **rocketmq-spark** connectorï¼ˆåœ¨ `apache/rocketmq-externals` é‡Œï¼‰ï¼Œå¯ä»¥åƒ Kafka ä¸€æ ·åˆ›å»º DStreamï¼š

### æ–¹å¼ Aï¼šReceiver æ¨¡å¼

*   ä½¿ç”¨è‡ªå®šä¹‰çš„ `Receiver` ä» RocketMQ æ‹‰å–æ¶ˆæ¯ã€‚
    
*   æ¯æ¡æ¶ˆæ¯è¿›å…¥ Spark Streaming çš„ `ReceiverInputDStream`ã€‚
    
*   ä¼˜ç‚¹ï¼šå®ç°ç®€å•ã€‚
    
*   ç¼ºç‚¹ï¼šæ¶ˆæ¯ä¼šå…ˆç¼“å­˜åœ¨ Spark executor çš„å†…å­˜é‡Œï¼Œå®¹é”™ä¾èµ– Spark çš„ WALï¼ˆWrite Ahead Logï¼‰ï¼Œæ€§èƒ½å’Œå¯é æ€§ä¸€èˆ¬ã€‚
    

#### a. ä¸ä½¿ç”¨WALï¼ˆWrite Ahead Logï¼‰

**æ ¸å¿ƒæ€è·¯æ˜¯ï¼š**

*   åœ¨ Spark é‡Œå®ç°ä¸€ä¸ªè‡ªå®šä¹‰ `Receiver<T>`ï¼Œå†…éƒ¨è¿è¡Œ **RocketMQ PushConsumer**ã€‚
    
*   PushConsumer æ”¶åˆ°æ¶ˆæ¯åï¼Œè°ƒç”¨ `store(msg)` æŠŠæ•°æ®å†™å…¥ Spark Streaming çš„å†…å­˜é˜Ÿåˆ—ã€‚
    
*   Spark Streaming åç»­æŠŠè¿™äº›æ•°æ®æ‰“åŒ…æˆ RDD å¤„ç†ã€‚
    

**æ ¸å¿ƒæµç¨‹ï¼š**

1.  **RocketMQ â†’ PushConsumer**
    
    *   æ¶ˆæ¯æ¨é€åˆ° Spark è¿›ç¨‹ã€‚
        
2.  **Spark Receiver â†’ store()**
    
    *   Receiver ç¼“å­˜æ¶ˆæ¯ï¼Œå­˜åˆ° Spark executor çš„ BlockManagerã€‚
        
3.  **Spark Streaming Job**
    
    *   å®šæ—¶å°†æ•°æ®ç”Ÿæˆ RDD è¿›è¡Œå¤„ç†ã€‚
        

**ç¤ºä¾‹ä»£ç **

### 1ï¸âƒ£ Order ç±»

 1 import java.io.Serializable; 2 
 3 public class Order implements Serializable { 4     private String orderNo; 5     private Long cost; 6 
 7     public Order(String orderNo, Long cost) { 8         this.orderNo = orderNo; 9         this.cost = cost;
10 }
11 
12     public String getOrderNo() { return orderNo; }
13     public Long getCost() { return cost; }
14 
15 @Override
16     public String toString() {
17         return "Order{" +
18                 "orderNo='" + orderNo + '\\'' +
19                 ", cost=" + cost +
20                 '}';
21 }
22 }

2ï¸âƒ£ è‡ªå®šä¹‰ RocketMQReceiver

 1 import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer; 2 import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext; 3 import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus; 4 import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently; 5 import org.apache.rocketmq.common.message.MessageExt; 6 import org.apache.spark.storage.StorageLevel; 7 import org.apache.spark.streaming.receiver.Receiver; 8 
 9 import java.io.ByteArrayInputStream;
10 import java.io.ObjectInputStream;
11 import java.util.List;
12 
13 public class RocketMQReceiver extends Receiver<Order> {
14     private final String namesrvAddr;
15     private final String topic;
16     private final String group;
17 
18     private transient DefaultMQPushConsumer consumer;
19 
20     public RocketMQReceiver(String namesrvAddr, String topic, String group) {
21         super(StorageLevel.MEMORY\_AND\_DISK\_2());
22         this.namesrvAddr = namesrvAddr;
23         this.topic = topic;
24         this.group = group;
25 }
26 
27 @Override
28     public void onStart() {
29         new Thread(this::initConsumer).start();
30 }
31 
32     private void initConsumer() {
33         try {
34             consumer = new DefaultMQPushConsumer(group);
35 consumer.setNamesrvAddr(namesrvAddr);
36             consumer.subscribe(topic, "\*");
37 
38             consumer.registerMessageListener((MessageListenerConcurrently) (msgs, context) -> {
39                 for (MessageExt msg : msgs) {
40                     Order order = deserialize(msg.getBody());
41                     if (order != null) {
42                         store(order); // æ¨é€åˆ° Spark
43 }
44 }
45                 return ConsumeConcurrentlyStatus.CONSUME\_SUCCESS;
46 });
47 
48 consumer.start();
49             System.out.println("RocketMQReceiver started.");
50         } catch (Exception e) {
51             restart("Error starting RocketMQReceiver", e);
52 }
53 }
54 
55 @Override
56     public void onStop() {
57         if (consumer != null) {
58 consumer.shutdown();
59 }
60 }
61 
62     private Order deserialize(byte\[\] body) {
63         try (ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(body))) {
64             return (Order) ois.readObject();
65         } catch (Exception e) {
66             return null;
67 }
68 }
69 }

3ï¸âƒ£ Spark Streaming ä¸»ç¨‹åº

 1 import org.apache.spark.SparkConf; 2 import org.apache.spark.streaming.Durations; 3 import org.apache.spark.streaming.api.java.JavaReceiverInputDStream; 4 import org.apache.spark.streaming.api.java.JavaStreamingContext; 5 
 6 public class RocketMQStreamingApp { 7     public static void main(String\[\] args) throws Exception { 8         SparkConf conf = new SparkConf().setAppName("RocketMQReceiverExample").setMaster("local\[2\]");
 9         JavaStreamingContext ssc = new JavaStreamingContext(conf, Durations.seconds(5));
10 
11         // åˆ›å»º Receiver
12         JavaReceiverInputDStream<Order> stream =
13                 ssc.receiverStream(new RocketMQReceiver("localhost:9876", "OrderTopic", "spark\_group"));
14 
15         // ç®€å•å¤„ç†ï¼šæ‰“å°è®¢å•
16         stream.foreachRDD(rdd -> {
17             rdd.foreach(order -> System.out.println("Got order: " + order));
18 });
19 
20 ssc.start();
21 ssc.awaitTermination();
22 }
23 }

#### **b.**Â ä½¿ç”¨WALï¼ˆWrite Ahead Logï¼‰

åœ¨ Spark Streaming é‡Œï¼Œå¼€å¯ WAL å¾ˆç®€å•ï¼š

1.  **è®¾ç½® checkpoint ç›®å½•**ï¼ˆå¿…é¡»æ˜¯ HDFS æˆ–å¯é å­˜å‚¨ï¼‰ï¼›
    
2.  Receiver è¦ç”¨ `StorageLevel.MEMORY_AND_DISK_SER_2()`ï¼ˆæ”¯æŒ WAL æŒä¹…åŒ–ï¼‰ï¼›
    
3.  Spark è‡ªåŠ¨æŠŠæ¯æ¡æ¥æ”¶åˆ°çš„æ•°æ®å…ˆå†™åˆ° WALï¼Œå†äº¤ç»™ BlockManagerã€‚
    

**ğŸš€ å®Œæ•´ç¤ºä¾‹ä»£ç ï¼ˆå¸¦ WALï¼‰**

1ï¸âƒ£ Order ç±»ï¼ˆå’Œä¹‹å‰ç›¸åŒï¼‰

 1 import java.io.Serializable; 2 
 3 public class Order implements Serializable { 4     private String orderNo; 5     private Long cost; 6 
 7     public Order(String orderNo, Long cost) { 8         this.orderNo = orderNo; 9         this.cost = cost;
10 }
11 
12     public String getOrderNo() { return orderNo; }
13     public Long getCost() { return cost; }
14 
15 @Override
16     public String toString() {
17         return "Order{" +
18                 "orderNo='" + orderNo + '\\'' +
19                 ", cost=" + cost +
20                 '}';
21 }
22 }

2ï¸âƒ£ RocketMQReceiverï¼ˆæ”¹ç”¨æ”¯æŒ WAL çš„ StorageLevelï¼‰

 1 import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer; 2 import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext; 3 import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus; 4 import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently; 5 import org.apache.rocketmq.common.message.MessageExt; 6 import org.apache.spark.storage.StorageLevel; 7 import org.apache.spark.streaming.receiver.Receiver; 8 
 9 import java.io.ByteArrayInputStream;
10 import java.io.ObjectInputStream;
11 
12 public class RocketMQReceiver extends Receiver<Order> {
13     private final String namesrvAddr;
14     private final String topic;
15     private final String group;
16 
17     private transient DefaultMQPushConsumer consumer;
18 
19     public RocketMQReceiver(String namesrvAddr, String topic, String group) {
20         // ä½¿ç”¨æ”¯æŒ WAL çš„å­˜å‚¨çº§åˆ«
21         super(StorageLevel.MEMORY\_AND\_DISK\_SER\_2());
22         this.namesrvAddr = namesrvAddr;
23         this.topic = topic;
24         this.group = group;
25 }
26 
27 @Override
28     public void onStart() {
29         new Thread(this::initConsumer).start();
30 }
31 
32     private void initConsumer() {
33         try {
34             consumer = new DefaultMQPushConsumer(group);
35 consumer.setNamesrvAddr(namesrvAddr);
36             consumer.subscribe(topic, "\*");
37 
38             consumer.registerMessageListener((MessageListenerConcurrently) (msgs, context) -> {
39                 for (MessageExt msg : msgs) {
40                     Order order = deserialize(msg.getBody());
41                     if (order != null) {
42                         // Spark ä¼šå…ˆå†™ WALï¼Œå†å†™ BlockManager
43 store(order);
44 }
45 }
46                 return ConsumeConcurrentlyStatus.CONSUME\_SUCCESS;
47 });
48 
49 consumer.start();
50             System.out.println("RocketMQReceiver started with WAL.");
51         } catch (Exception e) {
52             restart("Error starting RocketMQReceiver", e);
53 }
54 }
55 
56 @Override
57     public void onStop() {
58         if (consumer != null) {
59 consumer.shutdown();
60 }
61 }
62 
63     private Order deserialize(byte\[\] body) {
64         try (ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(body))) {
65             return (Order) ois.readObject();
66         } catch (Exception e) {
67             return null;
68 }
69 }
70 }

3ï¸âƒ£ ä¸»ç¨‹åºï¼ˆå¼€å¯ WAL éœ€è¦ checkpointï¼‰

 1 import org.apache.spark.SparkConf; 2 import org.apache.spark.streaming.Durations; 3 import org.apache.spark.streaming.api.java.JavaReceiverInputDStream; 4 import org.apache.spark.streaming.api.java.JavaStreamingContext; 5 
 6 public class RocketMQStreamingApp { 7     public static void main(String\[\] args) throws Exception { 8         SparkConf conf = new SparkConf() 9                 .setAppName("RocketMQReceiverWithWAL")
10                 .setMaster("local\[2\]");
11 
12         // æ¯ 5 ç§’ä¸€ä¸ª batch
13         JavaStreamingContext ssc = new JavaStreamingContext(conf, Durations.seconds(5));
14 
15         // è®¾ç½® checkpoint ç›®å½•ï¼ˆå¿…é¡»æ˜¯å¯é å­˜å‚¨ï¼Œå¦‚ HDFSï¼‰
16         ssc.checkpoint("hdfs://namenode:8020/spark-checkpoints/rocketmq");
17 
18         // åˆ›å»ºå¸¦ WAL çš„ Receiver
19         JavaReceiverInputDStream<Order> stream =
20                 ssc.receiverStream(new RocketMQReceiver("localhost:9876", "OrderTopic", "spark\_group"));
21 
22         // ç®€å•å¤„ç†ï¼šæ‰“å°è®¢å•
23         stream.foreachRDD(rdd -> {
24             rdd.foreach(order -> System.out.println("Got order (with WAL): " + order));
25 });
26 
27 ssc.start();
28 ssc.awaitTermination();
29 }
30 }

**æ³¨æ„äº‹é¡¹**

1.  **checkpoint å¿…é¡»æ˜¯ HDFS/S3/OSS** ç­‰åˆ†å¸ƒå¼å­˜å‚¨ï¼Œæœ¬åœ°è·¯å¾„åªé€‚åˆæµ‹è¯•ã€‚
    
2.  WAL ä¼šå†™æ—¥å¿—æ–‡ä»¶ï¼Œä¿è¯ **è‡³å°‘ä¸€æ¬¡ï¼ˆat-least-onceï¼‰** è¯­ä¹‰ï¼Œä½†ä»å¯èƒ½æœ‰é‡å¤æ¶ˆæ¯ï¼Œéœ€è¦ä¸šåŠ¡ç«¯å»é‡ã€‚
    
3.  Receiver æ¨¡å¼ + WAL æ€§èƒ½æ¯” Direct æ¨¡å¼å·®ï¼ˆå¤šä¸€æ¬¡ç£ç›˜ IOï¼‰ã€‚
    
4.  è‹¥æƒ³è¦ **exactly-once**ï¼Œé€šå¸¸æ¨è Structured Streamingï¼ˆè‡ªåŠ¨ checkpoint + sink æ”¯æŒäº‹åŠ¡ï¼‰ã€‚
    

#### âš ï¸ Receiver æ¨¡å¼ç‰¹ç‚¹

âœ… **ä¼˜ç‚¹**

*   å®ç°ç®€å•ï¼šç›´æ¥ç”¨ RocketMQ PushConsumer æ¨æ¶ˆæ¯åˆ° Sparkã€‚
    
*   ä¸éœ€è¦æ‰‹åŠ¨ç®¡ç† offsetã€‚
    

âŒ **ç¼ºç‚¹**

*   Spark Receiver å…ˆæŠŠæ•°æ®å­˜åˆ°å†…å­˜ï¼ˆBlockManagerï¼‰ï¼Œå¦‚æœ Spark å´©æºƒï¼Œæ•°æ®å¯èƒ½ä¸¢å¤±ã€‚
    
*   å®¹é”™è¦ä¾èµ– **WALï¼ˆWrite Ahead Logï¼‰**ï¼Œä½† WAL ä¼šå†™ HDFSï¼Œæ€§èƒ½æ¯” Direct æ¨¡å¼å·®ã€‚
    
*   éš¾ä»¥ä¿è¯ä¸¥æ ¼ **exactly-once**ã€‚
    

### æ–¹å¼ Bï¼šDirect æ¨¡å¼

*   ç±»ä¼¼ Kafka Direct Streamï¼ŒSpark Streaming ç›´æ¥ä» RocketMQ æ‹‰å–æ•°æ®ï¼Œä¸ä¾èµ– Spark Receiverã€‚
    
*   æ¶ˆæ¯ offset ç”±ç”¨æˆ·ç®¡ç†ï¼Œå¯ä»¥æ‰‹åŠ¨æäº¤ï¼ˆé€šå¸¸å†™åˆ° Zookeeper æˆ–å¤–éƒ¨å­˜å‚¨ï¼‰ã€‚
    
*   ä¼˜ç‚¹ï¼šæ€§èƒ½æ›´å¥½ï¼Œä¿è¯æ•°æ®è‡³å°‘ä¸€æ¬¡å¤„ç†ã€‚
    
*   ç¼ºç‚¹ï¼šéœ€è¦è‡ªå·±ç®¡ç† offset æäº¤ï¼Œå¼€å‘å¤æ‚ä¸€äº›ã€‚
    

è€ŒDirect æ¨¡å¼çš„ç‰¹ç‚¹æ˜¯ï¼š

*   ä¸ä¾èµ– Spark Receiverï¼ˆæ²¡æœ‰ WAL å¼€é”€ï¼‰ã€‚
    
*   Spark Driver ç›´æ¥ä» RocketMQ æ‹‰å–æ¶ˆæ¯ã€‚
    
*   æ¶ˆè´¹çš„ offset ç”± **Spark Driver ç»´æŠ¤**ï¼Œé€šå¸¸è¦æ‰‹åŠ¨å­˜å‚¨åˆ°å¤–éƒ¨ï¼ˆæ¯”å¦‚ HDFSã€MySQLã€Zookeeperï¼‰ä»¥ä¾¿æ¢å¤ã€‚
    

#### å®ç°æ€è·¯

1.  **å‡†å¤‡ RocketMQ Consumer API**
    
    *   Spark æ²¡æœ‰å†…ç½® RocketMQ Direct APIï¼ˆåƒ Kafka é‚£æ ·ï¼‰ï¼Œéœ€è¦å€ŸåŠ© **rocketmq-spark connector** æˆ–è€…è‡ªå®šä¹‰ Consumerã€‚
        
    *   åŸç†å’Œ Kafka DirectStream ä¸€æ ·ï¼š
        
        *   åœ¨æ¯ä¸ª micro-batch è§¦å‘æ—¶ï¼Œå» RocketMQ æ‹‰å–ä¸€æ®µæ¶ˆæ¯ï¼ˆæŒ‡å®šèµ·å§‹ offsetã€ç»“æŸ offsetï¼‰ã€‚
            
        *   è½¬æ¢æˆ RDDï¼Œäº¤ç»™ Spark æ‰§è¡Œã€‚
            
2.  **å…³é”®ç‚¹**
    
    *   **æ‰‹åŠ¨ç®¡ç† offset**ï¼šRocketMQ ä¸ä¼šè‡ªåŠ¨å¸® Spark æäº¤ï¼Œéœ€è¦ä½ æŠŠ offset å­˜åˆ°å¤–éƒ¨å­˜å‚¨ï¼ˆæ¯”å¦‚ HDFS/ZK/MySQLï¼‰ã€‚
        
    *   **å¹¶è¡Œåº¦**ï¼šå¯ä»¥æŒ‰ Topic çš„ Queueï¼ˆpartition ç±»ä¼¼ï¼‰æ‹†åˆ† RDDï¼Œåˆ†å‘åˆ°ä¸åŒ taskã€‚
        
    *   **å®¹é”™**ï¼šä½œä¸šå¤±è´¥åï¼Œé‡æ–°ä»å­˜å‚¨çš„ offset ä½ç½®æ¢å¤ã€‚
        

#### ğŸš€ ä»£ç ç¤ºä¾‹ï¼ˆDirect æ¨¡å¼ä¼ªå®ç°ï¼‰

å‡è®¾æœ‰ `OrderTopic`ï¼ŒåŒ…å«å¤šä¸ª MessageQueueï¼š

 1 package com.example; 2 
 3 import org.apache.rocketmq.client.consumer.DefaultMQPullConsumer; 4 import org.apache.rocketmq.client.consumer.PullResult; 5 import org.apache.rocketmq.client.consumer.PullStatus; 6 import org.apache.rocketmq.common.message.MessageExt; 7 import org.apache.rocketmq.common.message.MessageQueue; 8 import org.apache.spark.SparkConf; 9 import org.apache.spark.api.java.JavaRDD;
10 import org.apache.spark.api.java.JavaSparkContext;
11 import org.apache.spark.streaming.Durations;
12 import org.apache.spark.streaming.api.java.JavaInputDStream;
13 import org.apache.spark.streaming.api.java.JavaStreamingContext;
14 
15 import java.util.\*;
16 
17 public class RocketMQDirectStreamExample {
18     public static void main(String\[\] args) throws Exception {
19         SparkConf conf = new SparkConf()
20                 .setAppName("RocketMQDirectStreamExample")
21                 .setMaster("local\[2\]");
22 
23         JavaSparkContext sc = new JavaSparkContext(conf);
24         JavaStreamingContext ssc = new JavaStreamingContext(sc, Durations.seconds(5));
25 
26         // RocketMQ Consumer
27         DefaultMQPullConsumer consumer = new DefaultMQPullConsumer("spark\_consumer\_group");
28         consumer.setNamesrvAddr("localhost:9876");
29 consumer.start();
30 
31         // è·å– Topic ä¸‹æ‰€æœ‰ Queue
32         Set<MessageQueue> mqs = consumer.fetchSubscribeMessageQueues("OrderTopic");
33 
34         // æ‰‹åŠ¨ç»´æŠ¤æ¯ä¸ª queue çš„ offset
35         Map<MessageQueue, Long> offsetTable = new HashMap<>();
36         for (MessageQueue mq : mqs) {
37             offsetTable.put(mq, 0L); // å¯ä»¥ä»å¤–éƒ¨å­˜å‚¨æ¢å¤
38 }
39 
40         // æ¯ä¸ª micro-batch æ‹‰å–æ•°æ®
41         ssc.foreachRDD(time -> {
42             List<Order> orders = new ArrayList<>();
43 
44             for (MessageQueue mq : mqs) {
45                 long offset = offsetTable.get(mq);
46 
47                 // æ‹‰å–æ¶ˆæ¯
48                 PullResult pullResult = consumer.pullBlockIfNotFound(mq, "\*", offset, 32);
49 
50                 if (pullResult.getPullStatus() == PullStatus.FOUND) {
51                     for (MessageExt msg : pullResult.getMsgFoundList()) {
52                         // ååºåˆ—åŒ–æ¶ˆæ¯ä½“
53                         Order order = deserialize(msg.getBody());
54                         if (order != null) {
55 orders.add(order);
56 }
57 }
58                     // æ›´æ–° offset
59 offsetTable.put(mq, pullResult.getNextBeginOffset());
60 }
61 }
62 
63             // è½¬æ¢ä¸º RDD
64             JavaRDD<Order> rdd = sc.parallelize(orders);
65             rdd.foreach(o -> System.out.println("Got Order: " + o));
66 
67             // TODO: æŠŠ offsetTable æŒä¹…åŒ–åˆ°å¤–éƒ¨å­˜å‚¨ï¼ˆä¿è¯å®¹é”™ï¼‰
68 });
69 
70 ssc.start();
71 ssc.awaitTermination();
72 }
73 
74     private static Order deserialize(byte\[\] body) {
75         try (java.io.ObjectInputStream ois =
76                      new java.io.ObjectInputStream(new java.io.ByteArrayInputStream(body))) {
77             return (Order) ois.readObject();
78         } catch (Exception e) {
79             return null;
80 }
81 }
82 }

#### å…³é”®ç‚¹è¯´æ˜

1.  **offset ç®¡ç†**
    
    *   `offsetTable` è®°å½•æ¯ä¸ª MessageQueue çš„æ¶ˆè´¹ä½ç½®ã€‚
        
    *   æ¯ä¸ª batch æ¶ˆè´¹åæ›´æ–°ï¼Œå¹¶å†™å…¥å¤–éƒ¨å­˜å‚¨ï¼ˆæ¯”å¦‚ MySQL/HDFSï¼‰ã€‚
        
    *   ç¨‹åºé‡å¯æ—¶å…ˆä»å¤–éƒ¨æ¢å¤ offsetã€‚
        
2.  **å¹¶è¡Œåº¦**
    
    *   å¯ä»¥ç”¨ `sc.parallelize(orders)`ï¼Œä½†æ›´é«˜æ•ˆçš„æ˜¯ï¼šæ¯ä¸ª `MessageQueue` æ˜ å°„æˆä¸€ä¸ª RDD åˆ†ç‰‡ï¼Œåˆ©ç”¨ Spark åˆ†å¸ƒå¼å¹¶è¡Œæ¶ˆè´¹ã€‚
        
3.  **è¯­ä¹‰ä¿è¯**
    
    *   é»˜è®¤ at-least-onceï¼Œå¯èƒ½ä¼šæœ‰é‡å¤æ¶ˆè´¹ï¼Œéœ€è¦ç»“åˆä¸šåŠ¡å»é‡ã€‚
        
    *   å¦‚æœ offset å’Œç»“æœåŒæ—¶äº‹åŠ¡å†™å…¥ï¼Œå¯ä»¥åšåˆ° effectively-onceã€‚
        

ğŸ“Œ æ€»ç»“ï¼š

*   **Receiver æ¨¡å¼** â†’ ç®€å•ä½†æ€§èƒ½å·®ã€‚
    
*   **Direct æ¨¡å¼** â†’ æ‰‹åŠ¨æ‹‰å– offsetï¼Œæ€§èƒ½é«˜ï¼Œä½†éœ€è¦è‡ªå·±ç®¡ç† offsetã€‚
    
*   **Structured Streaming** â†’ æ¨èçš„ç°ä»£æ–¹æ¡ˆï¼Œè‡ªåŠ¨ offset ç®¡ç†ï¼ŒSQL APIï¼Œæ›´å®¹æ˜“ä¿è¯ exactly-onceã€‚
    

* * *

ğŸ”¹ 2. åŸºäº **Structured Streaming (DataFrame/Dataset API)**
---------------------------------------------------------

Structured Streaming æ˜¯ Spark 2.x ä¹‹åæ¨èçš„æµå¤„ç† APIã€‚RocketMQ Connector ä¹Ÿæ”¯æŒ Structured Streamingï¼š

### æ–¹å¼ Aï¼šä½œä¸º Source

ç›´æ¥é€šè¿‡ï¼š

1 spark.readStream() .format("org.apache.rocketmq.spark") .option("namesrvAddr", "localhost:9876") .option("consumerGroup", "test\_group") .option("topics", "OrderTopic") .load();

å¾—åˆ°ä¸€ä¸ª DataFrameï¼ŒåŒ…å«ï¼š

*   `key`
    
*   `body`
    
*   `topic`
    
*   `tags`
    
*   `offset`
    
*   `timestamp` ç­‰å­—æ®µã€‚
    

**offset è‡ªåŠ¨ checkpoint**ï¼Œä¸éœ€è¦æ‰‹åŠ¨æäº¤ã€‚

* * *

### æ–¹å¼ Bï¼šä½œä¸º Sink

Structured Streaming ä¹Ÿèƒ½æŠŠç»“æœå†™å› RocketMQï¼š

1 df.writeStream() .format("org.apache.rocketmq.spark") .option("namesrvAddr", "localhost:9876") .option("producerGroup", "result\_group") .option("topic", "ResultTopic") .start();

è¿™æ · Spark çš„è®¡ç®—ç»“æœä¼šè¢«å†™åˆ°å¦ä¸€ä¸ª RocketMQ topicã€‚

* * *

ğŸ”¹ 3. è‡ªå·±å®ç° Consumer â†’ Spark
---------------------------

å¦‚æœä¸æƒ³ç”¨å®˜æ–¹ connectorï¼Œä¹Ÿå¯ä»¥è‡ªå·±å†™ï¼š

1.  åœ¨ Spark é‡Œå¯åŠ¨ä¸€ä¸ª **RocketMQ Java Consumer**ã€‚
    
2.  æ¶ˆè´¹æ¶ˆæ¯åï¼ŒæŠŠæ•°æ®å†™åˆ° Spark Streaming çš„é˜Ÿåˆ—ï¼ˆä¾‹å¦‚ `queueStream`ï¼‰ã€‚
    
3.  Spark Streaming ä»è¿™ä¸ªé˜Ÿåˆ—é‡Œç”Ÿæˆ DStream è¿›è¡Œè®¡ç®—ã€‚
    

ğŸ‘‰ è¿™ç§æ–¹å¼çµæ´»ï¼Œä½† offset ç®¡ç†å’Œ exactly-once è¯­ä¹‰éƒ½è¦è‡ªå·±å¤„ç†ï¼Œä¸€èˆ¬ä¸æ¨èï¼Œé™¤éä½ æœ‰ç‰¹æ®Šéœ€æ±‚ï¼ˆæ¯”å¦‚è‡ªå®šä¹‰åºåˆ—åŒ–/è§£ç ï¼‰ã€‚

* * *

ğŸ” æ€»ç»“
-----

*   **è€çš„ Spark Streaming (DStream)**ï¼š
    
    *   Receiver æ¨¡å¼ï¼ˆç®€å•ï¼Œä½†å®¹é”™å·®ï¼‰ã€‚
        
    *   Direct æ¨¡å¼ï¼ˆæ€§èƒ½å¥½ï¼Œå¯æ‰‹åŠ¨æäº¤ offsetï¼‰ã€‚
        
*   **Structured Streaming**ï¼š
    
    *   æ¨èæ–¹å¼ï¼Œä½œä¸º RocketMQ Sourceï¼ˆoffset è‡ªåŠ¨ç®¡ç†ï¼ŒSQL API ç®€æ´ï¼‰ã€‚
        
    *   å¯ä»¥å†™å› RocketMQã€‚
        
*   **è‡ªç ” Consumer + queueStream**ï¼š
    
    *   çµæ´»ï¼Œä½† offsetã€å®¹é”™å…¨é è‡ªå·±ã€‚
        

è½¬å‘è¯·æ³¨æ˜å‡ºå¤„ï¼š[https://www.cnblogs.com/fnlingnzb-learner/p/19073518](https://www.cnblogs.com/fnlingnzb-learner/p/19073518)