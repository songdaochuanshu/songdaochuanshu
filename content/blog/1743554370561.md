---
layout: post
title: '如何优化和提高MaxKB回答的质量和准确性？'
date: "2025-04-02T00:39:30Z"
---
如何优化和提高MaxKB回答的质量和准确性？
======================

目前 ChatGPT、GLM等生成式人工智能在文本生成、文本到图像生成等在各行各业的都有着广泛的应用，但是由于大模型训练集基本都是构建于网络公开的数据，对于一些实时性的、非公开的或离线的数据是无法获取到的，这个导致了在实际应用场景中会发现，通用的基础大模型基本无法满足我们的实际业务需求，普遍都存在着知识的局限性比如专业领域知识缺失，上下文词不达意（一本正经地胡说八道）等。为了解决这些问题，目前主要有两种解决方案：

第一种模型微调（Fine Tune）：通过微调更新模型，让模型具备对新知识的理解和认知。

另一种就是RAG（Retrieval Augmented Generation,检索增强生成），将大模型（LLM）与外部知识源检索相结合，提升大模型的问答能力。

而MaxKB就属于RAG范畴，是基于大语言模型的知识库问答系统，那么同样在实际应用中，我们应该如何提高MaxKB回答的质量和准确性？

一、MaxKB实现原理
===========

在回答这个问题之前，我们先了解下MaxKB的实现原理：  
![](https://img2024.cnblogs.com/blog/3600464/202504/3600464-20250401104446781-112821921.png)

基于上述MaxKB的原理图，我们可以将MaxKB整体流程简单概括如下五点：

1、管理员将知识文档整理后上传MaxKB，MaxKB将文档进行分段存储和向量化；  
2、管理员为不同的知识库创建应用，并为应用接入大模型；  
3、用户在应用中提问，MaxKB依据用户的问题，检索向量库，并返回满足相似度的TOP分段；  
4、MaxKB将返回的TOP分段内容，作为提示词中的一部分，并且询问大模型；  
5、大模型依据提示词，最终给用户进行回答。

所以，从概括中我们可以理解，这个里面有几个关键点会影响到MaxKB回答质量和准确性：

*   知识文档的合理分类、分段以及保证文档质量。这个是大模型是否给出准确答案的源头，如果源数据就是错的，那么大模型回答的结果也就可想而知了；
*   合理设置应用的向量检索的相似度值和TOP分段数。理论上相似度值越高，TOP分段越少，那么向量检索返回的越准确，但是这样设置也很容易造成向量检索不到数据，会导致回答“知识库中查询不到答案”；
*   进行提示词优化，不同的提示词直接影响到模型生成的输出。好的提示词能够引导模型产生更准确、更相关且更富有创造性的回答；
*   采用更大、更新的大模型引擎来提供更好的性能和回答效果。

二、具体如何优化？
=========

那么如何在MaxKB中如何针对上诉的点进行优化呢？同样主要分为以下几个方面进行：

### 2.1 知识文档优化层面

知识文档的第一要点就是要保证知识的准确性。比如面向法律条文的知识文档，需要筛选出已经撤销或者更新的条文条款；面向信息技术的，需要筛选因为技术的迭代已经不适用的方案等等。这个是最重要的，不同的知识库类型需要不同的专业知识人员处理。

第二点，文本规范化处理，去除文本中特殊字符、不相关的信息、重复内容或冗余的内容。比如下图关于MeterSphere知识库中就有些无关的信息（因为在MaxKB中采用了自动爬取MeterSphere在线文档），可以在MaxKB关闭或者删除。

![](https://img2024.cnblogs.com/blog/3600464/202504/3600464-20250401104553134-1145065165.png)

比如自动化分段中有些内容不合理的，需要人工处理：

![](https://img2024.cnblogs.com/blog/3600464/202504/3600464-20250401104612607-1266314845.png)

比如针对不合理的内容进行修改优化：

![](https://img2024.cnblogs.com/blog/3600464/202504/3600464-20250401104705688-1031734001.png)

第三点，依据知识类型，将文档归类划分。需要合理地划分不同知识主题的文档，再MaxKB中按照不同知识的类型进行划分不同的知识库进行存储，比如下图分为了MeterSphere知识库和DataEase知识库。企业可以根据现有文档数据，在MaxKB中划分财务知识库、销售知识库、人事知识库、IT知识库等等。

![](https://img2024.cnblogs.com/blog/3600464/202504/3600464-20250401104734369-234241816.png)

第四点，合理的进行文档分段、分块。需要将文档拆分为一定大小的块，但还能保证文档表达的含义（因为我们知道，MaxKB最终是需要将向量检索到的数据，嵌入到提示词中输入大模型，但是不同的大模型输入的token是有一定容量的，而且如果输入过多，会影响大模型回答的效率和速度，还有更多的资源消耗，如果输入过少，有可能就会导致回答不准确或者查询不到知识点）。所以针对不同文档内容，需要进行合理的分段、分块才行。比如针对知识连贯部分采用大分块较为合适（比如详细描述MeterSphere产品特性的多段文本）；而对于信息分散，则可以使用小块进行（比如社交媒体帖子）。如果实在无从下手时，128大小字符为一个分块块往往是最佳选择，可以从这个大小作为基准进行测试。

### 2.2 向量检索优化层面

目前MaxKB默认向量检索相似度值为0.6，默认引用分段数 TOP分段为3。我们可以结合知识库的数据量的大小，设置不同的搜索模式和调整相似度值、TOP分段。

比如数据量大的场景，可以采用向量检索；数据量小采用全文检索；数据量中场景采用混合检索；然后基于MaxKB回答的效果，适当的调整检索相似度和引用TOP分段数，以此来实现最佳的回答效果。

![](https://img2024.cnblogs.com/blog/3600464/202504/3600464-20250401104755267-698683516.png)

### 2.3 提示词优化层面

优质的提示词能够显著提高大模型回答的准确性，这是因为提示词直接影响模型的思考和回应方式。所以很多时候不同的问答场景需要不同的提示词来引导模型，使其能够更好地适应各种应用场景，如编写诗歌、解答复杂问题或模拟特定角色进行对话等。所以在MaxKB中用户也可以针对不同的知识类型进行提示词优化。默认MaxKB中的提示词如下：

![](https://img2024.cnblogs.com/blog/3600464/202504/3600464-20250401104819166-717136959.png)  
比如，我们针对DataEase知识库进行提示词优化成如下部分：

![](https://img2024.cnblogs.com/blog/3600464/202504/3600464-20250401104836953-1538532322.png)  
最后通过提示词优化，MaxKB能够给出更加符合我们期望的答案：

![](https://img2024.cnblogs.com/blog/3600464/202504/3600464-20250401104900384-388572177.png)

### 2.4 大模型优化层面

MaxKB支持对接主流的大模型，包括本地私有大模型（如 Llama 2）、OpenAI、通义千问、Kimi、Azure OpenAI 和百度千帆大模型等。所以在MaxKB中优化模型最简单的办法就是换更大的接入模型，比如文心一言-3.5模型换成文心一言-4模型，Llama 3-8B换成Llama 3-70B（需要注意的是本地模型参数越多，需要硬件资源也更多）。

第二个办法就是模型微调，但是我们需要了解，模型微调固然效果好，在实际场景中，数据是不停更新的，而模型微调无论是从数据准备、算力资源、微调效果、训练时间等各个角度来看都不是一件简单的工作，也很难保证每次有新数据的产生都进行模型微调，无论财力和时间都不允许，并且有时候微调的效果有时候也不一定理想。

好了，上述就行基于MaxKB进行问答知识库优化的几个方向和要点，你学到了吗？

![](https://img2024.cnblogs.com/blog/3600464/202504/3600464-20250401104919746-1052664467.png)