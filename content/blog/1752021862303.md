---
layout: post
title: '如何通过向量化技术比较两段文本是否相似?'
date: "2025-07-09T00:44:22Z"
---
如何通过向量化技术比较两段文本是否相似?
====================

你有没有过这样的经历：想知道两篇文章是否在讲同一个主题？或者判断两段文本的意思是否接近？比如检查实习生写的报告是否存在抄袭，或者进行论文查重？  
通过向量化技术即可解决这个问题。

**一、首先需要将文字段落转换为向量**  
为什么要把文本变成"向量"？因为计算机无法直接理解人类文字，只能处理数字。例如“苹果”这个词，在计算机眼中只是一串字符，但我们可以通过特定的编码方法，将其转换为一组数字（如\[0.8, 0.3, 0.6...\]）。这组数字就像文本的“数字指纹”，包含了文本的语义信息，这个过程称为“向量化”。  
关于什么是向量，可参考：[https://www.cnblogs.com/twosedar/p/18957931](https://www.cnblogs.com/twosedar/p/18957931)  
关于如何将文本转换为向量，可以参考：[https://www.cnblogs.com/twosedar/p/18962405](https://www.cnblogs.com/twosedar/p/18962405)

**二、对比两段向量数据的相似度**  
将文本转换为向量后，下一步需要计算向量之间的相似度。常用的两种相似度计算方法如下：  
**1\. 余弦相似度**  
余弦相似度是判断两个向量“方向相似程度”的数字指标。想象二维空间中有两根箭头：若一根指向东，另一根指向东南，它们的方向较接近；若一根指向东，另一根指向西，方向则差异较大。余弦相似度通过数学方法计算两根箭头夹角的大小——夹角越小，值越接近1（越相似）；夹角越大，值越接近0（差异越大）。

我们可以通过一组二维向量具体解释：  
如图所示，二维向量可用平面坐标系中的点表示。图中有四个二维向量，分别为：A(1,2)、B(2,4)、C(2,2)、D(6,1)。  

向量A与B方向相同，余弦相似度为1（完全相似）；  
向量A与D夹角β最大，方向偏差最大，余弦相似度最低；  
向量A与C夹角α较小，余弦相似度较高。  
余弦相似度特别适合比较两段文本的含义。例如句子“我喜欢吃苹果”与“我爱吃苹果”的余弦相似度很高；而与“我不喜欢吃苹果”虽一字之差，余弦相似度却较低。  
可通过Python代码编写程序验证：

    from sentence_transformers import SentenceTransformer  #引入SentenceTransformer库
    from sklearn.metrics.pairwise import cosine_similarity #引入余弦相识度计算库
     
    # 1. 加载预训练模型
    model = SentenceTransformer('./all-MiniLM-L6-v2')  # 支持多语言的小型模型
    # 2. 待比较文本
    sentence1 = "我喜欢吃苹果"
    sentence2 = "我爱吃苹果"
    sentence3 = "我不喜欢吃苹果"
    # 3. 将文本转换为向量
    embeddings1 = model.encode(sentence1)
    embeddings2 = model.encode(sentence2)
    embeddings3 = model.encode(sentence3)
    # 4. 计算余弦相似度
    # 计算第一句和第二句的余弦相似度
    similarity_1_2 = cosine_similarity([embeddings1], [embeddings2])[0][0]
    
    # 计算第一句和第三句的余弦相似度
    similarity_1_3 = cosine_similarity([embeddings1], [embeddings3])[0][0]
    
    # 5. 打印结果
    print(f"「{sentence1}」和「{sentence2}」的相似度: {similarity_1_2:.4f}")
    print(f"「{sentence1}」和「{sentence3}」的相似度: {similarity_1_3:.4f}")
    

打印结果  
**「我喜欢吃苹果」和「我爱吃苹果」的相似度: 0.9966**  
**「我喜欢吃苹果」和「我不喜欢吃苹果」的相似度: 0.8603**

**2\. 欧氏距离相似度**  
另一种向量相似度比较方法是欧氏距离。在二维空间中，欧氏距离可理解为两个点之间的直线距离。如图所示：  

点C与A的距离最短，因此二者最相似；  
点D与A的距离最长，因此相似度最低。  
还以句子“我喜欢吃苹果”对比 “我爱吃苹果”、“我不喜欢吃苹果”这两句话。以下代码是欧氏距离相似度比较示例和结果

    from sentence_transformers import SentenceTransformer  #引入SentenceTransformer库
    import numpy as np                                     #引入算术库
    
    # 1. 加载预训练模型
    model = SentenceTransformer('./all-MiniLM-L6-v2')  # 支持多语言的小型模型
    # 2. 待比较文本
    sentence1 = "我喜欢吃苹果"
    sentence2 = "我爱吃苹果"
    sentence3 = "我不喜欢吃苹果"
    # 3. 将文本转换为向量
    embeddings1 = model.encode(sentence1)
    embeddings2 = model.encode(sentence2)
    embeddings3 = model.encode(sentence3)
    
    # 4. 计算欧氏距离相似度
    def euclidean_similarity(vec1, vec2):
        """计算欧氏距离相似度：距离越小越相似，转换为0-1范围"""
        distance = np.linalg.norm(vec1 - vec2)  # 计算欧氏距离
        similarity = 1 / (1 + distance)  # 将距离转换为相似度（0-1范围）
        return similarity
    
    # 比较第一句和第二句
    similarity_1_2 = euclidean_similarity(embeddings1, embeddings2)
    # 比较第一句和第三句
    similarity_1_3 = euclidean_similarity(embeddings1, embeddings3)
    
    # 5. 打印结果
    print(f"「{sentence1}」和「{sentence2}」的欧氏距离相似度: {similarity_1_2:.4f}")
    print(f"「{sentence1}」和「{sentence3}」的欧氏距离相似度: {similarity_1_3:.4f}")
    

打印结果  
**「我喜欢吃苹果」和「我爱吃苹果」的欧氏距离相似度: 0.9239**  
**「我喜欢吃苹果」和「我不喜欢吃苹果」的欧氏距离相似度: 0.6542**