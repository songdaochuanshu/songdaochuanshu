---
layout: post
title: '为什么在代理服务器上测试， http2 的转发性能比 http 1 更低？'
date: "2026-02-17T00:58:37Z"
---
**作者:张富春(ahfuzhang)，转载时请注明作者和引用链接，谢谢！**

*   [cnblogs博客](https://www.cnblogs.com/ahfuzhang/)
*   [zhihu](https://www.zhihu.com/people/ahfuzhang/posts)
*   [Github](https://github.com/ahfuzhang)
*   公众号:一本正经的瞎扯  
    

* * *

我在测试 Http2 server 与 Http 1.1 server 的性能差异时，最高测试数据是 http2 比 http1 快 3.6 倍。  
而 Carter 在测试 apisix 代理服务器的性能的时候，得到的数据是 http2 的性能只有 http 1 的 80%。  
我们曾彼此质疑对方的数据，并觉得不可思议！  
我的观点是：二进制协议一定快过文本协议，没理由在代理服务器上测试的数据会导致 http2 慢于 http 1。

今天终于想明白了原因，其实我们都没错！  
结论是：在代理服务器上，http2 的转发性能会低于 http 1。  
导致这一项差异的关键是 `splice()` 系统调用，也就是代理服务器中实现`零拷贝`的关键。

(后续大量引用 ChatGPT 的回答)

splice() 是什么？
=============

splice() 是 Linux 的一个系统调用（C 里通过 splice(2) 暴露），用来在 两个文件描述符之间搬运数据，并且尽量走 零拷贝（zero-copy） 路径，减少用户态缓冲区参与。

最典型的用途：文件 ↔ 管道、管道 ↔ socket，用它可以把数据从磁盘文件直接“送”到网络连接里，中间不需要 read() 到用户态再 write() 回内核。

⸻

它解决什么问题

传统写法：

    read(file_fd, user_buf, n);
    write(sock_fd, user_buf, n);
    

缺点：数据会在内核 ↔ 用户态之间拷贝（还可能污染 CPU cache、占用内存带宽）。

splice() 的目标：让数据尽量在内核内部移动（比如从 page cache / pipe buffer 直接到 socket buffer），减少一次或多次拷贝。

⸻

它的基本形态（语义）

    ssize_t splice(int fd_in,  loff_t *off_in,
                   int fd_out, loff_t *off_out,
                   size_t len, unsigned int flags);
    

    •	fd_in / fd_out：输入/输出 fd
    •	off_in / off_out：
    •	传 NULL 表示使用 fd 当前偏移并推进（像普通读写那样）
    •	非 NULL 则用你提供的偏移（类似 pread/pwrite 的味道），并且不一定修改 fd 的文件偏移（具体取决于对象类型）
    •	len：最多搬运多少字节
    •	flags：控制阻塞/移动行为（例如 SPLICE_F_NONBLOCK 等）
    

返回值：实际搬运的字节数；0 通常表示 EOF；-1 表示出错（errno 说明原因）。

⸻

常见组合

1.  file → pipe → socket（高性能“发送文件”）  
    • splice(file\_fd → pipe\_write\_end)  
    • splice(pipe\_read\_end → sock\_fd)  
    这类组合常用于实现“类似 sendfile 的效果”，但 splice 更通用（尤其适合你还要在中间做点别的内核态处理的场景）。
    
2.  pipe ↔ pipe
    

用于在管道之间转移数据（比如配合 tee() 做复制）。

⸻

适用限制（很重要）  
• 并不是任意 fd 都支持。splice 需要底层文件操作实现支持（VFS/驱动/协议栈）。  
• 在 Linux 上，pipe 经常是 splice 的“中转站”：很多场景要求 fd\_in 或 fd\_out 至少有一端是 pipe（或者最终在内核内部用 pipe buffer 做承载）。  
• 数据来源如果是普通文件，通常来自 page cache（因此能做到少拷贝或零拷贝）。

⸻

和 sendfile() 的关系  
• sendfile()：更“专用”，通常是 文件 → socket 的快速路径。  
• splice()：更“通用”，可以在更多类型的 fd 之间搬运，常见用法是 通过 pipe 作为桥 来拼接成 file→socket 的零拷贝链路。

就算 splice 把内核中 socket buffer 的数据转移到了 pipe 下面，用户使用时也仍然要 read()，似乎并没有做到零拷贝？
=========================================================================

对，你理解得很准确：只要最终要在用户态“看见/处理”字节流，就绕不开一次 copy\_to\_user。splice(socket → pipe) 只是把“从 socket 读到用户缓冲区”这一步，换成了“从 socket 读到内核 pipe”，因此它不能消除“内核 → 用户态”的拷贝；你后面 read(pipefd, userbuf, …) 仍然会拷贝。

更精确地说：  
• 传统路径（用户态消费）  
recv()/read(socket, userbuf)  
→ 内核 socket 接收队列 → 用户态 userbuf（一次 copy\_to\_user）  
• splice 路径（用户态仍要消费）  
splice(socket → pipe)（内核内搬运/重挂页，避免 copy\_to\_user）  
然后 read(pipe → userbuf)  
→ pipe → 用户态 userbuf（还是一次 copy\_to\_user）

所以：“用户态要拿到 payload”这一目标下，splice 不会减少总拷贝次数到 0。它可能减少的是：  
• 少一次“多余的中间 buffer 拷贝/搬运”（比如你原来先 read 到用户，再 write 到另一个 fd）  
• 或减少 CPU 开销（某些场景下从 socket 直接挂到 pipe、再 splice 到目标 fd）

什么时候 splice 真正有意义（能把用户态拷贝降到 0）？
===============================

1.  纯转发（不解析数据）

socket\_in → pipe → socket\_out / file  
你不在用户态触碰数据，只做转发/落盘。典型：反向代理、L7 但不解包、录流到文件等。

2.  “只看少量头部 + 大量 body” 的混合

比如 HTTP：你在用户态只 recv 一小段 header 做决策；body 用 splice 走零拷贝转发。  
这类能显著减少 copy\_to\_user 的总量（因为大头 body 不进用户态）。

⸻

你真正关心的点：TCP 通讯里的拷贝到底能不能减少？  
• 应用层必须处理 payload（解码、压缩、JSON、protobuf…）：  
至少一次内核→用户拷贝不可避免（把字节交给进程）。  
• 应用层不处理 payload，只转发：  
可以做到 0 次进入用户态（splice/送 NIC 相关 offload 另说）。

对于代理服务器， 是不是可以理解为 http 1 大部分都情况能做内核态的四层转发，而 http 2 只能做用户态的七层转发?
===============================================================

不完全对，但你这个直觉抓到了一半：决定能不能“像 L4 那样内核态转发”的关键，不是 HTTP/1 vs HTTP/2，而是代理要不要理解协议语义、要不要“终止连接并重建连接”。 HTTP/2 因为多路复用 + 流控 + 头压缩，确实更容易把你“逼到”用户态 L7，但 HTTP/1 也不是天然就能内核态转发。

把它拆成几种代理形态，你会更清楚：

1.  真·L4 代理（TCP/四层负载均衡）  
    • 不看 HTTP，只转发字节流：客户端 TCP ↔ 后端 TCP。  
    • 这对 HTTP/1 和 HTTP/2 都一样：都能做“内核友好”的转发（例如 splice/零拷贝路径、甚至内核里的 TPROXY/IPVS 等）。  
    • 代价：你做不了按 URL/Host/Header 的路由、鉴权、限速等 L7 能力。

✅ 结论：HTTP/2 也可以做 L4 转发，只是此时你根本不知道它是 HTTP/2。

2.  HTTP/1 的 L7 反代（常见 Nginx/Envoy 的那种）  
    • 你要读请求行/headers，决定路由，可能改 header，可能缓存、压缩、重试等。  
    • 这就已经是 用户态 L7 了，不是“内核态 L4”。

不过 HTTP/1 有一个“容易优化”的点：  
• header/body 分界清晰，且通常一个连接同一时刻服务一个请求（即便 keep-alive，也多是串行，管线化很少用）。  
• 所以可以做 “只在用户态读少量 header，然后 body 用 splice 直通”（大 body 上传/下载时很香）。

✅ 结论：HTTP/1 不是“大部分都能内核态 L4 转发”，它只是 更容易做“半 L7 + 半零拷贝直通”。

3.  HTTP/2 的 L7 反代（stream 级路由、多路复用）  
    • 同一条 TCP 连接里交错多个 stream 的 frames。  
    • 你要按 stream 拆帧、调度、维护流控窗口、处理 HPACK。  
    • 前后两端通常是两条独立连接（客户端一条 H2，后端另一条 H2 或 H1），stream id/窗口/HPACK 动态表都不可能原封不动“直通”。

这使得 把大段 payload 当作连续字节“splice 过去”非常困难，因为你必须先在用户态把属于某个 stream 的 DATA 帧摘出来再发到后端（而且还可能要重排/限速/优先级）。

✅ 结论：HTTP/2 做 L7 反代时，基本只能用户态为主（或者说，必须有“协议终止点”在用户态/实现层）。

⸻

更准确的一句话  
• HTTP/1：更容易把“body”做成内核态直通（splice/sendfile），用户态只处理少量控制面（headers）。  
• HTTP/2：只要你要做 L7（按 stream/headers 路由），就很难做到 body 完全内核态直通，因为 framing/mux/flow-control 迫使你参与数据分发。  
• 但 HTTP/2 依然可以做纯 L4 转发（只是你失去所有 L7 能力）。

总结
==

*   http 1.1 的协议特点：header 和 body 有明显的区分，body 的长度非常明确，一条 tcp 连接上同时只有一个请求响应 —— 因此，在代理服务器的场景， http 1 很容易使用 splice 这样零拷贝机制来优化。
    *   特别是 body 部分这样更长的内容，直接在内核态就能够实现数据交换，完全不需要把数据拷贝到用户态，再从用户态发送出去。
*   http 2 在一条 tcp 连接上有多个流，每个流超出 `SETTINGS_MAX_FRAME_SIZE` 后还会分成多个 frame —— 由此决定了 http2 上通过 splice 实现零拷贝优化很困难，或者说能够真正零拷贝的场景变少了。
*   对于服务器而言：
    *   http 2 这样的二进制协议确实比 http 1 更快，特别是像 api server / rcp server 这样的数据包小+请求频繁的场景，http2 比 http1 快 3.6 倍就不奇怪了。
    *   如果是图片下载/文件下载/大吞吐量的数据传输，选择 http1 更好

发表于 2026-02-15 16:15  [ahfuzhang](https://www.cnblogs.com/ahfuzhang)  阅读(74)  评论(0)    [收藏](javascript:void\(0\))  [举报](javascript:void\(0\))