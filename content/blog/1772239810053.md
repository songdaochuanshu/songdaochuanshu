---
layout: post
title: 'ai使用分享'
date: "2026-02-28T00:50:10Z"
---
ai使用分享
======

AI 辅助编程实践分享
===========

**以下内容由AI辅助生成，不保证信息的合理性。**

> 本文整理了当前主流 AI 编程模型、工具、获取渠道及实际开发工作流，供团队参考。

* * *

一、模型
----

当前三大厂商的旗舰编程模型各有侧重，选型时需结合任务类型综合考虑。

### 1.1 Claude Opus 4 (Anthropic)

项目

说明

模型标识

`claude-opus-4-6`

厂商

Anthropic

定位

Opus 系列为 Anthropic 最高能力等级

**核心优势**

*   多步骤代码推理能力强，擅长跨文件重构、复杂 Bug 定位
*   指令遵循度高，工具调用（Tool Use）准确率业界领先
*   支持 Extended Thinking（扩展思维链），适合复杂架构设计
*   原生 Agentic 能力，驱动 Claude Code 等终端工具

**适用场景：** 复杂重构、架构设计、多文件协同修改、代码审查

* * *

### 1.2 GPT-5.3 Codex (OpenAI)

项目

说明

模型标识

`gpt-5.3-codex`

厂商

OpenAI

定位

GPT-5 系列编程特化模型

**核心优势**

*   延续 OpenAI 在代码生成领域的深厚积累
*   推理能力强（继承 o 系列推理模型优势）
*   多模态输入支持（可传入截图、设计稿等）
*   生态成熟，与 Codex CLI 深度集成

**适用场景：** 通用代码生成、算法实现、多模态编程辅助

* * *

### 1.3 Gemini 3.1 Pro (Google)

项目

说明

模型标识

`gemini-3.1-pro`

厂商

Google DeepMind

定位

Gemini 系列专业版

**核心优势**

*   超大上下文窗口（支持百万级 Token），可一次性理解整个代码库
*   多模态能力原生支持（代码 + 文档 + 图片）
*   有免费额度，个人开发者友好
*   前端 UI 理解能力突出

**适用场景：** 大型代码库理解、前端开发、需要长上下文的场景

* * *

### 1.4 GML5 (gml5)

项目

说明

模型标识

`gml5`

厂商

开源 / 多渠道实现

定位

轻量低延迟的代码生成与补全模型

**核心优势**

*   面向工程实用性优化，响应速度快，延迟低
*   适合交互式补全、CI 级别代码生成与较短文本的推理
*   易于本地化部署和私有化训练

**适用场景：** 交互补全、低延迟场景、本地化部署

* * *

### 1.5 Qwen 3 Coder Plus (qwen3-coder-plus)

项目

说明

模型标识

`qwen3-coder-plus`

厂商

Qwen 生态 / 第三方提供

定位

面向编程的高质量生成与代码理解模型

**核心优势**

*   对代码理解与生成能力做了专项增强，支持多语言代码库
*   在大上下文与跨文件分析上表现良好，适配工程级任务
*   支持多语言注释与文档生成

**适用场景：** 跨文件重构、代码审查、复杂任务的代码生成

* * *

模型对比速览
======

维度

Claude Opus 4

GPT-5.3 Codex

Gemini 3.1 Pro

GML5

Qwen3-Coder-Plus

代码推理

★★★★★

★★★★☆

★★★★☆

★★★☆☆

★★★★☆

上下文长度

200K

128K+

1M+

64K

256K+

工具调用

★★★★★

★★★★☆

★★★★☆

★★★☆☆

★★★★☆

多模态

★★★☆☆

★★★★☆

★★★★★

★★☆☆☆

★★★★☆

免费额度

无

有限

较多

较多（开源实现）

有限

指令遵循

★★★★★

★★★★☆

★★★★☆

★★★☆☆

★★★★☆

* * *

二、工具
----

### 2.1 Claude Code (Anthropic)

Anthropic 官方推出的终端 AI 编程代理，直接在命令行中运行。

**功能特点**

*   自主读写文件、执行 Shell 命令、搜索代码库
*   完整的 Git 操作能力（提交、创建分支、PR 等）
*   支持 MCP 协议扩展工具能力
*   支持 Skills 插件系统，可复用社区工作流
*   通过 `CLAUDE.md` 实现项目级上下文记忆
*   支持 VS Code 扩展集成

**使用方式**

    # 安装
    npm install -g @anthropic-ai/claude-code
    
    # 在项目目录下启动
    claude
    

**优点：** 代码推理准确、多步骤任务能力强、生态丰富（MCP + Skills）  
**缺点：** API 成本较高（Opus 级别定价）、纯终端界面

* * *

### 2.2 Codex CLI (OpenAI)

OpenAI 开源的终端 AI 编程代理，Apache 2.0 协议。

**功能特点**

*   完全开源，社区驱动
*   三种自主模式：Suggest（建议）、Auto-Edit（自动编辑）、Full Auto（全自动）
*   沙箱化代码执行，安全隔离
*   支持多模态输入（可传入图片/截图）

**使用方式**

    # 安装
    npm install -g @openai/codex
    
    # 启动
    codex
    

**优点：** 开源免费（自备 API Key）、沙箱安全机制好  
**缺点：** 生态扩展不如 Claude Code 丰富

* * *

### 2.3 Gemini CLI (Google)

Google 开源的终端 AI 编程代理，同样 Apache 2.0 协议。

**功能特点**

*   基于 Gemini 模型，继承超大上下文窗口优势
*   支持 MCP 协议，可复用 Claude Code 的 MCP 工具服务
*   免费额度充足（Gemini API 免费层级较慷慨）
*   代理式文件编辑、Shell 执行、代码库探索

**使用方式**

    # 安装
    npm install -g @anthropic-ai/gemini-cli  # 具体包名以官方为准
    
    # 启动
    gemini
    

**优点：** 免费额度多、长上下文能力强、MCP 兼容  
**缺点：** 代码编辑精度在复杂重构场景略逊于 Claude

* * *

### 2.4 OpenCode

开源的、厂商无关的终端 AI 编程助手，支持接入任意 LLM 后端。

**功能特点**

*   厂商无关：支持 Anthropic / OpenAI / Google / Ollama（本地模型）等
*   终端 TUI 交互界面，美观易用
*   LSP 集成，提供代码智能提示
*   支持 MCP 协议
*   Go 语言编写，性能优秀

**优点：** 模型自由切换、无厂商锁定、支持本地模型  
**缺点：** 社区较小、效果取决于所选模型质量

* * *

### 2.5 VS Code + GitHub Copilot

最主流的 IDE 内置 AI 编程方案。

**功能特点**

*   代码自动补全（行内建议）
*   Copilot Chat 对话式编程
*   Agent 模式支持多步骤任务（较新版本）
*   支持 MCP 协议接入外部工具
*   支持切换不同模型后端（Claude、GPT、Gemini）

**优点：** 与 IDE 深度集成、开箱即用、团队协作方便  
**缺点：** 需要订阅（$10/月起）、Agent 能力弱于专用 CLI 工具

* * *

### 2.6 Kiro (AWS)

AWS 推出的 AI 原生 IDE，基于 VS Code 内核。

**功能特点**

*   **规范驱动开发 (Spec-Driven)：** 通过需求文档、设计文档、任务清单引导 AI 生成代码
*   Autopilot 和 Steering 两种模式切换
*   深度集成 AWS 服务（Lambda、DynamoDB、S3 等）
*   Agent Hooks：文件保存、终端事件等自动触发 AI 动作
*   支持 MCP 协议

**优点：** 结构化方法减少 AI 幻觉、AWS 生态集成好、有免费层级  
**缺点：** 学习曲线较陡、强依赖 AWS 生态

* * *

### 2.7 Antigravity

基于 Claude Code 的增强配置框架，支持多模型协作。

**功能特点**

*   底层基于 Claude Code 运行
*   通过 MCP 集成多个工具服务（代码语义搜索、文档查询、知识图谱等）
*   丰富的 Skills 工作流（commit、plan、review、debug 等）
*   支持多模型路由：不同任务分发给不同模型处理

**优点：** 集成度高、多模型协作能力强  
**缺点：** 配置复杂、需要多个 API Key

* * *

### 2.8 CCSwitch (ccswitch)

`ccswitch` 是一个轻量级的模型路由与切换工具，便于在多模型环境中按规则路由请求、快速切换后端模型。

**功能特点**

*   基于配置的路由规则，可以按任务类型或路径选择模型后端
*   支持 MCP 协议，能与 Claude Code / Gemini CLI / OpenCode 等集成
*   提供简单的 CLI 与配置文件管理，适合作为模型网关或本地代理

**适用场景：** 多模型协作、实验对比、按场景选择低延迟或高能力模型

*   下载链接：[https://github.com/farion1231/cc-switch/releases](https://github.com/farion1231/cc-switch/releases)

* * *

### 工具对比速览

工具

类型

开源

MCP 支持

免费可用

推荐场景

Claude Code

CLI

否

是

否

复杂重构、专业开发

Codex CLI

CLI

是

有限

自备Key

开源爱好者、轻量使用

Gemini CLI

CLI

是

是

是

个人开发、长上下文场景

OpenCode

CLI

是

是

自备Key

多模型切换、本地模型

Copilot

IDE插件

否

是

否

IDE 内日常开发

Kiro

IDE

否

是

部分

AWS 项目、规范驱动开发

Antigravity

框架

否

是

否

多模型协作工作流

CCSwitch

CLI / 代理

是

是

是

多模型路由与快速切换

* * *

三、模型渠道
------

### 3.1 三方中转站

通过第三方 API 中转服务使用各厂商模型，通常以 OpenAI 兼容格式提供 API。

**特点**

*   价格通常低于官方直连
*   支持多厂商模型统一接入
*   注意甄别服务商可靠性和数据安全

**常见平台：** OpenRouter、各类独立中转站

> **风险提示：** 三方渠道存在数据安全风险，敏感代码/业务逻辑建议走官方渠道。

*   [https://www.right.codes/models](https://www.right.codes/models)
*   [https://foxcode.rjj.cc/dashboard](https://foxcode.rjj.cc/dashboard)

* * *

### 3.2 闲鱼、淘宝

部分卖家提供共享账号、API Key 转卖、代充值等服务。

**注意事项**

*   价格较低，但存在封号风险
*   共享账号可能有并发限制
*   无法保证长期可用性
*   **不建议用于正式项目开发**

* * *

### 3.3 官方免费体验资格 与 学生邮箱

各厂商均提供一定的免费使用途径：

厂商

免费方式

Anthropic

Claude.ai 免费层级（有限次数）、API 试用额度

OpenAI

ChatGPT 免费层级、API 新用户赠送额度

Google

Gemini API 免费层级（额度充足）、Google AI Studio

GitHub

Copilot 学生免费（通过 GitHub Education）

**学生邮箱福利：**

*   GitHub Education Pack：含 Copilot 免费使用权
*   部分厂商对 `.edu` 邮箱提供额外 API 额度
*   Google Cloud 学生计划可获得免费云资源

*   阿里云：[https://bailian.console.aliyun.com/cn-beijing/?tab=model#/efm/coding\_plan](https://bailian.console.aliyun.com/cn-beijing/?tab=model#/efm/coding_plan)

* * *

四、MCP (Model Context Protocol)
------------------------------

MCP 是由 Anthropic 发起、现已被广泛采纳的开放协议，标准化了 AI 模型/代理与外部工具之间的连接方式。可以理解为 **"AI 的 USB-C 接口"**。

### 架构

    ┌─────────────┐     JSON-RPC      ┌─────────────────┐
    │  AI Agent    │ ◄──────────────► │  MCP Server      │
    │ (客户端)     │   stdio / HTTP   │  (工具/数据源)    │
    │              │                  │                  │
    │ Claude Code  │                  │ - GitHub Server  │
    │ Gemini CLI   │                  │ - DB Server      │
    │ Cursor       │                  │ - 文档 Server     │
    │ VS Code      │                  │ - 自定义 Server   │
    └─────────────┘                  └─────────────────┘
    

### MCP Server 提供三类能力

类型

说明

示例

**Tools**

AI 可调用的函数

搜索代码库、查询数据库、执行 Lint

**Resources**

AI 可读取的数据

文档内容、配置文件、API 规范

**Prompts**

可复用的提示模板

代码审查模板、提交信息模板

### 实用 MCP Server 推荐

Server

用途

ContextWeaver

语义化代码库搜索（混合精确 + 语义匹配）

Context7

实时查询任意编程库/框架的官方文档

Memory

持久化知识图谱，跨会话记忆

Sequential Thinking

结构化多步推理

GitHub MCP

Git 操作、PR/Issue 管理

Filesystem

文件系统操作

### 配置示例

MCP Server 通常在 Claude Code 的配置文件中声明：

    {
      "mcpServers": {
        "context7": {
          "command": "npx",
          "args": ["-y", "@context7/mcp-server"]
        },
        "memory": {
          "command": "npx",
          "args": ["-y", "@memory/mcp-server", "--db", "./memory.db"]
        }
      }
    }
    

* * *

五、Skills
--------

Skills 是 Claude Code 的插件系统，将常见开发工作流封装为可复用的斜杠命令。

### 工作方式

    用户输入 /commit  →  Skill 工具加载  →  执行预定义工作流  →  输出结果
    

### 常用 Skills 一览

命令

功能

说明

`/commit`

智能提交

分析改动，自动生成 Conventional Commit 信息

`/plan`

任务规划

多模型协作分析，产出可执行实施计划

`/review`

代码审查

自动审查 git diff，双模型交叉验证

`/debug`

问题诊断

多模型交叉定位 Bug

`/execute`

协作执行

获取原型 → 重构实施 → 多模型审计

`/frontend`

前端工作流

研究→构思→计划→执行→优化→评审

`/backend`

后端工作流

同上，侧重后端逻辑

`/team-exec`

并行实施

读取计划，Spawn 多个 Builder Agent 并行编码

### 自定义 Skills

可以创建自己的 Skills 来封装团队特定的工作流。Skills 本质上是结构化的 Prompt + 工具编排逻辑，存放在项目或全局配置中。

* * *

六、开发实践
------

### 6.1 小模块开发

**策略：直接在 IDE 中完成**

适合边界清晰、逻辑独立的小功能。

**流程**

1.  在 IDE 中打开目标文件
2.  使用 Copilot / Claude 内联补全或对话完成编码
3.  即时运行验证

**适用场景：** 工具函数、简单 CRUD、配置修改、样式调整

* * *

### 6.2 复杂功能开发

**策略：CLI 工具 + Skills 协作**

涉及多文件、多模块的复杂任务，推荐使用终端 AI 代理。

**推荐流程**

    /plan  →  确认方案  →  /execute  →  /review  →  /commit
    

1.  **需求分析：** 用 `/plan` 让 AI 分析需求、拆解任务、设计方案
2.  **方案确认：** 审查 AI 生成的计划，提出修改意见
3.  **协作实施：** 用 `/execute` 或直接对话，逐步实现功能
4.  **代码审查：** 用 `/review` 进行自动化审查
5.  **提交代码：** 用 `/commit` 生成规范的提交信息

**关键原则：**

*   AI 负责写代码，人负责把控方向和质量
*   每完成一个功能点就提交，保持小步快跑
*   复杂逻辑拆成多轮对话，而非一次性丢给 AI

* * *

### 6.3 代码审查

**AI 写好代码后一定要审查！**

这是 AI 辅助编程中最重要的环节，AI 生成的代码可能存在以下问题：

风险类型

表现

**逻辑错误**

边界条件处理不当、空值未判断

**安全漏洞**

SQL 注入、XSS、敏感信息硬编码

**过度工程**

不必要的抽象、冗余的错误处理

**风格不一致**

与项目现有代码风格/命名规范不符

**幻觉**

调用不存在的 API、编造库名/方法名

**审查要点清单**

*    核心业务逻辑是否正确
*    边界条件和异常处理是否完备
*    是否引入安全漏洞
*    是否符合项目代码规范
*    依赖的 API / 库是否真实存在
*    性能是否满足要求

* * *

### 6.4 自动化测试

**配合 Yaak CLI 实现接口自动化测试**

[Yaak](https://yaak.app/) 是一款 API 客户端工具，其 CLI 模式支持在终端中批量执行接口测试。

**工作流**

    AI 编写代码  →  AI 生成测试用例  →  Yaak CLI 执行  →  查看结果  →  修复问题
    

**实践建议**

*   让 AI 在编写功能代码的同时生成对应的接口测试用例
*   使用 Yaak CLI 在 CI/CD 流程中执行回归测试
*   对关键接口维护测试集合，每次改动后自动运行

* * *

七、总结
----

场景

推荐方案

日常小功能

IDE + Copilot

复杂重构

Claude Code + Skills

个人项目/免费使用

Gemini CLI

多模型协作

Antigravity / OpenCode

AWS 项目

Kiro

接口测试

Yaak CLI

**核心原则：AI 是副驾驶，不是自动驾驶。** 善用工具提升效率，但始终保持对代码质量的把控。