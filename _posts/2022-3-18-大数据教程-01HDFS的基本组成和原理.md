---
layout: post
title: "大数据教程-01HDFS的基本组成和原理"
date: "2022-03-18T13:31:29.539Z"
---
大数据教程-01HDFS的基本组成和原理
====================

![大数据教程-01HDFS的基本组成和原理](https://img2022.cnblogs.com/blog/1306636/202203/1306636-20220318201639669-1668627162.png) 大数据系统教程 HDFS的基本组成和原理

### 一 Hadoop历史背景

起源于2003年谷歌的Google File System相关论文，随后Doug Cutting（我们下面就叫他切哥吧）基于GFS的论文实现了分布式文件系统，并把它命名为NDFS（Nutch Distributied File System）。

2004年谷歌又发表了一篇学术论文，介绍了自己的MapReduce编程模型，这个编程模型适用于大规模数据集（大于1TB）的并行分析运算。随后，切哥又基于MapReduce在Nutch搜索引擎实现了该功能，这回切哥没改名，估计是想不出比这更好的名字了吧。

2006年谷歌又发了论文，介绍了自己BigTable（一种非关系型数据库），后面的结果你们能猜到了哈，我们机智的切哥就把BigTable的思想引入到了Hadoop系统里面，并命名为HBase（学习借鉴，切哥在起名这块从来不手软）。

切哥这么牛逼，后来就加入了雅虎，然后又升级改造，一阵duangduangduang，然后就有了现在Hadoop的雏形。

按照国际惯例，你们猜猜看切哥有没有头发？  
![Doug-Cutting-950x776.jpeg](https://cdn.nlark.com/yuque/0/2022/jpeg/281865/1647510970355-b9b52ad1-711f-4f33-8226-bc2ff04d7efa.jpeg#clientId=u173e41ec-1be0-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=388&id=uc853cf19&margin=%5Bobject%20Object%5D&name=Doug-Cutting-950x776.jpeg&originHeight=776&originWidth=950&originalType=binary&ratio=1&rotation=0&showTitle=true&size=124690&status=done&style=none&taskId=u8519fa9c-3db7-4102-88b7-844081dabe2&title=Doug%20Cutting&width=475 "Doug Cutting")

### 二 Hadoop简介

> 切哥果然没有头发，这下心里平衡了吧

Hadoop是Apache的一个开源的分布式计算平台，核心是以HDFS分布式文件系统和MapReduce分布式计算框架构成的，为用户提供了一套底层透明的分布式基础设施。

Hadoop的核心思想就是分布式计算和分布式存储，HDFS负责分布式存储，MapReduce负责分布式计算。

HDFS是Hadoop分布式文件系统，具有高容错性和高伸缩性，允许用户基于廉价硬件部署，构建分布式存储系统，为分布式计算存储提供了底层技术支持。

MapReduce其实就是一套封装好的API，用户可以在不了解底层细节的情况下，开发分布式并行程序，利用大规模集成资源，解决传统单机无法解决的大数据处理问题。  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647511412924-f9733078-3a60-406d-bca1-4ebab8363585.png#clientId=u173e41ec-1be0-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=257&id=uef871460&margin=%5Bobject%20Object%5D&name=image.png&originHeight=514&originWidth=1604&originalType=binary&ratio=1&rotation=0&showTitle=true&size=320999&status=done&style=none&taskId=u9ca39930-5599-4405-ac61-b34bf282614&title=HDFS%E4%B8%8EGFS%E6%9E%B6%E6%9E%84%E5%AF%B9%E6%AF%94&width=802 "HDFS与GFS架构对比")

### 三 Hadoop1.0架构

我先来讲解Hadoop1.0的架构，因为当时的架构比较简单，理解起来比较容易。  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647549523636-fbf60771-333b-48d4-9d86-5b179fbd5ea5.png#clientId=uba683a73-9b5a-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=289&id=u2cc9ec04&margin=%5Bobject%20Object%5D&name=image.png&originHeight=578&originWidth=1282&originalType=binary&ratio=1&rotation=0&showTitle=false&size=193250&status=done&style=none&taskId=uf75d981a-662a-447c-8d2e-af5934b6996&title=&width=641)

#### NameNode

负责维护整个文件系统的文件目录树，包括文件目录的元信息和文件数据块索引（元信息是指文件路径，数据块索引是指某个大文件被分割成的文件块所处的位置），由于NameNode是一个JVM进程，一旦重启就丢失掉了，所以要永久保存，这些元信息是以FsImage和EditLog形式存储在本地。  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647550207274-ee2348cd-142a-47a8-a80f-2064a9308e2e.png#clientId=uba683a73-9b5a-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=189&id=ued382a00&margin=%5Bobject%20Object%5D&name=image.png&originHeight=378&originWidth=652&originalType=binary&ratio=1&rotation=0&showTitle=false&size=176692&status=done&style=none&taskId=u136a87bb-2073-4343-b877-6554f3e9550&title=&width=326)  
FsImage相当于是一个元信息的镜像，当我们对目录树修改后，会把修改信息记录在EditLog中，然后定期做合并，生成一个新的FsImage。这个NameNode出现故障时，是不能对外提供服务的，因为它只有一个节点。

#### Secondary Name Node

这个并不是备份的，准确来说应该叫他CheckPoint Node，是负责做FsImage和EditLog定期合并。不接受客户端请求，作为NameNode的冷备份。当我们文件很多很大时，合并很消耗内存，NameNode要服务于线上的客户端读写，所以把它们拆开成了两个节点。

#### DataNode

实际存储数据的单元，数据以Block为单位，一个大文件在Hadoop存储时会切分成很多个Block，在Hadoop层面来讲存的是Block，不是文件，但是站在Linux层面来看，数据还是以文件形式保存在本地文件系统。

#### Client

通过一个API与HDFS交互，可以进行读写，创建目录，创建文件，复制，删除等等。HDFS提供了多种客户端：Shell命令行，Java API，Thrift接口，C library，WebHDFS等。

#### Data Block

文件是由Block组成的，假设每一块大小为64MB，实际上使用会设置相对大一点，这样切分时个数就会变少。Block越多，存储数据的元信息就会越多，使用时消耗的内存就会越大。所以，适当增大Block Size可以减少元信息数量，使用时更节省内存。  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647552012239-a1863a95-f94f-4f0a-ab0b-24320228dba6.png#clientId=uba683a73-9b5a-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=251&id=uc30a9ef7&margin=%5Bobject%20Object%5D&name=image.png&originHeight=502&originWidth=1358&originalType=binary&ratio=1&rotation=0&showTitle=false&size=578077&status=done&style=none&taskId=uf99988f2-39e8-40bd-922a-48880cd9571&title=&width=679)  
多出来40MB也是一个Block，即使是多出来1MB，也会是一个Block。

### 四 数据块分布

为了保持系统的高可用性，每一个Block会存3个副本（可以调，一般是3个），也就是说一个100G的文件需要用300G的空间来存储。  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647552565275-cd82ed6b-1493-4082-84ce-2717afadbca0.png#clientId=uba683a73-9b5a-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=172&id=u9be44018&margin=%5Bobject%20Object%5D&name=image.png&originHeight=344&originWidth=1168&originalType=binary&ratio=1&rotation=0&showTitle=false&size=168851&status=done&style=none&taskId=u93848989-cfc2-4dbd-b04a-aa33da6054f&title=&width=584)  
默认存放规则（驾驶复制因子是3）：

*   第一份拷贝写入创建文件的节点，目的是能够快速写入
*   第二份拷贝写入位于不用rack的节点，是为了应对交换机故障（假设节点2和节点1不再同一机柜）
*   第三份拷贝写入和第二份副本同一个rack内的节点，为了减少跨rack的网络流量（交换机故障率极低，跨顶层交换机流量消耗大）

什么是rack？不同的机柜怎么定义？  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647553538391-3deda7f5-014a-4408-ab2c-1027d7eb20eb.png#clientId=uba683a73-9b5a-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=292&id=u9619c610&margin=%5Bobject%20Object%5D&name=image.png&originHeight=584&originWidth=880&originalType=binary&ratio=1&rotation=0&showTitle=true&size=1071031&status=done&style=none&taskId=ub77e4e00-1f3b-46e4-90fa-203268a39d8&title=%E6%9C%BA%E6%9F%9C_rack&width=440 "机柜_rack")  
如你所见，上方有三个机柜，每个机柜ip地址是不同的，通过ip地址找到不同的rack。

### 五 HDFS各角色交互

#### 定时心跳

DataNode会定时给NameNode发送心跳，告诉NameNode我还活着，NameNode收到之后也会回复一些指令，比如请你下线。  
![WechatIMG408副本.jpg](https://cdn.nlark.com/yuque/0/2022/jpeg/281865/1647554220513-3b512451-89da-4077-8870-813142a7b270.jpeg#clientId=uba683a73-9b5a-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=344&id=ud2ec9a47&margin=%5Bobject%20Object%5D&name=WechatIMG408%E5%89%AF%E6%9C%AC.jpg&originHeight=688&originWidth=1394&originalType=binary&ratio=1&rotation=0&showTitle=false&size=128294&status=done&style=none&taskId=u9d37e8ff-7832-4de0-a13e-86d7cb5e29c&title=&width=697)

#### HDFS读流程

客户端发送指令给NameNode，NameNode返回Block列表，然后客户端连接对应的Block，最后读出大文件，整个过程是流式的。  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647554808020-3cf391be-b33c-4c30-ace4-9178a2825ace.png#clientId=uba683a73-9b5a-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=277&id=u17c2f1fa&margin=%5Bobject%20Object%5D&name=image.png&originHeight=554&originWidth=1410&originalType=binary&ratio=1&rotation=0&showTitle=false&size=339663&status=done&style=none&taskId=u989be6ee-a831-43ca-8829-22b1a3151de&title=&width=705)

#### 机架感知：拓扑距离

上面图中提到的拓扑距离排序，拓扑距离是怎么计算的？  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647555453480-0074d271-ca07-4660-a23b-ec4ea0583b0b.png#clientId=uba683a73-9b5a-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=234&id=udedb46e3&margin=%5Bobject%20Object%5D&name=image.png&originHeight=468&originWidth=1102&originalType=binary&ratio=1&rotation=0&showTitle=false&size=84567&status=done&style=none&taskId=u910850f0-9ffb-4b30-85fa-502638c09c4&title=&width=551)  
计算方式是两个节点到达最近的共同祖先的距离总和。

*   Distance(d1/r1/n0,d1/r1/n0)=0 同一节点上的进程
*   Distance(d1/r1/n1,d1/r1/n2)=2 同一机架上的不同节点，两个节点各上1步到同一位置
*   Distance(d1/r2/n0,d1/r3/n2)=4 同一数据中心不同机架上的节点，两个节点各上2步到同一位置
*   Distance(d1/r2/n1,d2/r1/n1)=6 不同数据中心的节点

#### 机架感知-再看副本放置策略

![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647595041336-bc8a9255-5b35-487d-8224-befc461298aa.png#clientId=ubb76502b-5281-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=277&id=uc55f6c43&margin=%5Bobject%20Object%5D&name=image.png&originHeight=554&originWidth=722&originalType=binary&ratio=1&rotation=0&showTitle=false&size=78957&status=done&style=none&taskId=u6a3b22cc-e7e9-47af-8075-833d84d57b6&title=&width=361)

*   第一个副本在Client所处的节点上，如果客户端在集群外，随机选一个
*   第二个副本在另一个机架的随机一个节点
*   第三个副本在第二个副本所在的机架

#### HDFS写流程

首先是客户端发送写的指令给NameNode，然后NameNode告知客户端第一个Block的放置位置，接着客户端连接对应的DataNode每次小批量循环写入，比如Block为64MB，每次每个DataNode先写入64KB，写完了就换下一个DataNode，直到第一个Block写入完成换下一个Blcok，如此循环往复。  
![WechatIMG110副本.jpg](https://cdn.nlark.com/yuque/0/2022/jpeg/281865/1647595849108-32a3b323-ccae-4e58-b5ff-8aaad22cf0bd.jpeg#clientId=ubb76502b-5281-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=368&id=u19aa25be&margin=%5Bobject%20Object%5D&name=WechatIMG110%E5%89%AF%E6%9C%AC.jpg&originHeight=736&originWidth=1412&originalType=binary&ratio=1&rotation=0&showTitle=false&size=147267&status=done&style=none&taskId=u8ab2a85d-b1d4-4f8f-ad42-96d29083a4c&title=&width=706)

#### 读写流程总结

读写的流程基本是类似的，都是流式进行的。  
![WechatIMG410副本.jpg](https://cdn.nlark.com/yuque/0/2022/jpeg/281865/1647601756361-5229a01d-2036-42f1-8a17-27d8e4f6ef91.jpeg#clientId=ubb76502b-5281-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=299&id=u40fee253&margin=%5Bobject%20Object%5D&name=WechatIMG410%E5%89%AF%E6%9C%AC.jpg&originHeight=598&originWidth=1552&originalType=binary&ratio=1&rotation=0&showTitle=false&size=126611&status=done&style=none&taskId=u2d668757-e0ec-4f6b-b655-774afced739&title=&width=776)

### 六 HDFS故障恢复流程

要保证系统的高可用性，容灾是必不可少的，主要的故障有以下几种。  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647602051837-3dfd84a9-3a84-449e-ba1e-31ca905bc6e5.png#clientId=ubb76502b-5281-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=340&id=u3f2125a3&margin=%5Bobject%20Object%5D&name=image.png&originHeight=680&originWidth=1254&originalType=binary&ratio=1&rotation=0&showTitle=false&size=345815&status=done&style=none&taskId=u20c71162-d2ac-4429-8983-114754f3357&title=&width=627)

#### DataNode容灾

如果DataNode坏掉，那么它对应的心跳就没有了，虽然还有其他的副本提供服务，但我们系统也要做一些恢复的操作。  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647602242829-b5554200-2fe3-4416-b96a-63867ac47398.png#clientId=ubb76502b-5281-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=238&id=u623571b7&margin=%5Bobject%20Object%5D&name=image.png&originHeight=476&originWidth=1410&originalType=binary&ratio=1&rotation=0&showTitle=false&size=188497&status=done&style=none&taskId=u352b789b-8dc0-4f1d-a323-98f62130256&title=&width=705)  
因为复制因子是3，但在集群里面只有两个副本，系统会把下图DataNode1黑色的Block复制一份，其他的也是类似的，这样就能保证系统的高可用性。  
![WechatIMG411.jpg](https://cdn.nlark.com/yuque/0/2022/jpeg/281865/1647602499421-f9ff6e0b-6960-4de3-b18f-f86815cec134.jpeg#clientId=ubb76502b-5281-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=287&id=u60e2cd46&margin=%5Bobject%20Object%5D&name=WechatIMG411.jpg&originHeight=574&originWidth=1438&originalType=binary&ratio=1&rotation=0&showTitle=false&size=102583&status=done&style=none&taskId=u57a23320-4332-4749-862e-8a6285089a5&title=&width=719)  
也还有一种可能，刚才系统以为坏掉的DataNode只是网络断了，后面又恢复了，这样就会有的Block多出一个副本，这时系统会根据它的负载均衡删除一个多的就可以了。

#### 机柜/交换机故障

其实机柜或者交换机故障与DataNode和磁盘故障是类似的，因为我们Block副本是在不同机柜的。

#### NameNode 容灾（Hadoop V2）

其实Hadoop1.0时候NameNode是一个单点，挂掉了必须重新启动起来，在Hadoop2.0时候有了一个备用的NameNode，注意这不是Secondary NameNode，这时候就有了主从模式，一个是active，另一个是standby  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647603137353-10f1ec01-92a2-4c90-84be-17f3aadac70e.png#clientId=ubb76502b-5281-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=250&id=uf9edcb33&margin=%5Bobject%20Object%5D&name=image.png&originHeight=500&originWidth=1416&originalType=binary&ratio=1&rotation=0&showTitle=false&size=173226&status=done&style=none&taskId=u7dfed38f-56bc-4754-a1ab-6acd3ad005c&title=&width=708)  
备用的NameNode也是可以接收心跳的，当主NameNode挂掉后，备用的NameNode可以立即接管。

#### FsImage和EditLog的作用

我们知道NameNode是没有HA结构的（High a Availability）,所以是一个单点故障，NameNode在内存中的元数据全部丢失，FsImage和EditLog的存在可以保证让重启的NameNode获得最新的宕机前的元数据。

![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647603763638-75cfdb91-c758-4136-972c-7f670cdc730b.png#clientId=ubb76502b-5281-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=221&id=u9e36ebbc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=442&originWidth=558&originalType=binary&ratio=1&rotation=0&showTitle=false&size=178238&status=done&style=none&taskId=u5d5b1865-13c6-40eb-bff5-3d2cc644bf8&title=&width=279)  
FsImage是整个NameNode内存中元数据在某一时候的Snapshot(快照)。

*   FsImage不能频繁地构建，生成FsImage要消耗大量的内存
*   目前FsImage只在NameNode重启时才重新构建

EditLog记录的是从这个快照开始到当前所有元数据的改动

*   如果EditLog太多，EditLog加载会消耗大量的时间
*   这会导致NameNode重启消耗数小时之久

![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647604211236-22df7f97-dca9-4548-b6d4-b62c2f6f43dc.png#clientId=ubb76502b-5281-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=216&id=ubf3d01cd&margin=%5Bobject%20Object%5D&name=image.png&originHeight=432&originWidth=1148&originalType=binary&ratio=1&rotation=0&showTitle=false&size=64363&status=done&style=none&taskId=ub73d0f63-5483-4775-9385-d5875a3d673&title=&width=574)

#### Secondary NameNode

Secondary NameNode就是来帮助减小EditLog文件的大小和更新FsIamge，以此来减小NameNode的压力。  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/281865/1647604682985-c340f09c-89e7-4d56-8330-e9ff8e708366.png#clientId=ubb76502b-5281-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=207&id=ub482f2db&margin=%5Bobject%20Object%5D&name=image.png&originHeight=414&originWidth=822&originalType=binary&ratio=1&rotation=0&showTitle=false&size=90731&status=done&style=none&taskId=u8ec2d108-d224-42b7-bf3f-44d04f83067&title=&width=411)

#### NameNode Failure

来看4个小问题：

*   NameNode进程挂了怎么办？
*   NameNode进程挂了，启动不起来怎么办？
*   NameNode所在机器操作系统进不去怎么办？
*   NameNode机器无法开机怎么办？

进程挂了就重启，重启起不来就把机器上对应的FsImage和EditLog文件迁移到一台新的机器上，如果操作系统进不去，或许可以通过BIOS方式把文件取出来，但是如果开机都开不了，那就只能把Secondary NameNode勉强可以作为NameNode使用，就是把他的IP改成NameNode的IP，从Secondary NameNode机器上来重启。再如果Secondary NameNode也开不了机，你就跟老板说，你买的什么破机器，要坏都一块坏，u can u up,ur father is down.

原创作者：[马一特](https://mayite.cn)

文章出处：http://www.cnblogs.com/mayite/

版权声明：自由转载-非商用-非衍生-保持署名 [（创意共享4.0许可证）](https://creativecommons.org/licenses/by/4.0/deed.zh)

转载说明：如果文章对您有帮助，欢迎点赞，评论加转载，赠人玫瑰，手留余香