---
layout: post
title: "罗景：连接效率优化实践"
date: "2022-06-11T17:15:50.375Z"
---
罗景：连接效率优化实践
===========

分享嘉宾：罗景 58同城 高级架构师

编辑整理：洪鹏飞

内容来源：DataFun AI Talk《连接效率优化实践》

出品社区：DataFun

* * *

**导读：**本次分享由以下几个部分构成——

*   58的业务背景
*   综合排序框架
*   效率优化框架
*   基础数据流程（数据）
*   策略优化路径（算法）
*   效率优化平台（工程）
*   总结和思考

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120238611-106319368.png)

\--

01 58的业务背景
==========

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120244152-384367960.png)

这是58app端的业务展示，可以看出58的业务场景丰富且复杂，产品形态多样，涵盖了租房、二手房、二手车、招聘、本地服务以及二手物品等多种业务，针对每个业务，又分为置顶，精品，普通等多种不同的产品形态。

\--

02 综合排序框架
=========

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120246588-172363842.png)

如上图所示，整个算法层分为三个阶段：粗排、精排和调序。

**粗排阶段**，主要考虑减小模型压力，筛选出一部分排序候选集。主要采用时效性策略以及质量因子的降权策略。分别根据不同周期进行分层处理，用于时间降权；同时对质量因子，采用价格偏离、类目错发、位置虚假等因子进行降权排序。

**精排阶段**，主要考虑列表点击率、有效转化率、个性化以及相关性信息，对粗排后的集合进行精细化排序。

**调序阶段**，根据业务相关以及过滤相关等策略进行重新排序。

在上述粗排、精排以及调序三个阶段中，算法团队重点输出了质量治理，效率优化以及流量调控三种核心能力。

\--

03 效率优化框架
=========

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120249722-1684808998.png)

效率优化框架由三部分组成：数据、算法以及工程。在进行效率优化框架设计和迭代过程中，主要结合相关业务，对策略的相关优化路径进行迭代更新，最后对相关技术以及方案进行相关积累，形成平台化沉淀，方便以后复用。

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120255154-1515945601.png)

优化路径，包括：策略优化路径和效率优化平台。

关于策略优化路径，主要分为四个阶段：

*   **反馈策略**。这主要运用于业务建模初期，采用平滑策略，位置消偏，时间衰减，流量反作弊策略进行初期模型的相关排序；
*   **基础模型**。主要进行基础流程建设，涉及LR、GBDT模型，用户个性化，帖子结构化这几方面进行优化；
*   **特征升级**。主要针对组合特征，时效性升级，文本特征以及图像特征几个方面，使模型效果更佳；
*   **模型升级**。主要针对融合模型，深度学习模型，以及在线学习方面进行相关迭代。

关于效率优化平台，主要针对日志合并清洗，特征工程，模型训练评估以及上线验证四个阶段进行优化。

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120258828-1212916199.png)

进一步对效率优化平台进行介绍：主要针对日志系统，日志样本，机器学习，上线试验以及线上系统进行相关优化。

*   **日志系统**：针对日志样本、机器学习、上线试验这几个方面进行平台化整合，包括流程执行、流程管理、特征开放以及配置管理等。
*   **日志样本**：涉及日志预处理，帖子特征抽取，个性化生成，样本生成等；
*   **机器学习**：涉及样本采样，特征工程，模型训练，评估分析等；
*   **上线试验**：涉及推送流程，实验系统，报表系统等。

接下来对涉及到的相关技术点进行介绍：

*   **数据**：日反作弊、特征开放平台、样本选取；
*   **算法**：反馈策略、基础模型、特征升级、模型升级；
*   **工程**：特征组件化、融合模型框架化、平台化整合。

1\. 基础数据流程（数据）
--------------

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120305528-2027206922.png)

关于数据，主要涉及日志反作弊和特征开放平台。

**数据的生成分为两个阶段，第一个阶段为原始样本生成，第二个阶段为样本生成。**

原始样本主要来自于曝光、点击以及转化日志，在相关日志的合并以及清洗之后可以获得原始样本数据。

样本生成，主要是在特征开放平台上生成。涉及到帖子特征库，用户个性化特征，以及相关的特征描述文件。

其中，帖子特征库由帖子结构化，反馈特征，文本图像特征三个方面组成；用户个性化特征，主要由帖子特征库和点击转化日志而来。

对于样本新特征问题，平台采用自动合并机制，对新增加的帖子新特征以及用户新特征进行合并。

经过上述两步的处理，样本数据便形成了。

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120311703-1411853027.png)

在数据日志反作弊阶段，主要针对IP，用户进行相关日志反作弊处理，主要涉及到多指标判断机制以及作弊标记机制：

*   在多指标判断机制中，主要有曝光量、点击量、转化量、点击率、转化率这多个指标进行相关的判断；
*   在作弊标记机制中，主要对特征的字段进行相关的作弊类型标识。

下面是针对IP反作弊规则的例子：

*   采用曝光大于某个阈值，CTR小于某个阈值，对曝光异常但是点击合理的IP数据进行相关的过滤；
*   采用曝光大于某个阈值，转化小于某个阈值，过滤掉曝光异常但转化量偏低的IP数据；
*   采用CTR大于某个阈值，过滤掉CTR异常的IP数据；
*   采用转化除以点击大于某个阈值，过滤掉点击到转化异常的IP数据；
*   采用CVR大于某个阈值，过滤掉CVR异常的IP数据等等。

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120318172-976394611.png)

模型的效果主要由特征，特征工程以及算法组成，特征工程在模型效果方面表现的异常重要。数据特征开放平台是主要为了简化新特征尝试流程，降低尝试代价，并快速支持试验。特征开放平台采用规范化元数据描述、管理，自定义合并机制，支持时效性对齐，自动触发，以及定制化回溯机制，其基本流程为，首先在特征注册平台上进行注册，完善特征的元数据描述；接着按规范格式与约定时效性在给定的存储位置生成数据；最后根据样本生成流程基于特征描述紧张自动化合并。

2.策略优化路径（算法）
------------

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120324264-858063682.png)

反馈策略在建模初期使用，主要采用平滑策略，位置消偏，时间衰减三种策略进行优化迭代，对准实时反馈以及历史反馈分别进行7天为周期分钟级滚动统计点击率和转化率以及30天为周期按天滚动的点击率与转化率。在实行反馈策略后，实时点击率有10%的提升，而历史转化率方面，转化效果有一定提升。

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120345054-194299378.png)

在数据样本选取方面，支持多种场景，例如模型类型、业务类型、产品形态，并实现了灵活配置样本的选取机制，大致有以下四种机制：

*   **基于表达式**；
*   **预定义缺省组件（Raito，Pos，Neighbor，Random，Unique..）**；
*   **组合方式（and，or，not）**；
*   **自定义组件**。

同时可以采用标准方式选取，相关实例采样以及样本过滤操作。

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120355000-1705182291.png)

在基础阶段模型上，通常采用14天的数据做训练，并采样成1:15的正负样本比例，使用3天数据做为测试，并以AUC作为主要离线评测指标。原始特征在150维左右，针对LR模型采用离散化编码处理方式，特征超高维度。模型方面，对原始特征主要采用XGB进行训练。

在效果方面，针对租房普通列表页面上，有20%以上的转化率提升；而在租房精选上实现了30%以上的ECPM提升；而在普通列表页面上，电话接通率提升10%以上。

3.效率优化平台（工程）
------------

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120400169-487165369.png)

在特征工程组件化方面，采用组件名（输入，配置）到输出的配置方案，其中涉及1对1的特征变换，1对n的特征编码，n对n的特征组合，同时还满足各种适配条件进行相关组件化配置。

在工程融合模型框架化方面，可以拥有以下两种功能：

**第一种，支持表达式配置，灵活，支持多种形式的组合；**  
**第二种，样本标识机制下，保证了批处理框架下的样本对齐。**

同时模型融合方面，主要采用结果融合以及特征融合，结果融合主要将模型预测结果作为特征，而特征融合方面，利用训练好的模型来构建特征，例如GBDT编码特征，NN编码，FM隐向量等方式。

融合流程：

*   第一步，在效率优化平台按照正常流程训练好待融合模型；
*   第二步，准备目标模型样本数据；
*   第三步，基于样本数据生成基于待融合模型提取的特征；
*   第四步，将初始样本数据与根据带融合模型提取的特征进行合并，形成融合模型样本；
*   第五步，训练目标模型。

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120404818-636554858.png)

特征升级主要包括：

*   **时效性升级**：反馈特征按周期滚动，分钟级更新，同时还提取了相应周期的个性化特征；
*   **特征组合**：采用笛卡尔组合和匹配组合方式，例如价格面积组合，价格性别组合，个性化偏好等；
*   **文本图像特征**：采用词向量，关键词，图像饱和度，图像全连接模型输出特征等。

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120408472-1045144839.png)

关于模型升级，主要采用LR的预测结果接入GBDT，或者GBDT的结果接入LR；而在深度学习方面，采用Wide&Deep以及DeepFM等技术实现算法迭代。

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120417331-123967845.png)

在WideDeep实现方面，主要将wide部分的连续特征进行离散化，相关特征有RCrctr，HCtagfhgectrap等特征；并将枚举离散化特征，主要用于离散特征个数较少的情况；而Hash离散特征，主要用户离散值数量较大的特征，离散分桶最大值为5000；在交叉特征方面，主要由帖子维度组合，帖子与用户基础属性组合。而在deep部分，连续特征主要采用离散化最大最小归一化处理，枚举离散特征和wide部分一致，而Hash离散特征采用embedding\_size方式，而在Embedding特征方面，采用个性化加个性化组合的方式。

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120419889-1993162070.png)

而在平台整合方面，主要由三个大的模块组成：

*   第一个模块为基础模块，包括日志样本、机器学习以及上线试验；
*   第二个模块为用户工作空间，主要用于数据相关的配置；
*   第三个模块为基础数据，主要涉及流程数据库，样本数据，日志数据，和效果数据。

通过这三个模块，平台拥有流程创建，流程配置，运行监控，模型转换，推送上线，报表关联等功能，同时应对了特征开放平台，数据管理，流程管理，实验管理，报表管理等方面。

![file](https://img2022.cnblogs.com/other/1701474/202206/1701474-20220611120430534-123448.png)

上图为机器学习平台的配置页面，可以看出从基础配置，训练采样，测试采样，特征以及训练，可以看出模型测试和训练简洁便利，做到了5+专属的流程切换，全效率优化流程管理，策略成电分享复用，也降低了维护代价，降低优化的门槛。

4.效果和下一步
--------

经过整个流程的优化，可以看出效果：房产精选（二手房精选、租房精选）实现了相比基线40%到60%的ECPM（千次展现收入）提升。而在普通业务方面，租房，二手房，二手车上实现10%的转化率提升。

下一阶段，将对深度学习进行相关的探索，尝试多种深度模型，并集成Tensorflow到模型训练流程，探索在线、离线学习一体化平台，同时要利用丰富的数据，例如有效转化数据，文本图像视频特征等。

\--

04 总结&思考
========

在策略优化上，要尽可能循序渐进，关注数据丰富度与质量，同时明确业务优化目标，兵保证线下线上的一致性，此外还要保证新技术探索与优化目标的权衡。在平台建设上，要重视工程能力，监控预警机制，同时进行迭代优化。

* * *

**今天的分享就到这里，谢谢大家。**  
本文首发于微信公众号“DataFunTalk”。