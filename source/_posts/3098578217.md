---
layout: post
title: "5. `sklearn`下的线性回归"
date: "2022-06-19T16:23:53.136Z"
---
5\. \`sklearn\`下的线性回归
=====================

以线性回归为例，介绍sklearn包进行机器学习的流程

本文以线性回归为例，介绍使用`sklearn`进行机器学习的一般过程。

*   首先生成模拟数据

    import numpy as np
    def get_data(theta_true,N):
        X=np.random.normal(size=(N,len(theta_true)))
        Y=X@theta_true+np.random.normal(size=(N))
        return (X,Y)
    theta_true=np.array([2,3,4])
    X,Y=get_data(theta_true,100)
    

*   实例化一个估计器，进行一些可选参数配置。`sklearn`里的回归和线性回归是位于
    
    `sklearn.linear_model`包中的\`\`LinearRegression\`类，在实例化对象时有两个参数：
    
    *   fit\_intercept：bool，默认为True，是否计算此模型的截距，False 表示不计算截距
    *   normalize：bool，默认为False如果为True，则在回归之前将对回归变量X进行归一化
    *   copy\_X : 布尔型参数，若为True，则X将被复制；否则将被覆盖。 可选参数。默认值为True。
    *   n\_jobs : 整型参数，表示用于计算的作业数量；若为-1，则用所有的CPU。可选参数。默认值为1

    from sklearn.linear_model import LinearRegression
    lm_model = LinearRegression()
    

*   调用估计器的`fit`方法，传入数据和标签，进行学习

    lm_model.fit(X,Y)
    

*   查看估计出来的参数

    lm_model.intercept_#查看截距
    lm_model.coef_#查看系数
    

*   进行预测

    lm_model.predict(X_test)
    

*   模型评估

    lm.model.score(X_test,Y_test)#用R方进行评估