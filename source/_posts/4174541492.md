---
layout: post
title: "一次XGBoost性能优化-超线程影响运算速度"
date: "2022-05-29T11:15:58.133Z"
---
一次XGBoost性能优化-超线程影响运算速度
=======================

一、问题背景
------

1.  一个朋友在使用 _XGBoost_ 框架进行机器学习编码，他们的一个demo, 在笔记本的虚拟机(4核)运行的时候，只要8s, 但是在一个64核128G 的物理机上面的虚拟机去跑的时候，发现时间需要更长。
    
    ![image-20220517103920522](https://djxblog.oss-cn-shenzhen.aliyuncs.com/picture/typora/image-20220517103920522.png)
    
    笔记本执行：
    
    ![image-20220517104217425](https://djxblog.oss-cn-shenzhen.aliyuncs.com/picture/typora/image-20220517104217425.png)
    

二、问题定位和解决
---------

首先看到负载是比较高的，内存占用比较少。因为是计算型的，所以这种状态是正常的。

一开始我觉得是GIL 锁，后面询问是使用了 XGBoost 框架，想去官网看看能不能找到相关内容

[XGBoost 多线程支持](https://github.com/apachecn/ml-mastery-zh/blob/master/docs/xgboost/best-tune-multithreading-support-xgboost-python.md) 文档的一段话提醒了我：

> 我们可以在具有更多核心的机器上运行相同的代码。例如大型的 Amazon Web Services EC2 具有 32 个核心。我们可以调整上面的代码来计算具有 1 到 32 个核心的模型所需的训练时间。结果如下图。
> 
> ![img](https://djxblog.oss-cn-shenzhen.aliyuncs.com/picture/typora/146f19ae6f7ee6886994a2b084b410b3.jpg)
> 
> XGBoost 在 1 到 32 个核心上训练模型所需的时间
> 
> 值得注意的是，在多于 16 个线程（大约 7 秒）的情况下，我们没有看到太多进步。我想其原因是 Amazon 仅在硬件中提供 16 个内核，而另外的 16 个核心是通过超线程提供额外。结果表明，如果您的计算机具有超线程能力，则可能需要将 **num\_threads** 设置为等于计算机中物理 CPU 核心的数量。

示例： [https://github.com/dmlc/xgboost/blob/master/demo/guide-python/sklearn\_parallel.py](https://github.com/dmlc/xgboost/blob/master/demo/guide-python/sklearn_parallel.py)

我们通过示例将 n\_job 的值调整为 cpu 核心的一半，

    n_jobs=multiprocessing.cpu_count()//2
    

发现解决了问题

![image-20220517104911783](https://djxblog.oss-cn-shenzhen.aliyuncs.com/picture/typora/image-20220517104911783.png)

作者：[理想三旬](https://www.cnblogs.com/operationhome/)

出处：

如果觉得文章写得不错，或者帮助到您了，请点个赞，加个关注哦。运维学习交流群:544692191

本文版权归作者所有，欢迎转载，如果文章有写的不足的地方，或者是写得错误的地方，请你一定要指出，因为这样不光是对我写文章的一种促进，也是一份对后面看此文章的人的责任。谢谢。