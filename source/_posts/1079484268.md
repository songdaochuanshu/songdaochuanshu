---
layout: post
title: "NLP实践！文本语法纠错模型实战，搭建你的贴身语法修改小助手 ⛵"
date: "2022-11-30T12:36:22.934Z"
---
NLP实践！文本语法纠错模型实战，搭建你的贴身语法修改小助手 ⛵
================================

![NLP实践！文本语法纠错模型实战，搭建你的贴身语法修改小助手 ⛵](https://img2023.cnblogs.com/blog/2637458/202211/2637458-20221130134957723-1470816751.png) 本文详细介绍 GECToR 这一优秀的文本纠错模型，使用 Transformer 编码器的序列标注器，以保证文本数据的质量，进而提升NLP模型的效果。

![](https://img-blog.csdnimg.cn/img_convert/1d9ab3a69fea51b80de57c8735d387cc.png)

> 💡 作者：[韩信子](https://github.com/HanXinzi-AI)@[ShowMeAI](https://www.showmeai.tech/)  
> 📘 [深度学习实战系列](https://www.showmeai.tech/tutorials/42)：[https://www.showmeai.tech/tutorials/42](https://www.showmeai.tech/tutorials/42)  
> 📘 [自然语言处理实战系列](https://www.showmeai.tech/tutorials/45)：[https://www.showmeai.tech/tutorials/45](https://www.showmeai.tech/tutorials/45)  
> 📘 [本文地址](https://showmeai.tech/article-detail/399)：[https://showmeai.tech/article-detail/399](https://showmeai.tech/article-detail/399)  
> 📢 声明：版权所有，转载请联系平台与作者并注明出处  
> 📢 收藏[ShowMeAI](https://www.showmeai.tech/)查看更多精彩内容

![](https://img-blog.csdnimg.cn/img_convert/235a942f08897d14fa3cf5bf07655c42.png)

自然语言处理（NLP）技术可以完成文本数据上的分析挖掘，并应用到各种业务当中。例如：

*   **机器翻译**（Machine Translation），接收一种语言的输入文本并返回目标语言的输出文本（包含同样的含义）。
*   **情感分析**（Sentiment Analysis），接收文本数据，判定文本是正面的、负面的还是中性的等。
*   **文本摘要**（Text Summarization），接收文本输入并将它们总结为更精炼的文本语言输出。

输入文本的质量会很大程度影响这些业务场景的模型效果。因此，在这些文本数据到达机器翻译、情感分析、文本摘要等下游任务之前，我们要尽量保证输入文本数据的语法正确性。

![](https://img-blog.csdnimg.cn/img_convert/34a0d50edb2e8fd763d00a027f5d419c.png)

**语法纠错**（Grammatical Error Correction）是一个有非常广泛使用的应用场景，有2种典型的模型方法：

> *   ① **序列到序列（seq2seq）模型**：它最早被使用在机器翻译引擎中，将给定语言翻译成同一种语言，这种映射方法同样可以用来做语法纠错（例如📘[Yuan 和 Briscoe，2014](https://aclanthology.org/N16-1042/)）。
> *   ② **序列标注模型**：输入文本被标注然后映射回更正的内容（例如📘[Malmi 等人，2019](https://aclanthology.org/D19-1510/)）。

虽然 seq2seq 神经机器翻译方法已被证明可以实现最先进的性能（例如📘[Vaswani 等人，2017 年](https://arxiv.org/abs/1706.03762)），但它仍然存在某些缺点，例如：1）推理和生成输出需要很长时间；2）训练需要大量数据；3）与非神经架构相比，模型的神经架构使得对结果的解释具有挑战性（例如📘[Omelianchuk 等人，2020 年](https://aclanthology.org/2020.bea-1.16/)）等。**为了克服这些缺点，我们在本文中讨论并应用更新的方法：使用 Transformer 编码器的序列标注器**。

![](https://img-blog.csdnimg.cn/img_convert/20e4e7b6b2cb14a84f67d8b208acf8c5.png)

📘[Omelianchuk, et al., 2020](https://aclanthology.org/2020.bea-1.16/) 中提出的 📘[**GECToR 模型**](https://github.com/grammarly/gector)，是非常优秀的文本纠错模型。它对 Transformer seq2seq 进行微调，Transformer 的引入极大改善了 seq2seq 模型的推理时间问题，并且可以在较小的训练数据的情况下实现更好的效果。

在后续的内容中，[ShowMeAI](https://showmeai.tech/)将演示使用这个库来实现纠正给定句子中语法错误的方案，我们还会创建一个可视化用户界面来将这个AI应用产品化。

💡 语法纠错代码全实现
============

整个语法纠错代码实现包含3个核心步骤板块：

*   **准备工作**：此步骤包括工具库设定、下载预训练模型、环境配置。
*   **模型实践**：实现并测试语法纠错模型。
*   **用户界面**：创建用户界面以产品化和提高用户体验

💦 准备工作
-------

我们先使用以下命令将 GitHub 中的代码复制到我们本地，这是 GECToR 模型对应的实现：

    git clone https://github.com/grammarly/gector.git
    

![](https://img-blog.csdnimg.cn/img_convert/4207155f8b0a62486c91fa73b0d5bee4.png)

GECToR 提供了3种预训练模型。我们在这里使用 📘[**RoBERTa**](https://github.com/facebookresearch/fairseq/blob/main/examples/roberta/README.md) 作为预训练编码器的模型，它在现有模型中具有最高总分最好的表现。我们使用以下命令下载预训练模型：

    wget https://grammarly-nlp-data-public.s3.amazonaws.com/gector/roberta_1_gectorv2.th
    

下载完毕后，我们把下载的模型权重移动到`gector`目录，以便后续使用：

    mv roberta_1_gectorv2.th ./gector/gector
    

接下来，我们切换到`gector`文件夹下：

    cd ./gector
    

`gector`对其他工具库有依赖，因此我们将使用以下命令安装这些依赖：

    pip install -r requirements.txt
    

💦 模型实践
-------

现在我们已经做好所有准备工作了，可以开始使用工具库。总共有下述步骤：

*   导入工具包
*   构建模型实例
*   在有语法错误的句子上测试模型，以查看输出

### ① she are looking at sky

为此，我们将使用以下句子『she are looking at sky』。

    # 导入工具库
    from gector.gec_model import GecBERTModel
    
    # 构建模型实例
    model = GecBERTModel(vocab_path = "./data/output_vocabulary", model_paths = ["./gector/roberta_1_gectorv2.th"])
    
    # 需要纠错的句子
    sent = 'she are looking at sky'
    
    # 存储处理结果
    batch = []
    batch.append(sent.split())
    final_batch, total_updates = model.handle_batch(batch)
    updated_sent = " ".join(final_batch[0])
    print(f"Original Sentence: {sent}\n")
    print(f"Updated Sentence: {updated_sent}")
    

结果：

![](https://img-blog.csdnimg.cn/img_convert/27919c978df0de03078487bfc83d616f.png)

模型的纠错结果非常准确！有以下变化：

*   句首将`she`大写为`She`
*   将`are`更改为`is`，以使`she`和`is`主谓一致
*   在`sky`之前添加`the`
*   在句子末尾加句号`.`

### ② she looks at sky yesterday whil brushed her hair

刚才的句子语法比较简单，让我们看看复杂场景，比如混合时态下模型的表现如何。

    # 添加复杂句子
    sent = 'she looks at sky yesterday whil brushed her hair'
    
    # 存储纠错后的句子
    batch = []
    batch.append(sent.split())
    final_batch, total_updates = model.handle_batch(batch)
    updated_sent = " ".join(final_batch[0])
    print(f"Original Sentence: {sent}\n")
    print(f"Updated Sentence: {updated_sent}")
    

结果：

![](https://img-blog.csdnimg.cn/img_convert/421ea46d0b123fe212840b8c11937156.png)

在这个句子中我们来看一下纠错模型做了什么：

*   句首将`she`大写为`She`
*   将`looks`改为`looked`，与`yesterday`一致
*   在`sky`之前添加`the`
*   将缺失的字母添加到`while`
*   将`brushed`改为`brushing`，这是`while`之后的正确格式

不过这里有一点大家要注意，模型的另外一种纠错方式是将`yesterday`更改为`today`，对应的时态就不需要用过去式。但这里模型决定使用过去时态。

### ③ she was looking at sky later today whil brushed her hair

现在让我们再看一个例子：

    # 添加复杂句子
    sent = 'she was looking at sky later today whil brushed her hair'
    
    # 纠错及存储
    batch = []
    batch.append(sent.split())
    final_batch, total_updates = model.handle_batch(batch)
    updated_sent = " ".join(final_batch[0])
    print(f"Original Sentence: {sent}\n")
    print(f"Updated Sentence: {updated_sent}")
    

结果：

![](https://img-blog.csdnimg.cn/img_convert/31c326f7964afb057d8a0ef5cba1d576.png)

我们发现了一种边缘情况，在这种情况下，模型无法识别正确的动词时态。更新后的句子是『She was looking at the sky later today while brushing her hair』，我们读下来感觉这句是将来时（今天晚点），而模型纠正后的句子是过去时。

我们想一想，为什么这句对模型比以前更具挑战性呢？答案是`later today`用两个词暗示时间，这需要模型具有更深层次的上下文意识。如果没有`later`这个词，我们会有一个完全可以接受的句子，如下所示：

![](https://img-blog.csdnimg.cn/img_convert/e6d820efef564e2e54f290081f1a7cfb.png)

在这种情况下，`today`可能指的是今天早些时候（即过去），纠错后的语法完全可以接受。但在原始示例中，模型未将`later today`识别为表示将来时态。

💦 用户界面
-------

在下一步，我们将制作一个web界面，通过用户界面把它产品化并改善用户体验：

    # 创建一个函数，对于输入的句子进行语法纠错并返回结果
    def correct_grammar(sent):
        batch = []
        batch.append(sent.split())
        final_batch, total_updates = model.handle_batch(batch)
        updated_sent = " ".join(final_batch[0])
        return updated_sent
    

我们找一个句子测试这个函数，确保它能正常工作和输出结果。

    sent = 'she looks at sky yesterday whil brushed her hair'
    
    print(f"Original Sentence: {sent}\n")
    print(f"Updated Sentence: {correct_grammar(sent = sent)}")
    

结果：

![](https://img-blog.csdnimg.cn/img_convert/6579db8ba909f71c346df4b450a8740c.png)

接下来我们将添加一个可视化用户界面。我们使用 📘[Gradio](https://github.com/gradio-app/gradio) 来完成这个环节，它是一个开源 Python 工具库，可以快捷创建 Web 应用程序，如下所示。

    # 在命令行运行以安装gradio
    pip install gradio
    

安装Gradio后，我们继续导入和创建用户界面，如下所示：

    # 导入Gradio
    import gradio as gr
    
    # 构建一个demo实例
    demo = gr.Interface(fn = correct_grammar, inputs = gr.Textbox(lines = 1, placeholder = 'Add your sentence here!'), outputs = 'text')
    
    # 启动demo
    demo.launch()
    

结果我们得到如下的界面：

![](https://img-blog.csdnimg.cn/img_convert/2dcd6c39559cf47b94acd50d55aa2bf8.png)

我们可以在 web 界面中再次测试我们的句子啦！我们只需在左侧的框中键入待纠错的句子，然后按 Submit（提交）。接错后的结果将显示在右侧的框中，如下所示：

![](https://img-blog.csdnimg.cn/img_convert/01e124b4f4d2d6ae2744ba813f45f589.png)

非常顺利，你也快来测试一下吧！

💡 总结
=====

在这篇文章中，我们实践了语法纠错模型。我们使用公开可用的 GECToR 库来实现一个预训练的语法纠错模型，在一些错误的句子上对其进行测试，发现该模型的适用场景和局限性（需要提高的地方），最后我们构建了一个可视化界面把文本纠错产品化。

参考资料
====

*   📘 [**Grammatical error correction using neural machine translation**](https://aclanthology.org/N16-1042/)：[https://aclanthology.org/N16-1042/](https://aclanthology.org/N16-1042/)
*   📘 [**Encode, Tag, Realize: High-Precision Text Editing**](https://aclanthology.org/D19-1510/)：[https://aclanthology.org/D19-1510/](https://aclanthology.org/D19-1510/)
*   📘 [**Attention Is All You Need**](https://arxiv.org/abs/1706.03762)：[https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)
*   📘 [**GECToR – Grammatical Error Correction: Tag, Not Rewrite**](https://aclanthology.org/2020.bea-1.16/)：[https://aclanthology.org/2020.bea-1.16/](https://aclanthology.org/2020.bea-1.16/)
*   📘 [**GECToR模型的GitHub页面**](https://github.com/grammarly/gector)：[https://github.com/grammarly/gector](https://github.com/grammarly/gector)
*   📘 [**RoBERTa的GitHub页面**](https://github.com/facebookresearch/fairseq/blob/main/examples/roberta/README.md)：[https://github.com/facebookresearch/fairseq/blob/main/examples/roberta/README.md](https://github.com/facebookresearch/fairseq/blob/main/examples/roberta/README.md)
*   📘 [**Gradio的GitHub页面**](https://github.com/gradio-app/gradio)：[https://github.com/gradio-app/gradio](https://github.com/gradio-app/gradio)

推荐阅读
====

*   🌍 [**数据分析实战系列**](https://www.showmeai.tech/tutorials/40) ：[https://www.showmeai.tech/tutorials/40](https://www.showmeai.tech/tutorials/40)
*   🌍 [**机器学习数据分析实战系列**](https://www.showmeai.tech/tutorials/41)：[https://www.showmeai.tech/tutorials/41](https://www.showmeai.tech/tutorials/41)
*   🌍 [**深度学习数据分析实战系列**](https://www.showmeai.tech/tutorials/42)：[https://www.showmeai.tech/tutorials/42](https://www.showmeai.tech/tutorials/42)
*   🌍 [**TensorFlow数据分析实战系列**](https://www.showmeai.tech/tutorials/43)：[https://www.showmeai.tech/tutorials/43](https://www.showmeai.tech/tutorials/43)
*   🌍 [**PyTorch数据分析实战系列**](https://www.showmeai.tech/tutorials/44)：[https://www.showmeai.tech/tutorials/44](https://www.showmeai.tech/tutorials/44)
*   🌍 [**NLP实战数据分析实战系列**](https://www.showmeai.tech/tutorials/45)：[https://www.showmeai.tech/tutorials/45](https://www.showmeai.tech/tutorials/45)
*   🌍 [**CV实战数据分析实战系列**](https://www.showmeai.tech/tutorials/46)：[https://www.showmeai.tech/tutorials/46](https://www.showmeai.tech/tutorials/46)

[![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e9190f41b8de4af38c8a1a0c96f0513b~tplv-k3u1fbpfcp-zoom-1.image)](https://www.showmeai.tech/)