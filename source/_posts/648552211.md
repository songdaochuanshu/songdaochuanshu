---
layout: post
title: "IO多路复用"
date: "2022-04-16T03:28:15.974Z"
---
IO多路复用
======

划分内核态/用户态
---------

之前说过七层/五层/四层的`网络模型`，我们从网络模型可以看出`传输层`（tcp/udp）开始 就是我们平常编写`程序`所`运行`的层次了。在系统层级，为了系统安全之类的考虑我们将 `传输层向上` 划分为`用户态` 将 `传输层向下` 划分到 `内核态`（暂时可以认为这么划分）  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650023596468-09d921a2-8e58-405a-a140-738e40cb6517.png#clientId=uc53d8dfb-dde2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=492&id=udbb8aa8c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=984&originWidth=1796&originalType=binary&ratio=1&rotation=0&showTitle=true&size=234722&status=done&style=none&taskId=u609d50b5-cb0f-474c-b30b-67d6e719e2d&title=%E5%86%85%E6%A0%B8%E6%80%81%E5%92%8C%E7%94%A8%E6%88%B7%E6%80%81%E5%88%92%E5%88%86%E5%9B%BE&width=898 "内核态和用户态划分图")

客户端-服务端
-------

在网络交互中`客户端`和`服务端`的交互时发生了什么？

1.  首先我们`应用启动`运行，对外`暴露`一个`端口`（或者多个），此时调用`系统``创建`一个（或多个）这个端口的`socket`(或者说是创建一个（或多个）`监听器`)
2.  `客户端`发起`请求`，此时`客户端生成`一个`socket` 然后通过 `传输层->网络层->链路层->物理层 ->( 物理层-链路层-网络层-传输层)``服务器` 进行`三次握手`确认链接
3.  然后`客户端`将`数据`按照第二部的链路顺序 在发送到 服务端
4.  `服务端`从 `网卡`\->将数据（0/1）`读出` -> `内核态` -> `用户态`
5.  用户态处理数据，将处理后的数据再原路返回。

![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650023786794-f05d5614-f0ff-43a9-969c-3655fc8a3d21.png#clientId=uc53d8dfb-dde2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=671&id=u0559a160&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1342&originWidth=1950&originalType=binary&ratio=1&rotation=0&showTitle=true&size=291354&status=done&style=none&taskId=ub90b53ed-fdf5-44cb-802a-188f39ff074&title=%E5%AE%A2%E6%88%B7%E7%AB%AF-%E6%9C%8D%E5%8A%A1%E7%AB%AF%20%E6%95%B0%E6%8D%AE%E6%B5%81&width=975 "客户端-服务端 数据流")  
从上我们可以知道 `客户端` 和 `服务端` 的`数据``流向`。这仅仅是`一台`客户端的，作为服务器肯定是要有`多台`客户端进行通信的，如果有多个客户端`同时`访问此时的`过程`如何呢？这就引出我们今天要说的主题：`IO多路复用`。为了讲清楚，我们先将`传统的网络io`拉出来进行一步步推导。

我们在上面说过，服务端应用启动的时候会创建一个`主动socket`（也就是监听器），那么如果有客户端建立链接的时候被监听到，然后执行 创建一个`被动socket`执行服务端的代码：服务端一般就是`读取数据` 然后 `处理数据` 最后`返回数据` `关闭链接`  
但是 我们建立链接的时候 数据`还没有``到达``用户态`，也就是此时数据不一定传输完成了。那么我们服务端的读数据 也就被阻塞了（我们程序发起io调用，如果内核态 没有准备好，那么我们程序是在io 阶段被阻塞的，也就是我们平常说的系统卡了）。此时就引出我们第一个概念：`阻塞IO`

### 关于数据的阻塞

![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650025753191-618f1c72-66df-423e-aa97-ed654027775c.png#clientId=uc53d8dfb-dde2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=374&id=ue6b60c07&margin=%5Bobject%20Object%5D&name=image.png&originHeight=748&originWidth=1466&originalType=binary&ratio=1&rotation=0&showTitle=true&size=400334&status=done&style=none&taskId=ub26bfbd7-23f3-4233-9f82-b212e81f9d0&title=%E9%98%BB%E5%A1%9Eio%20%E6%A8%A1%E5%9E%8B-%E5%BB%BA%E7%AB%8B%E9%93%BE%E6%8E%A5&width=733 "阻塞io 模型-建立链接")  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650025824435-202cdeb7-9662-47be-90a1-a5111e0b25a7.png#clientId=uc53d8dfb-dde2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=373&id=uc0eef4f6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=746&originWidth=1428&originalType=binary&ratio=1&rotation=0&showTitle=true&size=417627&status=done&style=none&taskId=uf13dc62b-0270-4bef-a433-cbc8f6deb75&title=%E9%98%BB%E5%A1%9Eio%E6%A8%A1%E5%9E%8B-%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%AD%89%E5%BE%85%E6%95%B0%E6%8D%AE&width=714 "阻塞io模型-服务端等待数据")

![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650018736299-cfa7d157-5077-4d12-8ef0-acf5f5f00100.png#clientId=u90d0f99d-e0c7-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=94&id=TZ36g&margin=%5Bobject%20Object%5D&name=image.png&originHeight=94&originWidth=720&originalType=binary&ratio=1&rotation=0&showTitle=true&size=28368&status=done&style=none&taskId=uc576efda-086e-489b-b4d8-d0fb5ce8398&title=%E5%9F%BA%E7%A1%80socket%E6%A8%A1%E5%9E%8B&width=720 "基础socket模型")

### Read 过程

在上面我们可以看到 客户端写入流 和 服务端读入流 是有一个阻塞的阶段的（客户端可以分多次写入流，然后发送到服务端），而且这里我们要注意的是，这个流是从`物理层`传入的（服务端举例子，客户端是相反的），那么数据到达用户层 还是有一个 `内核态` 到`用户态`的`切换`（这个`上下文切换`是比较`耗费`性能的）。  
然后我们对从 底层 到 用户层的过程进行一下分析：将read （`系统`提供的`read` 函数）展开来，可以发现这个read 分成`两个`部分：  
数据从外部流入网卡然后走到内核缓冲区，此时客户端socke文件描述符变成1，然后用户缓冲区再去读取（服务端进行读取使用）  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650025943525-97cbcaf4-4773-46f2-a1d8-a00ab1f34370.png#clientId=uc53d8dfb-dde2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=545&id=ucb83a27f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1090&originWidth=1374&originalType=binary&ratio=1&rotation=0&showTitle=true&size=506355&status=done&style=none&taskId=u4aec5468-425f-4867-96a4-b2ba2d8671c&title=%E6%95%B0%E6%8D%AE%E6%B5%81%E5%90%91%E7%94%A8%E6%88%B7%E6%80%81%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5&width=687 "数据流向用户态第一阶段")

![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650026165251-d8b49fa0-7cd8-4289-b5b7-0b30306e5335.png#clientId=uc53d8dfb-dde2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=536&id=uebc339e7&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1072&originWidth=1376&originalType=binary&ratio=1&rotation=0&showTitle=true&size=490579&status=done&style=none&taskId=u3c2805e9-771f-43a7-9229-675477940b2&title=%E6%95%B0%E6%8D%AE%E6%B5%81%E5%90%91%E7%94%A8%E6%88%B7%E6%80%81%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5&width=688 "数据流向用户态第二阶段")

一、阻塞IO
------

在这个模型中，服务端处理请求是串联的。也就是说如果这个请求被阻塞了，那么剩下的请求都要被`阻塞``等待``上一个`请求处理`完成`才行。所以，我们上面说，在 服务器读数据的时候，数据还没到（数据还没读到用户态），那么服务器被阻塞，然后其他客户端的请求也`不能`被处理。

> 比如：  
> 小明和小红两个人访问同一个服务，然后小明先点，但是数据没被处理完成，然后小红在进行发送请求，此时服务器就将小红的请求挂起，等待小明的处理完成在进行处理。

这样来说，服务器的cpu岂不是会浪费？当用户数量少的时候还可以，但是如果用户数量多来怎么行  
所以我们就自己优化一下。

### 优化阻塞io

怎么优化，既然服务器此时还在等待数据，那么我们在`开一个线程`去处理另外的客户端不就ok了？  
所以我们对`监听`和 `read`进行`解耦合`，监听到一个客户端就放进来一个客户端的请求，然后服务再`启动`一个线程去处理这个请求。  
但是这个有两个比较突出的问题：

1.  服务端需要开辟`大量`的`线程`，这对`服务端的压力`是很大的
2.  这个read 还是`单线程``阻塞`的，我们没办法向下走啊

所以这个对于传统的io 来说还是没有解决实际的问题，想要解决只能在操作系统中（内核态）处理。而这就引出我们第二个概念：非阻塞io

二、非阻塞IO
-------

我们在看上面的read 函数，可以发现read 函数是分成两个部分进行的，那我们是不是可以将这个两个过程分开？  
服务端的read 执行，然后read `直接`返回-1 让 服务端 代码进行下一步操作，不用在阻塞到读取这里。  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650027312969-1edf1f6f-9e77-492c-9f0e-dba0a94234a1.png#clientId=uc53d8dfb-dde2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=495&id=u8f0af620&margin=%5Bobject%20Object%5D&name=image.png&originHeight=990&originWidth=1414&originalType=binary&ratio=1&rotation=0&showTitle=true&size=583541&status=done&style=none&taskId=ue7db469e-9cfc-4295-9b48-136ecae9224&title=%E9%9D%9E%E9%98%BB%E5%A1%9Eio%E6%A8%A1%E5%9E%8B&width=707 "非阻塞io模型")  
虽然系统`不再`阻塞服务端的读取程序了，但是服务端还是要使用这个数据啊，所以服务端还是需要`有个线程`不断的进行循环，以此知道数据读取完成了，所以还是有服务端创建线程的压力啊。（也就是我们还是需要自己循环这个状态；还有一点 read 读取 还是 `阻塞`的，我们`非阻塞`的只是`数据预处理阶段`\-也就是网卡到内核缓冲区的部分,这个是`同步`和`异步`的一个重要区分点）  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650074970628-d631b905-4338-40fc-9597-2d10af9e71c0.png#clientId=u8b7066ed-9ccd-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=500&id=uc2be93df&margin=%5Bobject%20Object%5D&name=image.png&originHeight=453&originWidth=640&originalType=binary&ratio=1&rotation=0&showTitle=true&size=124598&status=done&style=none&taskId=ubb4e0885-f8e6-44ce-bc07-27738d04428&title=%E9%9D%9E%E9%98%BB%E5%A1%9E%E6%A8%A1%E5%9E%8B%E5%9B%BE&width=707 "非阻塞模型图")

### 优化

我们再一次发挥聪明的头脑，既然服务端为每个客户端创建一个线程是耗费创建线程的压力，那么就将每个客户端的文件描述符存储起来（数组），然后等到可以在用户态read 的时候在调用服务端的注册函数不就ok了，然后`单独`创建一个线程 `专门`用来做 `遍历`。这样不就减少了服务端的压力了  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650027946138-3af5acdc-42a5-4674-8bb5-6404fe079eaa.png#clientId=uc53d8dfb-dde2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=277&id=ubd8daaa6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=554&originWidth=1044&originalType=binary&ratio=1&rotation=0&showTitle=false&size=366689&status=done&style=none&taskId=u2cc6a80e-584e-46e6-9350-7899917baab&title=&width=522)  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650027971699-fecfa739-bd4e-497f-9a46-f856c72b5977.png#clientId=uc53d8dfb-dde2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=246&id=u021078bc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=492&originWidth=946&originalType=binary&ratio=1&rotation=0&showTitle=false&size=62046&status=done&style=none&taskId=uf12fec32-ab4c-4b3b-b1b0-e28efdf269f&title=&width=473)  
这是不是有点多路复用的意思？  
但是我们在应用层写的read 还是要调用系统的read 方法，也就是还是需要消耗系统资源的（在 while 循环里做系统调用，就好比你做分布式项目时在 while 里做 rpc 请求一样，是不划算的）。所以我们能不能扔到系统中去？这就引出我们今天的角-io多路复用

三、IO多路复用
--------

多路复用的思想： 是 在 非阻塞 io 的基础上进行优化的，也就是对于 read 第一部分 `预处理阶段` 是`非阻塞`的。（可以理解为，我们告诉系统那些在等待，等系统处理好了 在通知 系统，我们再去调用io 读取）

### select

此时操作系统提供了一个select 函数，我们可以通过它把一个文件描述符的数组发给操作系统， 让操作系统去遍历，确定哪个文件描述符可以读写， 然后告诉我们去处理：

![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650028363559-8dd67f81-f9e4-41d6-8c19-3cd0d9a351b9.png#clientId=uc53d8dfb-dde2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=406&id=u328bc1c4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=812&originWidth=1106&originalType=binary&ratio=1&rotation=0&showTitle=false&size=336292&status=done&style=none&taskId=u2b98078a-7148-481d-beb2-9da33d8bdd7&title=&width=553)  
这里注意一下，虽然我们让系统遍历了，但是我们自己还是需要遍历的，只不过此时我们自己遍历的没有了系统的开销了。然后有了数据之后我们在进行调用注册函数。

![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650028516405-68cb8fd7-1876-4f34-8afe-cfcab32f366c.png#clientId=uc53d8dfb-dde2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=424&id=u959ca7b0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=848&originWidth=1130&originalType=binary&ratio=1&rotation=0&showTitle=false&size=274803&status=done&style=none&taskId=ua2caf241-6b8f-4753-ad62-e1083d096a6&title=&width=565)

但是我们知道

1.  系统调用fd 数据，也就是拷贝一份到内核，高并发场景下这样的拷贝消耗的资源是惊人的。（可优化为不复制）且数组也是有限制的。
2.  还有select 在内核层仍然是通过遍历的方式检查文件描述符的就绪状态，是个同步过程，只不过无系统调用切换上下文的开销。（内核层可优化为异步事件通知）
3.  select 仅仅返回可读文件描述符的个数，具体哪个可读还是要用户自己遍历。（可优化为只返回给用户就绪的文件描述符，无需用户做无效的遍历）

这一点我们还有一个注意的点：我们`read第二步`还是在`阻塞`的

### poll

为了解决数组的限制（这不阻碍高并发的数量么），所以它用了动态数组，也就是链表，去掉了 select 只能监听 1024 个文件描述符的限制。

### epoll

此时我们的终极解决方案过来了  
epoll 主要就是针对这三点进行了改进。  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650028909612-70f527bc-4eab-4596-acfb-2cd025125bb5.png#clientId=uc53d8dfb-dde2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=379&id=u20b6cea8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=758&originWidth=1156&originalType=binary&ratio=1&rotation=0&showTitle=false&size=244821&status=done&style=none&taskId=u5fc3f31c-bff5-43dd-b42a-66f90b67764&title=&width=578)

1.  内核中保存一份文件描述符集合，无需用户每次都重新传入，只需告诉内核修改的部分即可。
2.  内核不再通过轮询的方式找到就绪的文件描述符，而是通过异步 IO 事件唤醒。
3.  内核仅会将有 IO 事件的文件描述符返回给用户，用户也无需遍历整个文件描述符集合。

这里我们就将linux中的io 多路复用讲完了。  
![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650031272024-fdf35f3a-8a10-4030-bee3-7dda66550837.png#clientId=uc53d8dfb-dde2-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=567&id=xhbCa&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1134&originWidth=1448&originalType=binary&ratio=1&rotation=0&showTitle=false&size=459094&status=done&style=none&taskId=u79b76d19-51e3-4b96-aea0-de49e6ffa60&title=&width=724)

四、信号驱动IO
--------

我们在io多路复用，到最后我们的epoll 中，可以看到，最后是内核态 将准备好的io 给到 应用层的 程序，所以我们可以进一步来进行一下优化，我们在程序层 将 数据准备 和io读取 进行分开：  
也就是 在主线中调用 数据预处理 等方法，然后另写 一个方法对 预处理完成 之后的方法进行 处理。也就是在程序层我们做一个“异步” （注意 ，这里其实还是同步的，因为我们的read 第二部分还是阻塞的，也就是我们还是在等待这个read ,可以理解为：我们不在主线程等待了，对于内核态来说并不知道，认为 用户态的这段还是在一个线程中）

五、异步IO（AIO）
-----------

我们上面做了那么多， 我们在应用层做的都是想要 在内核态数据真正 读取到用户态 的时候才使用数据，所以 我们考虑一下系统 对于第二部分也进行一个非阻塞的 返回 不就ok 了。  
也就是 服务端（用户态）进行`一次`系统调用（一次上下文切换），然后就往下进行，然后内核态 完成 用户态的 拷贝的时候在进行通知，处理。

总结
--

注意一下，本章重点想要说的是 io 多路复用，其他都是用来和 多路复用进行辅助理解的。

1.  阻塞io 就是 服务端 从建立链接 ->读取数据->处理数据 都是一个线程中完成，一次只处理一个；
2.  我们通过 创建多线程 来解决 防止 主线程 卡主 或者其他线程等待的时间太长的问题
3.  非阻塞io 出来之后，我们就可以将 监听 和 读取 在操作系统层面解 耦合，但是我们还是需要自己遍历状态
4.  select 函数出来之后，我们可以将数组放到用户态进行处理(还是需要自己遍历，只不过没有系统开销了)
5.  poll 使用动态数组来储存 描述符，解决数组长度问题(还是需要自己遍历，只不过没有系统开销了)
6.  epoll 不用每次都传入 描述符，然后使用红黑树 提高系统的性能，这下 我们应用层 终于不用在写遍历去处理了。
7.  型号驱动io 是 程序层结偶，等待 内核台可以读取的时候，在进行io 调用
8.  异步io(AIO) 是 内核态 进行解耦 ，也就是我们程序层 一次调用，然后内核态 到用户层的拷贝 完成的时候 我们的程序层的io 调用就被执行了，不用再去程序层 另外写东西执行了。

![image.png](https://cdn.nlark.com/yuque/0/2022/png/25537751/1650076690853-b057b99a-9cea-478e-b661-42e6d7f15e66.png#clientId=u8b7066ed-9ccd-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=286&id=u5a29fb9d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=572&originWidth=1398&originalType=binary&ratio=1&rotation=0&showTitle=false&size=130260&status=done&style=none&taskId=u6fcb60a4-79cd-499b-8f2f-55eba94366a&title=&width=699)  
最后说一下，这些都是我自己的理解，如果内容有误，请联系告知，在此不胜感激！！！

本文的内容都是使用下面的博客进行理解自己修改的：  
【[https://baijiahao.baidu.com/s?id=1718409483059542510&wfr=spider&for=pc](https://baijiahao.baidu.com/s?id=1718409483059542510&wfr=spider&for=pc)】  
【[https://zhuanlan.zhihu.com/p/470778284](https://zhuanlan.zhihu.com/p/470778284)】  
部分图片来源百度搜索  
如有侵权请联系我删除，感谢！！！