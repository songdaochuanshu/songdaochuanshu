---
layout: post
title: "FS2K人脸素描属性识别"
date: "2022-06-28T08:26:21.929Z"
---
FS2K人脸素描属性识别
============

根据FS2K数据集，利用VGG16，DenseNet，ResNet进行训练和测试，实现输入一张图片(简笔画和普通照片)，输出该图片的属性特征信息

人脸素描属性识别
========

代码：[https://github.com/linkcao/FS2K\_extract](https://github.com/linkcao/FS2K_extract)

问题分析
----

*   需要根据FS2K数据集进行训练和测试，实现输入一张图片，输出该图片的属性特征信息，提取属性特征包括`hair`（有无头发）、`hair_color`(头发颜色)、`gender`（图像人物性别）、`earring`（是否有耳环）、`smile`（是否微笑）、`frontal_face`(是否歪脖)、`style`（图片风格），详细信息均可通过FS2K的`anno_train.json`和`anno_test.json`获取，本质是一个多标签分类问题。

处理方案
----

*   首先对于FS2K数据集用官方的数据划分程序进行划分，之后对划分后的数据进行预处理，统一图片后缀为jpg，之后自定义数据加载类，在数据加载过程中进行标签编码，对图片大小进行统一，并转成tensor，在处理过程中发现存在4个通道的图片，采取取前3个通道的方案，之后再对图像进行标准化，可以加快模型的收敛，处理完成的数据作为模型的输入，在深度学习模型方面，首先需要进行模型选择，使用了三个模型，分别为VGG16,ResNet121以及DenseNet121，在通过pytorch预训练模型进行加载，并修改模型输出层，输出数量为图片属性特征数，之后在设定模型训练的参数，包括Batch，学习率，epoch等，在每一轮训练完成后，都需要对预测出的特征进行处理，在二分类标签设定概率阈值，多分类标签特征列则进行最大概率类别组合，取预测概率最大的类别作为当前属性的预测结果，每一轮训练都在测试集上进行性能评估，并根据F1指标择优保存模型。训练完成后，在测试集上预测属性提取结果，对每一个属性进行性能评估，最后取平均，得到平均的性能指标。

整体的处理流程如下图所示：

![](https://img2022.cnblogs.com/blog/2355982/202206/2355982-20220624105234334-1014798904.png)

数据预处理
-----

1.  数据划分，根据FS2K官方给出的数据划分得到训练集和测试集
2.  统一图片后缀为jpg，通道数为3
3.  所给数据集分为三个文件夹，每个文件夹图片的像素各不相同，分别为250\*250、475 \*340、223 \*318，这里统一变换成256 \* 256，便于后序处理
4.  将图片数据转成tensor
5.  逐channel的对图像进行标准化，可以加快模型的收敛

标签编码
----

1.  由于目标属性集中存在`hair_color`、`style` 两个多分类标签，因此对这两个标签做编码处理
2.  采用One\_Hot编码对多类别标签进行处理
    1.  `hair_color`中0 对应 \[1,0,0,0,0\], 1对应\[0,1,0,0,0\], 2对应\[0,0,1,0,0\],以此类推，共5类
    2.  `style`中 0 对应 \[1,0,0\]，1对应\[0,1,0\], 2对应\[0,0,1\],以此类推,共3类
3.  在和其他的5个二分类标签拼接组成标签向量，共13维

实验模型
----

### VGG16

**模型结构参数**

![](https://img2022.cnblogs.com/blog/2355982/202206/2355982-20220624105251221-267673081.png)

由于VGG16最后一层全连接输出1000维特征，因此在本题中需要在加一层全连接输入1000维特征，输出13维特征，最后再加上一层`sigmoid`激活函数，在得到每一类预测的概率后，针对编码过的hair\_color、style的8列，对各自的编码后的对应列计算概率最大的列下标，作为该属性的预测值。  
**训练参数**

batch

64

**epoch**

20

**optimizer (优化器)**

SGD(随机梯度下降)

**criterion (损失函数)**

BCELoss(二分类交叉熵损失)

**学习率**

0.01

**photo数据集上模型训练Loss**

![](https://img2022.cnblogs.com/blog/2355982/202206/2355982-20220624105314716-2018313125.png)

**结果** **「方法一」**

f1

precision

recall

accuracy

hair

0.926064

0.903045

0.950287

0.950287

gender

0.598046

0.611282

0.59369

0.59369

earring

0.74061

0.674408

0.821224

0.821224

smile

0.513038

0.580621

0.639579

0.639579

frontal\_face

0.758024

0.694976

0.833652

0.833652

hair\_color

0.351596

0.387132

0.389101

0.389101

style

0.460469

0.526145

0.443595

0.443595

**average**

**0.668481**

**0.672201**

**0.708891**

**0.708891**

### ResNet18

**模型结构参数**

![](https://img2022.cnblogs.com/blog/2355982/202206/2355982-20220624105341402-1902447571.png)

模型修改 ，模型最后加一层全连接输入1000维特征，输出13维特征，最后再加上一层`sigmoid`激活函数

**训练参数**

batch

64

**epoch**

20

**optimizer (优化器)**

SGD(随机梯度下降)

**criterion (损失函数)**

BCELoss(二分类交叉熵损失)

**学习率**

0.01

**photo数据集上模型训练Loss**

![](https://img2022.cnblogs.com/blog/2355982/202206/2355982-20220624105411876-1006642860.png)

**photo数据集结果** **「方法二」**

f1

precision

recall

accuracy

hair

0.926064

0.903045

0.950287

0.950287

gender

0.657874

0.657195

0.6587

0.6587

earring

0.744185

0.764809

0.821224

0.821224

smile

0.634135

0.63298

0.652008

0.652008

frontal\_face

0.758024

0.694976

0.833652

0.833652

hair\_color

0.498804

0.515916

0.546845

0.546845

style

0.508202

0.57917

0.482792

0.482792

**average**

**0.715911**

**0.718511**

**0.743188**

**0.743188**

**Sketch数据集上模型训练Loss**

![](https://img2022.cnblogs.com/blog/2355982/202206/2355982-20220624105426838-1302757829.png)

**sketch数据集结果** **「方法三」**

f1

precision

recall

accuracy

hair

0.926064

0.903045

0.950287

0.950287

gender

0.811982

0.813721

0.814532

0.814532

earring

0.743495

0.720011

0.813576

0.813576

smile

0.573169

0.573085

0.614723

0.614723

frontal\_face

0.758024

0.694976

0.833652

0.833652

hair\_color

0.358576

0.339481

0.419694

0.419694

style

0.842575

0.942995

0.803059

0.803059

**average**

**0.751736**

**0.748414**

**0.78119**

**0.78119**

### DenseNet121

**模型结构参数**

![](https://img2022.cnblogs.com/blog/2355982/202206/2355982-20220624105440482-1450380459.png)

**训练参数**

batch

64

**epoch**

20

**optimizer (优化器)**

SGD(随机梯度下降)

**criterion (损失函数)**

BCELoss(二分类交叉熵损失)

**学习率**

0.01

**photo数据集上模型训练Loss**

![](https://img2022.cnblogs.com/blog/2355982/202206/2355982-20220624105453644-641461246.png)

**photo数据集结果** **「方法四」**

f1

precision

recall

accuracy

hair

0.926064

0.903045

0.950287

0.950287

gender

0.935669

0.936043

0.935946

0.935946

earring

0.837358

0.837194

0.853728

0.853728

smile

0.784984

0.787445

0.790631

0.790631

frontal\_face

0.780436

0.832682

0.8413

0.8413

hair\_color

0.685242

0.665904

0.718929

0.718929

style

0.515421

0.567896

0.497132

0.497132

**avg**

**0.808147**

**0.816276**

**0.823494**

**0.823494**

**Sketch数据集上模型训练Loss**

![](https://img2022.cnblogs.com/blog/2355982/202206/2355982-20220624105506345-1143551266.png)

**sketch数据集结果** **「方法五」**

f1

precision

recall

accuracy

hair

0.926064

0.903045

0.950287

0.950287

gender

0.883773

0.886639

0.885277

0.885277

earring

0.743196

0.734733

0.819312

0.819312

smile

0.610952

0.661847

0.671128

0.671128

frontal\_face

0.758024

0.694976

0.833652

0.833652

hair\_color

0.372596

0.360252

0.423518

0.423518

style

0.944535

0.96071

0.938815

0.938815

**avg**

**0.779892**

**0.775275**

**0.815249**

**0.815249**