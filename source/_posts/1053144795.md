---
layout: post
title: "Flink集群部署"
date: "2022-10-31T19:16:35.644Z"
---
Flink集群部署
=========

集群 standalone 安装部署
------------------

1.  下载安装包

下载页面：[https://archive.apache.org/dist/flink/flink-1.7.2/](https://archive.apache.org/dist/flink/flink-1.7.2/)

我这里安装的 flink-1.7.2-bin-hadoop27-scala\_2.11.tgz 版本。

2.  修改配置文件 conf/flink-conf.yaml

修改如下两个参数：

    #填你机器的host名
    jobmanager.rpc.address: linux2
    taskmanager.numberOfTaskSlots: 2
    

3.  修改配置文件/conf/slave

    linux2
    linux3
    linux4
    

4.  将文件发送到其他两个机器

    scp -r flink-1.7.2 linux3:/opt/lagou/servers/
    scp -r flink-1.7.2 linux4:/opt/lagou/servers/
    

5.  给每台机器配置环境变量

vim /etc/profile

    export FLINK_HOME=/opt/lagou/servers/flink-1.7.2
    export PATH=$PATH:$FLINK_HOME/bin
    

配置完成后使配置文件生效

    source /etc/profile
    

6.  进入 bin 目录，启动集群

    ./start-cluster.sh
    

![](https://img2022.cnblogs.com/blog/1178991/202210/1178991-20221028232847115-1187368945.png)

启动完后我们可以输入网址http://linux2:8081/，验证  
![](https://img2022.cnblogs.com/blog/1178991/202210/1178991-20221028234800346-1334457480.png)

至此，安装完毕。

然后我们将程序放入集群环境测试。首先需要先打 jar 包，需要注意将依赖也打进去，打包插件如下：

    <build>
            <plugins>
                <!-- 打jar插件 -->
                <plugin>
                    <groupId>org.apache.maven.plugins</groupId>
                    <artifactId>maven-shade-plugin</artifactId>
                    <version>2.4.3</version>
                    <executions>
                        <execution>
                            <phase>package</phase>
                            <goals>
                                <goal>shade</goal>
                            </goals>
                            <configuration>
                                <filters>
                                    <filter>
                                        <artifact>*:*</artifact>
                                        <excludes>
                                            <exclude>META-INF/*.SF</exclude>
                                            <exclude>META-INF/*.DSA</exclude>
                                            <exclude>META-INF/*.RSA</exclude>
                                        </excludes>
                                    </filter>
                                </filters>
                            </configuration>
                        </execution>
                    </executions>
                </plugin>
    
            </plugins>
        </build>
    

1.  打包完成后，将 jar 包上传  
    ![](https://img2022.cnblogs.com/blog/1178991/202210/1178991-20221028234608521-1432805712.png)
    
2.  选中上传的 jar 包，填入我们 main 方法的全类名，参数等等。然后点击 submit 提交任务。
    
3.  我们可以先使用 nc 工具向程序输入数据 nc -lk 7000  
    ![](https://img2022.cnblogs.com/blog/1178991/202210/1178991-20221028235248123-2016608535.png)
    

查看日志的输出  
![](https://img2022.cnblogs.com/blog/1178991/202210/1178991-20221028235338105-1557959422.png)

Yarn 模式集群部署
-----------

1.  配置 yarn-site.xml 文件，增加如下配置：

    <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
      <property>
        <name>yarn.resourcemanager.address</name>
        <value>linux2:8032</value>
      </property>
      <property>
        <name>yarn.resourcemanager.scheduler.address</name>
        <value>linux2:8030</value>
      </property>
      <property>
        <name>yarn.resourcemanager.resource-tracker.address</name>
        <value>linux2:8031</value>
      </property>
    

2.  启动 hdfs

    start-dfs.sh
    

3.  启动 yarn

    start-yarn.sh
    

4.  进入到 flink 的 bin 目录

    # -n 2代表2个task manager，tm 800代表内存800m，-s 1代表一个slots，-d代表后台运行
    yarn-session.sh -n 2 -tm 800 -s 1 -d
    

5.  在 yarn 上提交 flink 作业

方式一：

    ./flink run -c com.mmc.flink.WordCountStream /export/servers/flink/examples/batch/WordCount.jar
    

方式二：

    # -m jobmanager的地址
    # -yn 表示TaskManager的个数
    ./flink run -m yarn-cluster -yn 2 -yjm 1024 -ytm 1024 /export/servers/flink/examples/batch/WordCount.jar
    

6.  关闭任务

    # 找到yarn任务的id，通过命令杀掉
    yarn application -kill application_1527077715040_0003
    

书山有路勤为径，学海无涯苦作舟