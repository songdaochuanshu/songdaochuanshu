---
layout: post
title: "HDFS 高可用分布式环境搭建"
date: "2022-09-07T16:28:26.418Z"
---
HDFS 高可用分布式环境搭建
===============

HDFS 高可用分布式环境搭建
===============

作者：[Grey](https://www.cnblogs.com/greyzeng/)

原文地址：

[博客园：HDFS 高可用分布式环境搭建](https://www.cnblogs.com/greyzeng/p/16667349.html)

[CSDN：HDFS 高可用分布式环境搭建](http://t.csdn.cn/uXvCX)

首先，一定要先完成[分布式环境搭建](https://www.cnblogs.com/greyzeng/p/16663406.html) 并验证成功

然后在 node01 上执行`stop-dfs.sh`

重新规划每个节点的职责

host

NN

JNN

DN

ZKFC

ZK

node01

√

√

√

node02

√

√

√

√

√

node03

√

√

√

node04

√

√

修改`node01~node04`节点上的配置文件

    vi $HADOOP_HOME/etc/hadoop/core-site.xml
    

将`<configuration></configuration>`内的配置信息修改为：

    <property>
    
    ​    <name>fs.defaultFS</name>    
    
    ​    <value>hdfs://mycluster</value>
    
    </property>
    
    <property>
    
    ​    <name>ha.zookeeper.quorum</name>
    
    ​    <value>node02:2181,node03:2181,node04:2181</value>
    
    </property>
    

然后修改`node01~node04`上的如下配置文件

执行`vi $HADOOP_HOME/etc/hadoop/hdfs-site.xml`

将`<configuration></configuration>`内的配置信息修改为：

    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/var/bigdata/hadoop/ha/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
    ​    <value>/var/bigdata/hadoop/ha/dfs/data</value>
    </property>
    <!-- 以下是 一对多，逻辑到物理节点的映射 -->
    <property>
        <name>dfs.nameservices</name>
        <value>mycluster</value>
    </property>
    <property>
        <name>dfs.ha.namenodes.mycluster</name>
        <value>nn1,nn2</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.mycluster.nn1</name>
        <value>node01:8020</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.mycluster.nn2</name>
        <value>node02:8020</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.mycluster.nn1</name>
        <value>node01:50070</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.mycluster.nn2</name>
        <value>node02:50070</value>
    </property>
    <!-- 以下是JN在哪里启动，数据存那个磁盘 -->
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://node01:8485;node02:8485;node03:8485/mycluster</value>
    </property>
    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/var/bigdata/hadoop/ha/dfs/jn</value>
    </property>
    <!-- HA角色切换的代理类和实现方法，我们用的ssh免密 -->
    <property>
        <name>dfs.client.failover.proxy.provider.mycluster</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>sshfence</value>
    </property>
    <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/root/.ssh/id_dsa</value>
    </property>
    <!-- 开启自动化： 启动zkfc： -->
    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>
    

安装 zookeeper

zookeeper [下载地址](https://archive.apache.org/dist/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz)

将`zookeeper`安装包上传到 node02，node03，node04 的`/opt/bigdata`目录下

在 node02 , node03 , node04 下执行`cd /opt/bigdata`

解压`tar xf zookeeper-3.4.6.tar.gz`

重命名`mv zookeeper-3.4.6 zookeeper`

修改 node02 ，node03 ，node04 上的 zookeeper 配置文件：

首先`cd /opt/bigdata/zookeeper/conf/`

执行`cp zoo_sample.cfg zoo.cfg`

执行`vi zoo.cfg`

配置如下配置项

修改如下配置`dataDir=/var/bigdata/hadoop/zk`

新增如下配置：

    server.1=node02:2888:3888
    server.2=node03:2888:3888
    server.3=node04:2888:3888
    

保存

然后在 node02 上，执行：

    mkdir /var/bigdata/hadoop/zk
    
    echo 1 > /var/bigdata/hadoop/zk/myid
    

在 node03 上，执行：

    mkdir /var/bigdata/hadoop/zk
    
    echo 2 > /var/bigdata/hadoop/zk/myid
    

在 node04 上，执行：

    mkdir /var/bigdata/hadoop/zk
    
    echo 3 > /var/bigdata/hadoop/zk/myid
    

在 node02，node03，node04 下配置环境变量

执行`vi /etc/profile`

新增如下配置

    export ZOOKEEPER_HOME=/opt/bigdata/zookeeper
    

追加到 PATH 中

    export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$ZOOKEEPER_HOME/bin
    

执行`source /etc/profile`

启动顺序：

在 node02，node03，node04 上分别启动 zookeeper

执行`zkServer.sh start`

在 node01，node02，node03 上分别启动 journalnode

执行`hadoop-daemon.sh start journalnode`

选择一个 NN 做格式化，注：**只有第一次搭建做，以后不用做**

我们选择 node02，在 node02 上执行`hdfs namenode -format`

启动这个格式化的 NN ，以备另外一台同步

在 node02 上执行`hadoop-daemon.sh start namenode`

格式化 zk, 注：**只有第一次搭建做，以后不用做**

在 node01 上执行`hdfs zkfc -formatZK`

验证 zk 是否格式化成功，在 node04 上执行`zkCli.sh`

打开 zk 客户端

执行`ls /`  
输出

    [zookeeper, hadoop-ha]
    

显示了新建的 hadoop-ha 目录，验证成功

在 node01 上执行`start-dfs.sh`

启动成功

测试，在 node01 上，执行如下命令，

    hdfs dfs -mkdir /bigdata
    
    hdfs dfs -mkdir -p /user/root
    
    hdfs dfs -put hadoop-2.6.5.tar.gz /user/root
    

打开浏览器

通过：[http://node01:50070/explorer.html#/user/root](http://node01:50070/explorer.html#/user/root)\>

可以看到上传的文件

接下来，我们切换我们用 root 搭建的HDFS 用 god 这个用户来启动

首先，停止 hdfs

在 node01 上，执行`stop-dfs.sh`

在`node01~node04`上都执行：

添加用户`useradd god`

修改密码`passwd god`

密码可以自定义。

将资源和用户绑定：

    chown -R god /opt/bigdata/hadoop
    
    chown -R god /var/bigdata/hadoop
    

将`node01~node04`都切换成 god 用户，在`node01~node04`上都执行`su god`

使用 god 用户执行如下命令`ssh localhost`

分别输入 yes 以及 god 的密码

在`node01~node04`上

执行：

    cd /home/god/.ssh
    
    ssh-keygen -t dsa -P '' -f ./id_dsa
    

然后在`node01~node04`上执行如下四条语句（每个节点都要执行这四条语句）

    ssh-copy-id -i id_dsa node01
    
    输入yes，god密码
    
    ssh-copy-id -i id_dsa node02
    
    输入yes，god密码
    
    ssh-copy-id -i id_dsa node03
    
    输入yes，god密码
    
    ssh-copy-id -i id_dsa node04
    
    输入yes，god密码
    

修改 node01~node04 中 hdfs-site.xml 的配置

在 node01~node04 上执行`vi $HADOOP_HOME/etc/hadoop/hdfs-site.xml`

将如下配置：

    <property>
    ​    <name>dfs.ha.fencing.ssh.private-key-files</name>
    ​    <value>/root/.ssh/id_dsa</value>
    </property>
    

修改为：

    <property>
    ​    <name>dfs.ha.fencing.ssh.private-key-files</name>
    ​    <value>/home/god/.ssh/id_dsa</value>
    </property>
    

完成如上配置，就可以使用 god 用户启动 hdfs 了

在 node01 上，使用 god 用户执行`start-dfs.sh`

验证：

在 node01 上执行：

    su god
    
    hdfs dfs -mkdir  /temp
    
    hdfs dfs -chown god:ooxx /temp
    
    hdfs dfs -chmod 775 /temp
    

查看控制台：

[http://node01:50070/explorer.html#/](http://node01:50070/explorer.html#/)

目录创建成功

**Permission**

**Owner**

**Group**

**Size**

**Replication**

**Block Size**

**Name**

drwxrwx---

god

ooxx

0 B

0

0 B

temp

且组 ooxx 拥有所有权限

我们再新建一个用户 good ，并且将 good 加入 ooxx 这个组，good 这个用户就可以正常上传文件到`/temp`目录下了

在 node01 上执行：

    su root
    
    useradd good
    
    passwd good
    

设置good的密码。

然后添加组：

    groupadd ooxx
    

将 good 这个用户添加进入 ooxx 这个组

    usermod -a -G ooxx good
    

然后执行：

    su god
    

在 god 用户下执行：

    hdfs dfsadmin -refreshUserToGroupsMappings
    

然后切换 good 用户

    su good
    
    cd /home/good
    
    touch good.txt
    

然后执行：

    vi good.txt
    

随意输入一些内容，保存

最后执行

    hdfs dfs -put good.txt /temp
    

更新成功。

本文来自博客园，作者：[Grey Zeng](https://www.cnblogs.com/greyzeng/)，转载请注明原文链接：[https://www.cnblogs.com/greyzeng/p/16667349.html](https://www.cnblogs.com/greyzeng/p/16667349.html)