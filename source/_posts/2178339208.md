---
layout: post
title: "【深入浅出 Yarn 架构与实现】2-1 Yarn 基础库概述"
date: "2022-11-08T21:17:53.935Z"
---
【深入浅出 Yarn 架构与实现】2-1 Yarn 基础库概述
===============================

了解 Yarn 基础库是后面阅读 Yarn 源码的基础，本节对 Yarn 基础库做总体的介绍。  
并对其中使用的第三方库 Protocol Buffers 和 Avro 是什么、怎么用做简要的介绍。

一、主要使用的库
--------

*   **Protocol Buffers**：是 Google 开源的序列化库，具有平台无关、高性能、兼容性好等优点。YARN 将其用到了 RPC 通信中，默认情况 下，YARN RPC 中所有参数采用 Protocol Buffers 进行序列化 / 反序列化。
*   **Apache Avro**：是 Hadoop 生态系统中的 RPC 框架，具有平台无关、支持动态模式(无需编译)等优点，Avro 的最初设计动机是解决 YARN RPC 兼容性和扩展性 差等问题。
*   **RPC 库**：YARN 仍采用了 MRv1 中的 RPC 库，但其中采用的默认序列化方法被替换成了 Protocol Buffers。
*   **服务库和事件库** :YARN 将所有的对象服务化，以便统一管理(比创建、销毁等)， 而服务之间则采用事件机制进行通信，不再使用类似 MRv1 中基于函数调用的方式。
*   **状态机库**：YARN 采用有限状态机描述一些对象的状态以及状态之间的转移。引入状态机模型后，相比 MRv1， YARN 的代码结构更加清晰易懂。

二、第三方开源库介绍
----------

### 一）**Protocol Buffers**

#### 1、简要介绍

Protocol Buffers 是 Google 开源的一个语言无关、平台无关的通信协议，其小巧、高效和友好的兼容性设计，使其被广泛使用。  
【可以类比 java 自带的 Serializable 库，功能上是一样的。】

> Protocol buffers are Google’s language-neutral, platform-neutral, extensible mechanism for serializing structured data – think XML, but smaller, faster, and simpler. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages.

**核心特点：**

*   语言、平台无关
*   简洁
*   高性能
*   兼容性好

#### 2、安装环境

以 mac 为例（其他平台方式请自查）

    # 1) brew安装
    brew install protobuf 
    
    # 查看安装目录
    $ which protoc 
    /opt/homebrew/bin/protoc 
    
    
    # 2) 配置环境变量
    vim ~/.zshrc
    
    # protoc (for hadoop)
    export PROTOC="/opt/homebrew/bin/protoc"
    
    source ~/.zshrc
    
    
    # 3) 查看protobuf版本
    $ protoc --version
    libprotoc 3.19.1
    

#### 3、写个 demo

1）创建个 maven 工程，添加依赖

    <dependencies>
      <dependency>
        <groupId>com.google.protobuf</groupId>
        <artifactId>protobuf-java</artifactId>
        <version>3.19.1</version>  <!--版本号务必和安装的protoc版本一致-->
      </dependency>
    </dependencies>
    

2）根目录新建 protobuf 的消息定义文件 `student.proto`

> proto 数据类型语法定义可以参考：[ProtoBuf 入门教程](https://www.tizi365.com/archives/367.html)

    syntax = "proto3"; // 声明为protobuf 3定义文件
    package tutorial;
    
    option java_package = "com.shuofxz.learning.student";	// 生成文件的包名
    option java_outer_classname = "StudentProtos";				// 类名
    
    message Student {								// 待描述的结构化数据
        string name = 1;
        int32 id = 2;
        optional string email = 3;	//optional 表示该字段可以为空
    
        message PhoneNumber {				// 嵌套结构
            string number = 1;
            optional int32 type = 2;
        }
    
        repeated PhoneNumber phone = 4;	// 重复字段
    }
    

3）使用 `protoc` 工具生成消息对应的Java类（在 proto 文件目录执行）

    protoc -I=. --java_out=src/main/java student.proto
    

可以在对应的文件夹下找到 `StudentProtos.java` 类，里面写了序列化、反序列化等方法。  
![image.png](https://img2022.cnblogs.com/blog/1324217/202211/1324217-20221108183858610-1530093882.png)

    public class StudentExample {
        static public void main(String[] argv) {
            StudentProtos.Student Student1 = StudentProtos.Student.newBuilder()
                    .setName("San Zhang")
                    .setEmail("zhangsan@yahoo.com")
                    .setId(11111)
                    .addPhone(StudentProtos.Student.PhoneNumber.newBuilder()
                            .setNumber("13911231231")
                            .setType(0))
                    .addPhone(StudentProtos.Student.PhoneNumber.newBuilder()
                            .setNumber("01082345678")
                            .setType(1)).build();
    
            // 写出到文件
            try {
                FileOutputStream output = new FileOutputStream("example.txt");
                Student1.writeTo(output);
                output.close();
            } catch(Exception e) {
                System.out.println("Write Error ! ");
            }
    
            // 从文件读取
            try {
                FileInputStream input = new FileInputStream("example.txt");
                StudentProtos.Student Student2 = StudentProtos.Student.parseFrom(input);
                System.out.println("Student2:" + Student2);
            } catch(Exception e) {
                System.out.println("Read Error!");
            }
        }
    }
    

以上就是一个 protocol buffers 使用的完整流程了。没什么难的，就是调用了一个第三方的序列化库，将对象序列化到文件，再反序列化读出来。  
只不过需要先在 proto 文件中定义好数据结构，并生成对应的工具类。

#### 4、在 Yarn 中应用

在 YARN 中，所有 RPC 函数的参数均采用 Protocol Buffers 定义的。RPC 仍使用 MRv1 中的 RPC。

### 二）**Apache Avro**

#### 1、简要介绍

Apache Avro 是 Hadoop 下的一个子项目。它本身既是一个序列化框架，同时也实现 了 RPC 的功能。  
但由于 Yarn 项目初期，Avro 还不成熟，Avro 则作为日志序列化库使用，所有事件的序列化均采用 Avro 完成。  
**特点：**

*   丰富的数据结构类型;
*   快速可压缩的二进制数据形式;
*   存储持久数据的文件容器;
*   提供远程过程调用 RPC;
*   简单的动态语言结合功能。

相比于 Apache Thrift 和 Google 的 Protocol Buffers，Apache Avro 具有以下特点:

*   支持动态模式。Avro 不需要生成代码，这有利于搭建通用的数据处理系统，同时避免了代码入侵。
*   数据无须加标签。读取数据前，Avro 能够获取模式定义，这使得 Avro 在数据编码时只需要保留更少的类型信息，有利于减少序列化后的数据大小。
*   无须手工分配的域标识。Thrift 和 Protocol Buffers 使用一个用户添加的整型域唯一性定义一个字段，而 Avro 则直接使用域名，该方法更加直观、更加易扩展。

#### 2、安装环境 & demo

> 参考：[Avro学习入门](https://juejin.cn/post/6899314424083906568#heading-0)

#### 3、在 Yarn 中应用

Apache Avro 最初是为 Hadoop 量身打造的 RPC 框架，考虑到稳定性，YARN 暂时采用 Protocol Buffers 作为序列化库，RPC 仍使用 MRv1 中的 RPC，而 Avro 则作为日志序列化库使用。在 YARN MapReduce 中，所有事件的序列化 / 反序列化均采用 Avro 完成，相关定义在 Events.avpr 文件中。

三、总结
----

本节简要介绍了 Yarn 中五个重要的基础库，了解这些库会帮助了解 Yarn 代码逻辑和数据传递方式。  
对其中两个第三方开源库进行了介绍。Protocol Buffers 用作 RPC 函数参数的序列化和反序列化；Avro 在日志和事件部分的序列化库使用。