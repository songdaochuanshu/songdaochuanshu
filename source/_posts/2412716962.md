---
layout: post
title: "PGL图学习之图神经网络ERNIESage、UniMP进阶模型[系列八]"
date: "2022-11-26T03:23:47.814Z"
---
PGL图学习之图神经网络ERNIESage、UniMP进阶模型\[系列八\]
======================================

通过以上两个版本的模型代码简单的讲解，可以知道他们的不同点，其实主要就是在消息传递机制的部分有所不同。ERNIESageV1版本只作用在text graph的节点上，在传递消息(Send阶段)时只考虑了邻居本身的文本信息；而ERNIESageV2版本则作用在了边上，在Send阶段同时考虑了当前节点和其邻居节点的文本信息，达到更好的交互效果。 为了实现可扩展的，健壮的和可重现的图学习研究，提出了Open Graph Benchmark (OGB)——具有规模大、领域广、任务类别多样化的现实图数据集。在特定于应用程序的使用案例的驱动下，对给定的数据集采用了实际的数据分割方法。通过广泛的基准实验，强调OGB数据集对于图学习模型在现实的数据分割方案下处理大规模图并进行准确的预测提出了重大挑战。总而言之，OGB为未来的研究提供了丰富的机会，以推动图学习的前沿。

PGL图学习之图神经网络ERNIESage、UniMP进阶模型\[系列八\]
======================================

原项目链接：fork一下即可：[https://aistudio.baidu.com/aistudio/projectdetail/5096910?contributionType=1](https://aistudio.baidu.com/aistudio/projectdetail/5096910?contributionType=1)

相关项目参考：（其余图神经网络相关项目见主页）

关于图计算&图学习的基础知识概览：前置知识点学习（PGL）\[系列一\] [https://aistudio.baidu.com/aistudio/projectdetail/4982973?contributionType=1](https://aistudio.baidu.com/aistudio/projectdetail/4982973?contributionType=1)

图机器学习(GML)&图神经网络(GNN)原理和代码实现(前置学习系列二）：[https://aistudio.baidu.com/aistudio/projectdetail/4990947?contributionType=1](https://aistudio.baidu.com/aistudio/projectdetail/4990947?contributionType=1)

图学习【参考资料1】词向量word2vec [https://aistudio.baidu.com/aistudio/projectdetail/5009409?contributionType=1](https://aistudio.baidu.com/aistudio/projectdetail/5009409?contributionType=1)

图学习【参考资料2】-知识补充与node2vec代码注解 [https://aistudio.baidu.com/aistudio/projectdetail/5012408?contributionType=1](https://aistudio.baidu.com/aistudio/projectdetail/5012408?contributionType=1)

1.Open Graph Benchmark（OGB）
===========================

![](https://s2.51cto.com/images/blog/202211/25203528_6380b690980f951552.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

1.1 OGB概述
---------

如何进一步推进图学习的研究呢？从历史上看，高质量和大规模的数据集在推进研究中发挥了重要的作用，例如**计算机视觉领域的IMAGENET、MS COCO，自然语言处理领域的GLUE BENCHMARK、SQUAD，语言处理领域的LIBRISPEECH、CHIME等**。但是，当前在图学习研究中常用的数据集和评估程序可能会对未来的发展产生负面影响。

**当前基准数据集存在的问题：**

与实际应用中的图相比，大多数常用数据集都非常小。例如广泛使用的**Cora、Citeseer、Pubmed数据集，在节点分类任务中只用2700至20000个节点**。由于在这些小型数据集上广泛开发了模型，因此大多数模型都无法扩展到较大的图；其次，较小的数据集很难去严格地评估需要大量数据的模型，例如图神经网络（GNNs）。  
没有统一且通常遵循的实验协议。不同的研究采用自己的数据集划分、评估指标和交叉验证协议，因此比较各种研究报告的成绩具有挑战性。另外，许多研究使用随机分割来生成train /test sets，这对于真实世界的应用是不现实的或无用的，并且通常导致过于乐观的性能结果。  
因此，迫切需要一套完整的现实世界基准测试套件，该套件将来自不同领域的各种大小的数据集组合在一起。数据拆分以及评估指标很重要，因此可以以一致且可重复的方式衡量进度。最后，基准测试还需要提供不同类型的任务，例如节点分类，链接预测和图分类。OGB就这样应运而生。

开放图谱基准 (OGB) 是图机器学习的基准数据集、数据加载器和评估器的集合。数据集涵盖各种图形机器学习任务和实际应用。OGB旨在提供涵盖重要图机器学习任务、多样化数据集规模和丰富领域的图数据集。

论文链接：[https://arxiv.org/abs/2005.00687](https://arxiv.org/abs/2005.00687)  
OGB官网：[https://ogb.stanford.edu/](https://ogb.stanford.edu/)  
GitHub地址：[https://github.com/snap-stanford/ogb](https://github.com/snap-stanford/ogb)

![](https://s2.51cto.com/images/blog/202211/25203528_6380b6909746d97587.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

*   Graph ML Tasks: 涵盖了三个基本的图机器学习任务：节点属性预测，链接属性预测，图属性预测。
    
*   Diverse scale: 小型图形数据集可以在单个 GPU 中处理，而中型和大型图形可能需要多个 GPU 或巧妙的采样/分区技术。分为small、medium、large三个规模，具体为small：超过10万个节点和超过100万条边；medium：超过100万个节点或超过1000万条边；large：大约1亿个节点或10亿条边。
    
*   Rich domains: 图数据集来自从科学领域到社会/信息网络的不同领域，还包括异构知识图谱。nature：包含生物网络和分子图；society：包含学术图和电子商务网络；information：包含知识图谱等。
    

看一下 OGB 现在包含的数据集和数据集的统计明细：

![](https://s2.51cto.com/images/blog/202211/25203528_6380b690a471c49728.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

![](https://s2.51cto.com/images/blog/202211/25203528_6380b690a763a10589.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

1.2 OGB数据集简介
------------

### 1.2.1 OGB节点属性预测

**ogbn-products：亚马逊产品共同购买网络。**

*   节点代表在Amazon销售的产品，两个产品之间的边表示产品是一起购买的。节点特征是通过从产品描述中提取词袋特征来生成的，然后进行主成分分析将维度减小到100。
*   预测任务：在多类别分类设置中预测产品的类别，其中有47个顶级类别用于目标标签。
*   数据集划分：使用销售排名（受欢迎程度）将节点划分为训练/验证/测试集，根据产品的销售排名对产品进行排序，并使用前10％作为训练集，然后使用前2％作为验证集，其余用于测试集。

**ogbn-proteins：蛋白质关联网络**

*   节点代表蛋白质，边表示蛋白质之间不同类型的有生物学意义的联系。所有的边都具有8维特征，其中每个维度表示单个关联类型的强度，值在0到1之间。这些蛋白质来自8个物种。
*   预测任务：在一个多标签二元分类系统中预测蛋白质功能的存在，该系统中总共有112种标签需要预测。通过112个任务的ROC-AUC分数的平均值来衡量性能。
*   数据集分割：根据蛋白质来源的物种，将蛋白质节点分成训练/验证/测试集。

实验中为了简单起见，使用传入边的平均边缘特征作为节点特征。

**ogbn-arxiv：论文引用网络**

*   每个节点都是一篇Arxiv论文，每条有向边表示一篇论文引用了另一篇论文。每篇论文都有一个128维的特征向量，它是通过对标题和摘要中单词的嵌入进行平均得到的。
*   预测任务：预测Arxiv论文的主要类别，这是一个40类的分类问题。
*   数据集分割：考虑一个基于论文发表日期的现实数据分割。建议将2017年及以前发表的论文作为训练集，将2018年发表的论文作为验证集，将2019年以后发表的论文作为测试集。

实验中为了简单起见，将有向图转换为无向图。从下面的结果可以看出，探索如何考虑边缘方向信息以及节点时间信息（例如论文发表的年份）以提高预测性能将是富有成效的。

**ogbn-papers100M：论文引用网络**

*   MAG（Microsoft Academic Graph）索引的1.11亿篇论文的有向引文图。此数据集的数量级比任何现有的节点分类数据集大。
*   预测任务：预测在Arxiv中发表的论文的子集的主题领域。有172个Arxiv主题领域，这使预测任务成为172类分类问题。
*   数据集分割：考虑一个基于论文发表日期的现实数据分割。建议将2017年及以前发表的论文作为训练集，将2018年发表的论文作为验证集，将2019年以后发表的论文作为测试集。

实验中为了简单起见，将有向图转换为无向图。从下面的结果可以看出，SGC严重拟合不足，表明使用更具表现力的GNNs可能会同时改善训练和测试准确性。

**ogbn-mag：异构微软学术图(MAG)**

*   由Microsoft Academic Graph (MAG)的一个子集组成的异构网络。它包含四种类型的实体（论文、作者、机构和研究领域），以及连接两种类型实体的四种有向关系。每一篇论文具有128维的特征。
*   预测任务：根据给定的内容、参考文献、作者和作者的隶属关系来预测每篇论文的会议地点。ogbn-mag中共有349个不同的会议地点，这使得该任务成为349类分类问题。
*   数据集分割：遵循相同的基于时间的策略。用2018年之前发表的所有论文的训练模型，并用2018年和2019年以后发表的论文分别验证和测试模型。

对于GCN和GRAPHSAGE，实验中在同构子图上应用模型。从下面的结果可以看出吗，利用图的异构性质对于在这个数据集上取得良好的性能是至关重要的。

### 1.2.2 OGB链接属性预测

**ogbl-ppa：蛋白质关联网络**

*   节点表示来自58个不同物种的蛋白质，边表示蛋白质之间的生物学上有意义的关联。每个节点都包含一个58维的one-hot特征向量，该向量指示相应蛋白质所来自的物种。
*   预测任务：在给定训练边的情况下预测新的关联边。评估基于模型对positive测试边胜过negative测试边的等级。具体来说，针对3,000,000个随机采样的negative边对验证/测试集中的每个positive边进行排名，并计算排名在第K位或更高（Hits@K）的positive边的比率。发现K=100是评估模型性能的一个很好的阈值。
*   数据集分割：根据边的生物学吞吐量分为训练/验证/测试边。

实验结果如下所示，GNN训练效果不佳表明，仅靠GNN无法捕获的位置信息对于适应训练边并获得有意义的节点嵌入可能至关重要。

**ogbl-collab：作者合作网络**

*   每个节点代表一个作者，边表示作者之间的合作。 所有节点都具有128维特征，这些特征是通过平均作者发表的论文的词嵌入获得的。所有边都与两种类型的元信息相关联：年份和边缘权重，代表当年发表的合作论文的数量。
*   预测任务：根据给定的过去合作来预测未来的作者合作关系。评估指标类似于ogbl-ppa，希望该模型将真实协作的等级高于虚假协作。 具体来说，在100,000个随机采样的negative协作中对每个真实协作进行排名，并计算排名在K位或更高（Hits@K）的positive边的比率。在初步实验中，发现K=50是一个很好的阈值。
*   数据集分割：根据时间拆分数据，以便在协作推荐中模拟实际应用。具体来说，将直到2017年的合作作为训练边，将2018年的合作作为验证边，并将2019年的合作作为测试边。

实验结果如下图，值得注意的是，MATRIXFACTORIZATION可以达到近乎完美的训练结果，但是即使应用大量的正则化处理，也无法将良好的结果转移到验证和测试拆分中。总体而言，探索将位置信息注入GNN并开发更好的正则化方法是富有成果的。

**ogbl-ddi：药品交互网络**

*   节点代表FDA批准的或实验药物，边代表药物之间的相互作用，并且可以解释为一种现象，其中将两种药物合用的联合效果与预期的药物彼此独立起作用的效果有很大不同。
*   预测任务：在已知药物相互作用的基础上预测药物相互作用。评估指标与ogbl-collab相似，希望该模型将真实药物相互作用的排名高于非相互作用药物对。具体来说，在大约100,000个随机采样的negative药物相互作用中对每个真实药物相互作用进行排名，并计算在K位或更高（Hits@K）处排名的positive边缘的比率。在初步实验中，发现K = 20是一个很好的阈值。
*   数据集分割：开发了一种蛋白质-靶标拆分，这意味着根据那些药物在体内靶向的蛋白质来拆分药物边缘。

实验结果如下所示，有趣的是，GNN模型和MATRIXFACTORIZATION方法都比NODE2 VEC获得了明显更高的训练结果。但是，只有GNN模型才能在某种程度上将这种性能传递给测试集，这表明关系信息对于使模型推广到看不见的交互作用至关重要。

**ogbl-citation：论文引用网络**

*   从MAG提取的论文子集之间的引文网络，与ogbn-arxiv相似，每个节点都是具有128维WORD2VEC特征的论文，该论文总结了其标题和摘要，并且每个有向边都表示一篇论文引用了另一篇论文。所有节点还带有表示相应论文发表年份的元信息。
*   预测任务：根据给定的现有引用来预测缺少的引用。具体来说，对于每篇原始论文，将随机删除其两个参考文献，并且希望模型将缺失的两个参考文献的排名高于1,000个negative参考候选集。negetive引用是从源论文未引用的所有先前论文中随机抽取的。评估指标是Mean Reciprocal Rank（MRR），其中针对每份原始论文计算真实参考文献在negative候选者中的互惠等级，然后取所有原始论文的平均值。
*   数据集分割：为了模拟引文推荐中的实际应用，会根据时间划分边缘（例如，用户正在撰写一篇新论文，并且已经引用了几篇现有论文，但希望被推荐为其他参考）。为此，使用最新论文（2019年发表）作为要推荐参考文献的原始论文。对于每篇原始论文，从参考文献中删除两篇——所得到的两个下降边（从原始论文指向删除的论文）指向分别用于验证和测试。 其余所有边缘均用于训练。

从下面的实验结果可以看出，mini-batch技术的性能要比full-batch差，这与节点分类数据集（例如ogbn-products和ogbn-mag）相反，基于小批量的模型有更强的泛化性能。与用于节点预测的技术不同，这种限制为将小批处理技术应用于链接预测提出了一个独特的挑战。

**ogbl-wikikg：Wikidata知识图**

*   从Wikidata知识库中提取的知识图（KG）。它包含一组三元组边缘（头部、关系、尾部）其捕获了世界各实体之间的不同类型的关系。检索了Wikidata中的所有关系语句，并过滤掉稀有实体。该KG中包含了2,500,604个实体和535个关系类型。
*   预测任务：在给定训练边缘的情况下预测新的三元组边缘。评估指标遵循KG中广泛使用的标准过滤指标。具体来说，通过用随机采样的1,000个negative实体（头部为500个，尾部为500个）替换其头部或尾部来破坏每个测试三元组边缘，同时确保生成的三元组不会出现在KG中。目标是将真实的头部（或尾部）实体排名高于negative实体，该排名由平均互惠排名（MRR）衡量。
*   数据集分割：根据时间划分三元组，模拟一个现实的KG完成方案，该方案旨在填充在某个时间戳上不存在的缺失三元组。具体来说，在三个不同的时间戳17（2015年5月，8月和11月）下载了Wikidata，并构建了三个KG，其中仅保留最早出现在5月KG中的实体和关系类型。使用五月 KG中的三元组进行训练，并使用八月和11月KG中的三元组分别进行验证和测试。

实验结果如下表所示，从表的上半部分可以看到，当使用有限的嵌入维数时，COMPLEX在四个基线中表现最佳。从表的下半部分可以看出，随着维数的增加，所有四个模型都能够在训练、验证和测试集上实现更高的MRR。这表明使用足够大的嵌入维数在此数据集中实现良好性能的重要性。

**ogbl-biokg：生物医学知识图**

*   是一个知识图（KG），使用了大量生物医学数据库中的数据创建了该图。它包含5种类型的实体：疾病（10,687个节点）、蛋白质（17,499个节点）、药物（10,533个节点）、副作用（9,969个节点）和蛋白质功能（45,085个节点）。有51种类型的有向关系将两种类型的实体联系起来，包括39种药物相互作用，8种蛋白质相互作用等 。所有关系都被建模为有向边，其中连接相同实体类型（例如蛋白质-蛋白质，药物-药物，功能-功能）的关系始终是对称的，即边是双向的。KG中的三元组来自具有各种置信度级别的来源，包括实验读数，人工策划的注释以及自动提取的元数据。
*   预测任务：在给定训练三元组的情况下预测新的三元组。评估协议ogbl-wikikg完全相同，这里只考虑针对相同类型的实体进行排名。例如，当破坏蛋白质类型的头部实体时，仅考虑negative蛋白质实体。
*   数据集分割：对于此数据集，采用随机分割。虽然根据时间划分三元组是一种有吸引力的选择，但注意到，要获得有关何时进行三元组的个别实验和观察的准确信息非常困难。努力在OGB的未来版本中提供其他数据集拆分。

实验结果如下图所示，在这四个模型中，COMPLEX达到了最佳的测试MRR，而TRANSE与其他模型相比，性能明显差。TRANSE的较差性能可以通过以下事实来解释：TRANSE无法为该数据集中普遍存在的对称关系建模，例如，蛋白质-蛋白质和药物-药物关系都是对称的。总体而言，进一步提高模型性能具有重大的实践意义。 一个有前途的方向是为异构知识图开发一种更专门的方法，该方法中存在多个节点类型，并且整个图遵循预定义的架构。

### 1.2.3OGB图属性预测

**ogbg-mol\*：分子图**

*   ogbg-molhiv和ogbg-molpcba是两个大小不同的分子属性预测数据集：ogbg-molhiv （small）和ogbg-molpcba（medium）。所有分子均使用RDKIT进行预处理。每个图表示一个分子，其中节点表示原子，而边表示化学键。输入节点特征为9维，包含原子序数和手性，以及其他附加原子特征，例如形式电荷和原子是否在环中。输入边特征是3维的，包含键类型，键立体化学以及指示键是否共轭的附加键特征。
*   预测任务：尽可能准确地预测目标分子特性，其中分子特性被标记为二元标记，例如分子是否抑制HIV病毒复制。对于ogbg-molhiv，使用ROC-AUC进行评估。 对于ogbg-molpcba，由于类平衡严重偏斜（仅1.4％的数据为positive），并且数据集包含多个分类任务，因此将任务平均后的精确召回曲线（PRC）-AUC作为评估指标。
*   数据集分割：采用支架分割程序，该程序根据分子的二维结构框架风格分子。支架分割试图将结构上不同的分子分为不同的子集，这在预期的实验环境中提供了对模型性能的更现实的估计。总体而言，OGB与它们的数据加载器一起提供了有意义的数据拆分和改进的分子功能，从而使对MOLECULENET数据集的评估和比较更加容易和标准化。

实验结果如下图所示，可以看到具有附加功能的GIN和虚拟节点在两个数据集中提供了最佳性能。

**ogbg-ppa：蛋白质关联网络**

*   从1,581个不同物种的蛋白质关联网络中提取的一组无向蛋白质关联邻域，涵盖了37个广泛的生物分类群。从每种物种中随机选择了100种蛋白质，并以每个选定的蛋白质为中心构建了2-hop蛋白质关联邻域。然后，从每个邻域中删除中心节点，并对邻域进行二次采样，以确保最终的蛋白质关联图足够小（少于300个节点）。每个蛋白质关联图中的节点表示蛋白质，边表示蛋白质之间的生物学上有意义的关联。边与7维特征相关，其中每个元素取0到1之间的值，并代表特定类型的蛋白质关联的强度。
*   预测任务：给定一个蛋白质关联邻域图，该任务是一个37-way多分类，以预测该图源自哪个分类组。
*   数据集分割：与ogbn-proteins类似，采用物种分割方法，其中验证和测试集中的邻域图是从在训练过程中未发现但属于37个分类组之一的物种蛋白质关联网络中提取的。

实验结果如下表，类似于ogbg-mol \*数据集，带有VIRTUAL NODE的GIN提供了最佳性能。尽管如此，泛化差距仍然很大（将近30个百分点）。

**ogbg-code：源代码的抽象语法树**

*   从大约45万个Python方法定义中获得的抽象语法树（AST）的集合。方法是从GITHUB上最受欢迎的项目的总共13,587个不同的存储库中提取的。Python方法集合来自GITHUB Code Search-Net，它是用于基于机器学习的代码检索的数据集和基准的集合。
*   预测任务：给定AST表示的Python方法主体及其节点特征，任务是预测组成方法名称的子标记——节点类型（来自97种类型的池）、节点属性（例如变量名，词汇量为10002），AST中的深度、预遍历索引
*   数据集分割：采用项目分割，其中训练集的AST是从GITHUB项目中获得的，这些项目未出现在验证和测试集中。这种划分尊重实际情况，即在大量源代码上训练模型，然后将其用于在单独的代码库上预测方法名称。

1.3 OGB Package
---------------

OGB Package包旨在通过自动化数据加载和评估部分，使研究人员易于访问OGB管道。OGB与Pytorch及其关联的图形库完全兼容：PyG和DGL。OGB还提供了与库无关的数据集对象，可用于任何其他Python深度学习框架（如Tensorflow和Mxnet）。下面，将解释数据加载和评估。为简单起见，专注于使用PyG进行图属性预测的任务。有关其他任务详见官网。

OGB数据加载器：OGB Package使获取与PyG完全兼容的数据集对象变得容易仅用一行代码即可完成操作，最终用户只需指定数据集的名称即可。然后，OGB Package将下载、处理、存储并返回所请求的数据集对象。此外，可以从数据集对象中轻松获得标准化的数据集分割。

OGB评估器：OGB还可以通过ogb.\*.Evaluator类实现标准化和可靠的评估。如下面的代买所示，最终用户首先指定他们要评估其模型的数据集，然后用户可以了解需要传递给Evaluator对象的输入格式。输入格式取决于数据集，例如，对于ogbg-molpcba数据集，Evaluator对象需要输入一个字典，其中包含y\_true（存储真实二进制标签的矩阵）和y\_pred（存储模型输出的分数的矩阵）。最终用户通过指定的词典作为输入后，评估程序对象将返回适合手头数据集的模型性能，例如ogbg-molpcba的PRC-AUC。

2.ERNIESage （邻居聚合）
==================

2.1模型概述
-------

ERNIE-Sage 是 ERNIE SAmple aggreGatE 的简称，该模型可以同时建模文本语义与图结构信息，有效提升 Text Graph 的应用效果。

论文链接：[https://aclanthology.org/2020.textgraphs-1.11/](https://aclanthology.org/2020.textgraphs-1.11/)  
论文介绍了百度 PGL 团队设计的系统，该系统在 TextGraphs 2020 共享任务中获得第一名。 该任务的重点是为基础科学问题提供解释。 给定一个问题及其相应的正确答案，被要求从大型知识库中选择可以解释为什么该问题和回答 (QA) 的答案是正确的事实。 为了解决这个问题，PGL团队使用预训练的语言模型来回忆每个问题的前 K 个相关解释。 然后，他们采用基于预训练语言模型的重新排序方法对候选解释进行排序。 为了进一步提高排名，还开发了一种由强大的预训练变压器和 GNN 组成的架构，以解决多跳推理问题。

2.2 原理介绍
--------

在很多工业应用中，往往出现如下图所示的一种特殊的图：Text Graph。顾名思义，图的节点属性由文本构成，而边的构建提供了结构信息。如搜索场景下的Text Graph，节点可由搜索词、网页标题、网页正文来表达，用户反馈和超链信息则可构成边关系。

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69d75bbc40310.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

ERNIE-Sage 是 ERNIE 与 GraphSAGE 碰撞的结果，是 ERNIE SAmple aggreGatE 的简称，它的结构如下图所示，主要思想是通过 ERNIE 作为聚合函数（Aggregators），建模自身节点和邻居节点的语义与结构关系。ERNIE-Sage 对于文本的建模是构建在邻居聚合的阶段，中心节点文本会与所有邻居节点文本进行拼接；然后通过预训练的 ERNIE 模型进行消息汇聚，捕捉中心节点以及邻居节点之间的相互关系；最后使用 ERNIESage 搭配独特的邻居互相看不见的 Attention Mask 和独立的 Position Embedding 体系，就可以轻松构建 TextGraph 中句子之间以及词之间的关系。

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69d7c78194838.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

使用 ID 特征的 GraphSAGE 只能够建模图的结构信息，而单独的ERNIE只能处理文本信息。通过 PGL 搭建的图与文本的桥梁，ERNIESage能够很简单的把 GraphSAGE 以及 ERNIE 的优点结合一起。以下面 TextGraph 的场景，ERNIESage 的效果能够比单独的 ERNIE 以及 GraphSAGE 模型都要好。

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69d873a197496.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

ERNIE-Sage 可以很轻松地在 PGL 中的消息传递范式中进行实现，目前提供了4个版本的 ERNIESage 模型：

*   ERNIE-Sage v1: ERNIE 作用于text graph节点上;
*   ERNIE-Sage v2: ERNIE 作用在text graph的边上;
*   ERNIE-Sage v3: ERNIE 作用于一阶邻居及起边上;
*   ERNIE-Sage v4: ERNIE 作用于N阶邻居及边上;

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69dadcb861621.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

**模型效果**

TextGraph 2020 效果当时的SOTA

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69d7c1413220.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

**应用场景**

文本匹配、Query 推荐等

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69d81a1d25539.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

2.3 如何对Text Graph进行建模
---------------------

上个项目讲到的GraphSage只关注结构信息，无法完成语义理解，而NLP对应的预训练模型却反之，这时候ErnieSage就能很好实现两者达到图语义理解

简单提一下Ernie 1.0核心是知识增强，通过词级别的Masked Language Model(MLM)任务以及持续学习思想取得优异性能

**Transformer基础结构**

transformer好比全连通图，图节点类比token外加了自注意机制。

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69d74a5484960.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

**持续学习效果**

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69d8c5fb42273.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

**将ERNIE作用于Graph的各大元素:**

1.  ERNIESage V1 模型核心流程---ERNIE 作用于Text Graph的Node（节点） 上

*   ERNIE提取节点语义 -> GNN聚合

![图片替换文本](https://ai-studio-static-online.cdn.bcebos.com/0ab25a4f0c1647acbcfacc1be2066d47e98ec4f1931d4dcebd209347dc1b5448)

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69d7fd4420207.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

*   利用ERNIE获得节点表示
*   聚合邻居特征，进行消息传递
*   将当前节点和聚合后的邻居特征进行concat，更新节点特征

2.  ERNIESage V2 核心代码---------ERNIE聚合Text Graph的Edge（边） 上信息

*   GNN send 文本id -> ERNIE提取边语义 -> GNN recv 聚合邻居语义 -> ERNIE提取中心节点语义并concat

![图片替换文本](https://ai-studio-static-online.cdn.bcebos.com/24d5cca257624cc6bb94eeea7a7c3f84512534070c5949a5a9aca8fc8455f52e)

为了使得大家对下面有关ERNIE模型的部分能够有所了解，这里先贴出ERNIE的主模型框架图。

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69d70f5284413.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69d828e862563.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

*   利用 ERNIE 获取中心节点的文本特征表示
*   特征交互：中心节点和邻居节点一同作为 ERNIE 输入，计算交互特征
*   聚合邻居特征
*   将当前节点和聚合后的邻居特征 concat，更新节点特征

**ERNIESage Node与ERNIESage Edge对比**

大部分单塔模型优于双塔模型因为含有特征交互信息更充分，做链接预测问题思路：将两个节点进行內积得到一个值，和阈值对比假设大于0.5则边存在

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69d83a0480487.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

3.  ERNIESage V3 核心过程--------ERNIE聚合节点的1 Neighbor（ 一阶邻居） 信息

*   GNN send 文本id序列 -> GNN recv 拼接文本id序列 -> ERNIE同时提取中心和多个邻居语义表达

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69d7f4b723685.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

将中心节点的文本与所有一阶邻居节点文本进行单塔拼接，再利用 ERNIE 做消息聚合；这样就会遇到：

1.  如何确保在输入时邻居不带有顺序？
2.  如果邻居数量过多，如何建模？

解决方案如下：针对问题一采用独立位置编码，邻居节点编码相同不受顺序影响；针对问题提二：进行邻居采样

![](https://s2.51cto.com/images/blog/202211/25203541_6380b69da001b41871.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

2.4 基于PGL算法实现
-------------

### PGL&paddle 2.x+版本

ErnieSage可以很轻松地在基于PaddleNLP构建基于Ernie的图神经网络，目前PaddleNLP提供了V2版本的ErnieSage模型：

ErnieSage V2: ERNIE 作用在text graph的边上;

核心部分包含：

*   **数据集部分**

1.  example\_data - 简单的输入文件，格式为每行query \\t answer，可作简单的运行实例使用。

*   **模型文件和配置部分**

1.  ernie\_config.json - ERNIE模型的配置文件。
2.  vocab.txt - ERNIE模型所使用的词表。
3.  ernie\_base\_ckpt/ - ERNIE模型参数。
4.  config/ - ERNIESage模型的配置文件

*   **代码部分**

1.  local\_run.sh - 入口文件，通过该入口可完成预处理、训练、infer三个步骤。
2.  preprocessing文件夹 - 包含dump\_graph.py,在预处理部分，首先需要进行建图，将输入的文件构建成一张图。由于所研究的是Text Graph，因此节点都是文本，将文本表示为该节点对应的node feature(节点特征)，处理文本的时候需要进行切字，再映射为对应的token id。
3.  dataset/ - 该文件夹包含了数据ready的代码，以便于在训练的时候将训练数据以batch的方式读入。
4.  models/ - 包含了ERNIESage模型核心代码。
5.  train.py - 模型训练入口文件。
6.  learner.py - 分布式训练代码，通过train.py调用。
7.  infer.py - infer代码，用于infer出节点对应的embedding。

*   **评价部分**

1.  build\_dev.py - 用于将的验证集修改为需要的格式。
2.  mrr.py - 计算MRR值。  
    部分结果展示：

    [2022-11-23 14:18:01,252] [    INFO] - global step 890, epoch: 27, batch: 25, loss: 0.005078, speed: 1.70 step/s
    [2022-11-23 14:18:06,836] [    INFO] - global step 900, epoch: 28, batch: 3, loss: 0.004688, speed: 1.79 step/s
    [2022-11-23 14:18:12,588] [    INFO] - global step 910, epoch: 28, batch: 13, loss: 0.004492, speed: 1.74 step/s
    [2022-11-23 14:18:18,633] [    INFO] - global step 920, epoch: 28, batch: 23, loss: 0.005273, speed: 1.65 step/s
    [2022-11-23 14:18:24,022] [    INFO] - global step 930, epoch: 29, batch: 1, loss: 0.004687, speed: 1.86 step/s
    [2022-11-23 14:18:29,897] [    INFO] - global step 940, epoch: 29, batch: 11, loss: 0.004492, speed: 1.70 step/s
    [2022-11-23 14:18:35,727] [    INFO] - global step 950, epoch: 29, batch: 21, loss: 0.007814, speed: 1.72 step/s
    [2022-11-23 14:18:41,339] [    INFO] - global step 960, epoch: 29, batch: 31, loss: 0.012500, speed: 1.78 step/s
    INFO 2022-11-23 14:18:47,170 launch.py:402] Local processes completed.
    INFO 2022-11-23 14:18:47,170 launch.py:402] Local processes completed.
    

运行完毕后，会产生较多的文件，这里进行简单的解释。

1.  graph\_workdir/ - 这个文件夹主要会存储和图相关的数据信息。
    
2.  output/ - 主要的输出文件夹，包含了以下内容：
    

*   (1)模型文件，根据config文件中的save\_per\_step可调整保存模型的频率，如果设置得比较大则可能训练过程中不会保存模型;
*   (2)last文件夹，保存了停止训练时的模型参数，在infer阶段会使用这部分模型参数；
*   (3)part-0文件，infer之后的输入文件中所有节点的Embedding输出。

预测结果见/output part-0，部分结果展示：

    1	干部走读之所以成为“千夫所指”，是因为这种行为增加了行政成本。	0.08133 -0.18362 0.00346 -0.01038 -0.05656 -0.05691 -0.09882 0.12029 0.05317 -0.02939 -0.14508 -0.07692 -0.02769 -0.04896 0.09963 -0.14497 -0.13574 0.02424 0.10587 -0.07323 -0.06388 0.01103 0.00944 -0.07593 -0.00731 -0.11897 0.11635 -0.05529 0.04156 0.01942 -0.07949 -0.02761 0.00033 -0.06539 0.05739 0.02487 0.03389 0.18369 0.05038 -0.02183 0.02685 0.09735 -0.13134 0.01999 -0.04034 -0.03441 0.07738 0.14992 0.06287 -0.20294 -0.05325 0.07003 0.02595 0.01826 0.12306 0.06234 -0.11179 -0.09813 0.14834 -0.16425 0.13985 0.06430 0.01662 -0.01184 0.02659 0.13431 0.05327 -0.07269 0.06539 -0.12416 -0.03247 0.12320 -0.06268 -0.06711 -0.01775 -0.02475 0.12867 0.05980 0.09311 0.11515 -0.06987 0.07372 0.09891 -0.10539 -0.03451 0.02539 -0.05701 -0.06300 0.03582 0.13427 -0.07082 -0.01588 -0.10033 0.04229 -0.02681 0.22213 0.00073 0.00075 -0.16839 0.12594 0.00807 -0.00040 -0.07686 0.08944 -0.04361 -0.13446 -0.15051 -0.08336 0.13476 -0.07999 0.00719 0.04443 -0.21426 -0.02944 0.04165 0.14448 -0.07233 -0.07226 -0.01737 -0.05904 -0.08729 0.01087 0.11581 -0.00041 -0.04341 0.01526 -0.01272 -0.15089
    1	承担县人大常委会同市人大常委会及乡镇人大的工作联系。	0.06494 -0.25502 -0.00777 -0.02933 -0.03097 -0.08472 -0.15055 0.03232 0.04819 -0.03571 -0.18642 0.01614 0.07226 0.04660 0.06138 -0.14811 -0.01807 -0.00931 0.11350 0.04235 -0.14285 0.08077 0.10746 -0.03673 -0.12217 -0.05147 0.15980 -0.02051 -0.08356 0.00127 0.02313 0.14206 0.02116 -0.02332 -0.02032 0.03704 0.04234 0.05832 -0.03426 -0.02491 0.07948 0.11802 0.10158 -0.06468 -0.11558 0.00161 0.02030 0.06531 -0.04109 -0.13033 -0.04947 0.10836 -0.06057 0.01797 0.00183 0.18616 -0.13693 -0.17120 0.02910 0.01781 0.24061 -0.03953 0.10843 0.05329 -0.08753 -0.09504 0.05383 -0.11522 0.05172 -0.02633 0.06554 0.18186 -0.03937 -0.09151 -0.01045 -0.01857 0.10766 0.04191 0.10127 -0.00513 -0.02739 -0.10974 0.07810 -0.17015 -0.07228 -0.05809 -0.08627 -0.02947 -0.01907 0.12695 -0.09196 0.03067 -0.09462 0.15618 -0.05241 0.17382 -0.06615 0.02156 0.07060 0.09616 -0.02560 0.01197 -0.00582 -0.06037 -0.11539 -0.11853 -0.16872 0.00075 0.13284 0.02941 -0.01361 -0.01200 -0.12901 0.06944 -0.03066 0.09824 -0.01635 0.04351 -0.08985 0.08947 0.00923 -0.02436 0.10783 0.00891 0.10256 0.01953 -0.06292 -0.04989
    

    # 接下来，计算MRR得分。
    # 注意，运行此代码的前提是，已经将config对应的yaml配置文件中的input_data参数修改为了："train_data.txt"
    # 并且注意训练的模型是针对train_data.txt的，如果不符合，请重新训练模型。
    !python mrr.py --emb_path output/part-0
    
    # 由于仅是为了提供一个可运行的实例，计算出来的MRR值可能比较小，需要的同学可以自己更换数据集来测试更多的结果。
    1021it [00:00, 19102.78it/s]
    46it [00:00, 68031.73it/s]
    100%|█████████████████████████████████████████| 46/46 [00:00<00:00, 2397.52it/s]
    MRR  0.22548099768841945
    
    

### PGL&paddle 1.x+版本

提供多版本供大家学习复现，含核心模型代码讲解

项目链接：

[https://aistudio.baidu.com/aistudio/projectdetail/5097085](https://aistudio.baidu.com/aistudio/projectdetail/5097085)

3.UniMP（标签迁移）
=============

UniMP：融合标签传递和图神经网络的统一模型

论文名：Masked Label Prediction：用于半监督分类的统一消息传递模型

论文链接：[https://arxiv.org/abs/2009.03509](https://arxiv.org/abs/2009.03509)

图神经网络（GNN）和标签传播算法（LPA）都是消息传递算法，在半监督分类中取得了优越的性能。GNN 通过神经网络执行特征传播来进行预测，而 LPA 使用跨图邻接矩阵的标签传播来获得结果。然而，目前还没有有效的方法将这两种算法直接结合起来。为了解决这个问题，提出了一种新颖的统一消息传递模型 (UniMP)，它可以在训练和推理时结合特征和标签传播。首先，UniMP采用Graph Transformer网络，将feature embedding和label embedding作为输入信息进行传播。其次，为了在自循环输入标签信息中不过度拟合地训练网络，UniMP 引入了一种屏蔽标签预测策略，其中一定比例的输入标签信息被随机屏蔽，然后进行预测。UniMP 在概念上统一了特征传播和标签传播，并且在经验上是强大的。它在 Open Graph Benchmark (OGB) 中获得了新的最先进的半监督分类结果。

此外，提出UniMP\_large通过增加来扩展基本模型的宽度，并通过合并APPNPhead\_num使其更深。此外，他们首先提出了一种新的基于注意力的 APPNP来进一步提高模型的性能。

APPNP：Predict then Propagate: Graph Neural Networks meet Personalized PageRank [https://arxiv.org/abs/1810.05997](https://arxiv.org/abs/1810.05997)

    用于图形半监督分类的神经消息传递算法最近取得了巨大成功。然而，为了对节点进行分类，这些方法仅考虑距离传播几步之遥的节点，并且这个使用的邻域的大小很难扩展。在本文中，利用图卷积网络 (GCN) 与 PageRank 之间的关系，推导出一种基于个性化 PageRank 的改进传播方案。利用这种传播过程来构建一个简单的模型、神经预测的个性化传播 (PPNP) 及其快速近似 APPNP。模型的训练时间与以前的模型相同或更快，其参数数量与以前的模型相同或更少。它利用一个大的、可调整的邻域进行分类，并且可以很容易地与任何神经网络相结合。表明，在迄今为止对类 GCN 模型所做的最彻底的研究中，该模型优于最近提出的几种半监督分类方法。的实施可在线获得。
    

3.1背景介绍
-------

![](https://s2.51cto.com/images/blog/202211/25203704_6380b6f04dc0294353.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

![](https://s2.51cto.com/images/blog/202211/25203704_6380b6f07c6aa31746.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

在半监督图节点分类场景下，节点之间通过边相连接，部分节点被打上标签。任务要求模型通过监督学习的方式，拟合被标注节点数据，并对未标注的节点进行预测。如下图所示，在一般机器学习的问题上，已标注的训练数据在新数据的推断上，并不能发挥直接的作用，因为数据的输入是独立的。然而在图神经网络的场景下，已有的标注数据可以从节点与节点的连接中，根据图结构关系推广到新的未标注数据中。

一般应用于半监督节点分类的算法分为图神经网络和标签传递算法两类，它们都是通过消息传递的方式（前者传递特征、后者传递标签）进行节点标签的学习和预测。其中经典标签传递算法如LPA，只考虑了将标签在图上进行传递，而图神经网络算法大多也只是使用了节点特征以及图的链接信息进行分类。但是单纯考虑标签传递或者节点特征都是不足够的。

百度PGL团队提出的统一消息传递模型 UniMP，将上述两种消息统一到框架中，同时实现了节点的特征与标签传递，显著提升了模型的泛化效果。UniMP以Graph Transformer模型作为基础骨架，联合使用标签嵌入方法，将节点特征和部分节点标签同时输入至模型中，从而实现了节点特征和标签的同时传递。

简单的加入标签信息会带来标签泄漏的问题，即标签信息即是特征又是训练目标。实际上，标签大部分是有顺序的，例如在引用网络中，论文是按照时间先后顺序出现的，其标签也应该有一定的先后顺序。在无法得知训练集标签顺序的情况下，UniMP提出了标签掩码学习方法。UniMP每一次随机将一定量的节点标签掩码为未知，用部分已有的标注信息、图结构信息以及节点特征来还原训练数据的标签。最终，UniMP在OGB上取得SOTA效果，并在论文的消融实验上，验证了方法的有效性。

通过：Masked Label Prediction 解决标签泄露问题

**模型结构**

![](https://s2.51cto.com/images/blog/202211/25203704_6380b6f06578f48456.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

论文一些数据仿真展示：【数据集情况等】

![](https://s2.51cto.com/images/blog/202211/25203704_6380b6f04b62c14172.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)  
![](https://s2.51cto.com/images/blog/202211/25203704_6380b6f04b25165773.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)  
![](https://s2.51cto.com/images/blog/202211/25203704_6380b6f07891421028.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)  
![](https://s2.51cto.com/images/blog/202211/25203704_6380b6f05d6dd34990.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

3.2原理介绍
-------

![](https://s2.51cto.com/images/blog/202211/25203704_6380b6f07df0162648.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

部分作者提出质疑也是值得探讨的：

![](https://s2.51cto.com/images/blog/202211/25203704_6380b6f054de663989.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

3.3 基于码源详细阐释
------------

### 3.3.1 为何引入MaskLabel?

简单的加入标签信息会带来**标签泄漏**的问题，即标签信息即是特征又是训练目标。可以想象直接将标签作为网络输入，要求输出也向标签靠拢，势必会造成“1=1”的训练结果，无法用于预测。

在引用网络中，论文是按照时间先后顺序出现的，其标签也应该有一定的先后顺序。在无法得知训练集标签顺序的情况下，UniMP提出了MaskLabel学习方法。每一次随机将一定量的节点标签掩码为未知，用部分已有的标注信息、图结构信息以及节点特征来还原训练数据的标签。

    def label_embed_input(self, feature):
    	label = F.data(name="label", shape=[None, 1], dtype="int64")
    	label_idx = F.data(name='label_idx', shape=[None, 1], dtype="int64")
    	label = L.reshape(label, shape=[-1])
    	label_idx = L.reshape(label_idx, shape=[-1])
    
    	embed_attr = F.ParamAttr(initializer=F.initializer.NormalInitializer(loc=0.0, scale=1.0))
    	embed = F.embedding(input=label, size=(self.out_size, self.embed_size), param_attr=embed_attr)
    	feature_label = L.gather(feature, label_idx, overwrite=False)
    	feature_label = feature_label + embed
    	feature = L.scatter(feature, label_idx, feature_label, overwrite=True)
            
    	lay_norm_attr = F.ParamAttr(initializer=F.initializer.ConstantInitializer(value=1))
    	lay_norm_bias = F.ParamAttr(initializer=F.initializer.ConstantInitializer(value=0))
    	feature = L.layer_norm(feature, name='layer_norm_feature_input', param_attr=lay_norm_attr, bias_attr=lay_norm_bias)
        
    	return feature
    

在上面的代码中可以看到，对于已知标签的节点，首先将其embedding成和节点特征同样维度（这里是100维），然后就可以直接与节点特征相加，进而完成了标签信息与特征信息的融合，一块送入graph\_transformer进行消息传递。

**改进**：这里，最核心的一句代码是feature\_label = feature\_label + embed，它完成了标签和特征的融合，由此可以想到控制两者的权重，得到：

    feature_label = alpha*feature_label + (1-alpha)*embed
    

alpha可以设定为固定值，也可以通过学习获得。参考model\_unimp\_large.py中的门控残差连接：

    if gate:
    	temp_output = L.concat([skip_feature, out_feat, out_feat - skip_feature], axis=-1)
    	gate_f = L.sigmoid(linear(temp_output, 1, name=name + '_gate_weight', init_type='lin'))
    	out_feat = skip_feature * gate_f + out_feat * (1 - gate_f)
    else:
    	out_feat = skip_feature + out_feat
    

可以写出：

    temp = L.concat([feature_label,embed,feature_label-embed], axis=-1)
    alpha = L.sigmoid(linear(temp, 1, name='alpha_weight', init_type='lin'))
    feature_label = alpha*feature_label + (1-alpha)*embed
    

当然也可以直接经过一层FC后再将两者相加：

    feature_label = L.fc(feature_label, size=100) + L.fc(embed, size=100)
    

而做这些的目的，都是为了寻找能使标签信息和特征信息融合的更好的方式。

### 3.3.2 Res连接&Dense连接?

（1）残差网络（或称深度残差网络、深度残差学习，英文ResNet）属于一种卷积神经网络。相较于普通的卷积神经网络，残差网络采用了跨层恒等连接，以减轻卷积神经网络的训练难度。残差网络的一种基本模块如下所示：  
![](https://s2.51cto.com/images/blog/202211/25203715_6380b6fbaa6ae37245.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

实现起来比较简单，这里不予赘述。

（2）DenseNet原文：[Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993.pdf)

相比ResNet，DenseNet提出了一个更激进的密集连接机制：即互相连接所有的层，具体来说就是每个层都会接受其前面所有层作为其额外的输入。DenseNet的网络结构如下所示：  
![](https://s2.51cto.com/images/blog/202211/25203715_6380b6fb8712467091.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

以下代码实现了Dense连接：

    dense=[feature]
    for i in range(self.num_layers - 1):
    	ngw = pgl.sample.edge_drop(graph_wrapper, edge_dropout) 
    	res_feature = feature
    
    	feature, _, cks = graph_transformer(str(i), ngw, feature,
    	hidden_size=self.hidden_size,
    	num_heads=self.heads, 
    		concat=True, skip_feat=True,
     		layer_norm=True, relu=True, gate=True)
    	if dropout > 0:
    	feature = L.dropout(feature, dropout_prob=dropout, dropout_implementation='upscale_in_train') 
    
    	dense.append(feature)
    	feature = L.fc(dense, size=self.hidden_size, name="concat_feature")
    

### 3.3.3 注意力机制?

注意力机制就是将注意力集中于局部关键信息的机制，可以分成两步：第一，通过全局扫描，发现局部有用信息；第二，增强有用信息并抑制冗余信息。SENet是一种非常经典的注意力机制下的深度学习方法。它可以通过一个小型的子网络，自动学习得到一组权重，对特征图的各个通道进行加权。其含义在于，某些特征通道是较为重要的，而另一些特征通道是信息冗余的；那么，我们就可以通过这种方式增强有用特征通道、削弱冗余特征通道。SENet的一种基本模块如下所示：

![](https://s2.51cto.com/images/blog/202211/25203715_6380b6fb82a5435131.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

值得指出的是，通过这种方式，每个样本都可以有自己独特的一组权重，可以根据样本自身的特点，进行独特的特征通道加权调整。

Unimp中的注意力机制出现在Graph Transformer以及最后的输出层attn\_appnp，attn\_appnp的代码为：

    def attn_appnp(gw, feature, attn, alpha=0.2, k_hop=10):
    	"""Attention based APPNP to Make model output deeper
    	Args:
    		gw: Graph wrapper object (:code:`StaticGraphWrapper` or :code:`GraphWrapper`)
    		attn: Using the attntion as transition matrix for APPNP
    		feature: A tensor with shape (num_nodes, feature_size).
    		k_hop: K Steps for Propagation
    	Return:
    		A tensor with shape (num_nodes, hidden_size)
    	"""
    	def send_src_copy(src_feat, dst_feat, edge_feat):
    		feature = src_feat["h"]
    		return feature
    
    	h0 = feature
    	attn = L.reduce_mean(attn, 1)
    	for i in range(k_hop):
    		msg = gw.send(send_src_copy, nfeat_list=[("h", feature)])
    		msg = msg * attn
    		feature = gw.recv(msg, "sum")
    		feature = feature * (1 - alpha) + h0 * alpha
    	return feature
    

在调用函数时，其中的alpha为前面的graph\_transformer学习到的参数，用于更好的融合各层特征。

3.4基于PGL算法实现
------------

### 3.4.1 基于斯坦福 OGB (1.2.1) 基准测试

实验基于斯坦福 OGB (1.2.1) 基准测试，

To\_do list:

*   UniMP\_large in Arxiv
*   UniMP\_large in Products
*   UniMP\_large in Proteins
*   UniMP\_xxlarge

这里给出giyhub官网代码链接：[https://github.com/PaddlePaddle/PGL/tree/main/ogb\_examples/nodeproppred/unimp](https://github.com/PaddlePaddle/PGL/tree/main/ogb_examples/nodeproppred/unimp)

因为在安装环境中需要安装torch，在aistudio上尝试多次仍无法运行，下面给出代码流程和官网结果。感兴趣同学私下本地运行吧。比较吃算力！

超参数介绍：

    Arxiv_dataset(Full Batch):          Products_dataset(NeighborSampler):          Proteins_dataset(Random Partition):
    --num_layers        3               --num_layers                3               --num_layers                7                   
    --hidden_size       128             --hidden_size               128             --hidden_size               64               
    --num_heads         2               --num_heads                 4               --num_heads                 4
    --dropout           0.3             --dropout                   0.3             --dropout                   0.1
    --lr                0.001           --lr                        0.001           --lr                        0.001
    --use_label_e       True            --use_label_e               True            --use_label_e               True
    --label_rate        0.625           --label_rate                0.625           --label_rate                0.5 
    --weight_decay.     0.0005
    
    

结果展示：

OGB的仿真性能：

Model

Test Accuracy

Valid Accuracy

Parameters

Hardware

Arxiv\_baseline

0.7225 ± 0.0015

0.7367 ± 0.0012

468,369

Tesla V100 (32GB)

Arxiv\_UniMP

0.7311 ± 0.0021

0.7450 ± 0.0005

473,489

Tesla V100 (32GB)

Arxiv\_UniMP\_large

0.7379 ± 0.0014

0.7475 ± 0.0008

1,162,515

Tesla V100 (32GB)

Products\_baseline

0.8023 ± 0.0026

0.9286 ± 0.0017

1,470,905

Tesla V100 (32GB)

Products\_UniMP

0.8256 ± 0.0031

0.9308 ± 0.0017

1,475,605

Tesla V100 (32GB)

Proteins\_baseline

0.8611 ± 0.0017

0.9128 ± 0.0007

1,879,664

Tesla V100 (32GB)

Proteins\_UniMP

0.8642 ± 0.0008

0.9175 ± 0.0007

1,909,104

Tesla V100 (32GB)

改进 OGBN 蛋白质的更多技巧

评估中的随机分区大小，随机分区在训练过程中表现得像DropEdge，发现的模型可以从这种策略中受益。，但在评估中，发现较小的分区大小可以提高分数。

    # To compare 
    
    python train.py --place 0 --use_label_e --log_file eval_partition_5 --eval_partition 5
    
    python train.py --place 0 --use_label_e --log_file eval_partition_3 --eval_partition 3
    

使用 Self-Attention 聚合 Neighbor Feature  
OGBN-Proteins 中 UniMP 和其他类似 DeeperGCN 的原始代码使用平均边缘特征作为初始节点特征。采用这些模块作为可学习的聚合器。为每个节点采样大约 64 个边，并使用变换器 \[3 \* (Self-Attention + Residual + ReLU + LayerNorm) + Mean Pooling\] 作为聚合器来获取初始化节点特征。简单地称它为CrossEdgeFeat。你可以在cross\_edge\_feat.py  
最初的 ogbn-proteins 工具获得了大约0.9175的验证分数和0.864的测试分数。并且通过CrossEdgeFeat，可以促进快速收敛并获得更高的分数。

    # To compare
    
    python train.py --place 0 --use_label_e --log_file with_cross_edge_feat  --cross_edge_feat 3
    
    python train.py --place 0 --use_label_e --log_file without_cross_edge_feat  --cross_edge_feat 0
    
    

训练曲线（验证 AUC）如下：

![](https://s2.51cto.com/images/blog/202211/25203736_6380b7107bac86470.png?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

### 3.4.2 图学习之基于PGL-UniMP算法的论文引用网络节点分类任务\[系列九\]

内容过多引到下一篇项目

项目链接：[https://aistudio.baidu.com/aistudio/projectdetail/5116458?contributionType=1](https://aistudio.baidu.com/aistudio/projectdetail/5116458?contributionType=1)

fork一下即可

4.OGB最新榜单部分展示
=============

这里就展示了节点预测的，更多的可以自行去官网查看获得最新模型

![](https://s2.51cto.com/images/blog/202211/25203752_6380b7205366442602.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)  
![](https://s2.51cto.com/images/blog/202211/25203752_6380b7208a34456938.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)  
![](https://s2.51cto.com/images/blog/202211/25203752_6380b7204e9a394371.jpg?x-oss-process=image/watermark,size_14,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

5.总结
====

通过以上两个版本的模型代码简单的讲解，可以知道他们的不同点，其实主要就是在消息传递机制的部分有所不同。ERNIESageV1版本只作用在text graph的节点上，在传递消息(Send阶段)时只考虑了邻居本身的文本信息；而ERNIESageV2版本则作用在了边上，在Send阶段同时考虑了当前节点和其邻居节点的文本信息，达到更好的交互效果。

为了实现可扩展的，健壮的和可重现的图学习研究，提出了Open Graph Benchmark (OGB)——具有规模大、领域广、任务类别多样化的现实图数据集。在特定于应用程序的使用案例的驱动下，对给定的数据集采用了实际的数据分割方法。通过广泛的基准实验，强调OGB数据集对于图学习模型在现实的数据分割方案下处理大规模图并进行准确的预测提出了重大挑战。总而言之，OGB为未来的研究提供了丰富的机会，以推动图学习的前沿。

OGB还在不断的扩展中，相信之后会有更多数据集，也将产生更多优秀的模型，推动图学习的研究，了解和掌握相关内容还是很有必要的。

原项目链接：fork一下即可：[https://aistudio.baidu.com/aistudio/projectdetail/5096910?contributionType=1](https://aistudio.baidu.com/aistudio/projectdetail/5096910?contributionType=1)