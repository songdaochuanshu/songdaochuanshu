---
layout: post
title: "NLPæ–°æ‰‹å…¥é—¨æŒ‡å—|åŒ—å¤§-TANGENT"
date: "2022-09-22T22:22:07.496Z"
---
NLPæ–°æ‰‹å…¥é—¨æŒ‡å—|åŒ—å¤§-TANGENT
====================

å¼€æºçš„å­¦ä¹ èµ„æºï¼šã€ŠNLP æ–°æ‰‹å…¥é—¨æŒ‡å—ã€‹ï¼Œé¡¹ç›®ä½œè€…ä¸ºåŒ—äº¬å¤§å­¦ TANGENT å®éªŒå®¤æˆå‘˜ã€‚ è¯¥æŒ‡å—ä¸»è¦æä¾›äº† NLP å­¦ä¹ å…¥é—¨å¼•å¯¼ã€å¸¸è§ä»»åŠ¡çš„å¼€å‘å®ç°ã€å„å¤§æŠ€æœ¯æ•™ç¨‹ä¸æ–‡çŒ®çš„ç›¸å…³æ¨èç­‰å†…å®¹ï¼Œæ˜¯ä¸€ä»½éå¸¸å…¨çš„é€‚åˆæ–°æ‰‹å°ç™½åˆå­¦å…¥é—¨çš„æƒå¨æŒ‡å—ã€‚ å€¼å¾—mark!

ä»¥ä¸‹æ­£æ–‡ï¼š

æœ¬æ•™ç¨‹ä¾›æ–°åŠ å…¥ TANGENT å®éªŒå®¤çš„åŒå­¦å…¥é—¨ NLP ä½¿ç”¨

*   PKU-TANGENT nlp-tutorial
    *   [å†™åœ¨å‰é¢](https://github.com/PKU-TANGENT/nlp-tutorial#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2)
    *   åŸºç¡€çŸ¥è¯†
        *   [æœºå™¨å­¦ä¹ ](https://github.com/PKU-TANGENT/nlp-tutorial#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)
        *   [æ·±åº¦å­¦ä¹ ](https://github.com/PKU-TANGENT/nlp-tutorial#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)
        *   [è‡ªç„¶è¯­è¨€å¤„ç†](https://github.com/PKU-TANGENT/nlp-tutorial#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86)
    *   æ–‡çŒ®é˜…è¯»
        *   [Google Scholar](https://github.com/PKU-TANGENT/nlp-tutorial#google-scholar)
        *   [ä¼šè®®è®ºæ–‡](https://github.com/PKU-TANGENT/nlp-tutorial#%E4%BC%9A%E8%AE%AE%E8%AE%BA%E6%96%87)
        *   [å‰æ²¿è¿›å±•](https://github.com/PKU-TANGENT/nlp-tutorial#%E5%89%8D%E6%B2%BF%E8%BF%9B%E5%B1%95)
        *   [å·¥å…·](https://github.com/PKU-TANGENT/nlp-tutorial#%E5%B7%A5%E5%85%B7)
    *   åŠ¨æ‰‹å®è·µ
        *   [å†™åœ¨å‰é¢](https://github.com/PKU-TANGENT/nlp-tutorial#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2-1)
        *   [ä»»åŠ¡ä¸€ï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æœ¬åˆ†ç±»](https://github.com/PKU-TANGENT/nlp-tutorial#%E4%BB%BB%E5%8A%A1%E4%B8%80%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB)
        *   [ä»»åŠ¡äºŒï¼šåŸºäº LSTM-CRF çš„å‘½åå®ä½“è¯†åˆ«](https://github.com/PKU-TANGENT/nlp-tutorial#%E4%BB%BB%E5%8A%A1%E4%BA%8C%E5%9F%BA%E4%BA%8E-lstm-crf-%E7%9A%84%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB)
        *   [ä»»åŠ¡ä¸‰ï¼šNeural Machine Translation (NMT)](https://github.com/PKU-TANGENT/nlp-tutorial#%E4%BB%BB%E5%8A%A1%E4%B8%89neural-machine-translation-nmt)
        *   [ä»»åŠ¡å››ï¼šTransformer & PLM](https://github.com/PKU-TANGENT/nlp-tutorial#%E4%BB%BB%E5%8A%A1%E5%9B%9Btransformer--plm)
    *   [æœ¬ä»“åº“çš„ä½¿ç”¨è¯´æ˜](https://github.com/PKU-TANGENT/nlp-tutorial#%E6%9C%AC%E4%BB%93%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E)

å†™åœ¨å‰é¢
----

ç›¸ä¿¡å¤§å®¶ç»è¿‡å‡ å¹´çš„å­¦ä¹ ï¼Œå·²ç»æ‹¥æœ‰äº†ä»¥ä¸‹çš„æŠ€èƒ½ï¼š

1.  ä¼˜ç§€çš„ä¿¡æ¯æ£€ç´¢èƒ½åŠ›ï¼Œæ— è®ºæ˜¯åœ¨è®ºæ–‡é˜…è¯»ã€å†™ä»£ç ã€ä½¿ç”¨æœåŠ¡å™¨ã€å†™è®ºæ–‡ç­‰è¿‡ç¨‹ä¸­éƒ½æœ‰å¯èƒ½é‡åˆ°å„ç§å„æ ·çš„é—®é¢˜ï¼Œåœ¨è¯¢é—®ä»–äººä¹‹å‰ï¼Œè¯·å–„ç”¨æœç´¢
2.  ä¼˜ç§€çš„è‹±æ–‡é˜…è¯»èƒ½åŠ›å’ŒåŸºæœ¬çš„è‹±è¯­å†™ä½œèƒ½åŠ›
3.  è‰¯å¥½çš„ç¼–ç¨‹èƒ½åŠ›ï¼Œåœ¨ NLP ç›¸å…³ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šä½¿ç”¨ Pythonï¼Œå¦‚æœä½ ä¹‹å‰åªå­¦è¿‡ C æˆ–è€… C++ï¼Œé‚£ä¹ˆå…¥é—¨ Python å¯¹äºä½ æ¥è¯´å°†ä¸æ˜¯ä¸€ä»¶éš¾äº‹ã€‚ æˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨ Anacondaï¼ˆMinicondaï¼‰æ¥ç®¡ç†ä¸ªäººç”µè„‘ä¹ƒè‡³ Linux æœåŠ¡å™¨ä¸Šçš„ Python ç¯å¢ƒï¼Œè¯·æå‰å®‰è£…å¹¶å­¦ä¹  conda çš„ä½¿ç”¨ã€‚ æ­¤å¤–åœ¨ç§‘ç ”ä¸­æˆ‘ä»¬ç»å¸¸ä¼šä¸ä»–äººåˆä½œï¼Œå› æ­¤è¯·ä¿æŒè‰¯å¥½çš„ä»£ç ä¹ æƒ¯ï¼Œå¦‚æœä½ ä¸äº†è§£ä»£ç è§„èŒƒï¼Œè¯·å‚è€ƒ [Google çš„ Python ä»£ç è§„èŒƒ](https://zh-google-styleguide.readthedocs.io/en/latest/google-python-styleguide/python_style_rules/)
4.  æ•°å­¦åŸºç¡€ï¼Œä½œä¸ºä¸€åç†å·¥ç§‘çš„å­¦ç”Ÿï¼Œä½ åº”è¯¥å·²ç»å­¦è¿‡é«˜ç­‰æ•°å­¦ï¼ˆæ•°å­¦åˆ†æï¼‰ã€çº¿æ€§ä»£æ•°ï¼ˆé«˜ç­‰ä»£æ•°ï¼‰ã€æ¦‚ç‡è®ºä¸ç»Ÿè®¡ç­‰åŸºç¡€æ•°å­¦è¯¾ç¨‹ï¼Œåœ¨å…¥é—¨é˜¶æ®µæˆ‘ä»¬æ¶‰åŠåˆ°çš„æ•°å­¦çŸ¥è¯†è¾ƒä¸ºç®€å•ï¼Œä½†æ˜¯æ‰å®çš„æ•°ç†åŸºç¡€ä¼šæ”¯æ’‘ä½ èµ°å¾—æ›´æ·±æ›´è¿œã€‚
5.  æœ€å¥½æ‹¥æœ‰ Linux ç³»ç»Ÿä½¿ç”¨ç»éªŒï¼Œç›®å‰æ˜¯æ·±åº¦å­¦ä¹ çš„æ—¶ä»£ï¼Œå¯¹äºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œåˆæ˜¯å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„æ—¶ä»£ï¼Œä¸ªäººç”µè„‘æ— æ³•æ”¯æ’‘å¤§æ¨¡å‹çš„è®­ç»ƒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Linux æœåŠ¡å™¨è¿›è¡Œ Coding å’Œå®éªŒï¼Œæå‰äº†è§£å·¥ä½œæµç¨‹ä¼šå¤§å¤§æé«˜æ•ˆç‡ã€‚ æœ¬æ•™ç¨‹[åŠ¨æ‰‹å®è·µ](https://github.com/PKU-TANGENT/nlp-tutorial#%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5)éƒ¨åˆ†åŸºäº CNN å’Œ RNNï¼ˆLSTMï¼‰çš„æ¨¡å‹ç†è®ºä¸Šå¯ä»¥åœ¨ä¸ªäººç”µè„‘ä¸Šè¿è¡Œï¼Œå¦‚éœ€ GPU èµ„æºï¼Œè¯·è”ç³»å®éªŒå®¤æœåŠ¡å™¨ç®¡ç†å‘˜ã€‚

åŸºç¡€çŸ¥è¯†
----

æˆ‘ä»¬é»˜è®¤å¤§å®¶å·²ç»å®Œæˆäº†è®¡ç®—æœºä¸“ä¸šæœ¬ç§‘ä¸€å¹´çº§å’ŒäºŒå¹´çº§çš„ç›¸å…³è¯¾ç¨‹ï¼Œæ‹¥æœ‰ä¸€å®šçš„æ•°å­¦å’Œç¼–ç¨‹åŸºç¡€

### æœºå™¨å­¦ä¹ 

è™½ç„¶ç›®å‰æ˜¯æ·±åº¦å­¦ä¹ çš„æ—¶ä»£ï¼Œæˆ‘ä»¬ä¹Ÿå¾ˆå°‘ä½¿ç”¨ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„ç®—æ³•æ¥è§£å†³é—®é¢˜ï¼Œä½†æ˜¯ä¸€æ–¹é¢ä¸€äº›åŸºç¡€æ¦‚å¿µä»ç„¶æ˜¯ç›¸é€šçš„ï¼Œå¦ä¸€æ–¹é¢ç»å…¸æœºå™¨å­¦ä¹ ç®—æ³•çš„æ€æƒ³ï¼Œå¦‚ EMã€LDA ç­‰ï¼Œåœ¨æ·±åº¦å­¦ä¹ æ—¶ä»£å¾€å¾€èƒ½å¤Ÿå†ä¹…å¼¥æ–°ï¼Œä»¥å¦ä¸€ç§æ–¹å¼ç„•å‘å‡ºæ–°çš„å…‰å½©ã€‚ å¯¹äºæƒ³è¦å¿«é€Ÿå…¥é—¨çš„åˆå­¦è€…æ¥è¯´ï¼Œå»ºè®®å…ˆç†Ÿæ‚‰æœºå™¨å­¦ä¹ åŸºç¡€æ¦‚å¿µï¼ˆä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Œæœºå™¨å­¦ä¹ ç”¨æ¥å¹²ä»€ä¹ˆï¼Œä»€ä¹ˆæ˜¯æ•°æ®é›†ï¼Œå¦‚ä½•å¯¹æœºå™¨å­¦ä¹ ç®—æ³•è¿›è¡Œè¯„æµ‹ç­‰ï¼‰ï¼Œäº†è§£å‡ ç§å…·ä½“çš„ç»å…¸æœºå™¨å­¦ä¹ ç®—æ³•ã€‚

å¯¹äºåˆå­¦è€…å¯ä»¥å­¦ä¹ ï¼š

*   ç½‘è¯¾ï¼šå´æ©è¾¾ æœºå™¨å­¦ä¹ å…¬å¼€è¯¾ï¼›æå®æ¯… æœºå™¨å­¦ä¹ 
*   ä¹¦ï¼šæœºå™¨å­¦ä¹ ï¼ˆå‘¨å¿—åï¼Œè¥¿ç“œä¹¦ï¼‰ï¼Œç»Ÿè®¡å­¦ä¹ æ–¹æ³•ï¼ˆæèˆªï¼‰

å¦‚æœæƒ³æ›´æ·±åœ°äº†è§£ï¼š

*   ç½‘è¯¾ï¼š[æœºå™¨å­¦ä¹ ç™½æ¿æ¨å¯¼](https://www.bilibili.com/video/BV1aE411o7qd)
*   ä¹¦
    *   [Pattern Recognition And Machine Learning](https://www.cs.uoi.gr/~arly/courses/ml/tmp/Bishop_book.pdf) (PRML)ï¼Œä»¥è´å¶æ–¯çš„è§†è§’ä»‹ç»æœºå™¨å­¦ä¹ ç®—æ³•ã€‚æœ¬ä¹¦æˆä¹¦äº2012å¹´ï¼Œç”±äºè¿‘å¹´æ¥æ·±åº¦å­¦ä¹ é£é€Ÿå‘å±•ï¼Œè¯¥ä½œè€…åˆç›¸ç»§æ¨å‡ºäº† [Probabilistic Machine Learning: An Introduction](https://github.com/probml/pml-book) å’Œ [Probabilistic Machine Learning: Advanced Topics](https://github.com/probml/pml2-book)
    *   Machine Learning: A Probabilistic Prospective (MLAPP)ï¼Œæœºå™¨å­¦ä¹ çš„ç™¾ç§‘å…¨ä¹¦ï¼ŒåŒæ ·åé‡è´å¶æ–¯è§†è§’
    *   The Elements of Statistical Learning (ESL)ï¼Œé¢‘ç‡æ´¾

### æ·±åº¦å­¦ä¹ 

æ·±åº¦å­¦ä¹ çš„å‘å±•ä¸ºæˆ‘ä»¬çš„ä¸–ç•Œå¸¦æ¥äº†å·¨å¤§çš„æ”¹å˜ï¼Œ2018çš„å›¾çµå¥–ä¹Ÿé¢ç»™äº†å¯¹æ·±åº¦å­¦ä¹ æœ‰å“è¶Šè´¡çŒ®çš„ Yoshua Bengioã€Yann LeCunã€Geoffrey Hintonã€‚

ä¹¦ï¼šDeep Learningï¼ˆGoodFellow, Bengio, Courvilleï¼‰ï¼Œç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ï¼ˆé‚±é”¡é¹ï¼‰

å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œä»…ä»…äº†è§£æ·±åº¦å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µã€åŸºæœ¬ç®—æ³•æ˜¯ä¸å¤Ÿçš„ï¼Œæ›´åº”å½“åˆ°ä»£ç å½“ä¸­å»è·å¾—æ›´ä¸ºç›´è§‚å’Œæ·±å…¥çš„è®¤è¯†ã€‚å¤§å®¶å¯èƒ½ä¹Ÿå¬è¯´è¿‡ TensorFlowã€PyTorch è¿™æ ·çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç›®å‰å­¦æœ¯ç•Œé€šå¸¸ä½¿ç”¨ PyTorchã€‚

PyTorch å¯¹åˆå­¦è€…ä¹Ÿæä¾›äº†[å¿«é€Ÿå…¥é—¨æŒ‡å—](https://pytorch.org/tutorials/beginner/basics/intro.html)å’Œ [tutorial](https://pytorch.org/tutorials/)ï¼Œå¯¹äº tutorialï¼Œå»ºè®®ä»[ç®€å•çš„å›¾åƒåˆ†ç±»ç®—æ³•](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html#)å­¦èµ·ï¼Œç„¶åå†è¿›ä¸€æ­¥å­¦ä¹ [ç®€å•çš„æ–‡æœ¬åˆ†ç±»](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)ã€[ç®€å•çš„æ–‡æœ¬ç”Ÿæˆ](https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html)ç­‰è‡ªç„¶è¯­è¨€å¤„ç†ç›¸å…³æ•™ç¨‹ã€‚

PyTorch æä¾›äº†éå¸¸è¯¦ç»†çš„[æ–‡æ¡£](https://pytorch.org/docs/stable/index.html)ï¼Œé‡åˆ°ä¸æ˜ç™½çš„å‡½æ•°ã€æ¦‚å¿µéƒ½å¯ä»¥åœ¨æ–‡æ¡£ä¸­è¿›è¡ŒæŸ¥è¯¢å’Œå­¦ä¹ 

### è‡ªç„¶è¯­è¨€å¤„ç†

æˆ‘ä»¬å®éªŒå®¤çš„åç§°ä¸ºè®¡ç®—è¯­è¨€å­¦ç ”ç©¶æ‰€ï¼Œé€šå¸¸æ„ä¹‰ä¸Š[è®¡ç®—è¯­è¨€å­¦](https://zh.wikipedia.org/zh-hans/%E8%AE%A1%E7%AE%97%E8%AF%AD%E8%A8%80%E5%AD%A6)ï¼ˆComputational Linguisticsï¼ŒCLï¼‰å±äºè¯­è¨€å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè€Œ[è‡ªç„¶è¯­è¨€å¤„ç†](https://zh.wikipedia.org/zh/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86)ï¼ˆNatural Language Processingï¼ŒNLPï¼‰ï¼Œåœ¨ç°ä»£æ„ä¹‰ä¸Šä¸¤è€…å¾€å¾€ä¼šæ··ä¸ºä¸€è°ˆã€‚

ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†æˆ–è€…è®¡ç®—è¯­è¨€å­¦ï¼Ÿè¿™é‡Œæ‘˜æŠ„ä¸€æ®µ The Association for Computational Linguistics (ACL) çš„ä»‹ç»ï¼š "Computational linguistics is the scientific study of language from a computational perspective. Computational linguists are interested in providing computational models of various kinds of linguistic phenomena. These models may be "knowledge-based" ("hand-crafted") or "data-driven" ("statistical" or "empirical"). Work in computational linguistics is in some cases motivated from a scientific perspective in that one is trying to provide a computational explanation for a particular linguistic or psycholinguistic phenomenon; and in other cases the motivation may be more purely technological in that one wants to provide a working component of a speech or natural language system. Indeed, the work of computational linguists is incorporated into many working systems today, including speech recognition systems, text-to-speech synthesizers, automated voice response systems, web search engines, text editors, language instruction materials, to name just a few."

NLP åŒ…å«å“ªäº› topic å‘¢ï¼ŸåŒæ ·æ˜¯æ‘˜æŠ„è‡ª 60th Annual Meeting of the Association for Computational Linguistics çš„ Submissions Topicsï¼š

*   Computational Social Science and Cultural Analytics
*   Dialogue and Interactive Systems
*   Discourse and Pragmatics
*   Ethics and NLP
*   Generation
*   Information Extraction
*   Information Retrieval and Text Mining
*   Interpretability and Analysis of Models for NLP
*   Language Grounding to Vision, Robotics and Beyond
*   Linguistic Theories, Cognitive Modeling, and Psycholinguistics
*   Machine Learning for NLP
*   Machine Translation and Multilinguality
*   NLP Applications
*   Phonology, Morphology, and Word Segmentation
*   Question Answering
*   Resources and Evaluation
*   Semantics: Lexical
*   Semantics: Sentence-level Semantics, Textual Inference, and Other Areas
*   Sentiment Analysis, Stylistic Analysis, and Argument Mining
*   Speech and Multimodality
*   Summarization
*   Syntax: Tagging, Chunking and Parsing

å¯ä»¥çœ‹åˆ° NLP è¿™ä¸ªè¯­è¨€å­¦å’Œè®¡ç®—æœºç§‘å­¦çš„äº¤å‰å­¦ç§‘å®åœ¨æ˜¯åŒ…å«äº†å¤ªå¤šçš„ç ”ç©¶æ–¹å‘ï¼Œè€Œå…¶ä¸­é™¤äº†æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ã€æ‘˜è¦ã€QA è¿™äº›å¤§å®¶æ—©æœ‰è€³é—»çš„åº”ç”¨ï¼Œå‰©ä¸‹çš„ç›¸ä¿¡åˆå­¦è€…å¤§å¤šä»æœªå¬è¯´è¿‡ï¼Œå³ä½¿æ˜¯ä¸€ä½ NLP ç ”ç©¶è€…æˆ–ä»ä¸šäººå‘˜ä¹Ÿåªèƒ½å¯¹è¿™ä¸ªåˆ—è¡¨ä¸­çš„æŸä¸€ä¸ªæˆ–å‡ ä¸ªæ–¹é¢æœ‰æ·±å…¥çš„ç ”ç©¶ã€‚

æƒ³è¦å¯¹ NLP æ˜¯ç ”ç©¶ä»€ä¹ˆçš„æœ‰ä¸ªå¤§è‡´çš„äº†è§£ï¼Œé¦–å…ˆæˆ‘ä»¬å¯ä»¥å¿«é€Ÿäº†è§£æ·±åº¦å­¦ä¹ æ—¶ä»£ NLP å‘å±•å†å²ï¼š[A Review of the Neural History of Natural Language Processing](https://ruder.io/a-review-of-the-recent-history-of-nlp/)ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥é€šè¿‡è¯¾ç¨‹æˆ–ä¹¦ç±è¿›è¡Œç³»ç»Ÿçš„å­¦ä¹ ï¼š

*   ç½‘è¯¾ï¼š
    *   [Stanford cs224n](https://web.stanford.edu/class/cs224n/)ï¼ˆå¼ºçƒˆæ¨èï¼Œä¸»è®²äººæ˜¯ç»å¯¹çš„å¤§ç‰› Christopher Manningï¼Œæ­¤è¯¾ç¨‹ä»æ·±åº¦å­¦ä¹ çš„è§’åº¦å‡ºå‘å¯¹ NLP è¿›è¡Œå…¨é¢çš„ä»‹ç»ï¼Œè€Œå…¶ä¸­çš„ talk åˆæ¶‰åŠå­¦æœ¯æœ€å‰æ²¿çš„è¿›å±•ï¼Œå¯è°“å¹¿åº¦ä¸æ·±åº¦ä¿±å…¨ï¼‰
    *   CMU CS 11-747
*   ä¹¦ï¼š
    *   ç»Ÿè®¡è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆå®—æˆåº†ï¼‰æˆä¹¦å¹´ä»£è¾ƒæ—©ï¼Œå…·ä½“æ–¹æ³•ä¸å½“ä¸‹æœ‰è¾ƒå¤§è·ç¦»ï¼Œå¯äº†è§£ NLP åŸºæœ¬é—®é¢˜
    *   ç°ä»£è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆé»„æ°‘çƒˆï¼‰ï¼Œå…³æ³¨è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNatural Language Generationï¼ŒNLGï¼‰
    *   è‡ªç„¶è¯­è¨€å¤„ç†ï¼šåŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•ï¼ˆè½¦ä¸‡ç¿”ï¼‰ï¼Œå½“ä»Šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPretrained Language Modelï¼ŒPLMï¼‰ä¿¨ç„¶æˆä¸ºäº† NLP ä¸­çš„â€œåŸºç¡€è®¾æ–½â€ï¼ˆFoundation Modelï¼‰ï¼Œâ€œé¢„è®­ç»ƒ-å¾®è°ƒâ€ï¼ˆPretrain & Fine-tuneï¼‰ä¹Ÿæˆä¸ºäº†åº”ç”¨ä¸­çš„åŸºæœ¬èŒƒå¼ï¼Œå› æ­¤æˆ‘ä»¬åŒæ ·éœ€è¦äº†è§£åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•

æ–‡çŒ®é˜…è¯»
----

### Google Scholar

[Google Scholar](https://scholar.google.com/) å¯ä»¥ç†è§£ä¸ºå­¦æœ¯ç•Œçš„ Google

### ä¼šè®®è®ºæ–‡

æˆ‘ä»¬ä¸»è¦é˜…è¯»å›½é™…ä¼šè®®è®ºæ–‡ï¼Œç›¸å…³çš„ä¼šè®®æœ‰ï¼š

*   è‡ªç„¶è¯­è¨€å¤„ç†ç›¸å…³ä¼šè®®ï¼šACL, EMNLP, NAACL, COLINGï¼ˆæŒ‰å½±å“åŠ›æ’åºï¼‰
*   ML ç†è®ºï¼šICML, NeurIPS, ICLR
*   AI åº”ç”¨ï¼šAAAI, IJCAIï¼ˆè¿™ä¸¤ä¸ªä¼šè®®è¿‘å¹´æ¥å½±å“åŠ›ä¸‹é™ï¼‰

å…¶ä¸­ï¼ŒACL ç³»ä¼šè®®æä¾› anthology ([https://aclweb.org/anthology/](https://aclweb.org/anthology/))

### å‰æ²¿è¿›å±•

å¦‚æœæƒ³äº†è§£æŸä¸€ä¸ªé¢†åŸŸçš„å‰æ²¿è¿›å±•ï¼Œé€šå¸¸ä¼šå…³æ³¨ [arXiv](https://arxiv.org/)ï¼ˆé¢„å°æœ¬ï¼‰ï¼Œéƒ¨åˆ†ä½œè€…ä¼šé€‰æ‹©åœ¨å‘è¡¨å‰å°†è®ºæ–‡ä¸Šä¼ è‡³ arXivã€‚arXiv åœ¨å·¥ä½œæ—¥[æ¯æ—¥æ›´æ–°](https://arxiv.org/list/cs.CL/recent)ï¼Œä¾¿äºåŠæ—¶è¿½è¸ªå‰æ²¿åŠ¨æ€

### å·¥å…·

ç»å…¸è®ºæ–‡å¾€å¾€åœ¨ CSDNã€çŸ¥ä¹ç­‰å¹³å°æœ‰ä¸­æ–‡è¯»åæ„Ÿï¼Œå¯ä»¥è¾…åŠ©é˜…è¯»

æ–‡çŒ®åˆ†ç±»æ•´ç†æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ï¼Œå»ºè®®æ ¹æ®ä¸ªäººå–œå¥½é€‰æ‹©è¯¸å¦‚ Zoteroï¼ˆç•Œé¢ç®€æ´ã€è·¨å¹³å°ã€å…è´¹ã€æ‰©å±•ä¸°å¯Œï¼‰, Endnote, Mendeley, Papers ç­‰æ–‡çŒ®ç®¡ç†è½¯ä»¶

åˆå­¦æ—¶åšå¥½è®ºæ–‡ç¬”è®°ï¼Œå¯ä»¥ä½¿ç”¨ Markdownï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ Notionã€Obsidianã€OneNote ç­‰ç¬”è®°è½¯ä»¶

åŠ¨æ‰‹å®è·µ
----

ä½œä¸ºè®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼ŒNLP åŒæ ·ç¦»ä¸å¼€ä»£ç ï¼Œè¯·æœ‰å¿—åŠ å…¥ TANGENT çš„åŒå­¦å®Œæˆä»¥ä¸‹ç»ƒä¹ ä»»åŠ¡ã€‚

### å†™åœ¨å‰é¢

åœ¨å®Œæˆè¿™äº›ä»»åŠ¡ä¹‹å‰ï¼Œè¿˜æ˜¯éœ€è¦ä¸€äº›è¯´æ˜ã€‚

ä¸€ä¸ªæ·±åº¦å­¦ä¹ é¡¹ç›®çš„æµç¨‹é€šå¸¸æ˜¯è¿™æ ·çš„ï¼š

1.  æ•°æ®è¯»å–å’Œé¢„å¤„ç†ï¼Œå¾—åˆ° Dataset å’Œ DataLoader
2.  æ„å»º Modelã€Optimizer
3.  ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™è¿­ä»£ä¼˜åŒ–æ¨¡å‹å‚æ•°
4.  è®¾ç½® Metricï¼Œå¯¹æ¨¡å‹è¿›è¡Œè¯„æµ‹

é€šå¸¸æˆ‘ä»¬ä¹Ÿä¼šæŒ‰ç…§ä¸Šè¿°æµç¨‹å’Œæµç¨‹ä¸­å‡ºç°çš„å„ä¸ªæ¨¡å—ç»„ç»‡é¡¹ç›®æ–‡ä»¶ï¼Œä¸€ä¸ªé¡¹ç›®å¾€å¾€ä¼šåŒ…å«è¿™äº›æ–‡ä»¶ï¼šä¸»å‡½æ•°ï¼ˆå…¥å£ï¼Œè´Ÿè´£ä»¥ä¸Šæµç¨‹çš„æ§åˆ¶ï¼‰ï¼Œæ•°æ®è¯»å–å’Œé¢„å¤„ç†ï¼Œæ¨¡å‹ï¼ŒMetricã€‚

æˆ‘ä»¬é’ˆå¯¹ä»»åŠ¡äºŒï¼Œç»™å‡ºäº†ä¸€ä¸ª ChineseNER å®Œæ•´é¡¹ç›®çš„æºä»£ç ã€‚éœ€æ³¨æ„ï¼Œä¸‹é¢éƒ¨åˆ†ä»»åŠ¡å‚è€ƒä»£ç æ˜¯ä»¥ Notebook çš„å½¢å¼ç»„ç»‡çš„ï¼Œåœ¨å®Œæˆä»»åŠ¡æ—¶ï¼Œè¯·å‚è€ƒ ChineseNER é‡æ–°ç»„ç»‡ä»£ç ã€‚

### ä»»åŠ¡ä¸€ï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æœ¬åˆ†ç±»

æ–‡æœ¬åˆ†ç±»æ˜¯å…¥é—¨ NLP çš„ä¸€ä¸ªå¥½çš„å¼€å§‹ï¼ŒåŒæ—¶ NLUï¼ˆè‡ªç„¶è¯­è¨€ç†è§£ï¼‰ä»»åŠ¡æœ¬è´¨ä¸Šæ¥è¯´éƒ½å¯ä»¥å½’ç±»ä¸ºæ–‡æœ¬åˆ†ç±»ã€‚è¯·ä½¿ç”¨ CNN æˆ– RNNï¼ˆLSTMï¼‰ å®Œæˆ Kaggle ä¸Šä¸€ä¸ªç®€å•çš„æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€‚

ä»»åŠ¡æè¿° & æ•°æ®é›†ï¼š[https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/)

Kaggle é‡Œä¹Ÿæœ‰ä¸€äº›[ä»£ç ](https://www.kaggle.com/competitions/sentiment-analysis-on-movie-reviews/code)å¯ä»¥å‚è€ƒï¼Œå¦‚ï¼š[LSTM å®ç°](https://www.kaggle.com/code/hanjoonchoe/movie-sentimental-analysis-lstm-pytorch)

å‚è€ƒæ–‡çŒ®ï¼š Convolutional Neural Networks for Sentence Classification ([https://aclanthology.org/D14-1181/](https://aclanthology.org/D14-1181/)) Recurrent Convolutional Neural Networks for Text Classification ([https://www.deeplearningitalia.com/wp-content/uploads/2018/03/Recurrent-Convolutional-Neural-Networks-for-Text-Classification.pdf](https://www.deeplearningitalia.com/wp-content/uploads/2018/03/Recurrent-Convolutional-Neural-Networks-for-Text-Classification.pdf))

### ä»»åŠ¡äºŒï¼šåŸºäº LSTM-CRF çš„å‘½åå®ä½“è¯†åˆ«

åœ¨ NLP ä¸­ï¼Œç»“æ„é¢„æµ‹ï¼ˆStructured Predictionï¼‰æ˜¯æŒ‡è¾“å‡ºç©ºé—´ä¸ºç»“æ„åŒ–å¯¹è±¡çš„ä¸€ç±»ä»»åŠ¡ï¼ŒåŒ…æ‹¬å‘½åå®ä½“è¯†åˆ«ã€å…³ç³»æŠ½å–ã€å…±æŒ‡æ¶ˆè§£ç­‰å­ä»»åŠ¡ï¼Œå‘½åå®ä½“è¯†åˆ«åˆå±äºåºåˆ—æ ‡æ³¨é—®é¢˜ã€‚è¯·å®ç°ç®€å•çš„åŸºäº LSTM-CRF çš„å‘½åå®ä½“è¯†åˆ«

ä»»åŠ¡æè¿°ï¼š[https://www.clips.uantwerpen.be/conll2003/ner/](https://www.clips.uantwerpen.be/conll2003/ner/)

æ•°æ®é›†ï¼šæœ¬ä»“åº“ [CoNLL03](https://github.com/PKU-TANGENT/nlp-tutorial/tree/main/CoNLL03) æ–‡ä»¶å¤¹ä¸‹

å‚è€ƒæ–‡çŒ®ï¼š Neural Architectures for Named Entity Recognition ([https://arxiv.org/pdf/1603.01360.pdf](https://arxiv.org/pdf/1603.01360.pdf))

ä¸ºäº†ç®€åŒ–ä»»åŠ¡éš¾åº¦ï¼Œæˆ‘ä»¬ç»™å‡ºäº†åŸºäº LSTM çš„ä¸­æ–‡å‘½åå®ä½“è¯†åˆ«çš„ä»£ç ï¼Œå¯å‚è€ƒè¯¥ä»£ç å°†å…¶è¿ç§»è‡³ CoNLL03 è‹±æ–‡æ•°æ®é›†ä¸Šï¼Œè¿›è¡Œå®éªŒè§‚å¯Ÿåˆæ­¥ç»“æœï¼Œåç»­å†å¢åŠ  CRF å±‚ã€‚

### ä»»åŠ¡ä¸‰ï¼šNeural Machine Translation (NMT)

æ‘˜è¦å’Œç¿»è¯‘æ˜¯æ–‡æœ¬ç”Ÿæˆä¸­æ¯”è¾ƒä¸»æµçš„ä¸¤å¤§ä»»åŠ¡ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬é€‰å– PyTorch tutorial ä¸­çš„æ–‡æœ¬ç¿»è¯‘ä½œä¸ºå…¥é—¨é¡¹ç›®ã€‚

è¯·æŒ‰ç…§ [PyTorch æ–‡æœ¬ç¿»è¯‘æ•™ç¨‹](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)ï¼Œä¸€æ­¥æ­¥å®ç°ä¸€ä¸ªç®€å•çš„æ–‡æœ¬ç¿»è¯‘æ¨¡å‹ï¼Œæ³¨æ„è¯·å‚è€ƒ ChineseNER çš„ç»„ç»‡æ–¹å¼é‡æ„ä»£ç ã€‚

ç”Ÿæˆä»»åŠ¡æ¶‰åŠåˆ°çš„ç»†èŠ‚è¾ƒå¤šï¼Œå¦‚ encoder-decoderï¼Œteacher forcingï¼Œbeam search ç­‰ï¼Œtutorial ä¸­ç»™å‡ºäº†æ·±å…¥æµ…å‡ºçš„ä»‹ç»ï¼Œè¯·ä»”ç»†é˜…è¯»å¹¶ç†è§£ã€‚

### ä»»åŠ¡å››ï¼šTransformer & PLM

ä»¥ BERTã€GPT ä¸ºä»£è¡¨çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPretrain Language Modelï¼ŒPLMï¼‰çš„å‡ºç°ä½¿ NLP ç¿»å¼€äº†æ–°çš„ä¸€é¡µï¼Œç›®å‰çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å¤§å¤šåŸºäº Transformerï¼Œå› æ­¤æƒ³è¦è¿½è¸ªå‰æ²¿ NLP æŠ€æœ¯ï¼Œæˆ‘ä»¬ä¸å¾—ä¸å¯¹ Transformer æœ‰æ·±å…¥çš„ç†è§£ã€‚

è¯·ç»“åˆ Attention Is All You Need åŸè®ºæ–‡ï¼Œè¯»æ‡‚ [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)

å»ºè®®ç»§ç»­é˜…è¯»ï¼š [encoder-decoder ç»“æ„](https://huggingface.co/blog/encoder-decoder#encoder-decoder) [å¯è§†åŒ– Transformer](http://jalammar.github.io/illustrated-transformer/) [å…³äº decode](https://huggingface.co/blog/how-to-generate)

å…³äºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œè¯·é˜…è¯» BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding å¹¶åšé˜…è¯»ç¬”è®°ï¼Œé‡ç‚¹å…³æ³¨ BERT æ˜¯å¦‚ä½•è®­ç»ƒå‡ºæ¥çš„ï¼Œä»¥åŠå¦‚ä½•å°† BERT åº”ç”¨äºä¸‹æ¸¸ä»»åŠ¡ã€‚

æˆ‘ä»¬åœ¨å®è·µä¸­é€šå¸¸ä¼šä½¿ç”¨ HuggingFaceğŸ¤— çš„ Transformers åº“ï¼Œè¯¥åº“æä¾›äº†åŒ…æ‹¬ BERT å’Œ GPT åœ¨å†…çš„å¸¸è§é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œä»£ç é£æ ¼è¾ƒå¥½ï¼Œ[æ–‡æ¡£](https://huggingface.co/docs/transformers/main/index)è¯¦ç»†ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ [Transformers æ•™ç¨‹](https://huggingface.co/course/)è¿›è¡Œå­¦ä¹ ã€‚

å®Œæˆæœ¬å°èŠ‚ä»»åŠ¡åï¼Œå¦‚æœå­¦æœ‰ä½™åŠ›ï¼Œå¯å°è¯•åŸºäº Transformers åº“ï¼Œå®ç°åŸºäº BERT çš„æ–‡æœ¬åˆ†ç±»å’Œ NERã€‚

æœ¬ä»“åº“çš„ä½¿ç”¨è¯´æ˜
--------

1.  æœ‰é—®é¢˜å°±æåœ¨issuesé‡Œé¢ï¼ŒåŒç†ä½ ä¹Ÿå¯ä»¥åœ¨issuesé‡Œé¢æ£€ç´¢æ˜¯å¦å·²ç»æœ‰ä½ é‡åˆ°çš„é—®é¢˜ï¼›
2.  mainåˆ†æ”¯æ— æ³•ç›´æ¥ä¿®æ”¹ï¼Œæ‰€æœ‰ä¿®æ”¹å‡éœ€è¦é€šè¿‡æäº¤`Pull requests`æ¥å®ç°ï¼Œå¿…é¡»é€‰æ‹©è‡³å°‘ä¸€ä¸ªreviewerï¼Œæ¨èé€‰æ‹©å¤§å¸ˆå…„`Yifan-Song793`æ¥reviewï¼›
3.  git commitçš„è§„èŒƒçœ‹[è¿™é‡Œ](https://juejin.cn/post/6844903793033756680)ï¼Œç¦æ­¢ä½¿ç”¨æ„ä¹‰ä¸æ˜çš„testã€addç­‰è¯­å¥ã€‚

é¦–æ¬¡è½¬è½½ï¼šå­¤é£-åšå®¢å›­

ä¸ªäººåšå®¢ï¼š[https://blog.onefly.top](https://blog.onefly.top)

ä»“åº“åœ°å€ï¼š[PKU-TANGENT/nlp-tutorial: NLPæ–°æ‰‹å…¥é—¨æ•™ç¨‹ (github.com)](https://github.com/PKU-TANGENT/nlp-tutorial)