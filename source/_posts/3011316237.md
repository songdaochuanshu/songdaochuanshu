---
layout: post
title: "k8s驱逐篇(5)-kube-controller-manager驱逐"
date: "2022-12-11T10:16:47.987Z"
---
k8s驱逐篇(5)-kube-controller-manager驱逐
===================================

kube-controller-manager驱逐主要依靠NodeLifecycleController以及其中的TaintManager；开启了污点驱逐：node上有NoExecute污点后，立马驱逐不能容忍污点的pod，对于能容忍该污点的pod，则等待pod上配置的污点容忍时间里的最小值后，pod会被驱逐；未开启污点驱逐：当node的ready Condition值为false或unknown且已经持续了一段时间时，对该node上的pod做驱逐操作；

kube-controller-manager驱逐
-------------------------

概述
--

kube-controller-manager驱逐主要依靠`NodeLifecycleController`以及其中的`TaintManager`；

#### kube-controller-manager驱逐分类

（1）开启了污点驱逐：node上有`NoExecute`污点后，立马驱逐不能容忍污点的pod，对于能容忍该污点的pod，则等待pod上配置的污点容忍时间里的最小值后，pod会被驱逐；

（2）未开启污点驱逐：当node的`ready Condition`值为false或unknown且已经持续了一段时间（通过kcm启动参数`--pod-eviction-timeout`配置，默认5分钟）时，对该node上的pod做驱逐操作；

#### NodeLifecycleController

`NodeLifecycleController`主要负责以下工作：  
（1）定期检查node的心跳上报，某个node间隔一定时间都没有心跳上报时，更新node的`ready condition`值为false或unknown，开启了污点驱逐的情况下，给该node添加`NoExecute`的污点；  
（2）未开启污点驱逐时的pod驱逐工作；  
（3）根据kcm启动参数配置，决定是否启动`TaintManager`；

#### TaintManager

`TaintManager`负责pod的污点驱逐工作，当node上有`NoExecute`污点后，立马驱逐不能容忍污点的pod，对于能容忍该污点的pod，则等待pod上配置的污点容忍时间里的最小值后，pod会被驱逐；

#### kcm驱逐相关参数配置

（1）`--pod-eviction-timeout`：默认值5分钟，当不开启污点驱逐时该参数起效，当node的ready condition值变为false或unknown并持续了5分钟后，将驱逐该node上的pod；  
（2）`--enable-taint-manager`：默认值true，代表启动`taintManager`，当已经调度到该node上的pod不能容忍node的 `NoExecute`污点时，由`TaintManager`负责驱逐此类pod，若为false即不启动`taintManager`，则根据`--pod-eviction-timeout`来做驱逐操作；  
（3）`--feature-gates=TaintBasedEvictions=xxx`：默认值true，配合`--enable-taint-manager`共同作用，两者均为true，才会开启污点驱逐；  
（4）`--node-monitor-grace-period`：默认值40秒，代表在距离上一次上报心跳时间超过40s后，将该node的conditions值更新为unknown（kubelet通过更新node lease来上报心跳）；  
（5）`--feature-gates=NodeLease=xxx`：默认值true，使用lease对象上报node心跳信息，替换老的更新node的status的方式，能大大减轻apiserver的负担；

更多其他配置参数会在后面做源码分析时进行分析；

kcm污点驱逐
-------

需要配置kcm相关的参数，来开启kcm污点驱逐，`taint`和`toleration`才会发挥作用；

#### taint

给node配置，打了taint的node节点可能会影响pod的调度和运行；

taint有三种`Effect`：  
（1）`PreferNoSchedule`：不容忍该污点的pod，调度器`kube-scheduler`会尽量避免把pod调度到具有该污点的节点上，如果不能避免（如其他节点资源不足等），pod也能调度到具有该污点的节点上，而对于已存在于具有该污点的节点上的pod不会被驱逐；  
（2）`NoSchedule`：不容忍该污点的pod一定不会被调度到具有该污点的节点上，而对于已存在于具有该污点的节点上的pod不会被驱逐；  
（3）`NoExecute`：不容忍该污点的pod一定不会被调度到具有该污点的节点上，同时会将已调度到该节点上但不容忍该污点的node节点上的pod驱逐掉；

#### toleration

给pod配置，配置了Toleration的pod，根据匹配条件可以容忍node的taint；

`Toleration`配置的属性值解析如下：  
（1）`Key`：匹配node污点的Key；  
（2）`Operator`：表示`Toleration`中Key与node污点的Key相同时，其Value与node污点的Value的关系，默认值`Equal`，代表相等，`Exists`则代表`Toleration`中Key与node污点的Key相同即可，不用比较其Value值；  
（3）`Value`：匹配node污点的Value；  
（4）`Effect`：匹配node污点的Effect；  
（5）`TolerationSeconds`：node污点容忍时间；

配置示例：

    tolerations:
    - key: "key1"
      operator: "Equal"
      value: "value1"
      effect: "NoExecute"
      tolerationSeconds: 3600
    

上述配置表示如果该pod正在运行，同时一个匹配的污点被添加到其所在的node节点上，那么该pod还将继续在节点上运行3600秒，然后会被驱逐（如果在此之前其匹配的node污点被删除了，则该pod不会被驱逐）；