---
layout: post
title: "ETL工具Datax、sqoop、kettle 的区别"
date: "2022-10-06T11:20:16.656Z"
---
ETL工具Datax、sqoop、kettle 的区别
===========================

**一、Sqoop主要特点：**

1.可以将关系型数据库中的数据导入到hdfs，hive，hbase等hadoop组件中，也可以将hadoop组件中的数据导入到关系型数据库中；

2.sqoop在导入导出数据时，充分采用了map-reduce计算框架（默认map数为4），根据输入条件生成一个map-reduce作业（只有map，没有reduce），在hadoop集群中运行。采用map-reduce框架同时在多个节点进行import或者export操作，熟读比单节点运行多个并行效率高，同时提供了良好的并发性和容错性；

3.支持insert，update模式，可以选择参数，若内容存在就更新，若不存在就插入；

4.对国外主流关系型数据库支持性更好。

**二、Datax 主要特点：**

1、异构数据库和文件系统之间的数据交换；

2、采用 Framework + plugin 架构构建，Framework 处理了缓冲，流控，并发，上下文加载等高速数据交换的大部分技术问题，提供了简单的接口与插件交互，插件仅需实现对数据处理系统的访问；

3、数据传输过程在单进程（单进程多线程）内完成，全内存操作，不读写磁盘，也没有 IPC（进程之间的通信）；

4、开放式的框架，开发者可以在极短的时间开发一个新插件以快速支持新的数据库/文件系统。

**三、Kettle 主要特点：**

1、kettle （数据抽取、清洗、转换、装载）是由 java 编写,可以在 Window、Linux、Unix 上运行。支持多数据源, 多种中间件的专业 ETL 工具。

2、支持图形化 GUI 设计界面，组件多样性，支持 http 请求,上手简单支持拖拽，支持 sql , 可以编写js ,可以编写一些 java 代码，然后以工作流的形式流转。如果没有冲突可以并行执行，并行开发。在工具内可以查看 读 写 修改 输出 更新 拒绝 错误 等 一些参数，快速定位和纠错。

**四、Sqoop 和 Datax 的区别：**

1、sqoop 采用 map-reduce 计算框架进行导入导出，而 datax 仅仅在运行 datax 的单台机器上进行数据的

抽取和加载，速度比 sqoop 慢了许多；

2、sqoop 只可以在关系型数据库和 hadoop 组件之间进行数据迁移，而在 hadoop 相关组件之间，比如

hive 和 hbase 之间就无法使用 sqoop 互相导入导出数据，同时在关系型数据库之间，比如 mysql 和

oracle 之间也无法通过 sqoop 导入导出数据。与之相反，datax 能够分别实现关系型数据库 hadoop 组件

之间、关系型数据库之间、hadoop 组件之间的数据迁移；

3、sqoop 是专门为 hadoop 而生，对 hadoop 支持度好，而 datax 可能会出现不支持高版本 hadoop 的现象；

4、sqoop 只支持官方提供的指定几种关系型数据库和 hadoop 组件之间的数据交换，而在 datax 中，用户

只需根据自身需求修改文件，生成相应 rpm 包，自行安装之后就可以使用自己定制的插件；

**五、Kettle 与 DataX 的区别：**

1、Kettle 拥有自己的管理控制台，可以直接在客户端进行 etl 任务制定，不过是 CS 架构（服务器-客户机），而不支持 BS（浏览器-服务器）架构。DataX 并没有界面，界面完全需要自己开发，增加了很大工作量。

2、Kettle 可以与我们自己的工程进行集成，通过 JAVA 代码集成即可，可以在 java 中调用 kettle 的转换、执行、结束等动作，这个还是有意义的，而 DataX 是不支持的，DataX 是以执行脚本的方式运行任务的，当然完全吃透源码的情况下，应该也是可以调用的。

3、支持的数据库，都支持的比较齐全，kettle 支持的应该更多，DataX 是阿里开发，可以更好地支持阿里自身的数据库系列，如 ODPS、ADS 等

4、Kettle 已经加入 BI 组织 Pentaho，加入后 kettle 的开发粒度和被关注度更进一步提升

5、DataX 开源的支持粒度不高，关注度远没有 kettle 高，代码提交次数更是少的很。

**六、Kettle 与 Sqoop 的区别**

1、Kettle 中有两种脚本文件，transformation 和 job，transformation 完成针对数据的基础转换，job则完成整个工作流的控制；Sqoop 主要用于在 Hadoop(Hive)与传统的数据库(mysql、postgresql...)间进行数据的传递

2、kettle 有图形化的操作界面，只需要描述你想做什么，而不是你想怎么做；sqoop 没有图形化界面，具体的数据流向需要手工配置。

3、kettle 底层使用多线程以提高效率；Sqoop 专为大数据批量传输设计，能够分割数据集并创建 Hadoop任务来处理每个区块。

4、kettle 可以利用 transformation 在数据传输过程中对数据的一些转换处理；Sqoop 只是一个用来将Hadoop 和关系型数据库中的数据相互转移的工具

5、kettle 数据的具体流向可以指定，可以是各种数据的存储工具；sqoop 只是完成 hdfs 到关系型数据库或者 关系型数据库到 hdfs 的数据传输，在传输的过程中保证传输数据的类型