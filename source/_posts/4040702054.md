---
layout: post
title: "Filebeat和logstash 使用过程中遇到的一些小问题记录"
date: "2022-04-06T16:25:42.613Z"
---
Filebeat和logstash 使用过程中遇到的一些小问题记录
=================================

一、filebeat 收集软链文件日志
-------------------

### 1.1、场景

1.  由于我们新部署的`Nginx` 日志都是采用的软链的形式。
    
        lrwxrwxrwx 1 root  root      72 Apr  6 00:00 jy.baidu.com-80-access.log -> /usr/local/openresty/nginx/logs/jy.usmartsg.com-80-access.log.2022040600
        -rw-r--r-- 1 nginx root 4502502 Apr  3 23:59 jy.baidu.com-80-access.log.2022040300
        -rw-r--r-- 1 nginx root 5790629 Apr  5 00:00 jy.baidu.com-80-access.log.2022040400
        -rw-r--r-- 1 nginx root 9166562 Apr  5 23:59 jy.baidu.com-80-access.log.2022040500
        -rw-r--r-- 1 nginx root 2447936 Apr  6 09:31 jy.baidu.com-80-access.log.2022040600
        
    
2.  我们收集日志的时候，通过配置`filebeat` 收集日志文件 `jy.baidu.com-80-access.log`, 因为这个文件会一直软链到最新的日志文件。
    
3.  但是我们会发现在启动`filebeat` 后 `filebeat` 并没有报错什么。 但是我们`logstash` 好像也没有往es 写日志。
    

### 1.2、问题排查

1.  我们首先是通过开启`filebeat` 的 debug模式，就是看下 `filebeat` 的详细日志，这一步理论上来说，我们应该先通过`kafka` 看下是否有日志写入`kafka`。 但是没有关系，我们通过看 `filebeat` 的详细日志。 可以一步分析到位。
    
        logging.level: debug
        
    
2.  我们在日志中可以看到下面的信息
    
        2022-04-03T19:48:21.675+0800        DEBUG        [monitoring]        memqueue/eventloop.go:228        handle ACK took: 54.938µs
        2022-04-03T19:48:21.675+0800        DEBUG        [monitoring]        memqueue/ackloop.go:128        ackloop: return ack to broker loop:1
        2022-04-03T19:48:21.675+0800        DEBUG        [monitoring]        memqueue/ackloop.go:131        ackloop:  done send ack
        2022-04-03T19:48:23.443+0800        DEBUG        [input]        input/input.go:152        Run input
        2022-04-03T19:48:23.443+0800        DEBUG        [input]        log/input.go:174        Start next scan
        2022-04-03T19:48:23.443+0800        DEBUG        [input]        log/input.go:273        File /usr/local/openresty/nginx/logs/jy.usmartsg.com-80-access.log skipped as it is a symlink.
        2022-04-03T19:48:23.443+0800        DEBUG        [input]        log/input.go:195        input states cleaned up. Before: 1, After: 1, Pending: 0
        2022-04-03T19:48:26.443+0800        DEBUG        [input]        input/input.go:152        Run input
        2022-04-03T19:48:26.444+0800        DEBUG        [input]        log/input.go:174        Start next scan
        
    
    日志内容
    
        File /usr/local/openresty/nginx/logs/jy.usmartsg.com-80-access.log skipped as it is a symlink.
        
    
    我们可以看到文件因为是软链接所以被忽略了。
    
3.  我们查看官方文档，需要增加配置 `symlinks: true`
    
        filebeat.inputs:
        - type: log
          symlinks: true
        
    
4.  然后我们重启`filebeat` 就可以看到有日志写入kafka了。
    

二、logstash
----------

### 2.1、logstash 解析日志不写入es

每个人的场景不一样。这里只提供大概思路。

1.  kafka 是否有数据， 可以kafka consumer 进行订阅用不同的 group 来同一个 topic。 进行查看是否有kafka数据
    
2.  看 `logstash` 启动是否有报错。
    
        [2022-04-02T20:55:06,432][INFO ][logstash.runner          ] Starting Logstash {"logstash.version"=>"6.8.0"}
        [2022-04-02T20:55:07,554][ERROR][logstash.agent           ] Failed to execute action {:action=>LogStash::PipelineAction::Create/pipeline_id:main, :exception=>"LogStash::ConfigurationError", :message=>"Expected one of #, {, } at line 5, column 43 (byte 118) after input {\n  kafka {\n    group_id => \"hz-sg\"\n    topics => [\"hz-sg-nginxlog\"]\n    bootstrap_servers => \"10.59.4.50:9092\"", :backtrace=>["/usr/share/logstash/logstash-core/lib/logstash/compiler.rb:41:in `compile_imperative'", "/usr/share/logstash/logstash-core/lib/logstash/compiler.rb:49:in `compile_graph'", "/usr/share/logstash/logstash-core/lib/logstash/compiler.rb:11:in `block in compile_sources'", "org/jruby/RubyArray.java:2577:in `map'", "/usr/share/logstash/logstash-core/lib/logstash/compiler.rb:10:in `compile_sources'", "org/logstash/execution/AbstractPipelineExt.java:151:in `initialize'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:22:in `initialize'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline.rb:90:in `initialize'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline_action/create.rb:43:in `block in execute'", "/usr/share/logstash/logstash-core/lib/logstash/agent.rb:96:in `block in exclusive'", "org/jruby/ext/thread/Mutex.java:165:in `synchronize'", "/usr/share/logstash/logstash-core/lib/logstash/agent.rb:96:in `exclusive'", "/usr/share/logstash/logstash-core/lib/logstash/pipeline_action/create.rb:39:in `execute'", "/usr/share/logstash/logstash-core/lib/logstash/agent.rb:334:in `block in converge_state'"]}
        [2022-04-02T20:55:07,807][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
        [2022-04-02T20:55:12,703][INFO ][logstash.runner          ] Logstash shut down.
        
        
    
    像这种就是配置文件格式可能存在一些问题。
    
        [2022-04-02T20:36:04,433][ERROR][logstash.pipeline        ] Error registering plugin {:pipeline_id=>"main", :plugin=>"#<LogStash::FilterDelegator:0x5fdbe919>", :error=>"pattern %{SERVICE:service} not defined", :thread=>"#<Thread:0x20114a64 run>"}
        
        
    
    这种报错就是我们没有定义变量的匹配规则。
    
3.  还有一种是我们最近遇到了的，就是我在 es 的 output 的时候，引用了一个变量 `service` 。 但是前面没有定义这个。最后这个logstash 也没有报错，就是写不到 es 里面。
    
                elasticsearch {
                    hosts => ["10.59.4.50","10.59.4.51","10.59.4.52"]
                    index => "%{[service]-%{+YYYY.MM.dd}"
                    template => "/etc/logstash/template/nginx.json"
                    template_name => "nginx.json"
                    template_overwrite => true
                    user => "elastic"
                    password => "1111111"
                }
        
        
    
4.  开启日志debug. `/etc/logstash/logstash.yml`
    
        #log.level: debug
        
    

### 2.2、logstash 配置多个后端

1.  `logstash -f /opt/logstash/conf/conf.d/`
    
    注意`/conf.d/` 后面不要加\*\*\*\*\* 这样会导致只匹配一个。
    
2.  使用多个配置文件里面的**input、filter、output** 不是互相独立的。
    
    logstash读取多个配置文件只是简单的将所有配置文件整合到了一起
    
    如果要彼此独立，需要自己加字段，然后在output 判断一下 ，通过字段进行区分。
    

作者：[理想三旬](https://www.cnblogs.com/operationhome/)

出处：

如果觉得文章写得不错，或者帮助到您了，请点个赞，加个关注哦。运维学习交流群:544692191

本文版权归作者所有，欢迎转载，如果文章有写的不足的地方，或者是写得错误的地方，请你一定要指出，因为这样不光是对我写文章的一种促进，也是一份对后面看此文章的人的责任。谢谢。