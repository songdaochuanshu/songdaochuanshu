---
layout: post
title: "ã€æ‰‹æ“æ¨¡å‹ã€‘äº²æ‰‹å®ç° Vision Transformer"
date: "2023-03-18T01:10:28.750Z"
---
ã€æ‰‹æ“æ¨¡å‹ã€‘äº²æ‰‹å®ç° Vision Transformer
=============================

äº²æ‰‹ä½¿ç”¨ pytorch æ„å»º ViT çš„æ¨¡å‹ä»£ç 

> ğŸš©å‰è¨€
> ====
> 
> *   ğŸ³åšå®¢ä¸»é¡µï¼šğŸ˜š[ç¡æ™šä¸çŒ¿åºç¨‹](https://www.cnblogs.com/whp135/)ğŸ˜š
> *   âŒšé¦–å‘æ—¶é—´ï¼š2023.3.17ï¼Œé¦–å‘äºåšå®¢å›­
> *   â°æœ€è¿‘æ›´æ–°æ—¶é—´ï¼š2023.3.17
> *   ğŸ™†æœ¬æ–‡ç”± **ç¡æ™šä¸çŒ¿åºç¨‹** åŸåˆ›
> *   ğŸ¤¡ä½œè€…æ˜¯è’»è’Ÿæœ¬è’Ÿï¼Œå¦‚æœæ–‡ç« é‡Œæœ‰ä»»ä½•é”™è¯¯æˆ–è€…è¡¨è¿°ä¸æ¸…ï¼Œè¯· tt æˆ‘ï¼Œä¸‡åˆ†æ„Ÿè°¢ï¼orz

**ç›¸å…³æ–‡ç« ç›®å½•** ï¼šæ— 

* * *

**ç›®å½•**

ç›®å½•

*   [ğŸš©å‰è¨€](#å‰è¨€)
*   [1\. å†…å®¹ç®€ä»‹](#1-å†…å®¹ç®€ä»‹)
*   [2\. Vision Transformer æ€»è§ˆ](#2-vision-transformer-æ€»è§ˆ)
*   [3\. æ‰‹æ’• Transformer](#3-æ‰‹æ’•-transformer)
    *   [3.1 é¢„å¤„ç†éƒ¨åˆ†](#31-é¢„å¤„ç†éƒ¨åˆ†)
        *   [3.1.1 patch åˆ’åˆ†](#311-patch-åˆ’åˆ†)
        *   [3.1.2 çº¿æ€§åµŒå…¥](#312-çº¿æ€§åµŒå…¥)
        *   [3.1.3 æ’å…¥ CLS Token](#313-æ’å…¥-cls-token)
        *   [3.1.4 åµŒå…¥ä½ç½®ä¿¡æ¯](#314-åµŒå…¥ä½ç½®ä¿¡æ¯)
    *   [3.2 Transformer](#32-transformer)
        *   [3.2.1 å¤šå¤´è‡ªæ³¨æ„åŠ›](#321-å¤šå¤´è‡ªæ³¨æ„åŠ›)
        *   [3.2.2 FeedForward](#322-feedforward)
        *   [3.2.3 Transformer Block](#323-transformer-block)
    *   [ViT](#vit)
*   [æ€»ç»“](#æ€»ç»“)
*   [å‚è€ƒ](#å‚è€ƒ)

1\. å†…å®¹ç®€ä»‹
========

æœ€è¿‘åœ¨å‡†å¤‡ä½¿ç”¨ Transformer ç³»åˆ—ä½œä¸º backbone å®Œæˆè‡ªå·±çš„ä»»åŠ¡ï¼Œæ„Ÿè§‰è‡ªå·±æ‰“ä»£ç çš„æ¬¡æ•°ä¹Ÿæ¯”è¾ƒå°‘ï¼Œæ­£å¥½ç›´æ¥ç”¨åˆ«äººå†™çš„ä»£ç è¿›è¡Œè®­ç»ƒçš„åŒæ—¶ï¼Œè‡ªå·±çœ‹ç€ ViT çš„è®ºæ–‡ä»¥åŠåˆ«äººå®ç°çš„ä»£ç è‡ªå·±å®ç°ä¸€ä¸‹ ViT

æ„Ÿè§‰ ViT ç›¸å¯¹æ¥è¯´å®ç°è¿˜æ˜¯æ¯”è¾ƒç®€å•çš„ï¼Œä¹Ÿç®—æ˜¯å¯¹è‡ªå·±ä»£ç èƒ½åŠ›çš„ä¸€æ¬¡ç»ƒä¹ å§ï¼Œå¥½çš„ï¼Œæˆ‘ä»¬æ¥ä¸‹æ¥å¼€å§‹æ‰‹æ’• ViT

* * *

2\. Vision Transformer æ€»è§ˆ
=========================

![ViT](https://blog-1312258508.cos.ap-shanghai.myqcloud.com/ViT.jpg#pic_center)

æˆ‘è¿™é‡Œé»˜è®¤å¤§å®¶éƒ½ç†è§£äº† Transformer çš„æ„é€ äº†ï¼å¦‚æœæœ‰éœ€è¦æˆ‘å¯ä»¥å†å‘ä¸€ä¸‹ Transformer ç›¸å…³çš„å†…å®¹

ViT çš„æ€»ä½“æ¶æ„å’Œ Transformer ä¸€è‡´ï¼Œå› ä¸ºå®ƒçš„ç›®æ ‡å°±æ˜¯å¸Œæœ›ä¿è¯ Transformer çš„æ€»ä½“æ¶æ„ä¸å˜ï¼Œå¹¶å°†å…¶åº”ç”¨åˆ° CV ä»»åŠ¡ä¸­ï¼Œå®ƒå¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š

1.  é¢„å¤„ç†
    
    åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š
    
    1.  åˆ’åˆ† patch
    2.  çº¿æ€§åµŒå…¥
    3.  æ·»åŠ  CLS Token
    4.  æ·»åŠ ä½ç½®ç¼–ç 
2.  ä½¿ç”¨ Transformer Block è¿›è¡Œå¤„ç†
    
3.  MLP åˆ†ç±»å¤´åŸºäº CLS Token è¿›è¡Œåˆ†ç±»
    

ä¸Šé¢è®²è¿°çš„æ˜¯å¤§æ¡†æ¶ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æ·±å…¥ ViT çš„Transformer Block å»çœ‹ä¸€ä¸‹å’ŒåŸæœ¬çš„ Transformer æœ‰ä»€ä¹ˆåŒºåˆ«

**Transformer Block**

![image-20230316223251693](https://blog-1312258508.cos.ap-shanghai.myqcloud.com/image-20230316223251693.png#pic_center)

å’Œ Transformer åŸºæœ¬ä¸€è‡´ï¼Œä½†æ˜¯ä½¿ç”¨çš„æ˜¯ Pre-Normï¼Œä¹Ÿå°±æ˜¯å…ˆè¿›è¡Œ LayerNorm ç„¶åå†åšè‡ªæ³¨æ„åŠ›/MLPï¼Œè€Œ Transformer é€‰æ‹©çš„æ˜¯ Pose-Normï¼Œä¹Ÿå°±æ˜¯å…ˆåšè‡ªæ³¨æ„åŠ›/MLP ç„¶åå†åš LayerNorm

Pre-Norm å’Œ Pose-Norm å„æœ‰ä¼˜åŠ£ï¼š

*   Pre-Norm å¯ä»¥ä¸ä½¿ç”¨ warmupï¼Œè®­ç»ƒæ›´ç®€å•
*   Pose-Norm å¿…é¡»ä½¿ç”¨ warmup ä»¥åŠå…¶ä»–æŠ€æœ¯ï¼Œè®­ç»ƒè¾ƒéš¾ï¼Œä½†æ˜¯å®Œæˆé¢„è®­ç»ƒåæ³›åŒ–èƒ½åŠ›æ›´å¥½

> ViT é€‰æ‹©äº† Pre-Normï¼Œæ‰€ä»¥è®­ç»ƒæ›´ä¸ºç®€å•

3\. æ‰‹æ’• Transformer
==================

æ¥ä¸‹æ¥æˆ‘ä»¬ä¸€éƒ¨åˆ†ä¸€éƒ¨åˆ†çš„æ¥æ„å»º ViTï¼Œç”±ä¸€ä¸ªä¸ªç»„ä»¶æœ€åæ‹¼åˆæˆ ViT

3.1 é¢„å¤„ç†éƒ¨åˆ†
---------

![image-20230316225110799](https://blog-1312258508.cos.ap-shanghai.myqcloud.com/image-20230316225110799.png)

è¿™ä¸€éƒ¨åˆ†æˆ‘ä»¬å°†ä¼šæ„å»ºï¼š

1.  åˆ’åˆ† patch
2.  çº¿æ€§åµŒå…¥
3.  æ’å…¥ CLS Token
4.  åµŒå…¥ä½ç½®ç¼–ç ä¿¡æ¯

æˆ‘ä»¬å…ˆæŠŠæ•´ä¸ªéƒ¨åˆ†çš„ä»£ç æ”¾åœ¨è¿™é‡Œï¼Œä¹‹åæˆ‘ä»¬å†è¯¦ç»†è®²è§£

    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from einops import rearrange, repeat
    from einops.layers.torch import Rearrange
    
    
    class pre_proces(nn.Module):
        def __init__(self, image_size, patch_size, patch_dim, dim):
            super().__init__()
            self.patch_size = patch_size
            self.dim = dim
            self.patch_num = (image_size//patch_size)**2
            self.linear_embedding = nn.Linear(patch_dim, dim)
            self.position_embedding = nn.Parameter(torch.randn(1, self.patch_num+1, self.dim))  # ä½¿ç”¨å¹¿æ’­
            self.CLS_token = nn.Parameter(torch.randn(1, 1, self.dim))  # åˆ«å¿˜äº†ç»´åº¦è¦å’Œ (B,L,C) å¯¹é½
    
        def forward(self, x):
            x = rearrange(x, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=self.patch_size, p2=self.patch_size)  # (B,L,C)
            x = self.linear_embedding(x)
            b, l, c = x.shape   # è·å– token çš„å½¢çŠ¶ (B,L,c)
            CLS_token = repeat(self.CLS_token, '1 1 d -> b 1 d', b=b)  # ä½ç½®ç¼–ç å¤åˆ¶ B ä»½
            x = torch.concat((CLS_token, x), dim=1)
            x = x+self.position_embedding
            return x
    

å¯ä»¥å…ˆå¤§æ¦‚æµè§ˆä¸€ä¸‹ï¼Œä¹Ÿä¸æ˜¯å¾ˆéš¾çœ‹æ‡‚å•¦ï¼

### 3.1.1 patch åˆ’åˆ†

    x = rearrange(x, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=self.patch_size, p2=self.patch_size)  # (B,L,C)
    

æˆ‘ä»¬ç›´æ¥ä½¿ç”¨ einops åº“ä¸­çš„ `rearrange` å‡½æ•°æ¥åˆ’åˆ† patchï¼Œæˆ‘ä»¬è¾“å…¥çš„ x çš„æ•°ç»„è¡¨ç¤ºä¸º (B,C,H,W)ï¼Œæˆ‘ä»¬è¦æŠŠå®ƒåˆ’åˆ†æˆ (B,L,C)ï¼Œå…¶ä¸­ \\(L=\\frac W{W\_p}\\times \\frac H{H\_p}\\)ï¼Œä¹Ÿå°±æ˜¯ patch çš„ä¸ªæ•°ï¼Œæœ€å \\(C=W\_p\\times H\_p\\times channels\\)

è¿™ä¸ªå‡½æ•°å°±æŠŠåŸå…ˆçš„ (B,C,H,W) è¡¨ç¤ºæ–¹å¼æ‹†å¼€äº†ï¼Œå¾ˆè½»æ˜“çš„å°±èƒ½å¤Ÿåšåˆ°æˆ‘ä»¬æƒ³è¦çš„ patch åˆ’åˆ†ï¼Œæ³¨æ„ h å’Œ p1 å’Œ p2 çš„é¡ºåºä¸èƒ½ä¹±

### 3.1.2 çº¿æ€§åµŒå…¥

é¦–å…ˆæˆ‘ä»¬è¦å…ˆå®šä¹‰ä¸€ä¸ªå…¨è¿æ¥å±‚

    self.linear_embedding = nn.Linear(patch_dim, dim)
    

ä½¿ç”¨è¿™ä¸ªå‡½æ•°å°† patch æ˜ å°„åˆ° Transformer å¤„ç†çš„ç»´åº¦

    x = self.linear_embedding(x)
    

æ¥ç€ä½¿ç”¨è¿™ä¸ªå‡½æ•°æ¥æ‰§è¡Œçº¿æ€§åµŒå…¥ï¼Œå°†å…¶æ˜ å°„åˆ°ç»´åº¦ dim

### 3.1.3 æ’å…¥ CLS Token

CLS Token æ˜¯æœ€ååˆ†ç±»å¤´å¤„ç†çš„ä¾æ®ï¼Œè¿™ä¸ªæ€æƒ³å¥½åƒæ˜¯æ¥æºäº BERTï¼Œå¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§ _æ± åŒ–_ æ–¹å¼ï¼ŒCLS Token åœ¨ Transformer ä¸­ä¼šå’Œå…¶ä»–å…ƒç´ è¿›è¡Œäº¤äº’ï¼Œæœ€åçš„è¾“å‡ºæ—¶å¯ä»¥è®¤ä¸ºå®ƒæ‹¥æœ‰äº†æ‰€æœ‰ patch ä¿¡æ¯ï¼Œå¦‚æœä¸ä½¿ç”¨ CLS Token ä¹Ÿå¯ä»¥é€‰æ‹©å¹³å‡æ± åŒ–ç­‰æ–¹å¼æ¥è¿›è¡Œåˆ†ç±»

é¦–å…ˆæˆ‘ä»¬è¦å®šä¹‰ CLS Tokenï¼Œä»–æ˜¯ä¸€ä¸ª**å¯å­¦ä¹ **çš„å‘é‡ï¼Œæ‰€ä»¥éœ€è¦æ³¨å†Œä¸º `nn.Parameter` ï¼Œå…¶ç»´åº¦å’Œ Transformer å¤„ç†ç»´åº¦ä¸€è‡´ï¼Œä»¥ä¾¿äºåé¢è¿›è¡Œçº§è”

    self.CLS_token = nn.Parameter(torch.randn(1, 1, self.dim))  # åˆ«å¿˜äº†ç»´åº¦è¦å’Œ (B,L,C) å¯¹é½
    

æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªå¤§å°ä¸º (1,1,dim) çš„å‘é‡ï¼Œä½†æ˜¯æˆ‘ä»¬çš„è¾“å…¥çš„æ˜¯ä¸€ä¸ª batchï¼Œæ‰€ä»¥æˆ‘ä»¬è¦å¯¹ä»–è¿›è¡Œå¤åˆ¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ einops åº“ä¸­çš„ `repeat` å‡½æ•°æ¥è¿›è¡Œå¤åˆ¶ï¼Œç„¶åå†è¿›è¡Œçº§è”

    CLS_token = repeat(self.CLS_token, '1 1 d -> b 1 d', b=b)  # ä½ç½®ç¼–ç å¤åˆ¶ B ä»½
    x = torch.concat((CLS_token, x), dim=1)
    

> å…¶ä¸­ b æ˜¯ batch å¤§å°
> 
> å¯ä»¥å‘ç° einops åº“å¯ä»¥å¾ˆæ–¹ä¾¿çš„è¿›è¡ŒçŸ©é˜µçš„é‡æ’

### 3.1.4 åµŒå…¥ä½ç½®ä¿¡æ¯

ViT ä½¿ç”¨**å¯å­¦ä¹ **çš„ä½ç½®ç¼–ç ï¼Œè€Œ Transformer ä½¿ç”¨çš„æ˜¯ sin/cos å‡½æ•°è¿›è¡Œç¼–ç ï¼Œä½¿ç”¨å¯å­¦ä¹ ä½ç½®ç¼–ç æ˜¾ç„¶æ›´ä¸ºæ–¹ä¾¿

    self.position_embedding = nn.Parameter(torch.randn(1, self.patch_num+1, self.dim))  # ä½¿ç”¨å¹¿æ’­
    

> å¯å­¦ä¹ çš„å‚æ•°ä¸€å®šè¦æ³¨å†Œä¸º `nn.Parameter`

å‘é‡çš„ä¸ªæ•°ä¸º patch çš„ä¸ªæ•°+1ï¼Œå› ä¸ºå› ä¸ºåœ¨å¤´éƒ¨è¿˜åŠ ä¸Šäº†ä¸€ä¸ª CLS Token å‘¢ï¼Œæœ€åä½¿ç”¨åŠ æ³•è¿›è¡Œä½ç½®åµŒå…¥

    x = x+self.position_embedding
    

* * *

å¥½äº†æ¯ä¸ªæ¨¡å—éƒ½è®²è§£å®Œæˆï¼Œæˆ‘ä»¬å°†ä»–æ‹¼åˆ

    class pre_proces(nn.Module):
        def __init__(self, image_size, patch_size, patch_dim, dim):
            super().__init__()
            self.patch_size = patch_size	# patch çš„å¤§å°
            self.dim = dim	# Transformer ä½¿ç”¨çš„ç»´åº¦ï¼ŒTransformer çš„ç‰¹æ€§æ˜¯è¾“å…¥è¾“å‡ºå¤§å°ä¸å˜
            self.patch_num = (image_size//patch_size)**2	# patch çš„ä¸ªæ•°
            self.linear_embedding = nn.Linear(patch_dim, dim)	# çº¿æ€§åµŒå…¥å±‚
            self.position_embedding = nn.Parameter(torch.randn(1, self.patch_num+1, self.dim))  # ä½¿ç”¨å¹¿æ’­
            self.CLS_token = nn.Parameter(torch.randn(1, 1, self.dim))  # åˆ«å¿˜äº†ç»´åº¦è¦å’Œ (B,L,C) å¯¹é½
    
        def forward(self, x):
            x = rearrange(x, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=self.patch_size, p2=self.patch_size)  # (B,L,C)
            x = self.linear_embedding(x)	# çº¿æ€§åµŒå…¥
            b, l, c = x.shape   # è·å– token çš„å½¢çŠ¶ (B,L,c)
            CLS_token = repeat(self.CLS_token, '1 1 d -> b 1 d', b=b)  # ä½ç½®ç¼–ç å¤åˆ¶ B ä»½
            x = torch.concat((CLS_token, x), dim=1)	# çº§è” CLS Token
            x = x+self.position_embedding	# ä½ç½®åµŒå…¥
            return x
    

3.2 Transformer
---------------

![image-20230316232801655](https://blog-1312258508.cos.ap-shanghai.myqcloud.com/image-20230316232801655.png)

è¿™ä¸€éƒ¨åˆ†å°†ä¼šæ˜¯æˆ‘ä»¬çš„é‡ç‚¹ï¼Œå»ºè®®å¤§å®¶æ‰‹æ¨ä¸€ä¸‹è‡ªæ³¨æ„åŠ›è®¡ç®—ï¼Œä¸ç„¶å¯èƒ½ä¼šæœ‰ç‚¹éš¾ç†è§£

### 3.2.1 å¤šå¤´è‡ªæ³¨æ„åŠ›

é¦–å…ˆæ¥å›å¿†ä¸€ä¸‹è‡ªæ³¨æ„åŠ›å…¬å¼ï¼š

\\\[Output=softmax(\\frac{QK^T}{\\sqrt{D\_k}})V \\\]

è¾“å…¥é€šè¿‡ \\(W\_q,W\_k,W\_v\\) æ˜ å°„ä¸º QKVï¼Œç„¶åç»è¿‡ä¸Šè¿°è®¡ç®—å¾—åˆ°è¾“å‡ºï¼Œå¤šå¤´æ³¨æ„åŠ›å°±æ˜¯ä½¿ç”¨å¤šä¸ªæ˜ å°„æƒé‡è¿›è¡Œæ˜ å°„ï¼Œç„¶åæœ€åæ‹¼æ¥æˆä¸ºä¸€ä¸ªå¤§çš„çŸ©é˜µï¼Œå†ä½¿ç”¨ä¸€ä¸ªæ˜ å°„çŸ©é˜µæ˜ å°„ä¸ºè¾“å‡ºå‡½æ•°

è¿˜æ˜¯ä¸€æ ·ï¼Œæˆ‘ä»¬å…ˆæŠŠæ•´ä¸ªä»£ç æ”¾ä¸Šæ¥ï¼Œæˆ‘ä»¬æ¥ç€åœ¨é€è¡Œè®²è§£

    class Multihead_self_attention(nn.Module):
        def __init__(self, heads, head_dim, dim):
            super().__init__()
            self.head_dim = head_dim    # æ¯ä¸€ä¸ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦
            self.heads = heads  # æ³¨æ„åŠ›å¤´ä¸ªæ•°
            self.inner_dim = self.heads*self.head_dim  # å¤šå¤´è‡ªæ³¨æ„åŠ›æœ€åçš„è¾“å‡ºç»´åº¦
            self.scale = self.head_dim**-0.5   # æ­£åˆ™åŒ–ç³»æ•°
            self.to_qkv = nn.Linear(dim, self.inner_dim*3)  # ç”Ÿæˆ qkvï¼Œæ¯ä¸€ä¸ªçŸ©é˜µçš„ç»´åº¦å’Œç”±è‡ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦ä»¥åŠå¤´çš„ä¸ªæ•°å†³å®š
            self.to_output = nn.Linear(self.inner_dim, dim)
            self.norm = nn.LayerNorm(dim)
            self.softmax = nn.Softmax(dim=-1)
    
        def forward(self, x):
            x = self.norm(x)    # PreNorm
            qkv = self.to_qkv(x).chunk(3, dim=-1)  # åˆ’åˆ† QKVï¼Œè¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­å°±åŒ…å«äº† QKV
            Q, K, V = map(lambda t: rearrange(t, 'b l (h dim) -> b h l dim', dim=self.head_dim), qkv)
            K_T = K.transpose(-1, -2)
            att_score = Q@K_T*self.scale
            att = self.softmax(att_score)
            out = att@V   # (B,H,L,dim)
            out = rearrange(out, 'b h l dim -> b l (h dim)')  # æ‹¼æ¥
            output = self.to_output(out)
            return output
    

æˆ‘ä»¬å…ˆç”¨å›¾æ¥è¡¨ç¤ºä¸€ä¸‹å¤šå¤´è‡ªæ³¨æ„åŠ›ï¼Œä¹Ÿå°±æ˜¯ç”¨å¤šä¸ªä¸åŒçš„æƒé‡æ¥æ˜ å°„ï¼Œç„¶åå†è®¡ç®—è‡ªæ³¨æ„åŠ›ï¼Œè¿™æ ·å°±å¾—åˆ°äº†å¤šç»„çš„è¾“å‡ºï¼Œæœ€åå†è¿›è¡Œæ‹¼æ¥ï¼Œä½¿ç”¨ä¸€ä¸ªå¤§çš„çŸ©é˜µæ¥æŠŠå¤šå¤´è‡ªæ³¨æ„åŠ›è¾“å‡ºæ˜ å°„å›è¾“å…¥å¤§å°

![image-20230317203621599](https://blog-1312258508.cos.ap-shanghai.myqcloud.com/image-20230317203621599.png)

æˆ‘ä»¬å¦‚ä½•æ„é€ è¿™å¤šä¸ªæƒé‡çŸ©é˜µæ¥è¿›è¡ŒçŸ©é˜µè¿ç®—æ›´å¿«å‘¢ï¼Ÿç­”æ¡ˆæ˜¯â€”â€”å†™æˆä¸€ä¸ªçº¿æ€§æ˜ å°„ï¼Œç„¶åå†é€šè¿‡çŸ©é˜µé‡æ’æ¥å¾—åˆ°å¤šç»„ QKVï¼Œç„¶åè®¡ç®—è‡ªæ³¨æ„åŠ›ï¼Œæˆ‘ä»¬æ¥çœ‹å›¾ï¼š

![image-20230317220427599](https://blog-1312258508.cos.ap-shanghai.myqcloud.com/image-20230317220427599.png)

é¦–å…ˆè¾“å…¥æ˜¯ä¸€ä¸ª (N,dim) çš„å¼ é‡ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå¤šå¤´çš„æ˜ å°„æ¨ªç€æ’åˆ—å˜æˆä¸€ä¸ªå¤§çŸ©é˜µï¼Œè¿™æ ·ä½¿ç”¨ä¸€æ¬¡çŸ©é˜µè¿ç®—å°±å¯ä»¥å¾—åˆ°å¤šä¸ªè¾“å‡º

> æˆ‘è¿™é‡Œå‡è®¾äº†å››ä¸ªå¤´ï¼Œå¹¶ä¸”æ¯ä¸€ä¸ªå¤´çš„ç»´åº¦æ˜¯ 2

ç»è¿‡æ˜ å°„ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ª \\((N,heads\\times head\\\_dim)\\) å¤§å°çš„å¼ é‡ï¼Œè¿™æ—¶å€™æˆ‘ä»¬å¯¹å…¶é‡æ–°æ’åˆ—ï¼Œå½¢æˆ \\((heads,N,head\\\_dim)\\) å¤§å°çš„å¼ é‡ï¼Œè¿™æ ·å°±æŠŠæ¯ä¸€ä¸ªå¤´ç»™åˆ†ç¦»å‡ºæ¥äº†

æ¥ç€å°±æ˜¯åšè‡ªæ³¨æ„åŠ›ï¼Œæˆ‘ä»¬ç°åœ¨çš„å¼ é‡å½“ä½œ Qï¼ŒK å°±éœ€è¦è¿›è¡Œè½¬ç½®ï¼Œå…¶å¼ é‡å¤§å°æ˜¯ \\((heads,head\\\_dim,N)\\) ï¼ŒäºŒè€…è¿›è¡Œç›¸ä¹˜ï¼Œå¾—åˆ°çš„è¾“å‡ºä¸º \\((heads,N,N)\\)ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬çš„æ³¨æ„åŠ›å¾—åˆ†ï¼Œç»è¿‡ softmax å°±å¯ä»¥å’Œ V ç›¸ä¹˜äº†

> è¿™é‡Œçœç•¥äº† softmaxï¼Œé‡ç‚¹çœ‹çŸ©é˜µçš„ç»´åº¦å˜åŒ–

![image-20230317221013326](https://blog-1312258508.cos.ap-shanghai.myqcloud.com/image-20230317221013326.png)

è®¡ç®—è‡ªæ³¨æ„åŠ›è¾“å‡ºï¼Œå°±æ˜¯å’Œ V ç›¸ä¹˜ï¼ŒV çš„å¼ é‡å¤§å°ä¸º \\((heads,N,head\\\_dim)\\) ï¼Œæœ€åå¾—åˆ°è¾“å‡ºå¤§å°ä¸º \\((heads,N,head\\\_dim)\\)

![image-20230317221405554](https://blog-1312258508.cos.ap-shanghai.myqcloud.com/image-20230317221405554.png)

æˆ‘ä»¬æŠŠä¸Šä¸€æ­¥çš„å¼ é‡ \\((heads,N,head\\\_dim)\\) é‡æ’ä¸º \\((N,heads\\times head\\\_dim)\\)ï¼Œç„¶åä½¿ç”¨ä¸€ä¸ªå¤§å°ä¸º \\((heads\\times\\\_dim,dim)\\) çš„çŸ©é˜µæ˜ å°„å›å’Œè¾“å…¥ç›¸åŒçš„å¤§å°ï¼Œè¿™æ ·å¤šå¤´è‡ªæ³¨æ„åŠ›å°±è®¡ç®—å®Œæˆäº†

å¤§å®¶å¯ä»¥åƒæˆ‘ä¸€æ ·æŠŠè¿‡ç¨‹ç»™å†™å‡ºæ¥ï¼Œå¯ä»¥æ¸…æ™°éå¸¸å¤šï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å†çœ‹ä¸€ä¸‹ä»£ç å®ç°ï¼š

é¦–å…ˆå®šä¹‰æˆ‘ä»¬éœ€è¦çš„æ˜ å°„çŸ©é˜µä»¥åŠ softmax å‡½æ•°ä»¥åŠ layernorm å‡½æ•°

    self.head_dim = head_dim    # æ¯ä¸€ä¸ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦
    self.heads = heads  # æ³¨æ„åŠ›å¤´ä¸ªæ•°
    self.inner_dim = self.heads*self.head_dim  # å¤šå¤´è‡ªæ³¨æ„åŠ›è¾“å‡ºçº§è”åçš„è¾“å‡ºç»´åº¦
    self.scale = self.head_dim**-0.5   # æ­£åˆ™åŒ–ç³»æ•°
    self.to_qkv = nn.Linear(dim, self.inner_dim*3)  # ç”Ÿæˆ qkvï¼Œæ¯ä¸€ä¸ªçŸ©é˜µçš„ç»´åº¦ç”±è‡ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦ä»¥åŠå¤´çš„ä¸ªæ•°å†³å®š
    self.to_output = nn.Linear(self.inner_dim, dim)	# è¾“å‡ºæ˜ å°„çŸ©é˜µ
    self.norm = nn.LayerNorm(dim)	# layerNorm
    self.softmax = nn.Softmax(dim=-1)	# softmax
    

æœ‰äº†è¿™äº›ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹ MHSA çš„è®¡ç®—

        def forward(self, x):
            x = self.norm(x)    # PreNorm
            qkv = self.to_qkv(x).chunk(3, dim=-1)  # æŒ‰ç…§æœ€åä¸€ä¸ªç»´åº¦å‡åˆ†ä¸ºä¸‰åˆ†ï¼Œä¹Ÿå°±æ˜¯åˆ’åˆ† QKVï¼Œè¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­å°±åŒ…å«äº† QKV
            Q, K, V = map(lambda t: rearrange(t, 'b l (h dim) -> b h l dim', dim=self.head_dim), qkv)	# å¯¹ QKV çš„å¤šå¤´æ˜ å°„è¿›è¡Œæ‹†åˆ†ï¼Œå¾—åˆ°(B,head,L,head_dim)
            K_T = K.transpose(-1, -2)	# K è¿›è¡Œè½¬ç½®ï¼Œç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›
            att_score = Q@K_T*self.scale	# è®¡ç®—è‡ªæ³¨æ„åŠ›å¾—åˆ†
            att = self.softmax(att_score)	# softmax
            out = att@V   # (B,H,L,dim); è‡ªæ³¨æ„åŠ›è¾“å‡º
            out = rearrange(out, 'b h l dim -> b l (h dim)')  # æ‹¼æ¥
            output = self.to_output(out)	#è¾“å‡ºæ˜ å°„
            return output
    

ä¸Šé¢çš„éƒ¨åˆ†è¿›è¡Œç»„åˆ

    class Multihead_self_attention(nn.Module):
        def __init__(self, heads, head_dim, dim):
            super().__init__()
            self.head_dim = head_dim    # æ¯ä¸€ä¸ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦
            self.heads = heads  # æ³¨æ„åŠ›å¤´ä¸ªæ•°
            self.inner_dim = self.heads*self.head_dim  # å¤šå¤´è‡ªæ³¨æ„åŠ›æœ€åçš„è¾“å‡ºç»´åº¦
            self.scale = self.head_dim**-0.5   # æ­£åˆ™åŒ–ç³»æ•°
            self.to_qkv = nn.Linear(dim, self.inner_dim*3)  # ç”Ÿæˆ qkvï¼Œæ¯ä¸€ä¸ªçŸ©é˜µçš„ç»´åº¦å’Œç”±è‡ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦ä»¥åŠå¤´çš„ä¸ªæ•°å†³å®š
            self.to_output = nn.Linear(self.inner_dim, dim)
            self.norm = nn.LayerNorm(dim)
            self.softmax = nn.Softmax(dim=-1)
    
        def forward(self, x):
            x = self.norm(x)    # PreNorm
            qkv = self.to_qkv(x).chunk(3, dim=-1)  # åˆ’åˆ† QKVï¼Œè¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­å°±åŒ…å«äº† QKV
            Q, K, V = map(lambda t: rearrange(t, 'b l (h dim) -> b h l dim', dim=self.head_dim), qkv)
            K_T = K.transpose(-1, -2)
            att_score = Q@K_T*self.scale
            att = self.softmax(att_score)
            out = att@V   # (B,H,L,dim)
            out = rearrange(out, 'b h l dim -> b l (h dim)')  # æ‹¼æ¥
            output = self.to_output(out)
            return output
    
    

### 3.2.2 FeedForward

æ„å»ºåé¢çš„ FeedForward æ¨¡å—ï¼Œè¿™ä¸ªæ¨¡å—å°±æ˜¯ä¸€ä¸ª MLPï¼Œä¸­é—´å¤¹ç€éçº¿æ€§æ¿€æ´»ï¼Œæ‰€ä»¥æˆ‘ä»¬ç›´æ¥çœ‹ä»£ç å§

    class FeedForward(nn.Module):
        def __init__(self, dim, mlp_dim):
            super().__init__()
            self.fc1 = nn.Linear(dim, mlp_dim)
            self.fc2 = nn.Linear(mlp_dim, dim)
            self.norm = nn.LayerNorm(dim)
    
        def forward(self, x):
            x = self.norm(x)
            x = F.gelu(self.fc1(x))
            x = self.fc2(x)
            return x
    

### 3.2.3 Transformer Block

æœ‰äº† MHSA ä»¥åŠ FeedForwardï¼Œæˆ‘ä»¬å¯ä»¥æ¥æ„å»º Transformer Blockï¼Œè¿™æ˜¯ Transformer çš„åŸºæœ¬å•å…ƒï¼Œåªéœ€è¦æŠŠæˆ‘ä»¬æ„å»ºçš„æ¨¡å—è¿›è¡Œç»„è£…ï¼Œç„¶åæ·»åŠ æ®‹å·®è¿æ¥å³å¯ï¼Œä¸ä¼šå¾ˆéš¾

    class Transformer_block(nn.Module):
        def __init__(self, dim, heads, head_dim, mlp_dim):
            super().__init__()
            self.MHA = Multihead_self_attention(heads=heads, head_dim=head_dim, dim=dim)
            self.FeedForward = FeedForward(dim=dim, mlp_dim=mlp_dim)
    
        def forward(self, x):
            x = self.MHA(x)+x
            x = self.FeedForward(x)+x
            return x
    

> æ·»åŠ äº†ä¸€ä¸ªå‚æ•° `depth` ï¼Œç”¨æ¥å®šä¹‰ Transformer çš„å±‚æ•°

ViT
---

ç¥è´ºå¤§å®¶ï¼Œèµ°åˆ°æœ€åä¸€æ­¥å•¦ï¼æˆ‘ä»¬æŠŠä¸Šé¢çš„ä¸œè¥¿ç»„è£…èµ·æ¥ï¼Œæ„å»º ViT å§

    class ViT(nn.Module):
        def __init__(self, image_size, channels, patch_size, dim, heads, head_dim, mlp_dim, depth, num_class):
            super().__init__()
            self.to_patch_embedding = pre_proces(image_size=image_size, patch_size=patch_size, patch_dim=channels*patch_size**2, dim=dim)
            self.transformer = Transformer(dim=dim, heads=heads, head_dim=head_dim, mlp_dim=mlp_dim, depth=depth)
            self.MLP_head = nn.Sequential(
                nn.LayerNorm(dim),
                nn.Linear(dim, num_class)
            )
            self.softmax = nn.Softmax(dim=-1)
    
        def forward(self, x):
            token = self.to_patch_embedding(x)
            output = self.transformer(token)
            CLS_token = output[:, 0, :]	# æå–å‡º CLS Token
            out = self.softmax(self.MLP_head(CLS_token))
            return out
    

æ€»ç»“
==

è¿™é‡Œæˆ‘ä»¬æ‰‹åŠ¨å®ç°äº† ViT çš„æ„å»ºï¼Œä¸çŸ¥é“å¤§å®¶æœ‰æ²¡æœ‰å¯¹ Transformer çš„æ¶æ„æœ‰æ›´æ·±å…¥çš„ç†è§£å‘¢ï¼Ÿæˆ‘ä¹Ÿæ˜¯åŠ¨æ‰‹å®ç°äº†æ‰ç†è§£å…¶å„ç§ç»†èŠ‚ï¼Œåˆšå¼€å§‹è§‰å¾—è‡ªå·±ä¸å¯èƒ½å®ç°ï¼Œä½†æ˜¯æœ€åè¿˜æ˜¯æˆåŠŸçš„ï¼Œæ„Ÿè§‰å¥½å¼€å¿ƒï¼šD

å‚è€ƒ
==

\[1\] [lucidrains/vit-pytorch](https://github.com/lucidrains/vit-pytorch)

\[2\] [å…¨ç½‘æœ€å¼ºViT (Vision Transformer)åŸç†åŠä»£ç è§£æ](https://zhuanlan.zhihu.com/p/427388113)

\[3\] Dosovitskiy A, Beyer L, Kolesnikov A, et al. An image is worth 16x16 words: Transformers for image recognition at scale\[J\]. arXiv preprint arXiv:2010.11929, 2020.