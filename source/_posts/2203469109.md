---
layout: post
title: "重磅！flink-table-store 将作为独立数据湖项目重新加入 Apache"
date: "2023-03-01T01:21:50.935Z"
---
重磅！flink-table-store 将作为独立数据湖项目重新加入 Apache
==========================================

数据湖是大数据近年来的网红项目，大家熟知的开源数据湖三剑客 Apache hudi、Apache iceberg 、Databricks delta 近年来野蛮生长，目前各自背后也都有商业公司支持，投入了大量的人力物力去做研发和宣传。然而今天我们要讲的是数据湖界的后起之秀 —— flink-table-store。

熟悉 Flink 项目的同学对这个项目应该并不陌生，它在去年作为 Flink 的子项目加入了 Apache 社区，由 Flink 团队主导研发，截止到目前 star 数 423，fork 数 171，总体来说并不算大火，也许是因为开源的时间并不长，也许是因为数据湖市场早已被三剑客占据了大半，也许是宣传的力度不够，也许是 Flink 子项目限制了它作为数据湖产品的发展。然而可能也正是这些种种的原因促成了这次 flink-table-store 作为独立项目重新加入 Apache，不再依附 Flink，这无论是对于 flink-table-store 的未来发展，还是对于数据湖领域来说都是一件好事。

从 Apache 的提案可以看出，flink-table-store 作为独立项目后的项目名是 Paimon，玩过原神的同学应该对这个名字不陌生，它是游戏中的 NPC，作为向导在整个冒险过程中陪伴着旅行者，至于 Paimon 具体的寓意可能得等官宣解释了。

说回正题，Paimon 的定位是分布式文件系统（HDFS、S3 等）上的数据文件支持的湖存储，用于使用大数据计算引擎（即 Flink、Spark、Hive、Trino 等）为流式处理和批处理构建动态表，支持高速数据摄取和实时数据查询。与其他数据湖存储项目不同，Paimon 旨在同时支持高吞吐量和低端到端延迟（更好的数据新鲜度），尤其适用于密集型 UPDATE 和 DELETE 工作负载。

### Paimon 独立加入Apache 后的一些规划：

*   扩展Paimon的生态，提供独立的Java API，支持 Spark、Hive、Trino、Presto、Doris等更多大数据引擎的读写。
*   补充关键能力，特别是流式读取和密集更新/删除，以创建统一且易于使用的流式数据仓库（lakehouse）。
*   成长为一个更有活力和中立的开源社区。（关键词“中立”，这也是促成Paimon独立的主要原因）

### Paimon 解决的痛点

随着流处理在生产中的应用（Flink、Spark-Streaming等技术），对存储同时支持更新、删除和流式读取的需求越来越大，为了支持这样的要求我们有如下一些方案：

*   一种选择是使用 OLAP 系统，如 ClickHouse 和 Aapache Doris，它们能够提供高速数据摄取。但是不支持流式读取，存储成本比较高。
*   另一种选择是使用现有的湖存储，例如 Apache Hudi 和 Apache Iceberg。然而，从实时处理系统高速摄取最新（更新）数据提出了巨大的挑战，并且会使两个系统不堪重负。  
    创建 Paimon 就是为了解决现有解决方案的局限
*   支持大数据集存储，支持批流式读写。
*   支持流消费的增量快照。
*   支持最低延迟至毫秒的流式查询。
*   支持批处理/OLAP 查询，延迟最小到秒级。

### Paimon 基本原理说明

Paimon原生采用LSM（Log-Structured Merge-tree）作为其底层数据结构，除了常见的湖存储能力外，还为带主键的数据提供了增强的性能。更重要的是，Paimon 支持批流操作（读和写），方便应用程序追求批流统一语义。具体来说：

*   Paimon 利用 LSM 数据结构的附加写入功能，在密集的更新/删除工作负载上提供出色的性能。
*   Paimon 利用 LSM 的有序特性支持有效的过滤器下推，可以将主键过滤查询的延迟降低到毫秒级。
*   Paimon 支持各种（基于行或行列）文件格式，包括 Apache Avro、Apache ORC 和 Apache Parquet（行在写出之前将按主键排序）。
*   Paimon提供的表可以被各种引擎查询，包括Apache Flink、Apache Spark、Apache Hive、Trino等。
*   Paimon 的元数据是自我管理的，存储在分布式文件系统上，可以同步到 Hive metastore (HMS)。
*   除了常见的批量读写支持外，Paimon 还支持流式读取和更改数据馈送。

* * *

目前该提案正在邮件讨论的阶段，孵化器导师对该项目独立加入 ASF 都持赞同态度，相信不久就会官宣这一消息。

![](https://img2023.cnblogs.com/blog/1491039/202303/1491039-20230301085945441-733768209.png)

另外有导师提出，鉴于大多数参与人员都熟悉 ASF 以及项目应该如何运作，是否可以不进过孵化器而直接作为单独的顶级项目（TLP）。比如 Apache Camel 是 Apache ActiveMQ 的一个子项目， 它没有经过孵化器过程就成为了 TLP，因为大多数开发人员知道如何运行 ASF 项目。该方案目前还在讨论当中。

![](https://img2023.cnblogs.com/blog/1491039/202303/1491039-20230301085949887-168881531.png)

随着 Paimon 的独立，数据湖市场的争夺将进入白热化阶段，其实百花齐发对于用户来说是利好的，良性竞争可以促进项目的快速迭代，但是在做选择上还是得头痛一会儿了，关于数据湖“四剑客”技术细节的文章后续会在这个公众号上陆续更新，欢迎持续关注。不知道这次 Paimon 可以在数据湖领域掀起多大的浪，让我们拭目以待！

* * *

![](https://img2023.cnblogs.com/blog/1491039/202301/1491039-20230117092417693-1735362128.png)