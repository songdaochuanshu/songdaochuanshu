---
layout: post
title: "【HMS Core】一张图片带你玩转机器学习服务"
date: "2023-02-10T07:15:44.363Z"
---
【HMS Core】一张图片带你玩转机器学习服务
========================

​**1、介绍**

**_总览_**

Cloud DB（云数据库）是一款端云协同的数据库产品，提供端云数据的协同管理、统一的数据模型和丰富的数据管理API接口等能力。在保证数据的可用性、可靠性、一致性，以及安全等特性基础上，能够实现数据在客户端和云端之间的无缝同步。

ML Kit为（机器学习服务）开发者提供简单易用、服务多样、技术领先的机器学习能力，助力开发者更快更好地开发各类AI应用。

_**您将建立什么**_

在本次Codelab中，您将建立一个示例项目并集成ML Kit和Cloud DB。在该项目中，您可以：

1、使用键盘或图像分类进行图像搜索

2、列出Cloud DB中的图像

3、检测图像描述的语言

4、翻译图像描述

5、声化图像描述

_**您需要什么**_

在本codelab中，你需要学习：

1、如何在AppGallery Connect中创建项目和应用程序

2、如何集成ML Kit和Cloud DB

3、如何使用ML Kit和Cloud DB

**2、您需要什么**

_**硬件需求**_

*   一台笔记本或台式电脑。
    
*   华为手机：EMUI 8.0版本或以上，运行HMS Core (APK) 5.0.1.301及以上版本；非华为手机：Android 7.0或以上，运行HMS Core (APK) 5.0.1.301或以上版本。
    
*   手机用于运行和调试demo
    

**_软件需求_**

*   [JDK](https://www.oracle.com/java/technologies/javase-downloads.html)版本：1.8或以上
    
*   [Android Studio](https://developer.android.com/studio)版本：3._X_或以上
    
*   minSdkVersion：24或以上
    
*   targetSdkVersion：29
    
*   compileSdkVersion：29
    
*   Gradle版本：4.6或以上
    

**_必备知识_**

安卓应用开发基础知识

**3、集成前准备**

集成前，需要完成以下准备工作：

**说明：**

在进行准备前，请先[注册开发者帐号](https://id1.cloud.huawei.com/CAS/portal/userRegister/regbyemail.html?reqClientType=89&loginChannel=89000003&lang=zh-cn&service=https%253A%252F%252Foauth-login.cloud.huawei.com%252Foauth2%252Fv2%252Fauthorize%253Faccess_type%253Doffline%2526response_type%253Dcode%2526client_id%253D6099200%2526login_channel%253D89000003%2526req_client_type%253D89%2526lang%253Dzh-cn%2526redirect_uri%253Dhttps%25253A%25252F%25252Fdeveloper.huawei.com%25252Fconsumer%25252Fen%25252Fdoc%25252F%2526state%253D3696845%2526scope%253Dhttps%25253A%25252F%25252Fwww.huawei.com%25252Fauth%25252Faccount%25252Fcountry%252Bhttps%25253A%25252F%25252Fwww.huawei.com%25252Fauth%25252Faccount%25252Fbase.profile)。

*   在AppGallery Connect中创建项目和应用。
    
*   创建Android Studio项目。
    
*   生成签名证书。
    
*   生成签名证书指纹。
    
*   在AppGallery Connect中将签名指纹添加到应用中。
    
*   添加必要配置。
    
*   配置项目签名。
    
*   同步项目。
    

详情请参见[HUAWEI HMS Core集成准备](https://developer.huawei.com/consumer/cn/codelab/HMSPreparation/index.html#0)。

**4、集成HMS Core SDK**

**_添加您应用的AppGallery Connect配置文件_**

1.  登录[AppGallery Connect](https://developer.huawei.com/consumer/cn/service/josp/agc/index.html)，点击“我的项目”，在项目列表中找到并点击您的项目。
    
2.  在“项目设置”页面选择“常规”页签。
    
3.  在“项目”区域下点击“数据处理位置”后的“启用”。
    
    ![1.png](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtybbs/150/224/722/0900086000150224722.20230117110328.12652208645500669077336868190034:50540209062448:2800:B9F9401A11C110A3B328877190A468A1D19CB5838FF4CF6CFA117DBAD048C594.png)​
    
4.  点击“应用”区域的“agconnect-services.json”下载配置文件。
    
    ![cke_20937.png](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtybbs/150/224/722/0900086000150224722.20230117112323.83029072889440728635550537703649:50540209062448:2800:36A367AF9C52A1725C4F43902AF9A04CE7D6115938EF3AFC4441BE39F43E9E54.png)​
    
5.  将配置文件"agconnect-services.json"复制到应用级根目录下。
    
    ![cke_7575.png](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtybbs/150/224/722/0900086000150224722.20230117110412.06000192790311861853483612425083:50540209062448:2800:11F9B9DC7AD516E0CC56AA218F11BDFC70EC624C1583748A4A04EDBF41F210C0.png)​
    

**_添加编译依赖_**

1.  打开应用级的“build.gradle”文件。
    
2.  在dependencies代码段中添加如下编译依赖。
    
        dependencies { 
             // Import Cloud DB. 
             implementation 'com.huawei.agconnect:agconnect-cloud-database:{version}' 
            // Import Image Classification
            implementation 'com.huawei.hms:ml-computer-vision-classification:{version}'
            // Import Image Classification Model
            Implementation 'com.huawei.hms:ml-computer-vision-image-classification-model:{version}'
            // Import Real-Time Translation
            implementation 'com.huawei.hms:ml-computer-translate:{version}'
            // Import Real-Time Language Detection
            implementation 'com.huawei.hms:ml-computer-language-detection:{version}'
            // Import Text To Speech
            implementation 'com.huawei.hms:ml-computer-voice-tts:{version}'
         }
    
    ![](https://img2023.cnblogs.com/blog/1969374/202302/1969374-20230210145612726-399375622.gif)
    
    具体说明如下：
    
    a.将{version}替换为Cloud DB的最新版本号，例如com.huawei.agconnect:agconnect-cloud-database:1.5.4.300。有关最新版本号的详细信息，请参见文档。
    
    b.将{version}替换为ML Kit的最新版本号，例如com.huawei.agconnect:agconnect-function-ktx 1.7.1.300。有关最新版本号的详细信息，请参见文档。
    
3.  在build.gradle文件中，设置Java源代码的兼容性模式为JDK1.8。
    
        compileOptions { 
        sourceCompatibility = 1.8 
        targetCompatibility = 1.8
        }
    
    ![](https://img2023.cnblogs.com/blog/1969374/202302/1969374-20230210145612726-399375622.gif)
    
4.  在应用级build.gradle文件中设置minSdkVersion。
    
        android {
         ... 
           defaultConfig {
              ... 
           minSdkVersion 26 
              ... 
          }
           ... 
        }
    
    ![](https://img2023.cnblogs.com/blog/1969374/202302/1969374-20230210145612726-399375622.gif)
    
5.  检查是否已添加AppGallery Connect插件。如没有，在应用级build.gradle文件中添加该插件。
    
        apply plugin: 'com.huawei.agconnect'
    
    ![](https://img2023.cnblogs.com/blog/1969374/202302/1969374-20230210145612726-399375622.gif)
    

**_配置混淆脚本_**

编译APK前需要配置混淆脚本，避免混淆HMS Core SDK。如果出现混淆，HMS Core SDK可能无法正常工作。

Android Studio开发环境里的混淆脚本是“proguard-rules.pro”。

加入排除HMS SDK的混淆配置。

    -ignorewarnings 
    -keepattributes *Annotation* 
    -keepattributes Exceptions 
    -keepattributes InnerClasses 
    -keepattributes Signature 
    -keepattributes SourceFile,LineNumberTable 
    -keep class com.huawei.hianalytics.**{*;} 
    -keep class com.huawei.updatesdk.**{*;} 
    -keep class com.huawei.hms.**{*;}

![](https://img2023.cnblogs.com/blog/1969374/202302/1969374-20230210145612726-399375622.gif)

**5、设计UI**

![cke_5924.png](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtybbs/150/224/722/0900086000150224722.20230117111043.09112215987859559718628132803892:50540209062448:2800:05850D2A7420462DE3E91020B2C3EA7ADD9A722FD6570C0E2AEB1848EDF3C7F1.png)​

![cke_8768.png](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtybbs/150/224/722/0900086000150224722.20230117111100.35939985911787818741914904471018:50540209062448:2800:B0BB40B77FE3A159C6F814E744C3BAF353F92A54A9637EDB0F9C4F68983E8776.png)​

**6、在AppGallery Connect中初始化****云数据库**

**_步骤一：_**_**创建云数据库的存储区**_

1）登录AppGallery Connect，单击我的项目。

2）在项目列表中选择一个项目，单击需要添加Cloud DB区域的应用。

3）在左侧导航栏中，选择“Serverless > 云数据库”。

4）点击云数据库区域选项卡。

5）点击“新增”，进入云数据库区域创建页面。

![cke_9515.png](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtybbs/150/224/722/0900086000150224722.20230117112144.29737397148235029961865622957436:50540209062448:2800:6263359BBD8015F6B70B70EE4FFCB60ED4BF88BB65D37C80FE149E832C3D4622.png)​

![cke_27389.png](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtybbs/150/224/722/0900086000150224722.20230117112402.74061848911902833643413712305870:50540209062448:2800:D48DFD634711BEA24E5965064779FFE23FCEF323BE6946B4C5FC6CE54E03F3CF.png)​

**_步骤二：__在AGC中创建云数据库对象_**_**类型**_

1）登录AppGallery Connect，单击我的项目。

2）在项目列表中选择一个项目，单击需要添加Cloud DB区域的应用。

3）在左侧导航栏中，选择“Serverless > 云数据库”。

4）根据需求执行以下操作：

a.创建对象类型：点击“新增”

b.编辑现有对象类型：点击“修改”

![cke_36196.png](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtybbs/150/224/722/0900086000150224722.20230117112513.19356607504477887180783993165770:50540209062448:2800:5F6271638CF6408E654E0EB45D3E866A0F9E7247A31080F3E5E30767382EA1EB.png)​

![cke_42957.png](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtybbs/150/224/722/0900086000150224722.20230117112538.09784543148311682655181083141980:50540209062448:2800:DBBCEE2A5045C27188F8D49BAB2950D7AF59BC7FBAE35F85078286B669A8353C.png)​

**7、初始化云数据库**

**_步骤一：__初始化云数据库_**

    private lateinit var mCloudDB: AGConnectCloudDB
    private var handler: CompletableDeferred<Result<Unit>>? = null
    private var cloudDBZone: CloudDBZone? = null
    override suspend fun initialize(): Result<Unit> {
        handler = CompletableDeferred()
        AGConnectCloudDB.initialize(context)
        initializeCloudDB()
        initializeZone()
        handler?.let { return it.await() }
            ?: run { return Result.Error("An error occurred") }
    }
    private fun initializeCloudDB() {
        val instance = AGConnectInstance.buildInstance(
            AGConnectOptionsBuilder().setRoutePolicy(
                AGCRoutePolicy.GERMANY
            ).build(context)
        )
        mCloudDB = AGConnectCloudDB.getInstance(
            instance, 
            AGConnectAuth.getInstance()
        )  mCloudDB.createObjectType(ObjectTypeInfoHelper.getObjectTypeInfo())
    }
    private fun initializeZone() {
        val mConfig = CloudDBZoneConfig(
            "ImageDbZone",
            CloudDBZoneConfig.CloudDBZoneSyncProperty.CLOUDDBZONE_CLOUD_CACHE,      CloudDBZoneConfig.CloudDBZoneAccessProperty.CLOUDDBZONE_PUBLIC
        )
        mConfig.persistenceEnabled = true
        val task = mCloudDB.openCloudDBZone2(mConfig, true)
        task.addOnSuccessListener {
            cloudDBZone = it
            handler?.complete(Result.Success(Unit))
        }.addOnFailureListener {
            handler?.complete(Result.Error(it.message ?: "An error occurred."))
        }
    }

![](https://img2023.cnblogs.com/blog/1969374/202302/1969374-20230210145612726-399375622.gif)

**_步骤二：将“query”作为搜索入参。对于接收到的“query”。根据图像对象对应的“key”字段在Cloud DB中完成过滤，根据过滤结果列出云数据库中的图像对象。_**

    override suspend fun searchImage(query: String): List<Image> {
        val result = CompletableDeferred<List<Image>>()
        cloudDBZone?.let { dbZone ->
            dbZone.executeQuery(
                CloudDBZoneQuery.where(Image::class.java)
                    .equalTo("key", query),
                CloudDBZoneQuery.CloudDBZoneQueryPolicy.POLICY_QUERY_DEFAULT
            ).addOnCompleteListener{
                if(it.isSuccessful) {
                    val cursor = it.result.snapshotObjects
                    val images = mutableListOf<Image>()
                    while(cursor.hasNext()) {
                        images.add(cursor.next())
                    }
                    result.complete(images)
                }else {
                    throw it.exception
                }
            }
        }?: run {
            throw CloudDbNotInitializedException()
        }
        return result.await()}

![](https://img2023.cnblogs.com/blog/1969374/202302/1969374-20230210145612726-399375622.gif)

**8、集成机器学习服务**

**_步骤一：查看权限。_**

    <uses-permission android:name="android.permission.INTERNET" />
    <uses-permission android:name="android.permission.ACCESS_NETWORK_STATE"/>
    <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE"/>
    <uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE"/>

![](https://img2023.cnblogs.com/blog/1969374/202302/1969374-20230210145612726-399375622.gif)

**_步骤二：ML Kit方法返回Task。创建Task.await()扩展函数，用于在协程和Task API之间转换。_**_**Task.await()等待任务完成，而不阻塞线程，并返回未包装的结果（Task<T>中的T）。**_

    suspend fun <T> Task<T>.await(): T = suspendCoroutine { continuation ->
        addOnCompleteListener { task ->
            if (task.isSuccessful) {
                continuation.resume(task.result)
            } else {
                continuation.resumeWithException(
                    task.exception ?: Exception("Unknown task exception")
                )
            }
        }
    }

![](https://img2023.cnblogs.com/blog/1969374/202302/1969374-20230210145612726-399375622.gif)

**_步骤三：图像分类_**

    /**
     * Step 1: Create an image classification analyzer.
     *  Use customized parameter settings or default parameter settings
     *  for on-device recognition.
     *
     *      Customized ->
     *          var setting = MLLocalClassificationAnalyzerSetting
     *                        .Factory()
     *                        .setMinAcceptablePossibility(0.8f)
     *                        .create()
     *          var analyzer = MLAnalyzerFactory
     *                        .getInstance()
     *                        .getLocalImageClassificationAnalyzer(setting)
     *
     *      Default -> var analyzer = MLAnalyzerFactory
     *                               .getInstance()
     *                               .localImageClassificationAnalyzer
     *
     * Step 2: Create an MLFrame object using android.graphics.Bitmap.
     * JPG, JPEG, PNG, and BMP images are supported.
     *
     * Step 3: Call the asyncAnalyseFrame method to classify images.
     *
     * Step 4: After the recognition is complete, stop the analyzer to
     * release recognition resources.
    */
    override suspend fun classifyImage(bitmap: Bitmap): List<MLImageClassification> {
        val analyzer = MLAnalyzerFactory
            .getInstance()
            .localImageClassificationAnalyzer //Step 1
        val frame = MLFrame.fromBitmap(bitmap) //Step 2
        val task = analyzer.asyncAnalyseFrame(frame) //Step 3
        val classificationResult = task.await()
        analyzer.stop() //Step 4
        return classificationResult
    }

![](https://img2023.cnblogs.com/blog/1969374/202302/1969374-20230210145612726-399375622.gif)

**_步骤四：语种检测_**

    /**
     * Step 1: Create a language detector.
     *  Use customized parameter settings or default parameter settings 
     *  to create a language detector.
     *  
     *      Customized -> val setting = MLRemoteLangDetectorSetting
     *                                  .Factory()
     *                                  .setTrustedThreshold(0.01f)
     *                                  .create()
     *                    val mlRemoteLangDetector = MLLangDetectorFactory
     *                                            .getInstance()
     *                                            .getRemoteLangDetector(setting)
     *
     *      Default -> val mlRemoteLangDetector = MLLangDetectorFactory
     *                                            .getInstance()
     *                                            .remoteLangDetector
     *
     * Step 2: Implement language detection.
     * 
     * Step 3: Release resources after the detection is complete.
     */
    override suspend fun detectLanguage(text: String): String {
        val mlRemoteLangDetector = MLLangDetectorFactory  //Step 1
            .getInstance()
            .remoteLangDetector
        val firstBestDetectTask = mlRemoteLangDetector //Step 2
            .firstBestDetect(text)
        val detectResult = firstBestDetectTask.await()
        mlRemoteLangDetector.stop() //Step 3
        return detectResult
    }

![](https://img2023.cnblogs.com/blog/1969374/202302/1969374-20230210145612726-399375622.gif)

**_步骤五：文本翻译_**

    /**
     * Step 1: Create a real-time text translator.
     * Language Code -> The BCP-47 standard is used for Traditional Chinese,
     * and the ISO 639-1 standard is used for other languages.
     *
     * Step 2: Implement real-time translation.
     *
     * Step 3: Release resources after the translation is complete.
     */
    override suspend fun translateText(
        text: String,
        sourceLanguage:String,
        targetLanguage: String
    ): String {
        val setting = MLRemoteTranslateSetting //Step 1
            .Factory()
            .setSourceLangCode(sourceLanguage)
            .setTargetLangCode(targetLanguage)
            .create()
        val mlRemoteTranslator = MLTranslatorFactory
            .getInstance()
            .getRemoteTranslator(setting)
        val translatorTask = mlRemoteTranslator //Step 2
            .asyncTranslate(text)
        val translationResult = translatorTask.await()
        mlRemoteTranslator.stop() //Step 3
        return translationResult
    }

![](https://img2023.cnblogs.com/blog/1969374/202302/1969374-20230210145612726-399375622.gif)

**_步骤六：语音合成_**

    private lateinit var mlTtsEngine: MLTtsEngine
    private lateinit var mlConfigs: MLTtsConfig
    // Step 1: Create a TTS engine.
    override fun createInstance(){
        // Use customized parameter settings to create a TTS engine.
        mlConfigs = MLTtsConfig()
            // Set the text converted from speech to English.
            .setLanguage(MLTtsConstants.TTS_EN_US)
            // Set the English timbre.
            .setPerson(MLTtsConstants.TTS_SPEAKER_FEMALE_EN)
            // Set the speech speed.
            // The range is (0,5.0]. 1.0 indicates a normal speed.
            .setSpeed(1.0f)
            // Set the volume.
            // The range is (0,2). 1.0 indicates a normal volume.
            .setVolume(1.0f)
        mlTtsEngine = MLTtsEngine(mlConfigs)
        mlTtsEngine.setTtsCallback(callback)
    }
    // Step 3: Control the playback
    override fun startSpeaking(text: String) {
        mlTtsEngine.speak(text,MLTtsEngine.QUEUE_APPEND)
    }
    // Step 3: Control the playback
    override fun resumeSpeaking() {
        mlTtsEngine.resume()
    }
    // Step 3: Control the playback
    override fun pauseSpeaking() {
        mlTtsEngine.pause()
    }
    // Step 4: Stop the ongoing TTS tasks and clear all TTS tasks in the queue.
    override fun stopSpeaking() {
        mlTtsEngine.stop()
    }
    // Step 5: Release resources after TTS ends.
    override fun shutDownTextToSpeech() {
        mlTtsEngine.shutdown()
    }
    
    // Step 2: Create a TTS callback function to process the TTS result.
    //Pass the TTS callback to the TTS engine created in Step 1 to perform TTS.
    private var callback: MLTtsCallback = object : MLTtsCallback {
        override fun onEvent(taskId: String, eventName: Int, bundle: Bundle?) {
            when(eventName){
                MLTtsConstants.EVENT_PLAY_START -> {/* Handle Event */}
                MLTtsConstants.EVENT_PLAY_RESUME -> {/* Handle Event */}
                MLTtsConstants.EVENT_PLAY_PAUSE -> {/* Handle Event */}
                MLTtsConstants.EVENT_PLAY_STOP -> {/* Handle Event */}
                MLTtsConstants.EVENT_SYNTHESIS_START -> {/* Handle Event */}
                MLTtsConstants.EVENT_SYNTHESIS_END -> {/* Handle Event */}
                MLTtsConstants.EVENT_SYNTHESIS_COMPLETE -> {{/* Handle Event */}}
            }
        }
        override fun onError(taskId: String, err: MLTtsError) {
            //Processing logic for TTS failure.
        }
        override fun onWarn(taskId: String, warn: MLTtsWarn) {
            //Alarm handling without affecting service logic.
        }
        //Return the mapping between the currently played segment and text.
        //start: start position of the audio segment in the input text;
        //end (excluded): end position of the audio segment in the input text
        override fun onRangeStart(taskId: String, start: Int, end: Int) {
            //Process the mapping between the currently played segment and text.
        }
        //taskId: ID of an audio synthesis task corresponding to the audio.
        //audioFragment: audio data.
        //offset: offset of the audio segment to be transmitted in the queue.
        //One audio synthesis task corresponds to an audio synthesis queue.
        //range: text area where the audio segment to be transmitted is located;
        //range.first (included): start position;
        //range.second (excluded): end position.
        override fun onAudioAvailable(
            taskId: String?,
            audioFragment: MLTtsAudioFragment?,
            offset: Int,
            range: android.util.Pair<Int, Int>?,
            bundle: Bundle?
        ) {
        //Audio stream callback API,
        // which is used to return the synthesized audio data to the app.
        }
    }

![](https://img2023.cnblogs.com/blog/1969374/202302/1969374-20230210145612726-399375622.gif)

**9、恭喜您**

祝贺您，您已经成功完成本codelab并学到了：

*   如何集成云数据库。
    
*   如何使用ML Kit（图像分类、语种检测、文本翻译、语音合成）。
    

**10、参考文件**

*   [云数据库开发指南](https://developer.huawei.com/consumer/cn/doc/development/AppGallery-connect-Guides/agc-clouddb-overview-0000001127558223)
    
*   [机器学习服务开发指南](https://developer.huawei.com/consumer/cn/doc/development/hiai-Guides/dev-process-0000001050038076)
    

点击此处[下载](https://github.com/huaweicodelabs/multi-kit-codelabs/tree/main/ImageApp)源码。

​

欲了解更多更全技术文章，欢迎访问[https://developer.huawei.com/consumer/cn/forum/?ha\_source=zzh](https://developer.huawei.com/consumer/cn/forum/?ha_source=zzh)