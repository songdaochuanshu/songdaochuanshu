---
layout: post
title: "隐私计算FATE-模型训练"
date: "2022-06-20T01:46:40.927Z"
---
隐私计算FATE-模型训练
=============

![mark](https://img2022.cnblogs.com/other/1769816/202206/1769816-20220620090438068-1480408077.jpg)

一、说明
----

本文分享基于 Fate 自带的测试样例，进行 `纵向逻辑回归` 算法的模型训练，并且通过 `FATE Board` 可视化查看结果。

> 本文的内容为基于 [《隐私计算FATE-概念与单机部署指南》](https://mp.weixin.qq.com/s/dsg-kmf_ABn_KPc_pZVUcA)中部署的环境。

二、进入容器
------

执行以下命令，进入 Fate 的容器中：

    docker exec -it $(docker ps -aqf "name=standalone_fate") bash
    

![file](https://img2022.cnblogs.com/other/1769816/202206/1769816-20220620090438474-23766189.png)

可以看到其中有一个 `examples` 的目录，里面包含各种算法的测试样例，以及测试的数据。

进入到 `examples` 后，创建一个 `my_test` 的目录：

    cd examples
    
    mkdir my_test
    

> **注意**：后面所有的操作都默认在该目录下执行。

三、上传数据
------

第一步需要准备好训练要用的数据，我们可以通过 `csv文件` 把数据上传到 Fate 里面；

自带的测试数据都在容器里的 `/data/projects/fate/examples/data` 目录中：

![file](https://img2022.cnblogs.com/other/1769816/202206/1769816-20220620090438794-367155485.png)

> 可以看到每种算法都分别提供了 guest 和 host 两方的数据。

### 3.1. 准备guest方配置

在 `my_test` 目录下，执行以下命令：

    vi upload_hetero_guest.json
    

内容如下：

    {
      "file": "/data/projects/fate/examples/data/breast_hetero_guest.csv",
      "head": 1,
      "partition": 10,
    	"work_mode": 0,
      "namespace": "experiment",
      "table_name": "breast_hetero_guest"
    }
    

*   file：数据文件的路径
*   head：数据文件是否包含表头
*   partition：用于存储数据的分区数
*   work\_mode：工作模式，0为单机版，1为集群版
*   namespace：命名空间
*   table\_name：数据表名

### 3.2. 准备host方配置

在 `my_test` 目录下，执行以下命令：

    vi upload_hetero_host.json
    

内容如下：

    {
      "file": "/data/projects/fate/examples/data/breast_hetero_host.csv",
      "head": 1,
      "partition": 10,
    	"work_mode": 0,
      "namespace": "experiment",
      "table_name": "breast_hetero_host"
    }
    

> 注意文件名与表名是和guest方不一样的。

### 3.3. 执行上传

执行以下两个命令，分别上传 guest 和 host 方的数据：

    flow data upload -c upload_hetero_guest.json
    
    flow data upload -c upload_hetero_host.json
    

> 通过 -c 来指定配置文件。

成功后返回上传任务的相关信息：

    {
        "data": {
            "board_url": "http://127.0.0.1:8080/index.html#/dashboard?job_id=202205070640371260700&role=local&party_id=0",
            "code": 0,
            "dsl_path": "/data/projects/fate/fateflow/jobs/202205070640371260700/job_dsl.json",
            "job_id": "202205070640371260700",
            "logs_directory": "/data/projects/fate/fateflow/logs/202205070640371260700",
            "message": "success",
            "model_info": {
                "model_id": "local-0#model",
                "model_version": "202205070640371260700"
            },
            "namespace": "experiment",
            "pipeline_dsl_path": "/data/projects/fate/fateflow/jobs/202205070640371260700/pipeline_dsl.json",
            "runtime_conf_on_party_path": "/data/projects/fate/fateflow/jobs/202205070640371260700/local/0/job_runtime_on_party_conf.json",
            "runtime_conf_path": "/data/projects/fate/fateflow/jobs/202205070640371260700/job_runtime_conf.json",
            "table_name": "breast_hetero_guest",
            "train_runtime_conf_path": "/data/projects/fate/fateflow/jobs/202205070640371260700/train_runtime_conf.json"
        },
        "jobId": "202205070640371260700",
        "retcode": 0,
        "retmsg": "success"
    }
    

### 3.4. 检查数据

执行以下命令，查看表的相关信息：

    flow table info -t breast_hetero_guest -n experiment
    

执行后返回：

    {
        "data": {
            "address": {
                "home": null,
                "name": "breast_hetero_guest",
                "namespace": "experiment",
                "storage_type": "LMDB"
            },
            "count": 569,
            "exist": 1,
            "namespace": "experiment",
            "partition": 10,
            "schema": {
                "header": "y,x0,x1,x2,x3,x4,x5,x6,x7,x8,x9",
                "sid": "id"
            },
            "table_name": "breast_hetero_guest"
        },
        "retcode": 0,
        "retmsg": "success"
    }
    

四、模型训练
------

接下来我们就开始进行建模任务，需要准备两个配置文件，流程配置文件 dsl 和参数配置文件 conf。

### 4.1. 准备dsl文件

执行以下命令：

    cp /data/projects/fate/examples/dsl/v2/hetero_logistic_regression/hetero_lr_normal_dsl.json /data/projects/fate/examples/my_test/
    

> 直接把 Fate 自带的纵向逻辑回归算法样例，复制到我们的 `my_test` 目录下。

Fate 把各种算法实现了组件化，dsl 文件主要配置整个建模流程是由哪些 component 组成的：

![file](https://img2022.cnblogs.com/other/1769816/202206/1769816-20220620090439076-1498800039.png)

比如第一个模块 `Reader` 就是用于读取刚刚上传的训练数据，然后是 `DataTransform` 模块，把训练数据转换为实例对象，一般所有的建模流程都需要有前面这两个模块；

总的来说配置一个 component 需要以下内容：

    - module：模型组件，Fate 当前支持 37 个模型组件 
    - input： 
    	- date：数据输入
    	- module：模型输入
    - output：
    	- date：数据输出
    	- module：模型输出
    

module 是定义这个组件的类型，当前 Fate 已经自带 37 个组件可以使用，当然我们也可以自己开发新增算法组件进去；

input 和 output 就是分别设置组件的输入输出，两个同时都支持两种类型，分别是数据和模型输入输出。

> 详细的配置说明可参考官方文档：[https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/dsl\_conf/dsl\_conf\_v2\_setting\_guide.zh.md](https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/dsl_conf/dsl_conf_v2_setting_guide.zh.md)

### 4.2. 准备conf文件

执行以下命令：

    cp /data/projects/fate/examples/dsl/v2/hetero_logistic_regression/hetero_lr_normal_conf.json /data/projects/fate/examples/my_test/
    

> 直接把 Fate 自带的纵向逻辑回归算法样例，复制到我们的 `my_test` 目录下。

![file](https://img2022.cnblogs.com/other/1769816/202206/1769816-20220620090439361-1292068606.png)

从上图可以看到在 `component_parameters` 元素下，配置 `Reader` 组件所读取的表名。

该配置主要是配置以下内容：

*   DSL的版本
*   各个参与方的角色以及 party\_id
*   组件运行参数

> 关于组件清单以及每一个组件的详细配置参数可参考官方文档：[https://fate.readthedocs.io/en/latest/zh/federatedml\_component/](https://fate.readthedocs.io/en/latest/zh/federatedml_component/)

### 4.3. 提交任务

执行以下命令：

    flow job submit -d hetero_lr_normal_dsl.json -c hetero_lr_normal_conf.json
    

> 通过 -d 和 -c 来分别指定 dsl 和 conf 配置文件。

成功后返回训练任务的相关信息：

    {
        "data": {
            "board_url": "http://127.0.0.1:8080/index.html#/dashboard?job_id=202205070226373055640&role=guest&party_id=9999",
            "code": 0,
            "dsl_path": "/data/projects/fate/fateflow/jobs/202205070226373055640/job_dsl.json",
            "job_id": "202205070226373055640",
            "logs_directory": "/data/projects/fate/fateflow/logs/202205070226373055640",
            "message": "success",
            "model_info": {
                "model_id": "arbiter-10000#guest-9999#host-10000#model",
                "model_version": "202205070226373055640"
            },
            "pipeline_dsl_path": "/data/projects/fate/fateflow/jobs/202205070226373055640/pipeline_dsl.json",
            "runtime_conf_on_party_path": "/data/projects/fate/fateflow/jobs/202205070226373055640/guest/9999/job_runtime_on_party_conf.json",
            "runtime_conf_path": "/data/projects/fate/fateflow/jobs/202205070226373055640/job_runtime_conf.json",
            "train_runtime_conf_path": "/data/projects/fate/fateflow/jobs/202205070226373055640/train_runtime_conf.json"
        },
        "jobId": "202205070226373055640",
        "retcode": 0,
        "retmsg": "success"
    }
    

其中有几个属性需要关注：

*   board\_url：这个地址是可以查看任务情况的 FATE Board 地址。
*   job\_id：任务的唯一关键字，可以在 FATE Board 上通过这个 ID 查看任务的详情。
*   logs\_directory：是日志的路径，可以通过这个地址查看任务的各种日志信息。
*   model\_info：里面有 model\_id 和 model\_version 这两个信息会在执行预测任务时需要用到，预测之前需要指定基于哪个模型来执行预测任务，而这两个信息就是模型的唯一关键字。

五、可视化
-----

### 5.1. 任务概览

通过上面返回信息中 `board_url` 的地址，在浏览器访问即可进入任务的概览页面：

[http://127.0.0.1:8080/index.html#/dashboard?job\_id=202205070226373055640&role=guest&party\_id=9999](http://127.0.0.1:8080/index.html#/dashboard?job_id=202205070226373055640&role=guest&party_id=9999)

> 需要注意的是：因为是在容器里面执行的，所以 IP 地址需要按照实际情况进行修改。

登录的用户名和密码都为 `admin`

![file](https://img2022.cnblogs.com/other/1769816/202206/1769816-20220620090439710-1869884617.png)

左边 Dataset info 是各个参与方的信息，中间呢是任务的运行情况显示运行的进度条以及耗时，右边是整个任务流程的组件 `DAG` 图，下方是任务日志信息。

### 5.2. 组件输出

点击中间的 `view this job` 按钮，进入任务的详细信息：

![file](https://img2022.cnblogs.com/other/1769816/202206/1769816-20220620090440159-69588179.png)

DAG 图中的每个组件都是可以点击的，选中 `hetero_lr_0` 组件，点击右下角的 `view the outputs` 按钮，进入 **逻辑回归** 组件的输出页面：

![file](https://img2022.cnblogs.com/other/1769816/202206/1769816-20220620090440433-1767407381.png)

左上角有三个 TAG 分别为：

*   model output：模型输出，是算法组件的训练结果。
*   data output：数据输出，每个组件数据处理后的输出，用于下游组件的输入。
*   log：该组件的运行日志。

**扫码关注有惊喜！**

![file](https://img2022.cnblogs.com/other/1769816/202206/1769816-20220620090441124-771991030.png)