---
layout: post
title: "《前端运维》五、k8s--1安装与基本配置"
date: "2022-03-28T09:18:35.323Z"
---
《前端运维》五、k8s--1安装与基本配置
=====================

 一、k8s基础概念与安装
-------------

　　k8s，即[kubernetes](https://kubernetes.io/zh/)是用于自动部署，扩展和管理容器化应用程序的开源系统。详细的描述就不多说了，官网有更详细的内容。简单来说，k8s，是一个可以操作多台机器调度部署镜像的平台。在k8s中，可以使用集群来组织服务器。集群中会存在一个master节点，该节点是kubernetes的控制节点，负责调度服务器中被称为Node的其他资源。

　　下面，我们就正式开始k8s的学习。

　　首先，我们需要两台服务器，一个是master，一个是node。master服务器的配置要稍微高些，2核4G就差不多了，如果不是长时间用的话，可以买按量付费，用完了给它关了就好了。

　　购买好服务器后，我们需要给两台服务器预先安装一些依赖工具：

yum install vim wget ntpdate -y

　　vim和wget就不说了，之前的内容也都有使用过，ntpdate是用来同步时区的。然后，我们还需要关闭防火墙，因为k8s会创建防火墙规则：

systemctl stop firewalld & systemctl disable firewalld

　　然后，关闭swap分区，Swap 是 Linux 的交换分区，在系统资源不足时，Swap 分区会启用,这个我们不需要。应该让新创建的服务自动调度到集群的其他 Node 节点中去，而不是使用 Swap 分区。

#临时关闭
swapoff \-a

　　关闭Selinux，这是为了支持容器可以访问宿主机文件系统。

\# 暂时关闭 selinux
setenforce 0

# 永久关闭
vi /etc/sysconfig/selinux
# 修改以下参数，设置为disable
SELINUX\=disabled

　　下面我们就需要使用nptdate来统一我们的系统时间和时区，服务器时间与阿里云服务器对齐。

\# 统一时区，为上海时区
ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
bash \-c "echo 'Asia/Shanghai' > /etc/timezone"

# 统一使用阿里服务器进行时间更新
ntpdate ntp1.aliyun.com

　　**下一步我们来安装docker：**

yum install -y yum\-utils device-mapper-persistent-data lvm2

sudo yum\-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
yum install docker-ce -y
systemctl start docker
systemctl enable docker

sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": \["https://fwvjnv59.mirror.aliyuncs.com"\]
}
EOF

sudo systemctl daemon-reload
sudo systemctl restart docker.service

　　上面的：

*   device-mapper-persistent-data: 存储驱动，Linux上的许多高级卷管理技术
*   lvm: 逻辑卷管理器，用于创建逻辑磁盘分区使用　　

　　然后，我们来安装kubernetes组件，首先，切换阿里云：

cat <<EOF > /etc/yum.repos.d/kubernetes.repo
\[kubernetes\]
name\=Kubernetes
baseurl\=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86\_64
enabled=1
gpgcheck\=0
repo\_gpgcheck\=0
gpgkey\=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
        http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

　　然后，安装kubernetes组件：

yum install -y kubelet kubeadm kubectl
# 启动kubelet
systemctl enable kubelet && systemctl start kubelet

*   kubelet 是 Kubernetes 中的核心组件。它会运行在集群的所有节点上，并负责创建启动服务容器
*   kubectl 则是Kubernetes的命令行工具。可以用来管理，删除，创建资源
*   kubeadm 则是用来初始化集群，子节点加入的工具

　　最后，我们需要设置一下bridge-nf-call-iptables：

echo 1 > /proc/sys/net/bridge/bridge-nf-call-iptables

　　安装的部分就完成啦。下面我们来配置一些基本内容吧

二、基本配置
------

###  1）master节点安装

　　之前说过，需要两台服务器，一台master，一台node。我们先来安装master服务器的基本依赖。我们首先修改下主机名：

hostnamectl set-hostname  master

　　然后我们来修改下master服务器的host，使两台服务器可以通信：

ip addr
vim /etc/hosts

172.31.178.169  master  master

　　在上面的文件中，把node服务器的ip添加进去即可。然后我们需要配置下初始文件：

kubeadm config print init-defaults > init-kubeadm.conf
vim init\-kubeadm.conf

　　init-defaults命令，会生成一份初始文件。下面我们需要在init-kubeadm.conf文件中进行一些额外的，必要的更改：

\- imageRepository: k8s.gcr.io 更换k8s镜像仓库
\+ imageRepository: registry.cn-hangzhou.aliyuncs.com/google\_containers
\- localAPIEndpointc，advertiseAddress为master ip ,port默认不修改
localAPIEndpoint:
\+ advertiseAddress: 172.31.178.169  # 此处为master的IP
  bindPort: 6443
# 配置子网络
networking:
  dnsDomain: cluster.local
  serviceSubnet: 10.96.0.0/12
+ podSubnet: 10.244.0.0/16    # 添加这个

　　上面修改的代码修改了镜像仓库为阿里云的，加速组件的拉取，替换ip为自己主机的ip，配置pod网络为flannel网段，后面为了让集群之间可以互相通信，需要配置子网络，这些在后面的flannel网络中会用到。10.96.0.0/12 是Kubernetes内部的网络pods需要的网络。10.244.0.0/16 是Kubernetes内部services需要的网络。

　　下面我们就需要拉取一下组件：

// 查看缺少的组件
kubeadm config images list --config init-kubeadm.conf
// 拉取缺少的组件
kubeadm config images pull --config init-kubeadm.conf

　　直接执行这两个命令，就可以查看、拉取缺少的组件了。我们来简单了解下，这些组件都是干什么的：

*   kubeadm 可以用来拉取我们的默认组件镜像
*   kube-apiserver 提供接口服务，可以让外网访问集群
*   kube-controller-manager 内部的控制指令工具
*   kube-scheduler 内部的任务调度器
*   kube-proxy 反向代理和负载均衡，流量转发
*   pause 进程管理工具
*   etcd 保持 集群内部的数据一致性
*   coredns 集群内网通信

　　![](https://img2020.cnblogs.com/blog/1184971/202108/1184971-20210815141236025-1715154069.png)

　　我们也可以通过上图，来理解下k8s的运行流程。下面我们来初始化k8s：

kubeadm init --config init-kubeadm.conf

　　然后，我们需要执行的命令内容，k8s做了一部分提示：

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG\=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f \[podnetwork\].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/
Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 172.31.178.169:6443 --token abcdef.0123456789abcdef \\
    \--discovery-token-ca-cert-hash sha256:8aac19f4dbe68f1e15ba3d80e141acdc912e353f9757ad69187e8fb9780bc975 

　　我们根据提示执行就好了。下面我们来安装下flannel，`flannel` 主要的作用是通过创建一个虚拟网络，让不同节点下的服务有着全局唯一的IP地址，且服务之前可以互相访问和连接。集群内网网络通信协议通信模式采用了Flannel协议：

wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
docker pull quay.io/coreos/flannel:v0.13.0\-rc2
kubectl apply \-f kube-flannel.yml

　　下面我们要修改下net-conf.json文件，把其中的Network网段，配置的跟之前的pod网段一样即可：

{ "Network": "10.244.0.0/16", "Backend": { "Type": "vxlan" } }

　　然后我们就可以通过下面的命令查看下启动情况：

kubectl get nodes

　　master节点的配置到这里就基本oK了，下面我们来看下node节点的配置，首先同样的，我们先修改下主机名：

hostnamectl set-hostname node1

　　然后将master节点的配置文件拷贝到node节点：

scp $HOME/.kube/config root@172.31.178.170:~/

　　然后在node节点归档配置文件：

mkdir -p $HOME/.kube
sudo mv $HOME/config $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

　　然后，把node节点加入到master集群内：

kubeadm join 172.16.81.164:6443 --token abcdef.0123456789abcdef \\
    \--discovery-token-ca-cert-hash sha256:b4a059eeffa2e52f2eea7a5d592be10c994c7715c17bda57bbc3757d4f13903d

　　如果刚才的命令丢失，可以在master机器上通过下面的命令重新生成一条命令：

kubeadm token create --print-join\-command

　　同样的，我们安装下flannel：

scp ~/kube-flannel.yml root@172.31.178.170:~/
kubectl apply \-f kube-flannel.yml

　　查看下状态：

kubectl get nodes

　　ok，到这里，master节点和node节点的k8s基本配置就完事了，下面我们来安装一些必要的服务器软件。

三、安装其他服务
--------

　　我们先来在master节点安装下nginx：

kubectl create deployment nginx --image=nginx

　　然后：

kubectl expose deployment nginx --port=80 --type=NodePort

　　然后我们扩容几个副本：

kubectl scale deployment nginx --replicas=3

　　nginx好了，下面我们配置下mysql，首先我们创建个mysql.yml文件，添加如下内容：

apiVersion: v1
kind: ReplicationController                           
metadata:
  name: mysql                                          
spec:
  replicas: 1           #Pod副本的期待数量
  selector:
    app: mysql          #符合目标的Pod拥有此标签
  template:             #根据此模板创建Pod的副本（实例）
    metadata:
      labels:
        app: mysql     #Pod副本拥有的标签，对应RC的Selector
    spec:
      containers:      #Pod内容器的定义部分
      \- name: mysql            #容器的名称
        image: mysql    #容器对应的Docker image
        ports: 
        \- containerPort: 3306       #容器应用监听的端口号
        env:                        #注入容器内的环境变量
        \- name: MYSQL\_ROOT\_PASSWORD 
          value: "123456"

　　然后执行：

kubectl create -f mysql-rc.yaml

　　就创建好了mysql的配置。我们可以看下状态：

kubectl get pods

kubectl describe pod mysql

　　基本的配置到这里就OK了。我们下期见。

站在巨人的肩膀上，希望我可以看的更远。