---
layout: post
title: "ã€èˆªç­ä¹˜å®¢æ»¡æ„åº¦ã€åœºæ™¯æ•°æ®åˆ†æå»ºæ¨¡ä¸ä¸šåŠ¡å½’å› è§£é‡Š â›µ"
date: "2022-12-05T22:16:04.270Z"
---
ã€èˆªç­ä¹˜å®¢æ»¡æ„åº¦ã€åœºæ™¯æ•°æ®åˆ†æå»ºæ¨¡ä¸ä¸šåŠ¡å½’å› è§£é‡Š â›µ
==========================

![ã€èˆªç­ä¹˜å®¢æ»¡æ„åº¦ã€åœºæ™¯æ•°æ®åˆ†æå»ºæ¨¡ä¸ä¸šåŠ¡å½’å› è§£é‡Š â›µ](https://img2023.cnblogs.com/blog/2637458/202212/2637458-20221205131607034-520106426.png) æœ¬æ–‡ç»“åˆèˆªç©ºå‡ºè¡Œçš„åœºæ™¯ï¼Œä½¿ç”¨æœºå™¨å­¦ä¹ å»ºæ¨¡ï¼Œè¯¦ç»†åˆ†æäº†èˆªç­ä¹˜å®¢æ»¡æ„åº¦çš„å½±å“å› ç´ ï¼šæœºä¸ŠWi-FiæœåŠ¡ã€åœ¨çº¿ç™»æœºã€æœºä¸Šå¨±ä¹è´¨é‡ã€é¤é¥®ã€åº§æ¤…èˆ’é€‚åº¦ã€æœºèˆ±æ¸…æ´åº¦å’Œè…¿éƒ¨ç©ºé—´ç­‰ã€‚

![](https://img-blog.csdnimg.cn/img_convert/e3ad9ca2c0b9b1094397d3f2458ad47f.png)

> ğŸ’¡ ä½œè€…ï¼š[éŸ©ä¿¡å­](https://github.com/HanXinzi-AI)@[ShowMeAI](https://www.showmeai.tech/)  
> ğŸ“˜ [æ•°æ®åˆ†æå®æˆ˜ç³»åˆ—](https://www.showmeai.tech/tutorials/40)ï¼š[https://www.showmeai.tech/tutorials/40](https://www.showmeai.tech/tutorials/40)  
> ğŸ“˜ [æœºå™¨å­¦ä¹ å®æˆ˜ç³»åˆ—](https://www.showmeai.tech/tutorials/41)ï¼š[https://www.showmeai.tech/tutorials/41](https://www.showmeai.tech/tutorials/41)  
> ğŸ“˜ [æœ¬æ–‡åœ°å€](https://www.showmeai.tech/article-detail/401)ï¼š[https://www.showmeai.tech/article-detail/401](https://www.showmeai.tech/article-detail/401)  
> ğŸ“¢ å£°æ˜ï¼šç‰ˆæƒæ‰€æœ‰ï¼Œè½¬è½½è¯·è”ç³»å¹³å°ä¸ä½œè€…å¹¶æ³¨æ˜å‡ºå¤„  
> ğŸ“¢ æ”¶è—[ShowMeAI](https://www.showmeai.tech/)æŸ¥çœ‹æ›´å¤šç²¾å½©å†…å®¹

ğŸ’¡ å¼•è¨€
=====

![](https://img-blog.csdnimg.cn/img_convert/13b630f581d16864181ded6dad374a0a.png)

åœ¨è¿‡å»å‡ å¹´ä¸­ï¼Œå®¢æˆ·å¯¹èˆªç©ºå…¬å¸çš„æ»¡æ„åº¦ä¸€ç›´åœ¨ç¨³æ­¥æ”€å‡ã€‚åœ¨ COVID-19 å¤§æµè¡Œå¯¼è‡´çš„åœé¡¿ä¹‹åï¼Œèˆªç©ºæ—…è¡Œä¸šé‡æ–°å¼€å§‹ï¼Œå¤§å®¶è¶Šæ¥è¶Šå…³æ³¨èˆªç©ºå‡ºè¡Œçš„æ»¡æ„åº¦é—®é¢˜ï¼Œå®¢æˆ·ä¹Ÿä¼šå¯¹ä¸€äº›å¸¸è§é—®é¢˜ï¼Œå¦‚ã€ä¸èˆ’æœçš„åº§ä½ã€ã€ã€æ‹¥æŒ¤çš„ç©ºé—´ã€ã€ã€å»¶è¯¯ã€å’Œã€ä¸åˆæ ‡å‡†çš„è®¾æ–½ã€ç­‰è¿›è¡Œåé¦ˆã€‚

å„å®¶èˆªç©ºå…¬å¸ä¹Ÿè¶Šæ¥è¶Šå…³æ³¨å®¢æˆ·æ»¡æ„åº¦é—®é¢˜å¹¶åŠªåŠ›æé«˜ã€‚**å¯¹èˆªç©ºå…¬å¸è€Œè¨€ï¼Œå‡ºè‰²çš„å®¢æˆ·æœåŠ¡ï¼Œæ˜¯é”€é‡å’Œå®¢æˆ·ç•™å­˜çš„å…³é”®ï¼›åä¹‹ï¼Œç³Ÿç³•çš„å®¢æˆ·æœåŠ¡è¯„çº§ä¼šå¯¼è‡´å®¢æˆ·æµå¤±å’Œå…¬å¸å£°èª‰ä¸ä½³**ã€‚

![](https://img-blog.csdnimg.cn/img_convert/a84e282f0df9dd2331e48b89a86e0b11.png)

åœ¨æœ¬é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å°†å¯¹èˆªç©ºæ»¡æ„åº¦æ•°æ®è¿›è¡Œåˆ†æå»ºæ¨¡ï¼Œå¯¹æ»¡æ„åº¦è¿›è¡Œé¢„ä¼°ï¼Œå¹¶æ‰¾å‡ºå½±å“æ»¡æ„åº¦çš„æ ¸å¿ƒå› ç´ ã€‚

ğŸ’¡ æ•°æ®&ç¯å¢ƒ
========

è¿™é‡Œä½¿ç”¨åˆ°çš„ä¸»è¦å¼€å‘ç¯å¢ƒæ˜¯ Jupyter Notebooksï¼ŒåŸºäº Python 3.9 å®Œæˆã€‚ä¾èµ–çš„å·¥å…·åº“åŒ…æ‹¬ ç”¨äºæ•°æ®æ¢ç´¢åˆ†æçš„Pandasã€Numpyã€Seaborn å’Œ Matplotlib åº“ã€ç”¨äºå»ºæ¨¡å’Œä¼˜åŒ–çš„ XGBoost å’Œ Scikit-Learn åº“ï¼Œä»¥åŠç”¨äºæ¨¡å‹å¯è§£é‡Šæ€§åˆ†æçš„ SHAP å·¥å…·åº“ã€‚

![](https://img-blog.csdnimg.cn/img_convert/c3273af80f2e50b2feec1915bc892284.png)

> å…³äºä»¥ä¸Šå·¥å…·åº“çš„ç”¨æ³•ï¼Œ[ShowMeAI](https://www.showmeai.tech/)åœ¨å®æˆ˜æ–‡ç« ä¸­åšäº†è¯¦ç»†ä»‹ç»ï¼Œå¤§å®¶å¯ä»¥æŸ¥çœ‹ä»¥ä¸‹æ•™ç¨‹ç³»åˆ—å’Œæ–‡ç« 
> 
> ğŸ“˜[**æ•°æ®åˆ†æå®æˆ˜ï¼šPython æ•°æ®åˆ†æå®æˆ˜æ•™ç¨‹**](https://www.showmeai.tech/tutorials/40)
> 
> ğŸ“˜[**æœºå™¨å­¦ä¹ å®æˆ˜ï¼šæ‰‹æŠŠæ‰‹æ•™ä½ ç©è½¬æœºå™¨å­¦ä¹ ç³»åˆ—**](https://www.showmeai.tech/tutorials/41)
> 
> ğŸ“˜[**åŸºäºSHAPçš„æœºå™¨å­¦ä¹ å¯è§£é‡Šæ€§å®æˆ˜**](https://showmeai.tech/article-detail/337)

![](https://img-blog.csdnimg.cn/img_convert/15da4276b0b9065612ef0d214661c268.png)

æˆ‘ä»¬æœ¬æ¬¡ç”¨åˆ°çš„æ•°æ®é›†æ˜¯ ğŸ†[**Kaggleèˆªç©ºæ»¡æ„åº¦æ•°æ®é›†**](https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction)ã€‚æ•°æ®é›†ä½¿ç”¨`csv`æ ¼å¼æ–‡ä»¶å­˜å‚¨ï¼Œé¢„å…ˆåˆ‡åˆ†å¥½äº† 80% çš„è®­ç»ƒé›† å’Œ 20% çš„æµ‹è¯•é›†ï¼›ç›®æ ‡åˆ—â€œ_Satisfaction/_æ»¡æ„åº¦â€ã€‚å¤§å®¶å¯ä»¥é€šè¿‡ [ShowMeAI](https://www.showmeai.tech/) çš„ç™¾åº¦ç½‘ç›˜åœ°å€ä¸‹è½½ã€‚

> ğŸ† **å®æˆ˜æ•°æ®é›†ä¸‹è½½ï¼ˆç™¾åº¦ç½‘ç›˜ï¼‰**ï¼šå…¬ä¼—å·ã€ShowMeAIç ”ç©¶ä¸­å¿ƒã€å›å¤ã€**å®æˆ˜**ã€ï¼Œæˆ–è€…ç‚¹å‡» [**è¿™é‡Œ**](https://www.showmeai.tech/article-detail/305) è·å–æœ¬æ–‡ [\[36\]ã€èˆªç­ä¹˜å®¢æ»¡æ„åº¦ã€åœºæ™¯æ•°æ®åˆ†æå»ºæ¨¡ä¸ä¸šåŠ¡å½’å› è§£é‡Š](https://www.showmeai.tech/article-detail/401) ã€**Airline Passenger Satisfactionæ•°æ®é›†**ã€

> â­ **ShowMeAIå®˜æ–¹GitHub**ï¼š[https://github.com/ShowMeAI-Hub](https://github.com/ShowMeAI-Hub)

è¯¦ç»†çš„æ•°æ®åˆ—å­—æ®µå¦‚ä¸‹ï¼š

å­—æ®µ

è¯´æ˜

è¯¦æƒ…

Gender

ä¹˜å®¢æ€§åˆ«

Female, Male

Customer Type

ä¹˜å®¢ç±»å‹

Loyal customer, disloyal customer

Age

ä¹˜å®¢å¹´é¾„

\--

Type of Travel

ä¹˜å®¢å‡ºè¡Œç›®çš„

Personal Travel, Business Travel

Class

å®¢èˆ±ç­‰çº§

Business, Eco, Eco Plus

Flight distance

èˆªç¨‹è·ç¦»

\--

Inflight wifi service

æœºä¸ŠWiFiæœåŠ¡æ»¡æ„åº¦

0:Not Applicable;1-5

Departure/Arrival time convenient

èµ·é£/é™è½èˆ’é€‚åº¦æ»¡æ„åº¦

\--

Ease of Online booking

åœ¨çº¿é¢„å®šæ»¡æ„åº¦

\--

Gate location

ç™»æœºé—¨ä½ç½®æ»¡æ„åº¦

\--

Food and drink

æœºä¸Šé£Ÿç‰©æ»¡æ„åº¦

\--

Online boarding

åœ¨çº¿å€¼æœºæ»¡æ„åº¦

\--

Seat comfort

åº§æ¤…èˆ’é€‚åº¦æ»¡æ„åº¦

\--

Inflight entertainment

æœºä¸Šå¨±ä¹è®¾æ–½æ»¡æ„åº¦

\--

On-board service

ç™»æœºæœåŠ¡æ»¡æ„åº¦

\--

Leg room service

è…¿éƒ¨ç©ºé—´æ»¡æ„åº¦

\--

Baggage handling

è¡Œæå¤„ç†æ»¡æ„åº¦

\--

Check-in service

å€¼æœºæ»¡æ„åº¦

\--

Inflight service

æœºä¸ŠæœåŠ¡æ»¡æ„åº¦

\--

Cleanliness

ç¯å¢ƒå¹²å‡€åº¦æ»¡æ„åº¦

\--

Departure Delay in Minutes

èµ·é£å»¶è¯¯æ—¶é—´

\--

Arrival Delay in Minutes

æŠµè¾¾å»¶è¯¯æ—¶é—´

\--

Satisfaction

èˆªçº¿æ»¡æ„åº¦

Satisfaction, neutral or dissatisfaction

ğŸ’¡ æ•°æ®ä¸€è§ˆå’Œæ¸…ç†
==========

ğŸ’¦ æ•°æ®ä¸€è§ˆ
-------

æˆ‘ä»¬å…ˆå¯¼å…¥å·¥å…·åº“ï¼Œè¿›è¡ŒåŸºæœ¬çš„è®¾å®šï¼Œå¹¶è¯»å–æ•°æ®ã€‚

    # å¯¼å…¥å·¥å…·åº“
    import pandas as pd
    import numpy as np
    import scipy.stats as sp
    import matplotlib.pyplot as plt
    import seaborn as sns
    
    import warnings
    warnings.filterwarnings("ignore")
    
    # å¯è§†åŒ–å›¾ä¾‹è®¾å®š
    from matplotlib import rcParams
    # å­—ä½“å¤§å°
    rcParams['font.size'] = 12
    # å›¾ä¾‹å¤§å°
    rcParams['figure.figsize'] = 7, 5
    
    # è¯»å–æ•°æ®
    air_train_df = pd.read_csv('air-train.csv')
    air_test_df = pd.read_csv('air-test.csv')
    
    air_train_df.head()
    

![](https://img-blog.csdnimg.cn/img_convert/589ddf50e854f1d55fdba8a279ca5db5.png)

    air_train_df.satisfaction.value_counts()
    neutral or dissatisfied    58879
    satisfied                  45025
    Name: satisfaction, dtype: int64
    air_train_df.info()
    
    air_test_df.info()
    

è¾“å‡ºçš„æ•°æ®ä¿¡æ¯å¦‚ä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨åˆ°çš„æ•°æ®æ€»å…±åŒ…å« 129,880 è¡Œ25 åˆ—ã€‚æ•°æ®é›†è¢«é¢„æ‹†åˆ†ä¸ºåŒ…å« 103,904 è¡Œçš„è®­ç»ƒæ•°æ®é›†ï¼ˆ19.8MBï¼‰å’ŒåŒ…å« 25,976 è¡Œçš„æµ‹è¯•æ•°æ®é›†ï¼ˆ5MBï¼‰ã€‚

    Training Data Set (air_train_df):
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 103904 entries, 0 to 103903
    Data columns (total 25 columns):
     #   Column                             Non-Null Count   Dtype  
    ---  ------                             --------------   -----  
     0   Unnamed: 0                         103904 non-null  int64  
     1   id                                 103904 non-null  int64  
     2   Gender                             103904 non-null  object 
     3   Customer Type                      103904 non-null  object 
     4   Age                                103904 non-null  int64  
     5   Type of Travel                     103904 non-null  object 
     6   Class                              103904 non-null  object 
     7   Flight Distance                    103904 non-null  int64  
     8   Inflight wifi service              103904 non-null  int64  
     9   Departure/Arrival time convenient  103904 non-null  int64  
     10  Ease of Online booking             103904 non-null  int64  
     11  Gate location                      103904 non-null  int64  
     12  Food and drink                     103904 non-null  int64  
     13  Online boarding                    103904 non-null  int64  
     14  Seat comfort                       103904 non-null  int64  
     15  Inflight entertainment             103904 non-null  int64  
     16  On-board service                   103904 non-null  int64  
     17  Leg room service                   103904 non-null  int64  
     18  Baggage handling                   103904 non-null  int64  
     19  Checkin service                    103904 non-null  int64  
     20  Inflight service                   103904 non-null  int64  
     21  Cleanliness                        103904 non-null  int64  
     22  Departure Delay in Minutes         103904 non-null  int64  
     23  Arrival Delay in Minutes           103594 non-null  float64
     24  satisfaction                       103904 non-null  object 
    dtypes: float64(1), int64(19), object(5)
    memory usage: 19.8+ MB
    
    Testing Set (air_test_df):
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 25976 entries, 0 to 25975
    Data columns (total 25 columns):
     #   Column                             Non-Null Count  Dtype  
    ---  ------                             --------------  -----  
     0   Unnamed: 0                         25976 non-null  int64  
     1   id                                 25976 non-null  int64  
     2   Gender                             25976 non-null  object 
     3   Customer Type                      25976 non-null  object 
     4   Age                                25976 non-null  int64  
     5   Type of Travel                     25976 non-null  object 
     6   Class                              25976 non-null  object 
     7   Flight Distance                    25976 non-null  int64  
     8   Inflight wifi service              25976 non-null  int64  
     9   Departure/Arrival time convenient  25976 non-null  int64  
     10  Ease of Online booking             25976 non-null  int64  
     11  Gate location                      25976 non-null  int64  
     12  Food and drink                     25976 non-null  int64  
     13  Online boarding                    25976 non-null  int64  
     14  Seat comfort                       25976 non-null  int64  
     15  Inflight entertainment             25976 non-null  int64  
     16  On-board service                   25976 non-null  int64  
     17  Leg room service                   25976 non-null  int64  
     18  Baggage handling                   25976 non-null  int64  
     19  Checkin service                    25976 non-null  int64  
     20  Inflight service                   25976 non-null  int64  
     21  Cleanliness                        25976 non-null  int64  
     22  Departure Delay in Minutes         25976 non-null  int64  
     23  Arrival Delay in Minutes           25893 non-null  float64
     24  satisfaction                       25976 non-null  object 
    dtypes: float64(1), int64(19), object(5)
    memory usage: 5.0+ MB
    

æ•°æ®é›†ä¸­ï¼Œ19 ä¸ª int æ•°æ®ç±»å‹å­—æ®µï¼Œ1 ä¸ª float æ•°æ®ç±»å‹å­—æ®µï¼Œ5 ä¸ªåˆ†ç±»æ•°æ®ç±»å‹ï¼ˆå¯¹è±¡ï¼‰å­—æ®µã€‚

ğŸ’¦ æ•°æ®æ¸…æ´—
-------

ä¸‹é¢æˆ‘ä»¬è¿›è¡Œæ•°æ®æ¸…æ´—ï¼š

*   `id`å’Œ`unnamed`ä¸¤åˆ—æ²¡æœ‰ä½œç”¨ï¼Œæˆ‘ä»¬ç›´æ¥åˆ é™¤ã€‚
*   ã€åˆ°è¾¾å»¶è¯¯æ—¶é—´ã€åˆ—æ˜¯æµ®ç‚¹æ•°æ®ç±»å‹ï¼Œã€å‡ºå‘å»¶è¯¯æ—¶é—´ã€åˆ—æ˜¯æ•´æ•°æ•°æ®ç±»å‹ï¼Œåœ¨è¿›è¡Œè¿›ä¸€æ­¥åˆ†æå‰ï¼Œæˆ‘ä»¬æŠŠå®ƒä»¬éƒ½è°ƒæ•´ä¸ºæµ®ç‚¹æ•°ç±»å‹ï¼Œä¿æŒä¸€è‡´ã€‚
*   ç±»åˆ«å‹å˜é‡ï¼ŒåŒ…æ‹¬åˆ—åå’Œåˆ—å–å€¼ï¼Œæˆ‘ä»¬å¯¹å®ƒä»¬åšè§„èŒƒåŒ–å¤„ç†ï¼ˆå…¨éƒ¨å°å†™åŒ–ï¼Œä»¥ä¾¿åœ¨åç»­å»ºæ¨¡è¿‡ç¨‹ä¸­å‡†ç¡®ç¼–ç ï¼‰ã€‚
*   `Arrival Delay` åˆ—ä¸­ä¹Ÿå­˜åœ¨ç¼ºå¤±å€¼â€”â€”è®­ç»ƒé›†ä¸­ç¼ºå°‘ 310 ä¸ªï¼Œæµ‹è¯•é›†ä¸­ç¼ºå°‘ 83 ä¸ªã€‚æˆ‘ä»¬åœ¨è¿™é‡Œç”¨æœ€ç®€å•çš„å¹³å‡å€¼æ¥å¡«å……å®ƒä»¬ã€‚
*   æ•°æ®é›†çš„æ»¡æ„åº¦ç­‰çº§åˆ—åº”è¯¥æ˜¯ 1 åˆ° 5 çš„ç­‰çº§è¯„åˆ†ã€‚æœ‰ä¸€äº›å–å€¼ä¸º0çš„è„æ•°æ®ï¼Œæˆ‘ä»¬å‰”é™¤æ‰å®ƒä»¬ã€‚
*   æˆ‘ä»¬æŠŠèˆªç­å»¶è¯¯ä¿¡æ¯èšåˆæˆä¸€äº›ç»Ÿä¸€çš„åˆ—ã€‚è¡¨æ˜èˆªç­æ˜¯å¦ç»å†äº†å»¶è¯¯ï¼ˆèµ·é£æˆ–åˆ°è¾¾ï¼‰å’Œèˆªç­å»¶è¯¯æ‰€èŠ±è´¹çš„æ€»æ—¶é—´ã€‚

    def clean_data(orig_df):
        '''
        This function applies 5 steps to the dataframe to clean the data.
        1. Dropping of unnecessary columns
        2. Uniformize datatypes in delay column
        3. Normalizing column names.
        4. Normalizing text values in columns.
        5. Imputing numeric null values with the mean value of the column.
        6. Dropping "zero" values from ranked categorical variables.
        7. Creating aggregated flight delay column
        
        
        Return: Cleaned DataFrame, ready for analysis - final encoding still to be applied.
        ''' 
        
        df = orig_df.copy()
        
        '''1. Dropping off unnecessary columns'''
        df.drop(['Unnamed: 0', 'id'], axis = 1, inplace = True)
        
        '''2. Uniformizing datatype in delay column'''
        df['Departure Delay in Minutes'] = df['Departure Delay in Minutes'].astype(float)
        
        '''3. Normalizing column names'''
        df.columns = df.columns.str.lower()
    
        '''Replacing spaces and other characters with underscores, this is more 
        for us to make it easier to work with them and so that we can call them using dot notation.'''
        special_chars = "/ -" 
        for special_char in special_chars:
            df.columns = [col.replace(special_char, '_') for col in df.columns]
        
        '''4. Normalizing text values in columns'''
        cat_cols = ['gender', 'customer_type', 'class', 'type_of_travel', 'satisfaction']
    
        for column in cat_cols:
            df[column] = df[column].str.lower() 
            
        '''5. Imputing the nulls in the arrival delay column with the mean.
        Since we cannot safely equate these nulls to a zero value, the mean value of the column is the
        most sensible method of replacement.'''
        df['arrival_delay_in_minutes'].fillna(df['arrival_delay_in_minutes'].mean(), inplace = True)
        df.round({'arrival_delay_in_minutes' : 1})
        
        '''6. Dropping rows from ranked value columns where "zero" exists as a value
        Since these columns are meant to be ranked on a scale from 1 to 5, having zero as a value 
        does not make sense nor does it help us in any way.'''
        rank_list = ["inflight_wifi_service", "departure_arrival_time_convenient", "ease_of_online_booking", "gate_location",
                    "food_and_drink", "online_boarding", "seat_comfort", "inflight_entertainment", "on_board_service",
                    "leg_room_service", "baggage_handling", "checkin_service", "inflight_service", "cleanliness"]
        
        '''7. Creating aggregated and categorical flight delay columns'''
        df['total_delay_time'] = (df['departure_delay_in_minutes'] + df['arrival_delay_in_minutes'])
        df['was_flight_delayed'] = np.nan
        df['was_flight_delayed'] = np.where(df['total_delay_time'] > 0, 'yes', 'no')
    
        for col in rank_list:
            df.drop(df.loc[df[col]==0].index, inplace=True)
        
        cleaned_df = df
        
        return cleaned_df
    

ğŸ’¡ æ¢ç´¢æ€§åˆ†æ
========

å®Œæˆæ•°æ®åŠ è½½ä¸åŸºæœ¬çš„æ•°æ®æ¸…æ´—åï¼Œæˆ‘ä»¬å¯¹æ•°æ®è¿›è¡Œè¿›ä¸€æ­¥çš„åˆ†ææŒ–æ˜ï¼Œå³EDAï¼ˆæ¢ç´¢æ€§æ•°æ®åˆ†æï¼‰çš„è¿‡ç¨‹ã€‚

ğŸ’¦ ç›®æ ‡å˜é‡ï¼ˆå®¢æˆ·æ»¡æ„åº¦ï¼‰åˆ†å¸ƒå¦‚ä½•
------------------

æˆ‘ä»¬å…ˆå¯¹ç›®æ ‡å˜é‡è¿›è¡Œåˆ†æï¼Œå³å®¢æˆ·æ»¡æ„åº¦æƒ…å†µï¼Œè¿™æ˜¯å»ºæ¨¡çš„æœ€ç»ˆæ ‡ç­¾ï¼Œå®ƒæ˜¯ä¸€ä¸ªç±»åˆ«å‹å­—æ®µã€‚

    air_train_cleaned = clean_data(air_train_df)
    air_test_cleaned = clean_data(air_test_df)
    
    fig = plt.figure(figsize = (10,7))
    air_train_cleaned.satisfaction.value_counts(normalize = True).plot(kind='bar', alpha = 0.9, rot=0)
    plt.title('Customer satisfaction')
    plt.ylabel('Percent')
    plt.show()
    

![](https://img-blog.csdnimg.cn/img_convert/aa279f51cd4683b7cd73e80e907c4f04.png)

æ€»ä½“æ¥è¯´ï¼Œæ ‡ç­¾è¿˜ç®—å‡è¡¡ï¼Œå¤§çº¦ 55% çš„ä¸­ç«‹æˆ–ä¸æ»¡æ„ï¼Œ45% çš„æ»¡æ„ã€‚è¿™ç§æ ‡ç­¾æ¯”ä¾‹åˆ†å¸ƒä¸‹ï¼Œæˆ‘ä»¬ä¸éœ€è¦è¿›è¡Œæ•°æ®é‡‡æ ·ã€‚

ğŸ’¦ æ€§åˆ«å’Œå®¢æˆ·èº«ä»½ V.S. æ»¡æ„åº¦
-------------------

    with sns.axes_style(style = 'ticks'):
        d = sns.histplot(x = "gender",  hue= 'satisfaction', data = air_train_cleaned,  
                         stat = 'percent', multiple="dodge", palette = 'Set1')
    

![](https://img-blog.csdnimg.cn/img_convert/3ba9fc281cd044c6ef8253b425166341.png)

ä»æ€§åˆ«ç»´åº¦æ¥çœ‹ï¼Œç”·å¥³ä¼¼ä¹å·®åˆ«ä¸å¤§ï¼Œæ€»ä½“æ»¡æ„åº¦å¯èƒ½æ›´å–å†³äºå…¶ä»–å› ç´ ã€‚

    with sns.axes_style(style = 'ticks'):
        d = sns.histplot(x = "customer_type",  hue= 'satisfaction', data = air_train_cleaned, 
                         stat = 'percent', multiple="dodge", palette = 'Set1')
    

![](https://img-blog.csdnimg.cn/img_convert/2c6083ae3b91e7b6914b8a27f7d20c0d.png)

ä»å®¢æˆ·å¿ è¯šåº¦è§’åº¦çœ‹ï¼Œå¿ è¯šå®¢æˆ·çš„æ»¡æ„åº¦æ¯”ä¾‹ä¼šç›¸å¯¹é«˜ä¸€ç‚¹ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ä»¬å¯ä»¥ç›´è§‚ç†è§£çš„ã€‚

ğŸ’¦ å®¢èˆ±ç­‰çº§ V.S. æ»¡æ„åº¦
----------------

    with sns.axes_style(style = 'ticks'):
        d = sns.histplot(x = "class",  hue= 'satisfaction', data = air_train_cleaned,
                         stat = 'percent', multiple="dodge", palette = 'Set1')
    

![](https://img-blog.csdnimg.cn/img_convert/5d7ffd68bd5af897c65a80a28979841e.png)

æˆ‘ä»¬åˆ†åˆ«çœ‹ä¸€ä¸‹ä¹˜åç»æµèˆ±ã€é«˜çº§èˆ±å’Œå•†åŠ¡èˆ±çš„æ—…å®¢çš„æ»¡æ„åº¦ï¼Œä»ä¸Šé¢çš„åˆ†å¸ƒæˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°ä¹˜åé«˜çº§èˆ±ï¼ˆå•†åŠ¡èˆ±ï¼‰çš„ä¹˜å®¢ä¸ä¹˜åé•¿é€”å®¢èˆ±ï¼ˆç»æµèˆ±æˆ–è±ªåèˆ±ï¼‰çš„ä¹˜å®¢åœ¨æ»¡æ„åº¦ä¸Šå­˜åœ¨æ ¹æœ¬å·®å¼‚ã€‚

é‚£æˆ‘ä»¬è¿›è€Œçœ‹ä¸€ä¸‹å› ä¸ªäººä¼‘é—²è€Œå‡ºå·®çš„ä¹˜å®¢

    with sns.axes_style(style = 'ticks'):
        d = sns.histplot(x = "type_of_travel",  hue= 'satisfaction', data = air_train_cleaned,
                         stat = 'percent', multiple="dodge", palette = 'Set1')
    

![](https://img-blog.csdnimg.cn/img_convert/84da7f580486abd455f46e6791972ba6.png)

ä»ä¸Šé¢çš„åˆ†ææˆ‘ä»¬å‘ç°ï¼Œå•†åŠ¡æ—…è¡Œçš„ä¹˜å®¢ä¸ä¼‘é—²æ—…è¡Œçš„ä¹˜å®¢ä¹‹é—´çš„æ»¡æ„åº¦å­˜åœ¨éå¸¸æ˜¾è‘—çš„å·®å¼‚ã€‚

ğŸ’¦ å¹´é¾„æ®µ V.S. æ»¡æ„åº¦
---------------

    with sns.axes_style('white'):
        g = sns.catplot(x = 'age', data = air_train_cleaned,  
                        kind = 'count', hue = 'satisfaction', order = range(7, 80),
                        height = 8.27, aspect=18.7/8.27, legend = False,
                       palette = 'Set1')
        
    plt.legend(loc='upper right');
    

![](https://img-blog.csdnimg.cn/img_convert/e338b0fda701902356b4d89025945be0.png)

    sns.violinplot(data = air_train_cleaned, x = "satisfaction", y = "age", palette='Set1')
    

![](https://img-blog.csdnimg.cn/img_convert/aed9a4b87a7cbe617ef9a06760111d0b.png)

ä¸Šå›¾æ˜¯å¹´é¾„å’Œæ»¡æ„åº¦ä¹‹é—´çš„å…³ç³»ï¼Œåˆ†æç»“æœéå¸¸æœ‰è¶£ï¼Œ37-61 å²å¹´é¾„ç»„ä¸å…¶ä»–å¹´é¾„ç»„ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ˆä»–ä»¬å¯¹ä½“éªŒçš„æ»¡æ„åº¦è¿œè¿œé«˜äºå…¶ä»–ç»„çš„ä¹˜å®¢ï¼‰ã€‚å¦å¤–æˆ‘ä»¬è¿˜è§‚å¯Ÿåˆ°ï¼Œè¿™ä¸ªæ®µçš„ä¹˜å®¢çš„æ»¡æ„åº¦éšç€å¹´é¾„çš„å¢é•¿è€Œç¨³æ­¥ä¸Šå‡ã€‚

ğŸ’¦ é£è¡Œæ—¶é—´é•¿çŸ­ V.S. æ»¡æ„åº¦
------------------

    sns.violinplot(data = air_train_cleaned, x = "satisfaction", y = "flight_distance", palette = 'Set1')
    

![](https://img-blog.csdnimg.cn/img_convert/835f5c79c464018e880573a3e0e8fd36.png)

ä»é£è¡Œè·ç¦»ç»´åº¦ï¼Œæˆ‘ä»¬çœ‹ä¸å‡ºæ˜¾è‘—çš„æ»¡æ„åº¦å·®å¼‚ï¼Œè€Œä¸”ç»å¤§å¤šæ•°ä¹˜å®¢çš„èˆªç­èˆªç¨‹ä¸º 1,000 è‹±é‡Œæˆ–æ›´çŸ­ã€‚

ğŸ’¦ é£è¡Œè·ç¦» V.S. å„ä¸ªä½“éªŒç»´åº¦
-------------------

    score_cols = ["inflight_wifi_service", "departure_arrival_time_convenient", "ease_of_online_booking", 
                  "gate_location","food_and_drink", "online_boarding", "seat_comfort", "inflight_entertainment", 
                  "on_board_service","leg_room_service", "baggage_handling", "checkin_service", "inflight_service","cleanliness"]
    plt.figure(figsize=(40, 20))
    plt.subplots_adjust(hspace=0.3)
    
    # Loop through scored columns
    for n, score_col in enumerate(score_cols):
        # Add a new subplot iteratively
        ax = plt.subplot(4, 4, n + 1)
    
        # Filter df and plot scored column on new axis
        sns.violinplot(data = air_train_cleaned, 
                       x = score_col, 
                       y = 'flight_distance', 
                       hue = "satisfaction",
                       split = True,
                       ax = ax,
                       palette = 'Set1')
    
        # Chart formatting
        ax.set_title(score_col)
        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),
              fancybox=True, shadow=True, ncol=5)
        ax.set_xlabel("")
    

![](https://img-blog.csdnimg.cn/img_convert/3a08d4bd3791fe7af420eb9e09e32458.png)

æˆ‘ä»¬ä½¿ç”¨å°æç´å›¾å¯¹èˆªç­ä¸åŒé£è¡Œè·ç¦»å’Œæ—…å®¢å¯¹ä¸åŒæœåŠ¡ç»´åº¦è¯„çº§çš„æ»¡æ„ç¨‹åº¦è¿›è¡Œäº¤å‰åˆ†æå¦‚ä¸Šï¼Œé£è¡Œè·ç¦»å¯¹å®¢æˆ·æ»¡æ„åº¦çš„å½±å“è¿˜æ˜¯æ¯”è¾ƒå¤§çš„ã€‚

ğŸ’¦ å¹´é¾„ V.S. å„ä¸ªä½“éªŒç»´åº¦
-----------------

    plt.figure(figsize=(40, 20))
    plt.subplots_adjust(hspace=0.3)
    
    # Loop through scored columns
    for n, score_col in enumerate(score_cols):
        # Add a new subplot iteratively
        ax = plt.subplot(4, 4, n + 1)
    
        # Filter df and plot scored column on new axis
        sns.violinplot(data = air_train_cleaned, 
                       x = score_col, 
                       y = 'age', 
                       hue = "satisfaction",
                       split = True,
                       ax = ax,
                       palette = 'Set1')
    
        # Chart formatting
        ax.set_title(score_col),
        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),
              fancybox=True, shadow=True, ncol=5)
        ax.set_xlabel("")
    

![](https://img-blog.csdnimg.cn/img_convert/c3a3c4ddaec4ef27283f3c869d9df7c7.png)

åŒæ ·çš„æ–¹å¼ï¼Œæˆ‘ä»¬é’ˆå¯¹ä¸åŒçš„å¹´é¾„æ®µï¼Œå¯¹äºä¹˜å®¢åœ¨ä¸åŒç»´åº¦çš„ä½“éªŒæ»¡æ„åº¦åˆ†æå¦‚ä¸Šï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œåœ¨è¿™äº›åˆ†å¸ƒçš„å¤§å¤šæ•°ä¸­ï¼Œ37-60 å²å¹´é¾„ç»„æœ‰ä¸€ä¸ªæ˜æ˜¾çš„é«˜å³°ã€‚

ğŸ’¦ å®¢èˆ±ç­‰çº§å’Œå‡ºè¡Œç›®çš„ V.S. å„ä¸ªä½“éªŒç»´åº¦
------------------------

    plt.figure(figsize=(40, 20))
    plt.subplots_adjust(hspace=0.3)
    
    # Loop through scored columns
    for n, score_col in enumerate(score_cols):
        # Add a new subplot iteratively
        ax = plt.subplot(4, 4, n + 1)
    
        # Filter df and plot scored column on new axis
        sns.violinplot(data = air_train_cleaned, 
                       x = 'class', 
                       y = score_col, 
                       hue = "satisfaction",
                       split = True,
                       ax = ax,
                       palette = 'Set1')
    
        # Chart formatting
        ax.set_title(score_col)
        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),
              fancybox=True, shadow=True, ncol=5)
        ax.set_xlabel("")
    

![](https://img-blog.csdnimg.cn/img_convert/22c631e8b3d7232a4738b08caf35710d.png)

    plt.figure(figsize=(40, 20))
    plt.subplots_adjust(hspace=0.3)
    
    # Loop through scored columns
    for n, score_col in enumerate(score_cols):
        # Add a new subplot iteratively
        ax = plt.subplot(4, 4, n + 1)
    
        # Filter df and plot scored column on new axis
        sns.violinplot(data = air_train_cleaned, 
                       x = 'type_of_travel', 
                       y = score_col, 
                       hue = "satisfaction",
                       split = True,
                       ax = ax,
                       palette = 'Set1')
    
        # Chart formatting
        ax.set_title(score_col)
        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),
              fancybox=True, shadow=True, ncol=5)
        ax.set_xlabel("")
    

![](https://img-blog.csdnimg.cn/img_convert/e423b536479e66821b32430f86ca2d01.png)

åŒæ ·çš„æ–¹å¼ï¼Œæˆ‘ä»¬é’ˆå¯¹ä¸åŒçš„å®¢èˆ±ç­‰çº§å’Œå‡ºè¡Œç›®çš„ï¼Œå¯¹äºä¹˜å®¢åœ¨ä¸åŒç»´åº¦çš„ä½“éªŒæ»¡æ„åº¦åˆ†æå¦‚ä¸Šï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œè¿™ä¸¤ä¸ªä¿¡æ¯å¾ˆå¤§ç¨‹åº¦å½±å“ä¹˜å®¢æ»¡æ„åº¦ã€‚æœºä¸Š Wi-Fi æœåŠ¡ã€åœ¨çº¿ç™»æœºã€åº§æ¤…èˆ’é€‚åº¦ã€æœºä¸Šå¨±ä¹ã€æœºä¸Šå®¢æˆ·æœåŠ¡ã€è…¿éƒ¨ç©ºé—´å’Œæœºä¸Šå®¢æˆ·æœåŠ¡çš„æ»¡æ„åº¦å’Œä¸æ»¡æ„åº¦éƒ½å‡ºç°äº†æ˜æ˜¾çš„é«˜å³°ã€‚

å¾ˆæœ‰æ„æ€çš„ä¸€ç‚¹æ˜¯æœºä¸Šwi-fiæœåŠ¡æ ï¼Œè¿™ä¸€é¡¹çš„æ»¡æ„ä¼¼ä¹å¯¹ä¹˜åç»æµèˆ±å’Œç»æµèˆ±çš„å®¢æˆ·çš„èˆªç­è¡Œç¨‹æ»¡æ„æœ‰å¾ˆå¤§å½±å“ï¼Œä½†å®ƒä¼¼ä¹å¯¹å•†åŠ¡èˆ±æ—…å®¢çš„æ»¡æ„åº¦æ²¡æœ‰å¤ªå¤§å½±å“ã€‚

ğŸ’¡ æ•°æ®å¤„ç†å’Œç‰¹å¾é€‰æ‹©
============

ğŸ’¦ æ•°æ®å¤„ç†/ç‰¹å¾å·¥ç¨‹
------------

åœ¨å°†æ•°æ®å¼•å…¥æ¨¡å‹ä¹‹å‰ï¼Œå¿…é¡»å¯¹æ•°æ®è¿›è¡Œç¼–ç ä»¥ä¾¿ä¸ºå»ºæ¨¡åšå¥½å‡†å¤‡ã€‚æˆ‘ä»¬é’ˆå¯¹ç±»åˆ«å‹çš„å˜é‡ï¼Œä½¿ç”¨åºå·ç¼–ç è¿›è¡Œç¼–ç æ˜ å°„ï¼Œå…·ä½“ä»£ç å¦‚ä¸‹ï¼ˆè€ƒè™‘åˆ°ä¸‹é¢çš„ä¸åŒç±»åˆ«å–å€¼æœ¬èº«æœ‰ç¨‹åº¦å¤§å°å…³ç³»ï¼Œä»¥åŠæˆ‘ä»¬ä¼šä½¿ç”¨xgboostç­‰éçº¿æ€§æ¨¡å‹ï¼Œå› æ­¤åºå·ç¼–ç æ˜¯OKçš„ï¼‰

> å…³äºç‰¹å¾å·¥ç¨‹çš„è¯¦ç»†çŸ¥è¯†ï¼Œæ¬¢è¿å¤§å®¶æŸ¥çœ‹[ShowMeAI](https://www.showmeai.tech/)çš„ç³»åˆ—æ•™ç¨‹æ–‡ç« ï¼š
> 
> ğŸ“˜[**æœºå™¨å­¦ä¹ å®æˆ˜ | æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹æœ€å…¨è§£è¯»**](https://showmeai.tech/article-detail/208)

    from sklearn.preprocessing import OrdinalEncoder
    
    def encode_data(orig_df):
        '''
        Encodes remaining categorical variables of data frame to be ready for model ingestion
        
        Inputs:
           Dataframe
           
        Manipulations:
            Encoding of categorical variables.    
        
        Return: 
            Encoded Column Values
        '''
       
        df = orig_df.copy()
        
        #Ordinal encode of scored rating columns.
        encoder = OrdinalEncoder()
        
        for j in score_cols:
            df[j] = encoder.fit_transform(df[[j]]) 
        
        # Replacement of binary categories.
        df.was_flight_delayed.replace({'no': 0, 'yes' : 1}, inplace = True)
        df['satisfaction'].replace({'neutral or dissatisfied': 0, 'satisfied': 1},inplace = True)
        df.customer_type.replace({'disloyal customer': 0, 'loyal customer': 1}, inplace = True)
        df.type_of_travel.replace({'personal travel': 0, 'business travel': 1}, inplace = True)
        df.gender.replace({'male': 0, 'female' : 1}, inplace = True)
        
        encoded_df = pd.get_dummies(df, columns = ['class'])
        
        return encoded_df
    # å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¿›è¡Œç¼–ç 
    air_train_encoded = encode_data(air_train_cleaned)
    air_test_encoded = encode_data(air_test_cleaned)
    
    # æŸ¥çœ‹ç‰¹å¾å’Œç›®æ ‡åˆ—ä¹‹é—´çš„ç›¸å…³æ€§
    train_corr = air_train_encoded.corr()[['satisfaction']]
    train_corr = train_corr
    
    plt.figure(figsize=(10, 12))
    
    heatmap = sns.heatmap(train_corr.sort_values(by='satisfaction', ascending=False), 
                          vmin=-1, vmax=1, annot=True, cmap='Blues')
    
    heatmap.set_title('Feature Correlation with Target Variable', fontdict={'fontsize':14});
    

![](https://img-blog.csdnimg.cn/img_convert/6f17454cc885b6eeef63f19419daca15.png)

ğŸ’¦ ç‰¹å¾é€‰æ‹©
-------

ä¸ºäº†æ›´ä½³çš„å»ºæ¨¡æ•ˆæœä¸æ›´é«˜æ•ˆçš„å»ºæ¨¡æ•ˆç‡ï¼Œåœ¨å®Œæˆç‰¹å¾å·¥ç¨‹ä¹‹åæˆ‘ä»¬è¦è¿›è¡Œç‰¹å¾é€‰æ‹©ï¼Œæˆ‘ä»¬è¿™é‡Œä½¿ç”¨ Scikit-Learn çš„å†…ç½®ç‰¹å¾é€‰æ‹©åŠŸèƒ½ï¼Œä½¿ç”¨ K-Best ä½œä¸ºç‰¹å¾ç­›é€‰å™¨ï¼Œå¹¶ä½¿ç”¨å¡æ–¹å€¼ä½œä¸ºç­›é€‰æ ‡å‡†ï¼ˆ å¡æ–¹æ˜¯ç›¸å¯¹åˆé€‚çš„æ ‡å‡†ï¼Œå› ä¸ºæˆ‘ä»¬çš„æ•°æ®é›†ä¸­æœ‰å‡ ä¸ªåˆ†ç±»å˜é‡ï¼‰ã€‚

    # Pre-processing and scaling dataset for feature selection
    from sklearn import preprocessing
    
    r_scaler = preprocessing.MinMaxScaler()
    r_scaler.fit(air_train_encoded)
     
    air_train_scaled = pd.DataFrame(r_scaler.transform(air_train_encoded), columns = air_train_encoded.columns)
    air_train_scaled.head()
    
    # Feature selection, applying Select K Best and Chi2 to output the 15 most important features
    from sklearn.feature_selection import SelectKBest, chi2
    
    X = air_train_scaled.loc[:,air_train_scaled.columns!='satisfaction']
    y = air_train_scaled[['satisfaction']]
    
    selector = SelectKBest(chi2, k = 10)
    selector.fit(X, y)
    X_new = selector.transform(X)
    
    features = (X.columns[selector.get_support(indices=True)])
    features
    

è¾“å‡ºï¼š

    Index(['type_of_travel', 'inflight_wifi_service', 'online_boarding',
           'seat_comfort', 'inflight_entertainment', 'on_board_service',
           'leg_room_service', 'cleanliness', 'class_business', 'class_eco'],
          dtype='object')
    

æˆ‘ä»¬é€šè¿‡K-Bestç­›é€‰è¿‡åçš„ç‰¹å¾æ˜¯æ—…è¡Œç±»å‹ã€æœºä¸Š wifi æœåŠ¡ã€åœ¨çº¿ç™»æœºæµç¨‹ã€åº§æ¤…èˆ’é€‚åº¦ã€æœºä¸Šå¨±ä¹ã€æœºä¸Šå®¢æˆ·æœåŠ¡ã€åº§ä½ç©ºé—´ã€æ¸…æ´åº¦å’Œæ—…è¡Œç­‰çº§ï¼ˆå•†åŠ¡èˆ±æˆ–ç»æµèˆ±ï¼‰ã€‚

ğŸ’¡ å»ºæ¨¡
=====

ä¸‹ä¸€æ­¥æˆ‘ä»¬å¯ä»¥åŸºäºå·²æœ‰æ•°æ®è¿›è¡Œå»ºæ¨¡äº†ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œè®­ç»ƒçš„æ¨¡å‹åŒ…æ‹¬ **é€»è¾‘å›å½’** æ¨¡å‹ã€ **Adaboost** åˆ†ç±»å™¨ã€ **éšæœºæ£®æ—** åˆ†ç±»å™¨ã€ **æœ´ç´ è´å¶æ–¯** åˆ†ç±»æ¨¡å‹å’Œ **Xgboost** åˆ†ç±»å™¨ã€‚æˆ‘ä»¬ä¼šåŸºäºå‡†ç¡®æ€§å’Œæµ‹è¯•å‡†ç¡®æ€§ã€ç²¾ç¡®åº¦ã€å¬å›ç‡å’Œ ROC å€¼ç­‰æŒ‡æ ‡å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚

ğŸ’¦ å·¥å…·åº“å¯¼å…¥ä¸æ•°æ®å‡†å¤‡
-------------

    import sklearn
    from sklearn.model_selection import RandomizedSearchCV
    from sklearn.linear_model import LogisticRegression
    from sklearn.ensemble import AdaBoostClassifier
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.naive_bayes import CategoricalNB
    import xgboost
    from xgboost import XGBClassifier
    
    # Features as selected from feature importance
    features = features
    
    # Specifying target variable
    target = ['satisfaction']
    
    # Splitting into train and test
    X_train = air_train_encoded[features].to_numpy()
    X_test = air_test_encoded[features]
    y_train = air_train_encoded[target].to_numpy()
    y_test = air_test_encoded[target]
    

ğŸ’¦ æ¨¡å‹è¯„ä¼°æŒ‡æ ‡è®¡ç®—
-----------

    import time
    from resource import getrusage, RUSAGE_SELF
    from sklearn.metrics import accuracy_score, roc_auc_score, plot_confusion_matrix, plot_roc_curve, precision_score, recall_score
    
    # æ¨¡å‹è¯„ä¼°ä¸ç»“æœç»˜å›¾
    def get_model_metrics(model, X_train, X_test, y_train, y_test):
       
        '''
        Model activation function, takes in model as a parameter and returns metrics as specified.
        
        Inputs: 
            model,  X_train, y_train, X_test, y_test
        Output: 
            Model output metrics, confusion matrix, ROC AUC curve
        '''
        
        # Mark of current time when model began running
        t0 = time.time()
        
        # Fit the model on the training data and run predictions on test data
        model.fit(X_train,  y_train)
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)[:,1]
        # Obtain training accuracy as a comparative metric using Sklearn's metrics package
        train_score = model.score(X_train, y_train)
        # Obtain testing accuracy as a comparative metric using Sklearn's metrics package
        accuracy = accuracy_score(y_test, y_pred)
        # Obtain precision from predictions using Sklearn's metrics package
        precision = precision_score(y_test, y_pred)
        # Obtain recall from predictions using Sklearn's metrics package
        recall = recall_score(y_test, y_pred)
        # Obtain ROC score from predictions using Sklearn's metrics package
        roc = roc_auc_score(y_test, y_pred_proba)
        # Obtain the time taken used to run the model, by subtracting the start time from the current time
        time_taken = time.time() - t0
        # Obtain the resources consumed in running the model
        memory_used = int(getrusage(RUSAGE_SELF).ru_maxrss / 1024)
    
        # Outputting the metrics of the model performance
        print("Accuracy on Training = {}".format(train_score))
        print("Accuracy on Test = {} â€¢ Precision = {}".format(accuracy, precision))
        print("Recall = {} â€¢ ROC Area under Curve = {}".format(recall, roc))
        print("Time taken = {} seconds â€¢ Memory consumed = {} Bytes".format(time_taken, memory_used))
    
        # Plotting the confusion matrix of the model's predictive capabilities
        plot_confusion_matrix(model, X_test, y_test, cmap = plt.cm.Blues, normalize = 'all')
        # Plotting the ROC AUC curve of the model 
        plot_roc_curve(model, X_test, y_test)    
        plt.show()
        
        return model, train_score, accuracy, precision, recall, roc, time_taken, memory_used
    

ğŸ’¦ å»ºæ¨¡ä¸ä¼˜åŒ–
--------

### â‘  é€»è¾‘å›å½’æ¨¡å‹

    # å»ºæ¨¡ä¸è°ƒå‚
    clf = LogisticRegression()
    
    params = {'C': [0.1, 0.5, 1, 5, 10]}
    
    rscv = RandomizedSearchCV(estimator = clf,
                             param_distributions = params,
                             scoring = 'f1',
                             n_iter = 10,
                             verbose = 1)
    rscv.fit(X_train, y_train)
    rscv.predict(X_test)
    
    # Parameter object to be passed through to function activation
    params = rscv.best_params_
    
    print("Best parameters:", params)
    model_lr = LogisticRegression(**params)
    model_lr, train_lr, accuracy_lr, precision_lr, recall_lr, roc_lr, tt_lr, mu_lr = get_model_metrics(model_lr, X_train, X_test, y_train, y_test)
    

![](https://img-blog.csdnimg.cn/img_convert/c616e97f1bece25766313642a58fa37d.png)

### â‘¡ éšæœºæ£®æ—æ¨¡å‹

    clf = RandomForestClassifier()
    
    params = { 'max_depth': [5, 10, 15, 20, 25, 30],
               'max_leaf_nodes': [10, 20, 30, 40, 50],
               'min_samples_split': [1, 2, 3, 4, 5]}
    
    rscv = RandomizedSearchCV(estimator = clf,
                             param_distributions = params,
                             scoring = 'f1',
                             n_iter = 10,
                             verbose = 1)
    rscv.fit(X_train, y_train)
    rscv.predict(X_test)
    
    # Parameter object to be passed through to function activation
    params = rscv.best_params_
    
    print("Best parameters:", params)
    model_rf = RandomForestClassifier(**params)
    model_rf, train_rf, accuracy_rf, precision_rf, recall_rf, roc_rf, tt_rf, mu_rf = get_model_metrics(model_rf, X_train, X_test, y_train, y_test)
    

![](https://img-blog.csdnimg.cn/img_convert/85c2548c02ab9a2bc1648b30281c6c23.png)

### â‘¢ Adaboostæ¨¡å‹

    clf = AdaBoostClassifier()
    
    params = { 'n_estimators': [25, 50, 75, 100, 125, 150],
               'learning_rate': [0.2, 0.4, 0.6, 0.8, 1.0]}
    
    rscv = RandomizedSearchCV(estimator = clf,
                             param_distributions = params,
                             scoring = 'f1',
                             n_iter = 10,
                             verbose = 1)
    rscv.fit(X_train, y_train)
    rscv.predict(X_test)
    
    # Parameter object to be passed through to function activation
    params = rscv.best_params_
    
    print("Best parameters:", params)
    model_ada = AdaBoostClassifier(**params)
    
    # Saving output metrics
    model_ada, accuracy_ada, train_ada, precision_ada, recall_ada, roc_ada, tt_ada, mu_ada = get_model_metrics(model_ada, X_train, X_test, y_train, y_test)
    

![](https://img-blog.csdnimg.cn/img_convert/8beacd880ac3febc6d1eda7791f09b3b.png)

### â‘£ æœ´ç´ è´å¶æ–¯

    clf = CategoricalNB()
    
    params = { 'alpha': [0.0001, 0.001, 0.1, 1, 10, 100, 1000],
               'min_categories': [6, 8, 10]}
    
    rscv = RandomizedSearchCV(estimator = clf,
                             param_distributions = params,
                             scoring = 'f1',
                             n_iter = 10,
                             verbose = 1)
    rscv.fit(X_train, y_train)
    rscv.predict(X_test)
    
    # Parameter object to be passed through to function activation
    params = rscv.best_params_
    
    print("Best parameters:", params)
    model_cnb = CategoricalNB(**params)
    
    # Saving Output Metrics
    model_cnb, accuracy_cnb, train_cnb, precision_cnb, recall_cnb, roc_cnb, tt_cnb, mu_cnb = get_model_metrics(model_cnb, X_train, X_test, y_train, y_test)
    

![](https://img-blog.csdnimg.cn/img_convert/4a2350b9d516de89dfc42090efeaa48e.png)

### â‘¤ Xgboostæ¨¡å‹

    clf = XGBClassifier()
    
    params = { 'max_depth': [3, 5, 6, 10, 15, 20],
               'learning_rate': [0.01, 0.1, 0.2, 0.3],
               'n_estimators': [100, 500, 1000]}
    
    rscv = RandomizedSearchCV(estimator = clf,
                             param_distributions = params,
                             scoring = 'f1',
                             n_iter = 10,
                             verbose = 1)
    rscv.fit(X_train, y_train)
    rscv.predict(X_test)
    
    # Parameter object to be passed through to function activation
    params = rscv.best_params_
    
    print("Best parameters:", params)
    model_xgb = XGBClassifier(**params)
    
    # Saving Output Metrics
    model_xgb, accuracy_xgb, train_xgb, precision_xgb, recall_xgb, roc_xgb, tt_xgb, mu_xgb = get_model_metrics(model_xgb, X_train, X_test, y_train, y_test)
    

![](https://img-blog.csdnimg.cn/img_convert/9c3a971d796ad6600b48d906b19fa5f3.png)

### ç»¼åˆå¯¹æ¯”

å¦‚ä¸‹æˆ‘ä»¬å¯¹æ•ˆæœåšä¸€ä¸ªç»¼åˆå¯¹æ¯”ï¼Œæ¯ä¸ªæ¨¡å‹éƒ½åº”ç”¨äº†å‚æ•°ä¼˜åŒ–ï¼Œåœ¨è®­ç»ƒæ•°æ®ä¸Šçš„å‡†ç¡®ç‡ä¸ä½äº 88%ï¼Œåœ¨æµ‹è¯•æ•°æ®ä¸Šçš„å‡†ç¡®ç‡ä¸ä½äº 87%ã€‚

    training_scores = [train_lr, train_rf, train_ada, train_cnb, train_xgb]
    accuracy = [accuracy_lr, accuracy_rf, accuracy_ada, accuracy_cnb, accuracy_xgb]
    roc_scores = [roc_lr, roc_rf, roc_ada, roc_cnb, roc_xgb]
    precision = [precision_lr, precision_rf, precision_ada, precision_cnb, precision_xgb]
    recall = [recall_lr, recall_rf, recall_ada, recall_cnb, recall_xgb]
    time_scores = [tt_lr, tt_rf, tt_ada, tt_cnb, tt_xgb]
    memory_scores = [mu_lr, mu_rf, mu_ada, mu_cnb, mu_xgb]
    
    model_data = {'Model': ['Logistic Regression', 'Random Forest', 'Adaptive Boost',
                           'Categorical Bayes', 'Extreme Gradient Boost'],
                'Accuracy on Training' : training_scores,
                'Accuracy on Test' : accuracy,
                'ROC AUC Score' : roc_scores,
                'Precision' : precision,
                'Recall' : recall,
                'Time Elapsed (seconds)' : time_scores,
                'Memory Consumed (bytes)': memory_scores}
    
    model_data = pd.DataFrame(model_data)
    model_data
    

![](https://img-blog.csdnimg.cn/img_convert/af08c5ce05b33cff0520c0498f6f6c05.png)

æˆ‘ä»¬æœ€ç»ˆé€‰æ‹©xgboostï¼Œå®ƒè¡¨ç°æœ€å¥½ï¼Œåœ¨è®­ç»ƒå’Œæµ‹è¯•ä¸­éƒ½è¡¨ç°å‡ºé«˜æ€§èƒ½ï¼Œæµ‹è¯•é›†ä¸ŠROC-AUCå€¼ä¸º 98ï¼Œç²¾åº¦ä¸º 95ï¼Œå¬å›ç‡ä¸º 92ã€‚

    plt.rcParams["figure.figsize"] = (25,15)
    
    ax1 = model_data.plot.bar(x = 'Model', y = ["Accuracy on Training", "Accuracy on Test", "ROC AUC Score", 
                                                "Precision", "Recall"], 
                              cmap = 'coolwarm')
    ax1.legend()
    
    ax1.set_title("Model Comparison", fontsize = 18)
    ax1.set_xlabel('Model', fontsize = 14)
    ax1.set_ylabel('Result', fontsize = 14, color = 'Black');
    

![](https://img-blog.csdnimg.cn/img_convert/42f54b275720f39113ec2724929d1823.png)

ğŸ’¡ æ¨¡å‹å¯è§£é‡Šæ€§
=========

é™¤äº†æ‹¿åˆ°æœ€ç»ˆæ€§èƒ½è‰¯å¥½çš„æ¨¡å‹ï¼Œåœ¨æœºå™¨å­¦ä¹ å®é™…åº”ç”¨ä¸­ï¼Œå¾ˆé‡è¦çš„å¦å¤–ä¸€ä»¶äº‹æƒ…æ˜¯ç»“åˆä¸šåŠ¡åœºæ™¯è¿›è¡Œè§£é‡Šï¼Œè¿™èƒ½å¸®åŠ©ä¸šåŠ¡åç»­æå‡ã€‚æˆ‘ä»¬å¯ä»¥åŸºäºXgboostè‡ªå¸¦çš„ç‰¹å¾é‡è¦åº¦å’ŒSHAPç­‰å®Œæˆè¿™é¡¹ä»»åŠ¡ã€‚

> å¯¹äºSHAPå·¥å…·åº“çš„ä½¿ç”¨ä»‹ç»ï¼Œæ¬¢è¿å¤§å®¶é˜…è¯»[ShowMeAI](https://www.showmeai.tech/)çš„æ–‡ç« ï¼š
> 
> ğŸ“˜[**åŸºäºSHAPçš„æœºå™¨å­¦ä¹ å¯è§£é‡Šæ€§å®æˆ˜**](https://showmeai.tech/article-detail/337)

ğŸ’¦ XGBoost ç‰¹å¾é‡è¦æ€§
----------------

    from xgboost import plot_importance
    
    model_xgb.get_booster().feature_names = ['type_of_travel', 'inflight_wifi_service', 'online_boarding',
           'seat_comfort', 'inflight_entertainment', 'on_board_service',
           'leg_room_service', 'cleanliness', 'class_business', 'class_eco']
    
    plot_importance(model_xgb)
    plt.show()
    

![](https://img-blog.csdnimg.cn/img_convert/ee7658dced0dc76c23a04e8b7c8e6875.png)

Xgboostç»™å‡ºçš„æœ€é‡è¦çš„ç‰¹å¾ä¾æ¬¡åŒ…æ‹¬ï¼šåº§æ¤…èˆ’é€‚åº¦ã€åœ¨çº¿ç™»æœºã€æœºä¸Šå¨±ä¹ã€æœºä¸ŠæœåŠ¡è´¨é‡ã€è…¿éƒ¨ç©ºé—´ã€æœºä¸Šæ— çº¿ç½‘ç»œå’Œæ¸…æ´åº¦ã€‚

ğŸ’¦ SHAP æ¨¡å‹å’Œç‰¹å¾å¯è§£é‡Šæ€§
-----------------

ä¸ºäº†åˆ†ææ¨¡å‹åœ¨ SHAP ä¸­çš„ç‰¹å¾å½±å“ï¼Œé¦–å…ˆä½¿ç”¨ Python çš„ pickle åº“å¯¹æ¨¡å‹è¿›è¡Œ pickleã€‚ç„¶åä½¿ç”¨æ¨¡å‹ç®¡é“å’Œæˆ‘ä»¬é€‰æ‹©çš„ç‰¹å¾åœ¨ Shap ä¸­åˆ›å»ºäº†ä¸€ä¸ªè§£é‡Šå™¨ï¼Œå¹¶å°†å…¶åº”ç”¨äº X\_train æ•°æ®é›†ä¸Šã€‚

    import shap
    # Saving test model. 
    pickle.dump(model_xgb, open('./Models/model_xgb.pkl', 'wb'))
    
    explainer = shap.Explainer(model_xgb, feature_names = features)
    shap_values = explainer(X_train)
    
    shap.initjs()
    shap.summary_plot(shap_values, X_train, class_names=model_xgb.classes_)
    

å¦‚æœå°†å¹³å‡ SHAP å€¼ä½œä¸ºæˆ‘ä»¬è¡¡é‡ç‰¹å¾é‡è¦æ€§çš„æŒ‡æ ‡ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æœºä¸Š Wi-Fi æœåŠ¡æ˜¯æˆ‘ä»¬æ•°æ®ä¸­æœ€å…·å½±å“åŠ›çš„ç‰¹å¾ï¼Œç´§éšå…¶åçš„æ˜¯æ—…è¡Œç±»å‹å’Œåœ¨çº¿ç™»æœºã€‚

![](https://img-blog.csdnimg.cn/img_convert/9d88c86b366d74461597ed226e0b7bbb.png)

å¯¹äºå‡ ä¹æ¯ä¸ªç‰¹å¾ï¼Œé«˜å–å€¼ï¼ˆå¤§éƒ¨åˆ†æ˜¯å¯¹è¿™ä¸ªç‰¹å¾ç»´åº¦çš„æ»¡æ„ç¨‹åº¦é«˜ï¼‰å¯¹é¢„æµ‹æœ‰ç§¯æå½±å“ï¼Œè€Œä½ç‰¹å¾å€¼å¯¹é¢„æµ‹æœ‰è´Ÿé¢å½±å“ã€‚æœºä¸Š wi-fi æœåŠ¡æ˜¯æˆ‘ä»¬æ•°æ®é›†ä¸­æœ€å…·å½±å“åŠ›çš„ç‰¹å¾ï¼Œç´§éšå…¶åçš„æ˜¯æ—…è¡Œç±»å‹å’Œåœ¨çº¿ç™»æœºæµç¨‹ã€‚

ğŸ’¦ æœºä¸Š Wi-Fi æœåŠ¡ ç‰¹å¾å½±å“åˆ†æ
---------------------

    shap.plots.scatter(shap_values[:, "inflight_wifi_service"], color=shap_values)
    

![](https://img-blog.csdnimg.cn/img_convert/9f69caf99f6cce5cb8e73dbfec3ab134.png)

æˆ‘ä»¬æ‹¿å‡ºæœ€é‡è¦çš„ç‰¹å¾ã€æœºä¸Š Wi-Fiã€è¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚ä¸Šå›¾ä¸­çš„æ¨ªåæ ‡ä¸ºæœºä¸Šwifiæ»¡æ„åº¦å¾—åˆ†ï¼Œçºµåæ ‡ä¸ºSHAPå€¼å¤§å°ï¼Œé¢œè‰²åŒºåˆ†æ—…è¡Œç±»å‹ï¼ˆä¸ªäººæ—…è¡Œç¼–ç ä¸º 0ï¼Œå•†åŠ¡æ—…è¡Œç¼–ç ä¸º 1ï¼‰ã€‚

æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼š

*   ä¸ªäººæ—…è¡Œä¹˜å®¢ï¼šæœºä¸ŠWiFiæ‰“åˆ†é«˜å¯¹æœ€ç»ˆé«˜æ»¡æ„åº¦æœ‰æ›´å¤šçš„æ­£é¢å½±å“ï¼Œè€Œæœºä¸ŠWiFiæ‰“åˆ†ä½å¯¹æœ€ç»ˆæ»¡æ„åº¦ä½çš„è´¡çŒ®æ›´å¤§ã€‚
    
*   å•†åŠ¡æ—…è¡Œä¹˜å®¢ï¼šæ— è®ºä»–ä»¬çš„ Wi-Fi æœåŠ¡ä½“éªŒå¦‚ä½•ï¼Œéƒ½æœ‰ä¸€éƒ¨åˆ†æ˜¯æ»¡æ„çš„ï¼ˆæ­£ SHAP å€¼è¶…è¿‡è´Ÿå€¼ï¼‰ã€‚
    

ğŸ’¦ åœ¨çº¿ç™»æœºç‰¹å¾å½±å“åˆ†æ
-------------

    shap.plots.scatter(shap_values[:, "online_boarding"], color=shap_values)
    

![](https://img-blog.csdnimg.cn/img_convert/01cb5d810aa74b5ff31cf831c8f84950.png)

å¯¹ã€åœ¨çº¿ç™»æœºã€ç‰¹å¾çš„å½±å“SHAPåˆ†æå¦‚ä¸Šã€‚æ— è®ºæ˜¯ä¸ªäººæ—…è¡Œè¿˜æ˜¯å•†åŠ¡å‡ºè¡Œï¼Œåœ¨çº¿ç™»æœºè¿‡ç¨‹çš„ä½åˆ†éƒ½ä¼šå¯¹æœ€ç»ˆæ»¡æ„åº¦è¾“å‡ºäº§ç”Ÿè´Ÿé¢å½±å“ã€‚

ğŸ’¡ æ€»ç»“
=====

åœ¨æœ¬ç¯‡å†…å®¹ä¸­ï¼Œæˆ‘ä»¬ç»“åˆèˆªç©ºå‡ºè¡Œåœºæ™¯ï¼Œå¯¹èˆªç­ä¹˜å®¢æ»¡æ„åº¦è¿›è¡Œäº†è¯¦å°½çš„æ•°æ®åˆ†æå’Œå»ºæ¨¡é¢„æµ‹ï¼Œå¹¶è¿›è¡Œäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§åˆ†æã€‚

**æˆ‘ä»¬æ•ˆæœæœ€å¥½çš„æ¨¡å‹å–å¾—äº†95%çš„accuracyå’Œ0.987çš„aucå¾—åˆ†ï¼Œæ¨¡å‹è§£é‡Šä¸Šå¯ä»¥çœ‹åˆ°å½±å“æ»¡æ„åº¦æœ€é‡è¦çš„å› ç´ æ˜¯æœºä¸Š Wi-Fi æœåŠ¡ã€åœ¨çº¿ç™»æœºã€æœºä¸Šå¨±ä¹è´¨é‡ã€é¤é¥®ã€åº§æ¤…èˆ’é€‚åº¦ã€æœºèˆ±æ¸…æ´åº¦å’Œè…¿éƒ¨ç©ºé—´**ã€‚

å‚è€ƒèµ„æ–™
====

*   ğŸ“˜ **èˆªç©ºå…¬å¸ä¹˜å®¢æ»¡æ„åº¦æ•°æ®é›†(Kaggle)**
*   ğŸ“˜ **ç¾å›½èˆªç©ºå…¬å¸çš„ä¹˜å®¢ä¸æ»¡æ„åŸå› åˆ†æï¼ˆCNNï¼‰**
*   ğŸ“˜ **æ–°é—»ï¼šéšç€é£æœºå®¢æ»¡å’Œç¥¨ä»·ä¸Šæ¶¨ï¼Œæ—…å®¢æ»¡æ„åº¦ä¸‹é™(CNBC)**
*   ğŸ“˜ **æ•°æ®åˆ†æå®æˆ˜ï¼šPython æ•°æ®åˆ†æå®æˆ˜æ•™ç¨‹**ï¼š[https://www.showmeai.tech/tutorials/40](https://www.showmeai.tech/tutorials/40)
*   ğŸ“˜ **æœºå™¨å­¦ä¹ å®æˆ˜ï¼šæ‰‹æŠŠæ‰‹æ•™ä½ ç©è½¬æœºå™¨å­¦ä¹ ç³»åˆ—**ï¼š[https://www.showmeai.tech/tutorials/41](https://www.showmeai.tech/tutorials/41)
*   ğŸ“˜ **åŸºäºSHAPçš„æœºå™¨å­¦ä¹ å¯è§£é‡Šæ€§å®æˆ˜**ï¼š[https://showmeai.tech/article-detail/337](https://showmeai.tech/article-detail/337)
*   ğŸ“˜ **æœºå™¨å­¦ä¹ å®æˆ˜ | æœºå™¨å­¦ä¹ ç‰¹å¾å·¥ç¨‹æœ€å…¨è§£è¯»**ï¼š[https://showmeai.tech/article-detail/208](https://showmeai.tech/article-detail/208)

æ¨èé˜…è¯»
====

*   ğŸŒ [**æ•°æ®åˆ†æå®æˆ˜ç³»åˆ—**](https://www.showmeai.tech/tutorials/40) ï¼š[https://www.showmeai.tech/tutorials/40](https://www.showmeai.tech/tutorials/40)
*   ğŸŒ [**æœºå™¨å­¦ä¹ æ•°æ®åˆ†æå®æˆ˜ç³»åˆ—**](https://www.showmeai.tech/tutorials/41)ï¼š[https://www.showmeai.tech/tutorials/41](https://www.showmeai.tech/tutorials/41)
*   ğŸŒ [**æ·±åº¦å­¦ä¹ æ•°æ®åˆ†æå®æˆ˜ç³»åˆ—**](https://www.showmeai.tech/tutorials/42)ï¼š[https://www.showmeai.tech/tutorials/42](https://www.showmeai.tech/tutorials/42)
*   ğŸŒ [**TensorFlowæ•°æ®åˆ†æå®æˆ˜ç³»åˆ—**](https://www.showmeai.tech/tutorials/43)ï¼š[https://www.showmeai.tech/tutorials/43](https://www.showmeai.tech/tutorials/43)
*   ğŸŒ [**PyTorchæ•°æ®åˆ†æå®æˆ˜ç³»åˆ—**](https://www.showmeai.tech/tutorials/44)ï¼š[https://www.showmeai.tech/tutorials/44](https://www.showmeai.tech/tutorials/44)
*   ğŸŒ [**NLPå®æˆ˜æ•°æ®åˆ†æå®æˆ˜ç³»åˆ—**](https://www.showmeai.tech/tutorials/45)ï¼š[https://www.showmeai.tech/tutorials/45](https://www.showmeai.tech/tutorials/45)
*   ğŸŒ [**CVå®æˆ˜æ•°æ®åˆ†æå®æˆ˜ç³»åˆ—**](https://www.showmeai.tech/tutorials/46)ï¼š[https://www.showmeai.tech/tutorials/46](https://www.showmeai.tech/tutorials/46)
*   ğŸŒ [**AI é¢è¯•é¢˜åº“ç³»åˆ—**](https://www.showmeai.tech/tutorials/48)ï¼š[https://www.showmeai.tech/tutorials/48](https://www.showmeai.tech/tutorials/48)

[![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e9190f41b8de4af38c8a1a0c96f0513b~tplv-k3u1fbpfcp-zoom-1.image)](https://www.showmeai.tech/)