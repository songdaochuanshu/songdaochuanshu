---
layout: post
title: "【YOLOv5】手把手教你使用LabVIEW ONNX Runtime部署 TensorRT加速，实现YOLOv5实时物体识别（含源码）"
date: "2022-10-31T09:22:37.003Z"
---
【YOLOv5】手把手教你使用LabVIEW ONNX Runtime部署 TensorRT加速，实现YOLOv5实时物体识别（含源码）
====================================================================

前言
==

上一篇博客给大家介绍了**LabVIEW开放神经网络交互工具包【ONNX】**，今天我们就一起来看一下如何使用LabVIEW开放神经网络交互工具包实现TensorRT加速YOLOv5。

以下是YOLOv5的相关笔记总结，希望对大家有所帮助。

内容

地址链接

【YOLOv5】LabVIEW+OpenVINO让你的YOLOv5在CPU上飞起来

https://www.cnblogs.com/virobotics/p/16802248.html

【YOLOv5】LabVIEW OpenCV dnn快速实现实时物体识别（Object Detection）

https://www.cnblogs.com/virobotics/p/16788146.html

* * *

一、TensorRT简介
============

TensorRT是一个高性能的深度学习推理（Inference）优化器，可以为深度学习应用提供低延迟、高吞吐率的部署推理。TensorRT可用于对超大规模数据中心、嵌入式平台或自动驾驶平台进行推理加速。TensorRT现已能支持TensorFlow、Caffe、Mxnet、Pytorch等几乎所有的深度学习框架，将TensorRT和NVIDIA的GPU结合起来，能在几乎所有的框架中进行快速和高效的部署推理。主要用来针对 NVIDIA GPU进行 高性能推理（Inference）加速。

![在这里插入图片描述](https://img-blog.csdnimg.cn/83a1b085dcc7475391ccbd8158640805.png#pic_center)

通常我们做项目，在部署过程中想要加速，无非就那么几种办法，如果我们的设备是CPU，那么可以用openvion，如果我们希望能够使用GPU，那么就可以尝试TensorRT了。那么为什么要选择TensorRT呢？因为我们目前主要使用的还是Nvidia的计算设备，TensorRT本身就是Nvidia自家的东西，那么在Nvidia端的话肯定要用Nvidia亲儿子了。

不过因为TensorRT的入门门槛略微有些高，直接劝退了想要入坑的玩家。其中一部分原因是官方文档比较杂乱；另一部分原因就是TensorRT比较底层，需要一点点C++和硬件方面的知识，学习难度会更高一点。我们做的**开放神经网络交互工具包GPU版本**，**在GPU上做推理时，ONNXRuntime可采用CUDA作为后端进行加速，要更快速可以切换到TensorRT**，虽然和纯TensorRT推理速度比还有些差距，但也十分快了。如此可以大大降低开发难度,能够更快更好的进行推理。。

二、准备工作
======

按照 [LabVIEW开放神经网络交互工具包（ONNX)下载与超详细安装教程](https://blog.csdn.net/virobotics/article/details/124998746) 安装所需软件，因本篇博客主要给大家介绍如何使用TensorRT加速YOLOv5，所以**建议大家安装GPU版本的onnx工具包，否则无法实现TensorRT的加速**。

三、YOLOv5模型的获取
=============

为方便使用，**博主已经将yolov5模型转化为onnx格式**，可在百度网盘下载 链接：[https://pan.baidu.com/s/15dwoBM4W-5\_nlRj4G9EhRg?pwd=yiku](https://pan.baidu.com/s/15dwoBM4W-5_nlRj4G9EhRg?pwd=yiku) 提取码：yiku

1.下载源码
------

将Ultralytics开源的YOLOv5代码Clone或下载到本地，可以直接点击Download ZIP进行下载，

下载地址：[https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5)

![在这里插入图片描述](https://img-blog.csdnimg.cn/13b42309f564428eb7b60b57a87bc1e7.png#pic_center)

2.安装模块
------

解压刚刚下载的zip文件，然后安装yolov5需要的模块，记住cmd的工作路径要在yolov5文件夹下：

![在这里插入图片描述](https://img-blog.csdnimg.cn/17bf484375334659b6e5b51067b76181.png#pic_center)

打开cmd切换路径到yolov5文件夹下，并输入如下指令，安装yolov5需要的模块

 pip install -r requirements.txt 

3.下载预训练模型
---------

打开cmd，进入python环境，使用如下指令下载预训练模型：

1 import torch
2 ​
3 # Model
4 model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5n - yolov5x6, custom

  
​

成功下载后如下图所示：

![在这里插入图片描述](https://img-blog.csdnimg.cn/859064cc03304b5993b3ebd3a84ad004.png#pic_center)

4.转换为onnx模型
-----------

在yolov5之前的yolov3和yolov4的官方代码都是基于darknet框架实现的，因此opencv的dnn模块做目标检测时，读取的是.cfg和.weight文件，非常方便。但是yolov5的官方代码是基于pytorch框架实现的。需要先把pytorch的训练模型.pt文件转换到.onnx文件，然后才能载入到opencv的dnn模块里。

将.pt文件转化为.onnx文件，主要是参考了nihate大佬的博客：[https://blog.csdn.net/nihate/article/details/112731327](https://blog.csdn.net/nihate/article/details/112731327)

将export.py做如下修改，将def export\_onnx（）中的第二个try注释掉，即如下部分注释：

 1 '''
 2     try:
 3         check\_requirements(('onnx',))
 4         import onnx
 5 ​
 6         LOGGER.info(f'\\n{prefix} starting export with onnx {onnx.\_\_version\_\_}...')
 7         f = file.with\_suffix('.onnx')
 8         print(f)
 9 ​
10 torch.onnx.export(
11 model,
12 im,
13 f,
14 verbose=False,
15 opset\_version=opset,
16 training=torch.onnx.TrainingMode.TRAINING if train else torch.onnx.TrainingMode.EVAL,
17 do\_constant\_folding=not train,
18 input\_names=\['images'\],
19 output\_names=\['output'\],
20 dynamic\_axes={
21 'images': {
22 0: 'batch',
23 2: 'height',
24 3: 'width'},  # shape(1,3,640,640)
25 'output': {
26 0: 'batch',
27 1: 'anchors'}  # shape(1,25200,85)
28 } if dynamic else None)
29 ​
30 # Checks
31 model\_onnx = onnx.load(f)  # load onnx model
32 onnx.checker.check\_model(model\_onnx)  # check onnx model
33 ​
34 # Metadata
35 d = {'stride': int(max(model.stride)), 'names': model.names}
36 for k, v in d.items():
37 meta = model\_onnx.metadata\_props.add()
38 meta.key, meta.value = k, str(v)
39         onnx.save(model\_onnx, f)'''

并新增一个函数def my\_export\_onnx（）：

 1 def my\_export\_onnx(model, im, file, opset, train, dynamic, simplify, prefix=colorstr('ONNX:')):
 2     print('anchors:', model.yaml\['anchors'\])
 3     wtxt = open('class.names', 'w')
 4     for name in model.names: 5         wtxt.write(name+'\\n')
 6     wtxt.close()
 7     # YOLOv5 ONNX export
 8     print(im.shape)
 9     if not dynamic:
10         f = os.path.splitext(file)\[0\] + '.onnx'
11         torch.onnx.export(model, im, f, verbose=False, opset\_version=12, input\_names=\['images'\], output\_names=\['output'\])
12     else:
13         f = os.path.splitext(file)\[0\] + '\_dynamic.onnx'
14         torch.onnx.export(model, im, f, verbose=False, opset\_version=12, input\_names=\['images'\],
15                           output\_names=\['output'\], dynamic\_axes={'images': {0: 'batch', 2: 'height', 3: 'width'},  # shape(1,3,640,640)
16                                         'output': {0: 'batch', 1: 'anchors'}  # shape(1,25200,85)
17 })
18     return f

在cmd中输入转onnx的命令（记得将export.py和pt模型放在同一路径下）：

python export.py \--weights yolov5s.pt \--include onnx

如下图所示为转化成功界面

![在这里插入图片描述](https://img-blog.csdnimg.cn/cd26124b6cc744f19d88e143491f13cd.png#pic_center)

其中yolov5s可替换为yolov5m\\yolov5m\\yolov5l\\yolov5x

![在这里插入图片描述](https://img-blog.csdnimg.cn/9d334d3e84654fae98700da32ed15557.png#pic_center)

四、LabVIEW使用TensorRT加速YOLOv5，实现实时物体识别（yolov5\_new\_onnx.vi）
==========================================================

1.LabVIEW调用YOLOv5源码
-------------------

![在这里插入图片描述](https://img-blog.csdnimg.cn/b7998c2d24944b4a9ac3f038f595b2df.png#pic_center)

2.识别结果
------

选择加速方式为：TensorRT

![在这里插入图片描述](https://img-blog.csdnimg.cn/b4e7cbacbbea4cc88238ab72855544fb.png#pic_center)

使用TensorRT加速，实时检测推理用时为**20~30ms/frame**,比单纯使用cuda加速快了30%，同时没有丢失任何的精度。博主使用的电脑显卡为1060显卡，各位如果使用30系列的显卡，速度应该会更快。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/452216642e104c25a5b91e913569b72b.jpeg#pic_center) 

五、纯CPU下opencv dnn和onnx工具包加载YOLOv5实现实时物体识别推理用时对比
===============================================

1、opencv dnn cpu下YOLOv5推理速度为：300ms左右/frame
------------------------------------------

![在这里插入图片描述](https://img-blog.csdnimg.cn/9189f19dc07a4246a9333619718facd9.png)

2、onnx工具包cpu下YOLOv5推理速度为：200ms左右/frame
--------------------------------------

![在这里插入图片描述](https://img-blog.csdnimg.cn/262e2162d0bb4927beaf17976f3791ba.png)

对比我们发现，同样使用cpu进行推理，onnx工具包推理速度要比opencv dnn推理速度快30%左右。

六、源码及模型下载
=========

可关注微信公众号：VIRobotics ，回复关键词：yolov5\_onnx ，进行源码下载

附加说明：计算机环境
==========

*   操作系统：Windows10
    
*   python：3.6及以上
    
*   LabVIEW：2018及以上 64位版本
    
*   视觉工具包：virobotics\_lib\_onnx\_cuda\_tensorrt-1.0.0.11以上版本
    

总结
==

以上就是今天要给大家分享的内容。大家可根据链接下载相关源码与模型。

如果有问题可以在评论区里讨论，提问前请先点赞支持一下博主哦，如您想要探讨更多关于LabVIEW与人工智能技术，欢迎加入我们的技术交流群：705637299，进群请备注暗号：LabVIEW机器学习

> **如果文章对你有帮助，欢迎关注、点赞、收藏**