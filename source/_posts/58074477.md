---
layout: post
title: "HDFS 分布式环境搭建"
date: "2022-09-06T13:43:55.461Z"
---
HDFS 分布式环境搭建
============

HDFS 分布式环境搭建
============

作者：[Grey](https://www.cnblogs.com/greyzeng/)

原文地址：

[博客园：HDFS 分布式环境搭建](https://www.cnblogs.com/greyzeng/p/16663406.html)

[CSDN：HDFS 分布式环境搭建](http://t.csdn.cn/BezXt)

准备四个Linux实例

每个实例对应的 host 和 ip 地址如下

    node01 192.168.150.128
    
    node02 192.168.150.138
    
    node03 192.168.150.139
    
    node04 192.168.150.140
    

每个节点的安排如下

host

NN

SNN

DN

node01

√

node02

√

√

node03

√

node04

√

首先，需要配置静态 ip，

在`node01~node04`上，分别执行

    vi /etc/sysconfig/network-scripts/ifcfg-ens33
    

内容参考如下内容修改

在 node01 上

修改`BOOTPROTO="static"`

新增`IPADDR="192.168.150.128"`

然后执行：

    service network restart
    

在 node02 上

修改`BOOTPROTO="static"`

新增`IPADDR="192.168.150.138"`

然后执行

    service network restart
    

在 node03 上

修改`BOOTPROTO="static"`

新增`IPADDR="192.168.150.139"`

然后执行

    service network restart
    

在 node04 上

修改`BOOTPROTO="static"`

新增`IPADDR="192.168.150.140"`

然后执行

    service network restart
    

接下来，配置 hostname

在 node01 上

执行`hostnamectl set-hostname node01`

执行

    vi /etc/sysconfig/network
    

设置为

    NETWORKING=yes
    HOSTNAME=node01
    

在 node02 上

执行`hostnamectl set-hostname node02`

执行

    vi /etc/sysconfig/network
    

设置为

    NETWORKING=yes
    HOSTNAME=node02
    

在 node03 上

执行`hostnamectl set-hostname node03`

执行

    vi /etc/sysconfig/network
    

设置为

    NETWORKING=yes
    HOSTNAME=node03
    

在 node04 上

执行`hostnamectl set-hostname node04`

执行

    vi /etc/sysconfig/network
    

设置为

    NETWORKING=yes
    HOSTNAME=node01
    

设置本机的ip到主机名的映射关系，在`node01~node04`上分别执行`vi /etc/hosts`

并添加如下信息：

    192.168.150.128 node01 
    
    192.168.150.138 node02 
    
    192.168.150.139 node03 
    
    192.168.150.140 node04 
    

接下来，需要关闭防火墙

在`node01~node04`上都执行如下命令

    systemctl stop firewalld.service
    
    systemctl disable firewalld.service
    
    firewall-cmd --reload
    
    service iptables stop
    
    chkconfig iptables off
    

关闭 SELINUX

在`node01~node04`上执行`vi /etc/selinux/config`, 配置如下选项

    SELINUX=disabled
    

做时间同步

在`node01~node04`上分别执行`yum install ntp -y`

且做如下配置

    vi /etc/ntp.conf 
    

添加如下信息

    server ntp1.aliyun.com
    

然后在`node01~node04`上都执行如下命令

    service ntpd start
    
    chkconfig ntpd on
    

接下来是配置免密登录

在`node01~node04`上分别执行

    ssh localhost
    

输入`yes`

输入密码

在`node01~node04`上执行如下命令生成本机的密钥和公钥`ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa`

将`node01`的公钥发送到另外三个机器，在`node01`上执行

    scp ~/.ssh/id_dsa.pub root@node02:~/.ssh/node1.id_rsa.pub
    
    scp ~/.ssh/id_dsa.pub root@node03:~/.ssh/node1.id_rsa.pub
    
    scp ~/.ssh/id_dsa.pub root@node04:~/.ssh/node1.id_rsa.pub
    

将`node02`的公钥发送到另外三个机器，在`node02`上执行

    scp ~/.ssh/id_dsa.pub root@node01:~/.ssh/node2.id_rsa.pub
    
    scp ~/.ssh/id_dsa.pub root@node03:~/.ssh/node2.id_rsa.pub
    
    scp ~/.ssh/id_dsa.pub root@node04:~/.ssh/node2.id_rsa.pub
    

将`node03`的公钥发送到另外三个机器，在`node03`上执行

    scp ~/.ssh/id_dsa.pub root@node01:~/.ssh/node3.id_rsa.pub
    
    scp ~/.ssh/id_dsa.pub root@node02:~/.ssh/node3.id_rsa.pub
    
    scp ~/.ssh/id_dsa.pub root@node04:~/.ssh/node3.id_rsa.pub
    

将`node04`的公钥发送到另外三个机器，在`node04`上执行

    scp ~/.ssh/id_dsa.pub root@node01:~/.ssh/node4.id_rsa.pub
    
    scp ~/.ssh/id_dsa.pub root@node02:~/.ssh/node4.id_rsa.pub
    
    scp ~/.ssh/id_dsa.pub root@node03:~/.ssh/node4.id_rsa.pub
    

在`node01`上执行

    cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
    
    cat ~/.ssh/node2.id_rsa.pub >> ~/.ssh/authorized_keys
    
    cat ~/.ssh/node3.id_rsa.pub >> ~/.ssh/authorized_keys
    
    cat ~/.ssh/node4.id_rsa.pub >> ~/.ssh/authorized_keys
    

在`node02`上执行

    cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
    
    cat ~/.ssh/node1.id_rsa.pub >> ~/.ssh/authorized_keys
    
    cat ~/.ssh/node3.id_rsa.pub >> ~/.ssh/authorized_keys
    
    cat ~/.ssh/node4.id_rsa.pub >> ~/.ssh/authorized_keys
    

在`node03`上执行

    cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
    
    cat ~/.ssh/node1.id_rsa.pub >> ~/.ssh/authorized_keys
    
    cat ~/.ssh/node2.id_rsa.pub >> ~/.ssh/authorized_keys
    
    cat ~/.ssh/node4.id_rsa.pub >> ~/.ssh/authorized_keys
    

在`node04`上执行

    cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
    
    cat ~/.ssh/node1.id_rsa.pub >> ~/.ssh/authorized_keys
    
    cat ~/.ssh/node2.id_rsa.pub >> ~/.ssh/authorized_keys
    
    cat ~/.ssh/node3.id_rsa.pub >> ~/.ssh/authorized_keys
    

接下来，需要在`node01~node04`上都安装Java环境，安装过程略。

`node01~node04`上都创建好目录

    mkdir -p /opt/bigdata
    

在`node01~node04`上，将`hadoop`安装包上传到`/opt/bigdata`下，然后执行：

    tar xf hadoop-2.6.5.tar.gz
    

然后执行：

    mv hadoop-2.6.5 hadoop
    

添加环境变量`vi /etc/profile`

把`Hadoop`加入环境变量：

    export JAVA_HOME=/usr/local/jdk
    
    export HADOOP_HOME=/opt/bigdata/hadoop
    
    export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
    

然后执行`source /etc/profile`

接下来是 Hadoop 配置，在`node01~node04`上

执行`vi $HADOOP_HOME/etc/hadoop/hadoop-env.sh`

配置 JAVA\_HOME：`export JAVA_HOME=/usr/local/jdk`

在`node01~node04`上执行`vi $HADOOP_HOME/etc/hadoop/core-site.xml`

在`<configuration></configuration>`之间，加入如下配置：

    <property>
     <name>fs.defaultFS</name>
     <value>hdfs://node01:9000</value>
    </property>
    

在`node01~node04`上执行`vi $HADOOP_HOME/etc/hadoop/hdfs-site.xml`

在`<configuration></configuration>`之间，加入如下配置

    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/var/bigdata/hadoop/full/dfs/name</value>
    </property>
    
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/var/bigdata/hadoop/full/dfs/data</value>
    </property>
    
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>node02:50090</value>
    </property>
    
    <property>
        <name>dfs.namenode.checkpoint.dir</name>
        <value>/var/bigdata/hadoop/full/dfs/secondary</value>
    </property>
    

在`node01~node04`上执行`vi $HADOOP_HOME/etc/hadoop/slaves`

    node02
    node03
    node04
    

在`node01`上格式化启动

格式化`hdfs namenode -format`

启动`start-dfs.sh`

如果使用 Windows作为客户端，那么可以配置 hosts 条目

进入`C:\Windows\System32\drivers\etc`

host 文件中增加如下条目：

    192.168.150.128 node01 
    
    192.168.150.138 node02 
    
    192.168.150.139 node03 
    
    192.168.150.140 node04
    

测试一下

在`node01`上，执行如下命令，

    hdfs dfs -mkdir /bigdata
    
    hdfs dfs -mkdir -p /user/root
    
    hdfs dfs -put hadoop-2.6.5.tar.gz /user/root
    

打开浏览器

通过：

[http://node01:50070/explorer.html#/user/root](http://node01:50070/explorer.html#/user/root)

可以看到上传的文件 hadoop-2.6.5.tar.gz

本文来自博客园，作者：[Grey Zeng](https://www.cnblogs.com/greyzeng/)，转载请注明原文链接：[https://www.cnblogs.com/greyzeng/p/16663406.html](https://www.cnblogs.com/greyzeng/p/16663406.html)