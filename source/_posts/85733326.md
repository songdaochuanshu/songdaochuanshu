---
layout: post
title: "磁盘的基本知识和基本命令"
date: "2022-07-02T01:48:17.785Z"
---
磁盘的基本知识和基本命令
============

一、概述
----

目的：更加系统的熟悉磁盘和磁盘的基本操作

二、文件系统
------

### 2.1、硬盘的构成

​ 从存储数据的介质上来区分，硬盘可分为机械硬盘（Hard Disk Drive, HDD）和固态硬盘（Solid State Disk, SSD），机械硬盘采用磁性碟片来存储数据，而固态硬盘通过闪存颗粒来存储数据

机械硬盘主要由磁盘盘片、磁头、主轴与传动轴等组成，数据就存放在磁盘盘片中。

*   什么是磁道呢？每个盘片都在逻辑上有很多的同心圆，最外面的同心圆就是 0 磁道。我们将**每个同心圆称作磁道**（注意，磁道只是逻辑结构，在盘面上并没有真正的同心圆）。硬盘的磁道密度非常高，通常一面上就有上千个磁道。但是相邻的磁道之间并不是紧挨着的，这是因为磁化单元相隔太近会相互产生影响。
*   那扇区又是什么呢？扇区其实是很形象的，大家都见过折叠的纸扇吧，纸扇打开后是半圆形或扇形的，不过这个扇形是由每个扇骨组合形成的。在磁盘上每个同心圆是磁道，从圆心向外呈放射状地产生分割线（扇骨），将每个磁道等分为若干弧段，每个弧段就是一个扇区。每个扇区的大小是固定的，为 512Byte。**扇区也是磁盘的最小存储单位**。硬盘的容量越来越大，为了减少数据量的拆解，所以新的大容量硬盘已经有 4KByte 的扇区设计
*   柱面又是什么呢？如果硬盘是由多个盘片组成的，每个盘面都被划分为数目相等的磁道，那么所有盘片都会从外向内进行磁道编号，最外侧的就是 0 磁道。具有相同编号的磁道会形成一个圆柱，这个圆柱就被称作磁盘的柱面  
    ![](https://img2022.cnblogs.com/blog/1271254/202207/1271254-20220701175236086-1794951653.png)

硬盘的大小是使用"磁头数 x 柱面数 x 扇区数 x 每个扇区的大小"这样的公式来计算的。其中，磁头数（Heads）表示硬盘共有几个磁头，也可以理解为硬盘有几个盘面，然后乘以 2；柱面数（Cylinders）表示硬盘每面盘片有几条磁道；扇区数（Sectors）表示每条磁道上有几个扇区；每个扇区的大小一般是 512Byte。

外圈的扇区数量比较多，因此如果数据写入在外圈，转一圈能够读写的数据量当然比内圈还要多！ 因此通常数据的读写会由外圈开始往内写的喔！这是默认值啊！

传输接口：**SAS接口、SATA接口、USB接口、（IDE 与 SCSI ，这两被前面的取代）**

​ 固态硬盘和传统的机械硬盘最大的区别就是不再采用盘片进行数据存储，而采用存储芯片进行数据存储。固态硬盘的存储芯片主要分为两种：一种是采用闪存作为存储介质的；另一种是采用DRAM作为存储介质的。目前使用较多的主要是采用闪存作为存储介质的固态硬盘

近年来在测试磁盘的性能时， 有个很特殊的单位，称为每秒读写操作次数 （Input/Output Operations PerSecond, **IOPS**）！这个数值越大，代表可操作次数较高，当然性能好的很！

*   扇区（Sector）为最小的物理储存单位，且依据磁盘设计的不同，目前主要有 512Bytes 与 4K 两种格式；
*   将扇区组成一个圆，那就是柱面（Cylinder）；
*   早期的分区主要以柱面为最小分区单位，现在的分区通常使用扇区为最小分区单位（每个扇区都有其号码喔，就好像座位一样）；
*   磁盘分区表主要有两种格式，一种是限制较多的 MBR 分区表，一种是较新且限制较少的 GPT 分区表。
*   MBR 分区表中，第一个扇区最重要，里面有：（1）主要开机区（Master boot record, MBR）及分区表（partition table）， 其中 MBR 占有 446 Bytes，而 partition table 则占有 64 Bytes。
*   GPT 分区表除了分区数量扩充较多之外，支持的磁盘容量也可以超过 2TB
*   /dev/sd\[a-p\]\[1-128\]：为实体磁盘的磁盘文件名；
*   /dev/vd\[a-d\]\[1-128\]：为虚拟磁盘的磁盘文件名

### 2.2、文件系统基础知识

​ 因为每种操作系统所设置的文件属性/权限并不相同， 为了存放这些文件所需的数据，因此就需要将分区进行格式化，以成为操作系统能够利用的“文件系统格式（filesystem），磁盘分区完毕后还需要进行格式化（format），之后操作系统才能够使用这个文件系统

​ 传统的磁盘与文件系统之应用中，一个分区就是只能够被格式化成为一个文件系统，所以我们可以说一个 filesystem 就是一个 partition。但是由于新技术的利用，例如我们常听到的LVM与软件磁盘阵列（software raid）， 这些技术可以将一个分区格式化为多个文件系统（例如LVM），也能够将多个分区合成一个文件系统（LVM, RAID），一个可被挂载的数据为一个文件系统而不是一个分区

​ Linux 操作系统的文件权限（rwx）与文件属性（拥有者、群组、时间参数等）。 文件系统通常会将这两部份的数据分别存放在不同的区块，权限与属性放置到 inode 中，至于实际数据则放置到 data block 区块中。 另外，还有一个超级区块 （superblock） 会记录整个文件系统的整体信息，包括 inode 与 block 的总量、使用量、剩余量等。

*   superblock：记录此 filesystem 的整体信息，包括inode/block的总量、使用量、剩余量， 以及文件系统的格式与相关信息等；
*   inode：记录文件的属性，一个文件占用一个inode，同时记录此文件的数据所在的 block 号码；
*   block：实际记录文件的内容，若文件太大时，会占用多个 block 。

### 2.3、EXT2文件系统

​ 文件系统一开始就将 inode 与 block 规划好了，除非重新格式化（或者利用 resize2fs 等指令变更文件系统大小），否则 inode 与block 固定后就不再变动。

​ Ext2 文件系统在格式化的时候基本上是区分为多个区块群组 （block group） 的，每个区块群组都有独立的 inode/block/superblock 系统。

​ 文件系统最前面有一个开机扇区（boot sector），这个开机扇区可以安装开机管理程序，  
![](https://img2022.cnblogs.com/blog/1271254/202207/1271254-20220701175308760-33387229.jpg)

**1、data block （数据区块）**

​ 在 Ext2 文件系统中所支持的 block 大小有 1K, 2K 及 4K 三种而已。在格式化

时 block 的大小就固定了，且每个 block 都有编号，以方便 inode 的记录啦

![](https://img2022.cnblogs.com/blog/1271254/202207/1271254-20220701175322484-752116627.jpg)

*   原则上，block 的大小与数量在格式化完就不能够再改变了（除非重新格式化）；
*   每个 block 内最多只能够放置一个文件的数据；
*   承上，如果文件大于 block 的大小，则一个文件会占用多个 block 数量；
*   承上，若文件小于 block ，则该 block 的剩余容量就不能够再被使用了（磁盘空间会浪费）

**2、inode table （inode 表格）**

inode 记录的文件数据至少有下面这些：

*   该文件的存取模式（read/write/excute）；
*   该文件的拥有者与群组（owner/group）；
*   该文件的容量；
*   该文件创建或状态改变的时间（ctime）；
*   最近一次的读取时间（atime）；
*   最近修改的时间（mtime）；
*   定义文件特性的旗标（flag），如 SetUID...；
*   该文件真正内容的指向 （pointer）；
*   每个 inode 大小均固定为 128 Bytes （新的 ext4 与 xfs 可设置到 256 Bytes）；
*   每个文件都仅会占用一个 inode 而已；
*   承上，因此文件系统能够创建的文件数量与 inode 的数量有关；
*   系统读取文件时需要先找到 inode，并分析 inode 所记录的权限与使用者是否符合，若符合才能够开始实际读取 block 的内容

​ inode 记录 block 号码的区域定义为12个直接，一个间接, 一个双间接与一个三间接记录区

![](https://img2022.cnblogs.com/blog/1271254/202207/1271254-20220701175346359-1956109611.png)

*   12 个直接指向： 12\*1K=12K

由于是直接指向，所以总共可记录 12 笔记录，因此总额大小为如上所示；

*   间接： 256\*1K=256K

每笔 block 号码的记录会花去 4Bytes，因此 1K 的大小能够记录 256 笔记录，因此一个间接可以记录的文件大小如上；

*   双间接： 256_256_1K=2562K

第一层 block 会指定 256 个第二层，每个第二层可以指定 256 个号码，因此总额大小如上；

*   三间接： 256_256_256\*1K=2563K

第一层 block 会指定 256 个第二层，每个第二层可以指定 256 个第三层，每个第三层可以指定 256 个号码，因此总额大小如

上；

**总额：将直接、间接、双间接、三间接加总，得到 12 + 256 + 256\*256 + 256\*256\*256 （K） = 16GB**

**3、Superblock （超级区块）**

主要记录如下信息：

*   block 与 inode 的总量；
    
*   未使用与已使用的 inode / block 数量；
    
*   block 与 inode 的大小 （block 为 1, 2, 4K，inode 为 128Bytes 或 256Bytes）；
    
*   filesystem 的挂载时间、最近一次写入数据的时间、最近一次检验磁盘 （fsck） 的时间等文件系统的相关信息；
    
*   一个 valid bit 数值，若此文件系统已被挂载，则 valid bit 为 0 ，若未被挂载，则 valid bit 为 1 。
    

**4、Filesystem Description （文件系统描述说明）**

​ 描述每个 block group 的开始与结束的 block 号码，以及说明每个区段 （superblock, bitmap, inodemap,data block） 分别介于哪一个 block 号码之间

**5、block bitmap （区块对照表）**

​ 从 block bitmap 当中可以知道哪些 block 是空的，因此我们的系统就能够很快速的找到可使用的空间来处置文件，删除block也是

**6、inode bitmap （inode 对照表）**

​ 与 block bitmap 是类似的功能，只是 block bitmap 记录的是使用与未使用的 block 号码， 至于 inode bitmap 则是记录使用与未使用的 inode 号码

### 2.4、与目录树的关系

​ 在 Linux 下的文件系统创建一个目录时，文件系统会分配一个 inode 与至少一块 block 给该目录。其中，inode 记录该目录的相关权限与属性，并可记录分配到的那块 block 号码； 而 block 则是记录在这个目录下的文件名与该文件名占用的 inode号码数据

​ 由于目录树是由根目录开始读起，因此系统通过挂载的信息可以找到挂载点的 inode 号码，此时就能够得到根目录的inode 内容，并依据该 inode 读取根目录的 block 内的文件名数据，再一层一层的往下读到正确的文件名

### 2.5、EXT2、EXT3、EXT4文件的存取和日志式文件系统

假设我们想要新增一个文件，此时文件系统的行为是：

*   先确定使用者对于欲新增文件的目录是否具有 w 与 x 的权限，若有的话才能新增；
    
*   根据 inode bitmap 找到没有使用的 inode 号码，并将新文件的权限/属性写入；
    
*   根据 block bitmap 找到没有使用中的 block 号码，并将实际的数据写入 block 中，且更新 inode 的 block 指向数据；
    
*   将刚刚写入的 inode 与 block 数据同步更新 inode bitmap 与 block bitmap，并更新 superblock 的内容。
    

​ 一般来说，我们将 inode table 与 data block 称为数据存放区域，至于其他例如 superblock、 block bitmap 与 inodebitmap 等区段就被称为 metadata （中介数据） ，因为 superblock, inode bitmap 及 block bitmap 的数据是经常变动的，每次新增、移除、编辑时都可能会影响到这三个部分的数据，因此才被称为中介数据

日志式文件系统 （Journaling filesystem）

避免的文件系统不一致的情况发生，所以提出了日志是文件系统（有点类似事务）

*   预备：当系统要写入一个文件时，会先在日志记录区块中纪录某个文件准备要写入的信息；
    
*   实际写入：开始写入文件的权限与数据；开始更新 metadata 的数据；
    
*   结束：完成数据与 metadata 的更新后，在日志记录区块当中完成该文件的纪录
    

这样的日志式文件系统在EXT3和EXT4中默认有

### 2.6、XFS文件系统

​ EXT 家族当前较伤脑筋的地方：支持度最广，但格式化超慢

​ xfs 就是一个日志式文件系统，几乎所有 Ext4 文件系统有的功能， xfs 都可以具备！主要规划为三个部份，一个数据区 （data section）、一个文件系统活动登录区 （log section）以及一个实时运行区 （realtime section）。

**1、数据区 （data section）**

​ 数据区就跟我们之前谈到的 ext 家族一样，包括 inode/data block/superblock 等数据，都放置在这个区块。这个数据区与 ext 家族的 block group 类似，也是分为多个储存区群组 （allocation groups） 来分别放置文件系统所需要的数据。 每个储存区群组都包含了

*   （1）整个文件系统的 superblock
*   （2）剩余空间的管理机制
*   （3）inode的分配与追踪。此

外，inode与 block 都是系统需要用到时， 这才动态配置产生，所以格式化动作超级快！另外，与 ext 家族不同的是， xfs 的 block 与 inode 有多种不同的容量可供设置，block 容量可由 512Bytes ~ 64K 调配，不过，Linux 的环境下， 由于内存控制的关系 （分页档 pagesize 的容量之故），因此最高可以使用的 block 大小为 4K 而已！

**2、文件系统活动登录区 （log section）**

​ 登录区这个区域主要被用来纪录文件系统的变化，其实有点像是日志区啦！文件的变化会在这里纪录下来，直到该变化完整的写入到数据区后， 该笔纪录才会被终结。

**3、实时运行区 （realtime section）**

​ 当有文件要被创建时，xfs 会在这个区段里面找一个到数个的 extent 区块，将文件放置在这个区块内，等到分配完毕后，再写入到 data section 的 inode 与 block 去！ 这个 extent 区块的大小得要在格式化的时候就先指定，最小值是 4K 最大可到 1G。一般非磁盘阵列的磁盘默认为 64K 容量，而具有类似磁盘阵列的 stripe 情况下，则建议 extent 设置为与 stripe 一样大较佳。这个 extent 最好不要乱动，因为可能会影响到实体磁盘的性能喔

### 2.7、文件系统的挂载和卸载

*   单一文件系统不应该被重复挂载在不同的挂载点（目录）中；
    
*   单一目录不应该重复挂载多个文件系统；
    
*   要作为挂载点的目录，理论上应该都是空目录才是
    

/etc/filesystems：系统指定的测试挂载文件系统类型的优先顺序；

/proc/filesystems：Linux系统已经载入的文件系统类型

可以使用mount和umount命令进行挂载和卸载，详情见相关命令

开机挂载：/etc/fstab

*   根目录 / 是必须挂载的﹐而且一定要先于其它 mount point 被挂载进来。
    
*   其它 mount point 必须为已创建的目录﹐可任意指定﹐但一定要遵守必须的系统目录架构原则 （FHS）
    
*   所有 mount point 在同一时间之内﹐只能挂载一次。
    
*   所有 partition 在同一时间之内﹐只能挂载一次。
    
*   如若进行卸载﹐您必须先将工作目录移到 mount point（及其子目录） 之外
    

    [root@study ~]# cat /etc/fstab
    # Device Mount point filesystem parameters dump fsck
    /dev/mapper/centos-root / xfs defaults 0 0
    UUID=94ac5f77-cb8a-495e-a65b-2ef7442b837c /boot xfs defaults 0 0
    /dev/mapper/centos-home /home xfs defaults 0 0
    /dev/mapper/centos-swap swap swap defaults 0 0
    【设备/UUID等】【挂载点】【文件系统】【文件系统参数】【dump】【fsck】
    

**第一栏：磁盘设备文件名/UUID/LABEL name：**

这个字段可以填写的数据主要有三个项目：

*   文件系统或磁盘的设备文件名，如 /dev/vda2 等（不推荐使用）
    
*   文件系统的 UUID 名称，如 UUID=xxx
    
*   文件系统的 LABEL 名称，例如 LABEL=xxx
    

**第二栏：挂载点 （mount point）：**：

就是挂载点啊！挂载点是什么？一定是目录啊～要知道啊！忘记的话，请回本章稍早之前的数据瞧瞧喔！

**第三栏：磁盘分区的文件系统：**

在手动挂载时可以让系统自动测试挂载，但在这个文件当中我们必须要手动写入文件系统才行！ 包括 xfs, ext4, vfat,reiserfs, nfs 等等。

**第四栏：文件系统参数**

![](https://img2022.cnblogs.com/blog/1271254/202207/1271254-20220701175413353-1230980092.jpg)

**第五栏：能否被 dump 备份指令作用：**

dump 是一个用来做为备份的指令，不过现在有太多的备份方案了，所以这个项目可以不要理会啦！直接输入 0 就好了

**第六栏：是否以 fsck 检验扇区：**

早期开机的流程中，会有一段时间去检验本机的文件系统，看看文件系统是否完整 （clean）。 不过这个方式使用的主要是通过 fsck 去做的，我们现在用的 xfs 文件系统就没有办法适用，因为 xfs 会自己进行检验，不需要额外进行这个动作！所以直接填 0 就好了

### 2.8、内存交换空间swap创建

*   分区：先使用 gdisk 在你的磁盘中分区出一个分区给系统作为 swap 。由于 Linux 的 gdisk 默认会将分区的 ID 设置为 Linux 的
    
*   文件系统，所以你可能还得要设置一下 system ID 就是了。
    
*   格式化：利用创建 swap 格式的“mkswap 设备文件名”就能够格式化该分区成为 swap 格式啰
    
*   使用：最后将该 swap 设备启动，方法为：“swapon 设备文件名”。
    
*   观察：最终通过 free 与 swapon -s 这个指令来观察一下内存的用量吧！
    

### 2.9、RAID

**RAID-0** （等量模式, stripe）：性能最佳：越多颗磁盘组成的 RAID-0 性能会越好，因为每颗负责的数据量就更低了，RAID-0 只要有任何一颗磁盘损毁，在 RAID 上面的所有数据都会遗失而无法读取

**RAID-1** （映射模式, mirror）：完整备份：让同一份数据，完整的保存在两颗磁盘上头，整体 RAID 的容量几乎少了 50%

**RAID 1+0，RAID 0+1**：（1）先让两颗磁盘组成 RAID 1，并且这样的设置共有两组；（2）将这两组 RAID 1 再组成一组 RAID 0。这就是 RAID 1+0 啰！反过来说，RAID 0+1 就是先组成 RAID-0 再组成 RAID-1 的意思

**RAID 5**：性能与数据备份的均衡考虑：RAID5 至少需要三颗以上的磁盘才能够组成这种类型的磁盘阵列，RAID 5 默认仅能支持一颗磁盘的损毁情况

**Spare Disk**：预备磁盘的功能：当磁盘阵列的磁盘损毁时，就得要将坏掉的磁盘拔除，然后换一颗新的磁盘。换成新磁盘并且顺利启动磁盘阵列后， 磁盘阵列就会开始主动的重建 （rebuild） 原本坏掉的那颗磁盘数据到新的磁盘上！然后你磁盘阵列上面的数据就复原了！ 这就是磁盘阵列的优点

**spare disk** 就是一颗或多颗没有包含在原本磁盘阵列等级中的磁盘，这颗磁盘平时并不会被磁盘阵列所使用， 当磁盘阵列有任何磁盘损毁时，则这颗 spare disk 会被主动的拉进磁盘阵列中，并将坏掉的那颗硬盘移出磁盘阵列！ 然后立即重建数据系统。如此你的系统则可以永保安康啊！若你的磁盘阵列有支持热拔插那就更完美了

**磁盘阵列的优点**

*   数据安全与可靠性：指的并非网络信息安全，而是当硬件 （指磁盘） 损毁时，数据是否还能够安全的救援或使用之意；
    
*   读写性能：例如 RAID 0 可以加强读写性能，让你的系统 I/O 部分得以改善；
    
*   容量：可以让多颗磁盘组合起来，故单一文件系统可以有相当大的容量。
    

![](https://img2022.cnblogs.com/blog/1271254/202207/1271254-20220701175431349-778097112.jpg)

关闭RAID

    # 1. 先卸载且删除配置文件内与这个 /dev/md0 有关的设置：
    [root@study ~]# umount /srv/raid
    [root@study ~]# vim /etc/fstab
    UUID=494cb3e1-5659-4efc-873d-d0758baec523 /srv/raid xfs defaults 0 0
    # 将这一行删除掉！或者是注解掉也可以！
    # 2. 先覆盖掉 RAID 的 metadata 以及 XFS 的 superblock，才关闭 /dev/md0 的方法
    [root@study ~]# dd if=/dev/zero of=/dev/md0 bs=1M count=50
    [root@study ~]# mdadm --stop /dev/md0
    mdadm: stopped /dev/md0 <==不啰唆！这样就关闭了！
    [root@study ~]# dd if=/dev/zero of=/dev/vda5 bs=1M count=10
    [root@study ~]# dd if=/dev/zero of=/dev/vda6 bs=1M count=10
    [root@study ~]# dd if=/dev/zero of=/dev/vda7 bs=1M count=10
    [root@study ~]# dd if=/dev/zero of=/dev/vda8 bs=1M count=10
    [root@study ~]# dd if=/dev/zero of=/dev/vda9 bs=1M count=10
    [root@study ~]# cat /proc/mdstat
    Personalities : [raid6] [raid5] [raid4]
    unused devices: <none> <==看吧！确实不存在任何阵列设备！
    [root@study ~]# vim /etc/mdadm.conf
    #ARRAY /dev/md0 UUID=2256da5f:4870775e:cf2fe320:4dfabbc6
    # 一样啦！删除他或是注解他！
    

### 2.10、逻辑卷管理

**Physical Volume, PV, 实体卷轴**：我们实际的 partition （或 Disk） 需要调整系统识别码 （system ID） 成为 8e （LVM 的识别码），然后再经过pvcreate 的指令将他转成 LVM 最底层的实体卷轴 （PV） ，之后才能够将这些 PV 加以利用！ 调整 system ID 的方是就是通过 gdisk 啦！

**Volume Group, VG, 卷轴群组**：所谓的 LVM 大磁盘就是将许多 PV 整合成这个 VG 的东西就是啦！所以 VG 就是 LVM 组合起来的大磁盘！

**Physical Extent, PE, 实体范围区块**：LVM 默认使用 4MB 的 PE 区块，而 LVM 的 LV 在 32 位系统上最多仅能含有 65534 个 PE （lvm1 的格式）

**Logical Volume, LV, 逻辑卷轴**：最终的 VG 还会被切成 LV，这个 LV 就是最后可以被格式化使用的类似分区

![](https://img2022.cnblogs.com/blog/1271254/202207/1271254-20220701175457943-1826238863.jpg)

数据写入这个LV 时，到底他是怎么写入硬盘当中的？ 呵呵！好问题～其实，依据写入机制的不同，而有两种方式：

*   线性模式 （linear）：假如我将 /dev/vda1, /dev/vdb1 这两个 partition 加入到 VG 当中，并且整个 VG 只有一个 LV 时，那么所谓的线性模式就是：当 /dev/vda1 的容量用完之后，/dev/vdb1 的硬盘才会被使用到， 这也是我们所建议的模式。
    
*   交错模式 （triped）：那什么是交错模式？很简单啊，就是我将一笔数据拆成两部分，分别写入 /dev/vda1 与 /dev/vdb1 的意思，感觉上有点像 RAID 0 啦！如此一来，一份数据用两颗硬盘来写入，理论上，读写的性能会比较好。
    

三、磁盘相关命令
--------

### 3.1、dumpe2fs

查询 Ext 家族 superblock 信息的指令

    [root@study ~]# dumpe2fs [-bh] 设备文件名
    选项与参数：
    -b ：列出保留为坏轨的部分（一般用不到吧！？）
    -h ：仅列出 superblock 的数据，不会列出其他的区段内容！
    范例：鸟哥的一块 1GB ext4 文件系统内容
    
    [root@study ~]# blkid <==这个指令可以叫出目前系统有被格式化的设备
    /dev/vda1: LABEL="myboot" UUID="ce4dbf1b-2b3d-4973-8234-73768e8fd659" TYPE="xfs"
    /dev/vda2: LABEL="myroot" UUID="21ad8b9a-aaad-443c-b732-4e2522e95e23" TYPE="xfs"
    /dev/vda3: UUID="12y99K-bv2A-y7RY-jhEW-rIWf-PcH5-SaiApN" TYPE="LVM2_member"
    /dev/vda5: UUID="e20d65d9-20d4-472f-9f91-cdcfb30219d6" TYPE="ext4" <==看到 ext4 了！
    
    [root@study ~]# dumpe2fs /dev/vda5
    dumpe2fs 1.42.9 （28-Dec-2013）
    Filesystem volume name: <none> # 文件系统的名称（不一定会有）
    Last mounted on: <not available> # 上一次挂载的目录位置
    Filesystem UUID: e20d65d9-20d4-472f-9f91-cdcfb30219d6
    Filesystem magic number: 0xEF53 # 上方的 UUID 为 Linux 对设备的定义码
    Filesystem revision #: 1 （dynamic） # 下方的 features 为文件系统的特征数据
    Filesystem features: has_journal ext_attr resize_inode dir_index filetype extent 64bit
    flex_bg sparse_super large_file huge_file uninit_bg dir_nlink extra_isize
    Filesystem flags: signed_directory_hash
    Default mount options: user_xattr acl # 默认在挂载时会主动加上的挂载参数
    Filesystem state: clean # 这块文件系统的状态为何，clean 是没问题
    Errors behavior: Continue
    Filesystem OS type: LinuxInode count: 65536 # inode 的总数
    Block count: 262144 # block 的总数
    Reserved block count: 13107 # 保留的 block 总数
    Free blocks: 249189 # 还有多少的 block 可用数量
    Free inodes: 65525 # 还有多少的 inode 可用数量
    First block: 0
    Block size: 4096 # 单个 block 的容量大小
    Fragment size: 4096
    Group descriptor size: 64
    ....（中间省略）....
    Inode size: 256 # inode 的容量大小！已经是 256 了喔！
    ....（中间省略）....
    Journal inode: 8
    Default directory hash: half_md4
    Directory Hash Seed: 3c2568b4-1a7e-44cf-95a2-c8867fb19fbc
    Journal backup: inode blocks
    Journal features: （none）
    Journal size: 32M # Journal 日志式数据的可供纪录总容量
    Journal length: 8192
    Journal sequence: 0x00000001
    Journal start: 0
    Group 0: （Blocks 0-32767） # 第一块 block group 位置
    Checksum 0x13be, unused inodes 8181
    Primary superblock at 0, Group descriptors at 1-1 # 主要 superblock 的所在喔！
    Reserved GDT blocks at 2-128
    Block bitmap at 129 （+129）, Inode bitmap at 145 （+145）
    Inode table at 161-672 （+161） # inode table 的所在喔！
    28521 free blocks, 8181 free inodes, 2 directories, 8181 unused inodes
    Free blocks: 142-144, 153-160, 4258-32767 # 下面两行说明剩余的容量有多少
    Free inodes: 12-8192
    Group 1: （Blocks 32768-65535） [INODE_UNINIT] # 后续为更多其他的 block group 喔！
    
    

*   Group0 所占用的 block 号码由 0 到 32767 号，superblock 则在第 0 号的 block 区块内！
    
*   文件系统描述说明在第 1 号 block 中；
    
*   block bitmap 与 inode bitmap 则在 129 及 145 的 block 号码上。
    
*   至于 inode table 分布于 161-672 的 block 号码中！
    
*   由于 （1）一个 inode 占用 256 Bytes ，（2）总共有 672 - 161 + 1（161本身） = 512 个 block 花在 inode table 上， （3）每
    
*   个 block 的大小为 4096 Bytes（4K）。由这些数据可以算出 inode 的数量共有 512 \* 4096 / 256 = 8192 个 inode 啦！
    
*   这个 Group0 目前可用的 block 有 28521 个，可用的 inode 有 8181 个；
    
*   剩余的 inode 号码为 12 号到 8192 号
    

### 3.2、xfs\_info

    [root@study ~]# xfs_info 挂载点|设备文件名
    范例一：找出系统 /boot 这个挂载点下面的文件系统的 superblock 纪录
    [root@study ~]# df -T /boot
    Filesystem Type 1K-blocks Used Available Use% Mounted on
    /dev/vda2 xfs 1038336 133704 904632 13% /boot
    # 没错！可以看得出来是 xfs 文件系统的！来观察一下内容吧！
    
    [root@study ~]# xfs_info /dev/vda2
    1 meta-data=/dev/vda2 isize=256 agcount=4, agsize=65536 blks
    2 = sectsz=512 attr=2, projid32bit=1
    3 = crc=0 finobt=0
    4 data = bsize=4096 blocks=262144, imaxpct=25
    5 = sunit=0 swidth=0 blks
    6 naming =version 2 bsize=4096 ascii-ci=0 ftype=0
    7 log =internal bsize=4096 blocks=2560, version=2
    8 = sectsz=512 sunit=0 blks, lazy-count=1
    9 realtime =none extsz=4096 blocks=0, rtextents=0
    

*   第 1 行里面的 isize 指的是 inode 的容量，每个有 256Bytes 这么大。至于 agcount 则是前面谈到的储存区群组 （allocationgroup） 的个数，共有 4 个， agsize 则是指每个储存区群组具有 65536 个 block 。配合第 4 行的 block 设置为 4K，因此整个文件系统的容量应该就是 4_65536_4K 这么大！
    
*   第 2 行里面 sectsz 指的是逻辑扇区 （sector） 的容量设置为 512Bytes 这么大的意思。
    
*   第 4 行里面的 bsize 指的是 block 的容量，每个 block 为 4K 的意思，共有 262144 个 block 在这个文件系统内。
    
*   第 5 行里面的 sunit 与 swidth 与磁盘阵列的 stripe 相关性较高。这部份我们下面格式化的时候会举一个例子来说明。
    
*   第 7 行里面的 internal 指的是这个登录区的位置在文件系统内，而不是外部设备的意思。且占用了 4K \* 2560 个 block，总共约10M 的容量。
    
*   第 9 行里面的 realtime 区域，里面的 extent 容量为 4K。不过目前没有使用
    

### 3.3、df

列出文件系统的整体磁盘使用量

    [root@study ~]# df [-ahikHTm] [目录或文件名]
    选项与参数：
    -a ：列出所有的文件系统，包括系统特有的 /proc 等文件系统；
    -k ：以 KBytes 的容量显示各文件系统；
    -m ：以 MBytes 的容量显示各文件系统；
    -h ：以人们较易阅读的 GBytes, MBytes, KBytes 等格式自行显示；
    -H ：以 M=1000K 取代 M=1024K 的进位方式；
    -T ：连同该 partition 的 filesystem 名称 （例如 xfs） 也列出；
    -i ：不用磁盘容量，而以 inode 的数量来显示
    范例一：将系统内所有的 filesystem 列出来！
    [root@study ~]# df
    Filesystem 1K-blocks Used Available Use% Mounted on
    /dev/mapper/centos-root 10475520 3409408 7066112 33% /
    devtmpfs 627700 0 627700 0% /dev
    tmpfs 637568 80 637488 1% /dev/shm
    tmpfs 637568 24684 612884 4% /run
    tmpfs 637568 0 637568 0% /sys/fs/cgroup
    /dev/mapper/centos-home 5232640 67720 5164920 2% /home
    /dev/vda2 1038336 133704 904632 13% /boot
    # 在 Linux 下面如果 df 没有加任何选项，那么默认会将系统内所有的
    # （不含特殊内存内的文件系统与 swap） 都以 1 KBytes 的容量来列出来！
    # 至于那个 /dev/shm 是与内存有关的挂载，大小为内存的一半，重启会丢失数据 
    

*   Filesystem：代表该文件系统是在哪个 partition ，所以列出设备名称；
    
*   1k-blocks：说明下面的数字单位是 1KB 呦！可利用 -h 或 -m 来改变容量；
    
*   Used：顾名思义，就是使用掉的磁盘空间啦！
    
*   Available：也就是剩下的磁盘空间大小；
    
*   Use%：就是磁盘的使用率啦！如果使用率高达 90% 以上时， 最好需要注意一下了，免得容量不足造成系统问题喔！（例如最容易被灌爆的 /var/spool/mail 这个放置邮件的磁盘）
    
*   Mounted on：就是磁盘挂载的目录所在啦！（挂载点啦！）
    

​ 系统里面其实还有很多特殊的文件系统存在的。那些比较特殊的文件系统几乎都是在内存当中，例如 /proc 这个挂载点。因此，这些特殊的文件系统都不会占据磁盘空间喔！

​ 由于 df 主要读取的数据几乎都是针对一整个文件系统，因此读取的范围主要是在 Superblock 内的信息， 所以这个指令显示结果的速度非常的快速！

​ /dev/shm/ 目录，其实是利用内存虚拟出来的磁盘空间，通常是总实体内存的一半！ 由于是通过内存仿真出来的磁盘，因此你在这个目录下面创建任何数据文件时，存取速度是非常快速的！（在内存内工作） 不过，也由于他是内存仿真出来的，因此这个文件系统的大小在每部主机上都不一样，而且创建的东西在下次开机时就消失了！ 因为是在内存中嘛！

### 3.4、du

评估文件系统的磁盘使用量（常用在推估目录所占容量）

    [root@study ~]# du [-ahskm] 文件或目录名称
    选项与参数：
    -a ：列出所有的文件与目录容量，因为默认仅统计目录下面的文件量而已。
    -h ：以人们较易读的容量格式 （G/M） 显示；
    -s ：列出总量而已，而不列出每个各别的目录占用容量；
    -S ：不包括子目录下的总计，与 -s 有点差别。
    -k ：以 KBytes 列出容量显示；
    -m ：以 MBytes 列出容量显示；
    范例一：列出目前目录下的所有文件大小
    
    [root@study ~]# du
    4 ./.cache/dconf <==每个目录都会列出来
    4 ./.cache/abrt
    8 ./.cache
    ....（中间省略）....
    0 ./test4
    4 ./.ssh <==包括隐藏文件的目录
    76 . <==这个目录（.）所占用的总量
    # 直接输入 du 没有加任何选项时，则 du 会分析“目前所在目录”
    # 的文件与目录所占用的磁盘空间。但是，实际显示时，仅会显示目录容量（不含文件），
    # 因此 . 目录有很多文件没有被列出来，所以全部的目录相加不会等于 . 的容量喔！
    # 此外，输出的数值数据为 1K 大小的容量单位。
    

一般使用`du -hs *`统计当前目录下第一级子目录的大小

### 3.5、ln

​ Linux 下面的链接文件有两种，一种是类似 Windows 的捷径功能的文件，可以让你快速的链接到目标文件（或目录）； 另一种则是通过文件系统的 inode 链接来产生新文件名，而不是产生新文件！这种称为实体链接 （hard link）

Hard Link （实体链接, 硬式链接或实际链接）

*   每个文件都会占用一个 inode ，文件内容由 inode 的记录来指向；
*   想要读取该文件，必须要经过目录记录的文件名来指向到正确的 inode 号码才能读取
*   如果你将任何一个“文件名”删除，其实 inode 与 block 都还是存在的！
*   hard link 只是在某个目录下的 block 多写入一个关连数据而已，既不会增加 inode 也不会耗用 block 数量
*   不能跨 Filesystem；
*   不能 link 目录

Symbolic Link （符号链接，亦即是捷径）

ymbolic link 就是在创建一个独立的文件，而这个文件会让数据的读取指向他 link 的那个文件的文件名

    [root@study ~]# ln [-sf] 来源文件 目标文件
    选项与参数：
    -s ：如果不加任何参数就进行链接，那就是hard link，至于 -s 就是symbolic link
    -f ：如果 目标文件存在时，就主动的将目标文件直接移除后再创建！
    范例一：将 /etc/passwd 复制到 /tmp 下面，并且观察 inode 与 block
    
    [root@study ~]# cd /tmp
    [root@study tmp]# cp -a /etc/passwd .
    [root@study tmp]# du -sb ; df -i .
    6602 . <==先注意一下这里的容量是多少！
    Filesystem Inodes IUsed IFree IUse% Mounted on
    /dev/mapper/centos-root 10485760 109748 10376012 2% /
    # 利用 du 与 df 来检查一下目前的参数～那个 du -sb 是计算整个 /tmp 下面有多少 Bytes 的容量啦！
    

### 3.6、lsblk

lsblk 列出系统上的所有磁盘列表

    [root@study ~]# lsblk [-dfimpt] [device]
    选项与参数：
    -d ：仅列出磁盘本身，并不会列出该磁盘的分区数据
    -f ：同时列出该磁盘内的文件系统名称
    -i ：使用 ASCII 的线段输出，不要使用复杂的编码 （再某些环境下很有用）
    -m ：同时输出该设备在 /dev 下面的权限数据 （rwx 的数据）
    -p ：列出该设备的完整文件名！而不是仅列出最后的名字而已。
    -t ：列出该磁盘设备的详细数据，包括磁盘伫列机制、预读写的数据量大小等
    范例一：列出本系统下的所有磁盘与磁盘内的分区信息
    [root@study ~]# lsblk
    NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
    sr0 11:0 1 1024M 0 rom
    vda 252:0 0 40G 0 disk # 一整颗磁盘
    |-vda1 252:1 0 2M 0 part
    |-vda2 252:2 0 1G 0 part /boot
    `-vda3 252:3 0 30G 0 part
    |-centos-root 253:0 0 10G 0 lvm / # 在 vda3 内的其他文件系统
    |-centos-swap 253:1 0 1G 0 lvm [SWAP]
    `-centos-home 253:2 0 5G 0 lvm /home
    

*   NAME：就是设备的文件名啰！会省略 /dev 等前导目录！
*   MAJ:MIN：其实核心认识的设备都是通过这两个代码来熟悉的！分别是主要：次要设备代码！
*   RM：是否为可卸载设备 （removable device），如光盘、USB 磁盘等等
*   SIZE：当然就是容量啰！
*   RO：是否为只读设备的意思
*   TYPE：是磁盘 （disk）、分区 （partition） 还是只读存储器 （rom） 等输出
*   MOUTPOINT：就是前一章谈到的挂载点

### 3.7、blkid

列出设备的 UUID 等参数，lsblk 已经可以使用 -f 来列出文件系统与设备的 UUID 数据

    [root@study ~]# blkid
    /dev/vda2: UUID="94ac5f77-cb8a-495e-a65b-2ef7442b837c" TYPE="xfs"
    /dev/vda3: UUID="WStYq1-P93d-oShM-JNe3-KeDl-bBf6-RSmfae" TYPE="LVM2_member"
    /dev/sda1: UUID="35BC-6D6B" TYPE="vfat"
    /dev/mapper/centos-root: UUID="299bdc5b-de6d-486a-a0d2-375402aaab27" TYPE="xfs"
    /dev/mapper/centos-swap: UUID="905dc471-6c10-4108-b376-a802edbd862d" TYPE="swap"
    /dev/mapper/centos-home: UUID="29979bf1-4a28-48e0-be4a-66329bf727d9" TYPE="xfs"
    

### 3.8、parted

磁盘的分区类型，还可以进行分区的相关操作

    [root@study ~]# parted device_name print
    范例一：列出 /dev/vda 磁盘的相关数据
    [root@study ~]# parted /dev/vda print
    Model: Virtio Block Device （virtblk） # 磁盘的模块名称（厂商）
    Disk /dev/vda: 42.9GB # 磁盘的总容量
    Sector size （logical/physical）: 512B/512B # 磁盘的每个逻辑/物理扇区容量
    Partition Table: gpt # 分区表的格式 （MBR/GPT）
    Disk Flags: pmbr_boot
    Number Start End Size File system Name Flags # 下面才是分区数据
    1 1049kB 3146kB 2097kB bios_grub
    2 3146kB 1077MB 1074MB xfs
    3 1077MB 33.3GB 32.2GB lvm
    

    [root@study ~]# parted [设备] [指令 [参数]]
    选项与参数：
    指令功能：
    新增分区：mkpart [primary|logical|extended] [ext4|vfat|xfs] 开始 结束
    显示分区：print
    删除分区：rm [partition]
    范例一：以 parted 列出目前本机的分区表数据
    [root@study ~]# parted /dev/vda print
    Model: Virtio Block Device （virtblk） <==磁盘接口与型号
    Disk /dev/vda: 42.9GB <==磁盘文件名与容量
    Sector size （logical/physical）: 512B/512B <==每个扇区的大小
    Partition Table: gpt <==是 GPT 还是 MBR 分区
    Disk Flags: pmbr_boot
    Number Start End Size File system Name Flags
    1 1049kB 3146kB 2097kB bios_grub
    2 3146kB 1077MB 1074MB xfs
    3 1077MB 33.3GB 32.2GB lvm
    4 33.3GB 34.4GB 1074MB xfs Linux filesystem
    5 34.4GB 35.4GB 1074MB ext4 Microsoft basic data
    6 35.4GB 36.0GB 537MB linux-swap（v1） Linux swap
    [ 1 ] [ 2 ] [ 3 ] [ 4 ] [ 5 ] [ 6 ]
    

*   Number：这个就是分区的号码啦！举例来说，1号代表的是 /dev/vda1 的意思；
    
*   Start：分区的起始位置在这颗磁盘的多少 MB 处？有趣吧！他以容量作为单位喔！
    
*   End：此分区的结束位置在这颗磁盘的多少 MB 处？
    
*   Size：由上述两者的分析，得到这个分区有多少容量；
    
*   File system：分析可能的文件系统类型为何的意思！
    
*   Name：就如同 gdisk 的 System ID 之意。
    

### 3.9、gdisk/fdisk

MBR 分区表请使用 fdisk 分区， GPT 分区表请使用 gdisk 分区

    [root@study ~]# gdisk 设备名称
    范例：由前一小节的 lsblk 输出，我们知道系统有个 /dev/vda，请观察该磁盘的分区与相关数据
    [root@study ~]# gdisk /dev/vda <==仔细看，不要加上数字喔！
    GPT fdisk （gdisk） version 0.8.6
    Partition table scan:
    MBR: protective
    BSD: not present
    APM: not present
    GPT: present
    Found valid GPT with protective MBR; using GPT. <==找到了 GPT 的分区表！
    Command （? for help）: <==这里可以让你输入指令动作，可以按问号 （?） 来查看可用指令
    Command （? for help）: ?
    b back up GPT data to a file
    c change a partition's name
    d delete a partition # 删除一个分区
    i show detailed information on a partition
    l list known partition types
    n add a new partition # 增加一个分区
    o create a new empty GUID partition table （GPT）
    p print the partition table # 印出分区表 （常用）
    q quit without saving changes # 不储存分区就直接离开 gdisk
    r recovery and transformation options （experts only）
    s sort partitions
    t change a partition's type code
    v verify disk
    w write table to disk and exit # 储存分区操作后离开 gdisk
    x extra functionality （experts only）
    ? print this menu
    Command （? for help）:
    

​ 应该要通过 lsblk 或 blkid 先找到磁盘，再用 parted /dev/xxx print 来找出内部的分区表类型，之后才用 gdisk 或 fdisk 来操作系统

​ fdisk 跟 gdisk 使用的方式几乎一样！只是一个使用 ? 作为指令提示数据，一个使用 m 作为提示这样而已

### 3.10、partprobe

更新 Linux 核心的分区表信息，分区后可以使用该命令进行更新

    [root@study ~]# partprobe [-s] # 你可以不要加 -s ！那么屏幕不会出现讯息！
    [root@study ~]# partprobe -s # 不过还是建议加上 -s 比较清晰！
    /dev/vda: gpt partitions 1 2 3 4 5 6
    [root@study ~]# lsblk /dev/vda # 实际的磁盘分区状态
    NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
    vda 252:0 0 40G 0 disk
    |-vda1 252:1 0 2M 0 part
    |-vda2 252:2 0 1G 0 part /boot
    |-vda3 252:3 0 30G 0 part
    | |-centos-root 253:0 0 10G 0 lvm /
    | |-centos-swap 253:1 0 1G 0 lvm [SWAP]
    | `-centos-home 253:2 0 5G 0 lvm /home
    |-vda4 252:4 0 1G 0 part
    |-vda5 252:5 0 1G 0 part
    `-vda6 252:6 0 500M 0 part
    [root@study ~]# cat /proc/partitions # 核心的分区纪录
    major minor #blocks name
    252 0 41943040 vda
    252 1 2048 vda1
    252 2 1048576 vda2
    252 3 31461376 vda3
    252 4 1048576 vda4
    252 5 1048576 vda5
    252 6 512000 vda6
    # 现在核心也正确的抓到了分区参数了！
    

### 3.11、mkfs.xfs

创建 xfs 文件系统， 因此使用的是 mkfs.xfs 这个指令

    [root@study ~]# mkfs.xfs [-b bsize] [-d parms] [-i parms] [-l parms] [-L label] [-f] \
    [-r parms] 设备名称
    选项与参数：
    关於单位：下面只要谈到“数值”时，没有加单位则为 Bytes 值，可以用 k,m,g,t,p （小写）等来解释
    比较特殊的是 s 这个单位，它指的是 sector 的“个数”喔！
    -b ：后面接的是 block 容量，可由 512 到 64k，不过最大容量限制为 Linux 的 4k 喔！
    -d ：后面接的是重要的 data section 的相关参数值，主要的值有：
    agcount=数值 ：设置需要几个储存群组的意思（AG），通常与 CPU 有关
    agsize=数值 ：每个 AG 设置为多少容量的意思，通常 agcount/agsize 只选一个设置即可
    file ：指的是“格式化的设备是个文件而不是个设备”的意思！（例如虚拟磁盘）
    size=数值 ：data section 的容量，亦即你可以不将全部的设备容量用完的意思
    su=数值 ：当有 RAID 时，那个 stripe 数值的意思，与下面的 sw 搭配使用
    sw=数值 ：当有 RAID 时，用于储存数据的磁盘数量（须扣除备份碟与备用碟）
    sunit=数值 ：与 su 相当，不过单位使用的是“几个 sector（512Bytes大小）”的意思
    swidth=数值 ：就是 su*sw 的数值，但是以“几个 sector（512Bytes大小）”来设置
    -f ：如果设备内已经有文件系统，则需要使用这个 -f 来强制格式化才行！
    -i ：与 inode 有较相关的设置，主要的设置值有：
    size=数值 ：最小是 256Bytes 最大是 2k，一般保留 256 就足够使用了！
    internal=[0|1]：log 设备是否为内置？默认为 1 内置，如果要用外部设备，使用下面设置
    logdev=device ：log 设备为后面接的那个设备上头的意思，需设置 internal=0 才可！
    size=数值 ：指定这块登录区的容量，通常最小得要有 512 个 block，大约 2M 以上才行！
    -L ：后面接这个文件系统的标头名称 Label name 的意思！
    -r ：指定 realtime section 的相关设置值，常见的有：
    extsize=数值 ：就是那个重要的 extent 数值，一般不须设置，但有 RAID 时，
    最好设置与 swidth 的数值相同较佳！最小为 4K 最大为 1G 。
    范例：将前一小节分区出来的 /dev/vda4 格式化为 xfs 文件系统
    [root@study ~]# mkfs.xfs /dev/vda4
    meta-data=/dev/vda4 isize=256 agcount=4, agsize=65536 blks
    = sectsz=512 attr=2, projid32bit=1
    = crc=0 finobt=0
    data = bsize=4096 blocks=262144, imaxpct=25
    = sunit=0 swidth=0 blks
    naming =version 2 bsize=4096 ascii-ci=0 ftype=0
    log =internal log bsize=4096 blocks=2560, version=2
    = sectsz=512 sunit=0 blks, lazy-count=1
    realtime =none extsz=4096 blocks=0, rtextents=0
    # 很快格是化完毕！都用默认值！较重要的是 inode 与 block 的数值
    [root@study ~]# blkid /dev/vda4
    /dev/vda4: UUID="39293f4f-627b-4dfd-a
    

### 3.12、mkfs.ext4

格式化为ext4文件系统

    [root@study ~]# mkfs.ext4 [-b size] [-L label] 设备名称
    选项与参数：
    -b ：设置 block 的大小，有 1K, 2K, 4K 的容量，
    -L ：后面接这个设备的标头名称。
    范例：将 /dev/vda5 格式化为 ext4 文件系统Tips
    [root@study ~]# mkfs.ext4 /dev/vda5
    mke2fs 1.42.9 （28-Dec-2013）
    Filesystem label= # 显示 Label name
    OS type: Linux
    Block size=4096 （log=2） # 每一个 block 的大小
    Fragment size=4096 （log=2）
    Stride=0 blocks, Stripe width=0 blocks # 跟 RAID 相关性较高
    65536 inodes, 262144 blocks # 总计 inode/block 的数量
    13107 blocks （5.00%） reserved for the super user
    First data block=0
    Maximum filesystem blocks=268435456
    8 block groups # 共有 8 个 block groups 喔！
    32768 blocks per group, 32768 fragments per group
    8192 inodes per group
    Superblock backups stored on blocks:
    32768, 98304, 163840, 229376
    Allocating group tables: done
    Writing inode tables: done
    Creating journal （8192 blocks）: done
    Writing superblocks and filesystem accounting information: done
    [root@study ~]# dumpe2fs -h /dev/vda5
    dumpe2fs 1.42.9 （28-Dec-2013）
    Filesystem volume name: <none>
    Last mounted on: <not available>
    Filesystem UUID: 3fd5cc6f-a47d-46c0-98c0-d43b072e0e12
    ....（中间省略）....
    Inode count: 65536
    Block count: 262144
    Block size: 4096
    Blocks per group: 32768
    Inode size: 256
    Journal size: 32M
    

### 3.13、xfs\_repair

处理 XFS 文件系统，当有 xfs 文件系统错乱才需要使用这个指令！所以，这个指令最好是不要用到啦

    [root@study ~]# xfs_repair [-fnd] 设备名称
    选项与参数：
    -f ：后面的设备其实是个文件而不是实体设备
    -n ：单纯检查并不修改文件系统的任何数据 （检查而已）
    -d ：通常用在单人维护模式下面，针对根目录 （/） 进行检查与修复的动作！很危险！不要随便使用
    范例：检查一下刚刚创建的 /dev/vda4 文件系统
    [root@study ~]# xfs_repair /dev/vda4
    Phase 1 - find and verify superblock...
    Phase 2 - using internal log
    Phase 3 - for each AG...
    Phase 4 - check for duplicate blocks...
    Phase 5 - rebuild AG headers and trees...
    Phase 6 - check inode connectivity...
    Phase 7 - verify and correct link counts...
    done
    # 共有 7 个重要的检查流程！详细的流程介绍可以 man xfs_repair 即可！
    范例：检查一下系统原本就有的 /dev/centos/home 文件系统
    [root@study ~]# xfs_repair /dev/centos/home
    xfs_repair: /dev/centos/home contains a mounted filesystem
    xfs_repair: /dev/centos/home contains a mounted and writable filesystem
    fatal error -- couldn't initialize XFS library
    

### 3.14、fsck.ext4

​ 处理 EXT4 文件系统fsck 是个综合指令，如果是针对 ext4 的话，建议直接使用 fsck.ext4 来检测比较妥当

    [root@study ~]# fsck.ext4 [-pf] [-b superblock] 设备名称
    选项与参数：
    -p ：当文件系统在修复时，若有需要回复 y 的动作时，自动回复 y 来继续进行修复动作。
    -f ：强制检查！一般来说，如果 fsck 没有发现任何 unclean 的旗标，不会主动进入
    细部检查的，如果您想要强制 fsck 进入细部检查，就得加上 -f 旗标啰！
    -D ：针对文件系统下的目录进行最优化配置。
    -b ：后面接 superblock 的位置！一般来说这个选项用不到。但是如果你的 superblock 因故损毁时，
    通过这个参数即可利用文件系统内备份的 superblock 来尝试救援。一般来说，superblock 备份在：
    1K block 放在 8193, 2K block 放在 16384, 4K block 放在 32768
    范例：找出刚刚创建的 /dev/vda5 的另一块 superblock，并据以检测系统
    [root@study ~]# dumpe2fs -h /dev/vda5 | grep 'Blocks per group'
    Blocks per group: 32768
    # 看起来每个 block 群组会有 32768 个 block，因此第二个 superblock 应该就在 32768 上！
    # 因为 block 号码为 0 号开始编的！
    [root@study ~]# fsck.ext4 -b 32768 /dev/vda5
    e2fsck 1.42.9 （28-Dec-2013）
    /dev/vda5 was not cleanly unmounted, check forced.
    Pass 1: Checking inodes, blocks, and sizes
    Deleted inode 1577 has zero dtime. Fix<y>? yes
    Pass 2: Checking directory structurePass 3: Checking directory connectivity
    Pass 4: Checking reference counts
    Pass 5: Checking group summary information
    /dev/vda5: ***** FILE SYSTEM WAS MODIFIED ***** # 文件系统被改过，所以这里会有警告！
    /dev/vda5: 11/65536 files （0.0% non-contiguous）, 12955/262144 blocks
    # 好巧合！鸟哥使用这个方式来检验系统，恰好遇到文件系统出问题！于是可以有比较多的解释方向！
    # 当文件系统出问题，它就会要你选择是否修复～如果修复如上所示，按下 y 即可！
    # 最终系统会告诉你，文件系统已经被更改过，要注意该项目的意思！
    
    

### 3.15、mount

    [root@study ~]# mount -a
    [root@study ~]# mount [-l]
    [root@study ~]# mount [-t 文件系统] LABEL='' 挂载点
    [root@study ~]# mount [-t 文件系统] UUID='' 挂载点 # 鸟哥近期建议用这种方式喔！
    [root@study ~]# mount [-t 文件系统] 设备文件名 挂载点
    选项与参数：
    -a ：依照配置文件 /etc/fstab 的数据将所有未挂载的磁盘都挂载上来
    -l ：单纯的输入 mount 会显示目前挂载的信息。加上 -l 可增列 Label 名称！
    -t ：可以加上文件系统种类来指定欲挂载的类型。常见的 Linux 支持类型有：xfs, ext3, ext4,
    reiserfs, vfat, iso9660（光盘格式）, nfs, cifs, smbfs （后三种为网络文件系统类型）
    -n ：在默认的情况下，系统会将实际挂载的情况实时写入 /etc/mtab 中，以利其他程序的运行。
    但在某些情况下（例如单人维护模式）为了避免问题会刻意不写入。此时就得要使用 -n 选项。
    -o ：后面可以接一些挂载时额外加上的参数！比方说帐号、密码、读写权限等：
    async, sync: 此文件系统是否使用同步写入 （sync） 或非同步 （async） 的
    内存机制，请参考文件系统运行方式。默认为 async。
    atime,noatime: 是否修订文件的读取时间（atime）。为了性能，某些时刻可使用 noatime
    ro, rw: 挂载文件系统成为只读（ro） 或可读写（rw）
    auto, noauto: 允许此 filesystem 被以 mount -a 自动挂载（auto）
    dev, nodev: 是否允许此 filesystem 上，可创建设备文件？ dev 为可允许
    suid, nosuid: 是否允许此 filesystem 含有 suid/sgid 的文件格式？
    exec, noexec: 是否允许此 filesystem 上拥有可执行 binary 文件？
    user, nouser: 是否允许此 filesystem 让任何使用者执行 mount ？一般来说，
    mount 仅有 root 可以进行，但下达 user 参数，则可让
    一般 user 也能够对此 partition 进行 mount 。
    defaults: 默认值为：rw, suid, dev, exec, auto, nouser, and async
    remount: 重新挂载，这在系统出错，或重新更新参数时，很有用！
    

### 3.16、umount

    [root@study ~]# umount [-fn] 设备文件名或挂载点
    选项与参数：
    -f ：强制卸载！可用在类似网络文件系统 （NFS） 无法读取到的情况下；
    -l ：立刻卸载文件系统，比 -f 还强！
    -n ：不更新 /etc/mtab 情况下卸载。
    

### 3.17、mdadm

    [root@study ~]# mdadm --detail /dev/md0
    [root@study ~]# mdadm --create /dev/md[0-9] --auto=yes --level=[015] --chunk=NK \
    > --raid-devices=N --spare-devices=N /dev/sdx /dev/hdx...
    选项与参数：
    --create ：为创建 RAID 的选项；
    --auto=yes ：决定创建后面接的软件磁盘阵列设备，亦即 /dev/md0, /dev/md1...
    --chunk=Nk ：决定这个设备的 chunk 大小，也可以当成 stripe 大小，一般是 64K 或 512K。
    --raid-devices=N ：使用几个磁盘 （partition） 作为磁盘阵列的设备
    --spare-devices=N ：使用几个磁盘作为备用 （spare） 设备
    --level=[015] ：设置这组磁盘阵列的等级。支持很多，不过建议只要用 0, 1, 5 即可
    --detail ：后面所接的那个磁盘阵列设备的详细信息
    

    [root@study ~]# mdadm --manage /dev/md[0-9] [--add 设备] [--remove 设备] [--fail 设备]
    选项与参数：
    --add ：会将后面的设备加入到这个 md 中！
    --remove ：会将后面的设备由这个 md 中移除
    --fail ：会将后面的设备设置成为出错的状态
    

### 3.18、逻辑卷相关命令

![](https://img2022.cnblogs.com/blog/1271254/202207/1271254-20220701175517465-204006235.jpg)

### 3.19、dd

[https://www.cnblogs.com/yuanqiangfei/p/9138625.html](https://www.cnblogs.com/yuanqiangfei/p/9138625.html)

    dd：用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换。
    注意：指定数字的地方若以下列字符结尾，则乘以相应的数字：b=512；c=1；k=1024；w=2
    参数注释：
    1. if=文件名：输入文件名，缺省为标准输入。即指定源文件。< if=input file >
    2. of=文件名：输出文件名，缺省为标准输出。即指定目的文件。< of=output file >
    3. ibs=bytes：一次读入bytes个字节，即指定一个块大小为bytes个字节。
        obs=bytes：一次输出bytes个字节，即指定一个块大小为bytes个字节。
        bs=bytes：同时设置读入/输出的块大小为bytes个字节。
    4. cbs=bytes：一次转换bytes个字节，即指定转换缓冲区大小。
    5. skip=blocks：从输入文件开头跳过blocks个块后再开始复制。
    6. seek=blocks：从输出文件开头跳过blocks个块后再开始复制。
    注意：通常只用当输出文件是磁盘或磁带时才有效，即备份到磁盘或磁带时才有效。
    7. count=blocks：仅拷贝blocks个块，块大小等于ibs指定的字节数。
    8. conv=conversion：用指定的参数转换文件。
        ascii：转换ebcdic为ascii
         ebcdic：转换ascii为ebcdic
        ibm：转换ascii为alternate ebcdic
        block：把每一行转换为长度为cbs，不足部分用空格填充
        unblock：使每一行的长度都为cbs，不足部分用空格填充
        lcase：把大写字符转换为小写字符
        ucase：把小写字符转换为大写字符
        swab：交换输入的每对字节
         noerror：出错时不停止
         notrunc：不截短输出文件
        sync：将每个输入块填充到ibs个字节，不足部分用空（NUL）字符补齐。
    

### 3.20、fio

[https://www.cnblogs.com/raykuan/p/6914748.html](https://www.cnblogs.com/raykuan/p/6914748.html)

在fio官网下载fio-2.1.10.tar文件，解压后./configure、make、make install之后就可以使用fio了（**注意：该命令不要在已有数据的文件系统操作**）

    filename=/dev/emcpowerb　支持文件系统或者裸设备，-filename=/dev/sda2或-filename=/dev/sdb
    direct=1                 测试过程绕过机器自带的buffer，使测试结果更真实
    rw=randwread             测试随机读的I/O
    rw=randwrite             测试随机写的I/O
    rw=randrw                测试随机混合写和读的I/O
    rw=read                  测试顺序读的I/O
    rw=write                 测试顺序写的I/O
    rw=rw                    测试顺序混合写和读的I/O
    bs=4k                    单次io的块文件大小为4k
    bsrange=512-2048         同上，提定数据块的大小范围
    size=5g                  本次的测试文件大小为5g，以每次4k的io进行测试
    numjobs=30               本次的测试线程为30
    runtime=1000             测试时间为1000秒，如果不写则一直将5g文件分4k每次写完为止
    ioengine=psync           io引擎使用pync方式，如果要使用libaio引擎，需要yum install libaio-devel包
    rwmixwrite=30            在混合读写的模式下，写占30%
    group_reporting          关于显示结果的，汇总每个进程的信息此外
    lockmem=1g               只使用1g内存进行测试
    zero_buffers             用0初始化系统buffer
    nrfiles=8                每个进程生成文件的数量
    

测试场景：

    100%随机，100%读， 4K
    fio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=rand_100read_4k
    
    100%随机，100%写， 4K
    fio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=rand_100write_4k
    
    100%顺序，100%读 ，4K
    fio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=read -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=sqe_100read_4k
     
    100%顺序，100%写 ，4K
    fio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=write -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=sqe_100write_4k
    
    100%随机，70%读，30%写 4K
    fio -filename=/dev/emcpowerb -direct=1 -iodepth 1 -thread -rw=randrw -rwmixread=70 -ioengine=psync -bs=4k -size=1000G -numjobs=50 -runtime=180 -group_reporting -name=randrw_70read_4k
    

    bw=平均IO带宽
    iops=IOPS
    runt=线程运行时间
    slat=提交延迟
    clat=完成延迟
    lat=响应时间
    bw=带宽
    cpu=利用率
    IO depths=io队列
    IO submit=单个IO提交要提交的IO数
    IO complete=Like the above submit number, but for completions instead.
    IO issued=The number of read/write requests issued, and how many of them were short.
    IO latencies=IO完延迟的分布
    
    io=总共执行了多少size的IO
    aggrb=group总带宽
    minb=最小.平均带宽.
    maxb=最大平均带宽.
    mint=group中线程的最短运行时间.
    maxt=group中线程的最长运行时间.
    
    ios=所有group总共执行的IO数.
    merge=总共发生的IO合并数.
    ticks=Number of ticks we kept the disk busy.
    io_queue=花费在队列上的总共时间.
    util=磁盘利用率
    

### 3.21、iostat

[https://blog.csdn.net/qq\_20332637/article/details/82146753](https://blog.csdn.net/qq_20332637/article/details/82146753)

    yum install sysstat
    
    cpu属性值说明：
    %user：CPU处在用户模式下的时间百分比。
    %nice：CPU处在带NICE值的用户模式下的时间百分比。
    %system：CPU处在系统模式下的时间百分比。
    %iowait：CPU等待输入输出完成时间的百分比。
    %steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。
    %idle：CPU空闲时间百分比。
    

备注：

如果%iowait的值过高，表示硬盘存在I/O瓶颈

如果%idle值高，表示CPU较空闲

如果%idle值高但系统响应慢时，可能是CPU等待分配内存，应加大内存容量。

如果%idle值持续低于10，表明CPU处理能力相对较低，系统中最需要解决的资源是CPU。

cpu属性值说明:

tps：该设备每秒的传输次数

kB\_read/s：每秒从设备（drive expressed）读取的数据量；

kB\_wrtn/s：每秒向设备（drive expressed）写入的数据量；

kB\_read： 读取的总数据量；

kB\_wrtn：写入的总数量数据量

![](https://img2022.cnblogs.com/blog/1271254/202207/1271254-20220701175537249-1470956012.jpg)

    [root@rac01-node01 /]# iostat -xd 3
    Linux 3.8.13-16.2.1.el6uek.x86_64 (rac01-node01)     05/27/2017     _x86_64_    (40 CPU)
    Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await  svctm  %util
    sda               0.05     0.75    2.50    0.50    76.59    69.83    48.96     0.00    1.17   0.47   0.14
    scd0              0.00     0.00    0.02    0.00     0.11     0.00     5.25     0.00   21.37  20.94   0.05
    dm-0              0.00     0.00    2.40    1.24    75.88    69.83    40.00     0.01    1.38   0.38   0.14
    dm-1              0.00     0.00    0.02    0.00     0.14     0.00     8.00     0.00    0.65   0.39   0.00
    sdc               0.00     0.00    0.01    0.00     0.11     0.00    10.20     0.00    0.28   0.28   0.00
    sdb               0.00     0.00    0.01    0.00     0.11     0.00    10.20     0.00    0.15   0.15   0.00
    sdd               0.00     0.00    0.01    0.00     0.11     0.00    10.20     0.00    0.25   0.25   0.00
    sde               0.00     0.00    0.01    0.00     0.11     0.00    10.20     0.00    0.14   0.14  0.00
    
    

*   rrqms：每秒这个设备相关的读取请求有多少被Merge了（当系统调用需要读取数据的时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge）
*   wrqm/s：每秒这个设备相关的写入请求有多少被Merge了。
*   rsec/s：The number of sectors read from the device per second.
*   wsec/s：The number of sectors written to the device per second.
*   rKB/s：The number of kilobytes read from the device per second.
*   wKB/s：The number of kilobytes written to the device per second.
*   avgrq-sz：平均请求扇区的大小,The average size (in sectors) of the requests that were issued to the device.
*   avgqu-sz：是平均请求队列的长度。毫无疑问，队列长度越短越好,The average queue length of the requests that were issued to the device.
*   await：每一个IO请求的处理的平均时间（单位是微秒毫秒）。这里可以理解为IO的响应时间，一般地系统IO响应时间应该低于5ms，如果大于10ms就比较大了。这个时间包括了队列时间和服务时间，也就是说，一般情况下，await大于svctm，它们的差值越小，则说明队列时间越短，反之差值越大，队列时间越长，说明系统出了问题。
*   svctm：表示平均每次设备I/O操作的服务时间（以毫秒为单位）。如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘性能很好。如果await的值远高于svctm的值，则表示I/O队列等待太长，系统上运行的应用程序将变慢。
*   %util： 在统计时间内所有处理IO时间，除以总共统计时间。例如，如果统计间隔1秒，该设备有0.8秒在处理IO，而0.2秒闲置，那么该设备的%util = 0.8/1 = 80%，所以该参数暗示了设备的繁忙程度，一般地，如果该参数是100%表示磁盘设备已经接近满负荷运行了（当然如果是多磁盘，即使%util是100%，因为磁盘的并发能力，所以磁盘使用未必就到了瓶颈）。

### 3.22、iotop

[https://www.cnblogs.com/yinzhengjie/p/9934260.html](https://www.cnblogs.com/yinzhengjie/p/9934260.html)

yum -y install iotop

    各个参数说明：
    
    　　-o, --only只显示正在产生I/O的进程或线程。除了传参，可以在运行过程中按o生效。
    　　-b, --batch非交互模式，一般用来记录日志。
    　　-n NUM, --iter=NUM设置监测的次数，默认无限。在非交互模式下很有用。
    　　-d SEC, --delay=SEC设置每次监测的间隔，默认1秒，接受非整形数据例如1.1。
    　　-p PID, --pid=PID指定监测的进程/线程。
    　　-u USER, --user=USER指定监测某个用户产生的I/O。
    　　-P, --processes仅显示进程，默认iotop显示所有线程。
    　　-a, --accumulated显示累积的I/O，而不是带宽。
    　　-k, --kilobytes使用kB单位，而不是对人友好的单位。在非交互模式下，脚本编程有用。
    　　-t, --time 加上时间戳，非交互非模式。
    　　-q, --quiet 禁止头几行，非交互模式。有三种指定方式。
    　　-q 只在第一次监测时显示列名
    　　-qq 永远不显示列名。
    　　-qqq 永远不显示I/O汇总。
    交互按键：
    　　和top命令类似，iotop也支持以下几个交互按键。
    　　left和right方向键：改变排序。　　
    　　r：反向排序。
    　　o：切换至选项--only。
    　　p：切换至--processes选项。
    　　a：切换至--accumulated选项。
    　　q：退出。
    　　i：改变线程的优先级。
    
    

作者：[一寸HUI](https://www.cnblogs.com/zsql/ "一寸HUI的博客")  
出处：[https://www.cnblogs.com/zsql/](https://www.cnblogs.com/zsql/ "https://www.cnblogs.com/zsql/")  
如果您觉得阅读本文对您有帮助，请点击一下右下方的**推荐**按钮，您的**推荐**将是我写作的最大动力！  
版权声明：本文为博主原创或转载文章，欢迎转载，**但转载文章之后必须在文章页面明显位置注明出处**，否则保留追究法律责任的权利。