---
layout: post
title: "开发实践丨昇腾CANN的推理应用开发体验"
date: "2022-07-14T09:19:13.213Z"
---
开发实践丨昇腾CANN的推理应用开发体验
====================

> **摘要：**这是关于一次 Ascend 在线实验的记录，主要内容是通过网络模型加载、推理、结果输出的部署全流程展示，从而快速熟悉并掌握 ACL（Ascend Computing Language）基本开发流程。

本文分享自华为云社区《[基于昇腾CANN的推理应用开发快速体验（Python)](https://bbs.huaweicloud.com/blogs/357549?utm_source=cnblog&utm_medium=bbs-ex&utm_campaign=other&utm_content=content)》，作者： Tianyi\_Li 。

前情提要
----

这是关于一次 Ascend 在线实验的记录，主要内容是通过网络模型加载、推理、结果输出的部署全流程展示，从而快速熟悉并掌握 ACL（Ascend Computing Language）基本开发流程。

注意，为了保证学习和体验效果，用户应该具有以下知识储备：

1.熟练的Python语言编程能力

2.深度学习基础知识，理解神经网络模型输入输出数据结构

1\. 目录
------

![](https://pic2.zhimg.com/80/v2-5b0db34e4dcfab405d83ce8e807daafd_720w.jpg)

2\. 最终目标
--------

![](https://pic1.zhimg.com/80/v2-7d9ec4e4e890ecd91f954d76ee1f82cc_720w.jpg)

1.了解ACL的基本概念，清楚ACL具备哪些能力，能为我们做什么

2.了解ACL定义的编程模型，理解各类运行资源的概念及其相互关系

3.能够区分Host和Device的概念，并学会管理这两者各自的内存

4.加载一个离线模型进行推理，并为推理准备输入输出数据结构

3\. 基础知识
--------

### 3.1 ATC介绍

ATC（Ascend Tensor Compiler）是华为昇腾软件栈提供的一个编译工具，它的主要功能是将基于开源框架的网络模型（如 Caffe、TensorFlow 等）以及单算子 Json 文件，转换成昇腾AI处理器支持的离线模型 Offline-Model 文件（简称OM文件）。在编译过程中，可以实现算子调度的优化、权值数据重排、内存使用优化等，并且可以脱离设备完成模型的预处理。更详细的ATC介绍，可参看官方文档 。

需要说明的是，理论上对于华为自研 AI 计算框架 MindSpore 的支持会更加友好。

![](https://pic2.zhimg.com/80/v2-cd4ef2a9c479187a8401f2a18df32cd1_720w.jpg)

### 3.2 ACL介绍

对已训练好的权重文件，比如 Caffe框架下的 caffemodel, TensorFlow框架下得到的 checkpoint 或者 pb 文件，再经过 ATC 工具转换后得到的离线模型文件，ACL（Ascend Computing Language，昇腾计算语言）提供了一套用于在昇腾系列处理器上进行加速计算的API。基于这套API，您能够管理和使用昇腾软硬件计算资源，并进行机器学习相关计算。更详细的ACL介绍，可参看官方文档 。

最新版本支持 onnx 模型和 MindSpore 模型转换为离线模型文件，甚至可以直接通过MindSpore进行部署和推理。

当前 ACL 提供了 C/C++ 和 Python 编程接口，能够很方便的帮助开发者达成包括但不限于如下这些目标：

1.加载深度学习模型进行推理

2.加载单算子进行计算

3.图像、视频数据的预处理

![](https://pic1.zhimg.com/80/v2-786ed401d37f8602ed46c141b0bca538_720w.jpg)

4\. 准备工作
--------

最终结果是使用 Resnet50 对 3 张图片进行分类推理。为了达成这个结果，首先我们准备了如下两个素材：

*   三张待推理分类的图片数据，如：

![](https://pic3.zhimg.com/80/v2-16f035d146828bc2238ed1eb86ab3d52_720w.jpg)

*   使用ATC工具，将 tensorflow 的 googlenet.pb 模型转换成昇腾支持的om(offine-model) 文件。

**推理后我们将打印每张图片置信度排前5位的标签及其置信度。**

5\. 开始
------

### 5.1 初始化

在开始调用ACL的任何接口之前，首先要做ACL的初始化。初始化的代码很简单，只有一行：

acl.init(config\_path)

这个接口调用会帮您准备好ACL的运行时环境。其中调用时传入的参数是一个配置文件在磁盘上的路径，这里暂时不必关注。

有初始化就有去初始化，在确定完成了ACL的所有调用之后，或者进程退出之前，要做去初始化操作，接口调用也十分简单：

acl.finalize()

### 导入Python包：

import argparse
import numpy as np
import struct
import acl
import os
from PIL import Image

### 接口介绍：

![](https://pic1.zhimg.com/80/v2-be3f65c91bfcc8c6479704671d98eec0_720w.jpg)

### 函数示例：

def init():
    ret \= acl.init()
    check\_ret("acl.init", ret)

### 5.2 申请计算资源

想要使用昇腾处理器提供的加速计算能力，需要对运行管理资源申请，包括Device、Context、Stream。且需要按顺序申请，主要涉及以下三个接口：

acl.rt.set\_device(device\_id)

这个接口指定计算设备，告诉运行时环境我们想要用哪个设备，或者更具体一点，哪个芯片。但是要注意，芯片和我们在这里传入的编号之间并没有物理上的一一对应关系。

acl.rt.create\_context(device\_id)

Context作为一个容器，管理了所有对象（包括Stream、Event、设备内存等）的生命周期。不同Context的Stream、不同Context的Event是完全隔离的，无法建立同步等待关系。个人理解为，如果计算资源足够的话，可以创建多个Context，分别运行不同的应用，来提高硬件利用率，而不用担心应用之间的互相干扰，类似于Docker。

acl.rt.create\_stream()

Stream用于维护一些异步操作的执行顺序，确保按照应用程序中的代码调用顺序在Device上执行。基于Stream的kernel执行和数据传输能够实现Host运算操作、Host与Device间的数据传输、Device内的运算并行。

### 接口介绍：

![](https://pic3.zhimg.com/80/v2-a1ec417df166d0067b074aea3c7243de_720w.jpg)![](https://pic3.zhimg.com/80/v2-d2851f212ed7a9abf0f02b3d71c6eaae_720w.jpg)![](https://pic2.zhimg.com/80/v2-8db8391cbe6791a22f584e98c5f6f2b5_720w.jpg)

### 函数示例：

import sys
import os
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast\_node\_interactivity \= "all" 

home\_path \= !echo ${HOME}
sys.path.append(os.path.join(home\_path\[0\] , "jupyter-notebook/"))
print('System init success.')

# atlas\_utils是本团队基于pyACL封装好的一套工具库，如果您也想引用的话，请首先将
# https://gitee.com/ascend/samples/tree/master/python/common/atlas\_utils
\# 这个路径下的代码引入您的工程中
from atlas\_utils.acl\_resource import AclResource
from constants import \*

# 创建一个AclResource类的实例
acl\_resource \= AclResource()
#AscendCL资源初始化（封装版本）
acl\_resource.init()

# 上方“init”方法具体实现（仅供参考）
# 请阅读“init(self)”方法，观察初始化和运行时资源申请的详细操作步骤
def init(self):
    """
    Init resource
    """
    print("init resource stage:")
    ret \= acl.init()
    utils.check\_ret("acl.init", ret)
    #指定用于运算的Device
    ret \= acl.rt.set\_device(self.device\_id)
    utils.check\_ret("acl.rt.set\_device", ret)
    print("Set device n success.")

    #显式创建一个Context
    self.context, ret \= acl.rt.create\_context(self.device\_id)
    utils.check\_ret("acl.rt.create\_context", ret)

    #创建一个Stream
    self.stream, ret \= acl.rt.create\_stream()
    utils.check\_ret("acl.rt.create\_stream", ret)

    #获取当前昇腾AI软件栈的运行模式
    #0：ACL\_DEVICE，表示运行在Device的Control CPU上或开发者版上
    #1：ACL\_HOST，表示运行在Host CPU上
    self.run\_mode, ret \= acl.rt.get\_run\_mode()
    utils.check\_ret("acl.rt.get\_run\_mode", ret)

    print("Init resource success")

需要说明的是这里使用了 atlas\_utils ，这是昇腾团队基于 pyACL 封装好的一套工具库，可以更加便捷的使用，但可能存在更新不及时的问题，也不易于优化提升，以及个人学习理解，建议能不用，则不用。

### 5.3 加载模型

既然要调用模型进行推理，首先当然是要把模型加载进来。ACL 提供了多种模型加载和内存管理方式，这里我们只选取其中相对简单的一种，即从磁盘上加载离线模型，并且加载后的模型内存由ACL自动管理:

model\_path = "./model/resnet50.om";  # 模型文件在磁盘上的路径
model\_id, ret \= acl.mdl.load\_from\_file(model\_path)  # 加载模型

其中，model\_id 是系统完成模型加载后生成的模型ID对应的指针对象，加载后生成的model\_id，全局唯一。

记得这个“model\_id”，后边我们使用模型进行推理，以及卸载模型的时候还要用到。

有加载自然就有卸载，模型卸载的接口比较简单：

acl.mdl.unload(model\_id)

至此，您脑海中应该有这样一个概念，即使用了任何的资源，加载了任何的素材，都要记得用完后销毁和卸载。这点对于使用 C/C++编程的同学应该很好理解。

### 接口介绍：

![](https://pic1.zhimg.com/80/v2-f4d59285aeb3d3b4a7aff1f2209216e4_720w.jpg)

### 函数示例：

def load\_model(model\_path):
    model\_path \= "./model/googlenet\_yuv.om"
    model\_id, ret \= acl.mdl.load\_from\_file(model\_path)
    check\_ret("acl.mdl.load\_from\_file", ret)
    return model\_id

### 5.4 获取模型信息

模型描述需要特殊的数据类型，使用以下函数来创建并获取该数据类型。

acl.mdl.create\_desc()
acl.mdl.get\_desc(model\_desc, model\_id)

获取到模型类型后，还需要根据该类型来获取模型的输入输出个数，调用函数如下：

acl.mdl.get\_num\_inputs(model\_desc)
acl.mdl.get\_num\_outputs(model\_desc)

### 接口介绍：

![](https://pic2.zhimg.com/80/v2-0319550e8bc833f3dc80f5f87d8850dd_720w.jpg)

### 函数示例：

def get\_model\_data(model\_id):
    global model\_desc
    model\_desc \= acl.mdl.create\_desc()
    ret \= acl.mdl.get\_desc(model\_desc, model\_id)
    check\_ret("acl.mdl.get\_desc", ret)

    input\_size \= acl.mdl.get\_num\_inputs(model\_desc)
    output\_size \= acl.mdl.get\_num\_outputs(model\_desc)
    return input\_size, output\_size

### 5.5 申请device内存

要使用 NPU 进行加速计算，首先要申请能够被 NPU 直接访问到的专用内存。在讲解内存申请之前，首先我们要区分如下两个概念：

Host：Host指与Device相连接的X86服务器、ARM服务器，会利用Device提供的NN（Neural-Network ）计算能力，完成业务。

Device：Device指安装了芯片的硬件设备，利用PCIe接口与Host侧连接，为Host提供NN计算能力。

简而言之，我们的数据需要先从Host侧进行加载，即读进Host侧内存，随后将其拷贝到Device侧内存，才能进行计算。计算后的结果还要传回Host侧才能进行使用。

申请Device侧内存：

dev\_ptr, ret = acl.rt.malloc(size, policy)   # 申请device侧内存

其中，dev\_ptr是device侧内存指针，size是device侧内存大小。

这里我们分配了跟Host侧同样大小的内存，准备用于在Device侧存放推理数据。本接口最后一个参数policy是内存分配规则。

ACL\_MEM\_MALLOC\_HUGE\_FIRST ----- 优先申请大页内存，如果大页内存不够，则使用普通页的内存。
ACL\_MEM\_MALLOC\_HUGE\_ONLY \----- 仅申请大页，如果大页内存不够，则返回错误。
ACL\_MEM\_MALLOC\_NORMAL\_ONLY \----- 仅申请普通页。

**使用完别忘了释放申请过的内存：acl.rt.malloc-> acl.rt.free，切记！！！**

### 接口介绍：

![](https://pic2.zhimg.com/80/v2-b18add2749a31d00fe875ce3d0f39f39_720w.jpg)

### 函数示例：

def gen\_data\_buffer(size, des):
    global model\_desc
    func \= buffer\_method\[des\]
    for i in range(size):
        temp\_buffer\_size  \= acl.mdl.get\_output\_size\_by\_index(model\_desc, i)
        temp\_buffer, ret \= acl.rt.malloc(temp\_buffer\_size,
                                         const.ACL\_MEM\_MALLOC\_NORMAL\_ONLY)
        check\_ret("acl.rt.malloc", ret)
        if des == "in":
            input\_data.append({"buffer": temp\_buffer,
                                    "size": temp\_buffer\_size})
        elif des \== "out":
            output\_data.append({"buffer": temp\_buffer,
                                     "size": temp\_buffer\_size})

def malloc\_device(input\_num, output\_num):
    gen\_data\_buffer(input\_num, des\="in")
    gen\_data\_buffer(output\_num, des\="out")

### 5.6 图片处理(DVPP)

数字视觉预处理模块(DVPP)作为昇腾AI软件栈中的编解码和图像转换模块，为神经网络发挥着预处理辅助功能。当来自系统内存和网络的视频或图像数据进入昇腾AI处理器的计算资源中运算之前，由于Davinci架构对输入数据有固定的格式要求，如果数据未满足架构规定的输入格式、分辨率等要求，就需要调用数字视觉处理模块进行格式的转换，才可以进行后续的神经网络计算步骤。

### DVPP相关接口介绍：

读取、初始化图片：

AclImage(image\_file)

图片预处理：

yuv\_image=jpegd(image)

将输入图片缩放为输出尺寸：

resized\_image = \_dvpp.resize(yuv\_image, MODEL\_WIDTH, MODEL\_HEIGHT)

### 函数示例：

def image\_process\_dvpp():
    global run\_mode
    global images\_list
 
    stream, ret \= acl.rt.create\_stream()
    check\_ret("acl.rt.create\_stream", ret)

    run\_mode, ret \= acl.rt.get\_run\_mode()
    check\_ret("acl.rt.get\_run\_mode", ret)

    \_dvpp \= Dvpp(stream, run\_mode)
    \_dvpp.init\_resource()
    IMG\_EXT \= \['.jpg', '.JPG', '.png', '.PNG', '.bmp', '.BMP', '.jpeg', '.JPEG'\]
    images\_list \= \[os.path.join("./data", img)
                    for img in os.listdir("./data")
                    if os.path.splitext(img)\[1\] in IMG\_EXT\]
    img\_list \= \[\]
    for image\_file in images\_list:
        image \= AclImage(image\_file)
        image\_input \= image.copy\_to\_dvpp()
        yuv\_image \= \_dvpp.jpegd(image\_input)
        resized\_image \= dvpp.resize(yuv\_image, 
                        MODEL\_WIDTH, MODEL\_HEIGHT)
        img\_list.append(resized\_image)
        print("dvpp\_process image: {} success".format(image\_file))
    return img\_list

### 5.7 数据传输

### 5.7.1 host传输数据至device

把数据从Host侧拷贝至Device侧：

acl.rt.memcpy(dst, dest\_max, src, count, direction)

参数的顺序是：目的内存地址，目的内存最大大小，源内存地址，拷贝长度，拷贝方向。

direction拷贝方向当前支持四种:

ACL\_MEMCPY\_HOST\_TO\_HOST ----- host->host

ACL\_MEMCPY\_HOST\_TO\_DEVICE \----- host->device

ACL\_MEMCPY\_DEVICE\_TO\_HOST \----- device->host

ACL\_MEMCPY\_DEVICE\_TO\_DEVICE \----- device->device

该步骤已在DVPP接口内自动完成。

### 接口介绍：

![](https://pic4.zhimg.com/80/v2-b446e109789ba475fc2e55f18ef7c13f_720w.jpg)![](https://pic3.zhimg.com/80/v2-fe625125540f702eda212cc833052a8a_720w.jpg)

### 函数示例：

def \_data\_interaction\_in(dataset):
    global input\_data
    temp\_data\_buffer \= input\_data
    for i in range(len(temp\_data\_buffer)):
        item \= temp\_data\_buffer\[i\]
        ptr \= acl.util.numpy\_to\_ptr(dataset)
        ret \= acl.rt.memcpy(item\["buffer"\],
                            item\["size"\],
                            ptr,
                            item\["size"\],
                            ACL\_MEMCPY\_HOST\_TO\_DEVICE)
        check\_ret("acl.rt.memcpy", ret)

### 5.7.2 准备推理所需数据结构

模型推理所需的输入输出数据，是通过一种特定的数据结构来组织的，这种数据结构叫“dataSet”，即所有的输入，组成了1个dateset，所有的输出组成了一个dataset。而对于很多模型来讲，输入其实不止一个，那么所有的输入集合叫“dataSet”，其中的每一个输入叫什么呢？

**答案是“dataBuffer”。**即一个模型的多个输入，每个输入是一个“dataBuffer”，所有的dataBuffer构成了一个“dataSet”。

下面我们从构建dataBuffer开始。

dataBuffer的创建很简单，还记得前边我们申请了Device侧的内存，并且把数据传过去了吗？现在要用到了。我们当时的device侧内存地址：data，这段内存的长度：size。使用上边两个对象来创建一个dataBuffer:

acl.create\_data\_buffer(data, size)

现在，这个“buffer”就是我们的第一个输入了。

### 接口介绍：

![](https://pic4.zhimg.com/80/v2-12ef10aacd26a8934ced2a86f961201f_720w.jpg)

### 函数示例：

def create\_buffer(dataset, type="in"):
    global input\_data, output\_data
    if type == "in":    
        temp\_dataset \= input\_data
    else:
        temp\_dataset \= output\_data
    for i in range(len(temp\_dataset)):
        item \= temp\_dataset\[i\]
        data \= acl.create\_data\_buffer(item\["buffer"\], item\["size"\])
        if data is None:
            ret \= acl.destroy\_data\_buffer(dataset)
            check\_ret("acl.destroy\_data\_buffer", ret)
        \_, ret \= acl.mdl.add\_dataset\_buffer(dataset, data)
        if ret != ACL\_ERROR\_NONE:
            ret \= acl.destroy\_data\_buffer(dataset)
            check\_ret("acl.destroy\_data\_buffer", ret)

针对本实验所用到的 resnet50 模型，我们只需要一个输入即可，那现在有了dataBuffer，要如何构建dataSet呢？

很简单：

acl.mdl.create\_dataset()

dataset有了，下面就是向这个dataset中放置DataBuffer了：

acl.mdl.add\_dataset\_buffer(dataset, data)

这样，我们在dataset中添加了一个databuffer，输入准备好了。

创建输出数据结构同理，当您拿到一个模型，您应该是清楚这个模型的输出数据结构的，根据其输出个数、每个输出占用内存的大小来申请相应的device内存、dataBuffer以及dataSet即可。

现在假设我们已经创建好了输出的dataset，其变量名称叫做：  
outputDataSet

至此，我们准备好了推理所需的所有素材。

**当然，将来用完之后别忘了销毁：**

acl.create\_data\_buffer-> acl.destory\_data\_buffer;     acl.mdl.create\_dataset-> acl.mdl.destroy\_dataset

### 接口介绍：

![](https://pic1.zhimg.com/80/v2-433988620d8db02198cc65dcd4ae199c_720w.jpg)![](https://pic3.zhimg.com/80/v2-16a4687fbd015a3ecaf8af8f4607e96a_720w.jpg)![](https://pic2.zhimg.com/80/v2-597acfadc2f576ea38d9f9ce3c77a379_720w.jpg)

### 函数实例：

def \_gen\_dataset(type="in"):
    global load\_input\_dataset, load\_output\_dataset
    dataset \= acl.mdl.create\_dataset()
    if type == "in":    
        load\_input\_dataset \= dataset
    else:
        load\_output\_dataset \= dataset
    create\_buffer(dataset, type)

### 5.8 推理

所有素材准备好之后，模型推理已经是顺理成章的事情了，还记得我们的几个关键素材吗？

model\_id

load\_input\_dataset

load\_output\_dataset

最终的推理，其实只需要一行代码：

ret = acl.mdl.execute(model\_id, input, output)

这是个同步接口，线程会阻塞在这里直到推理结束。推理结束后就可以提取load\_output\_dataset中的数据进行使用了。

### 接口介绍：

![](https://pic2.zhimg.com/80/v2-6bc3be4f23ad4ea1c000e24ce45fe91d_720w.jpg)

函数示例：

def inference(model\_id, \_input, \_output):
    global load\_input\_dataset, load\_output\_dataset
    ret \= acl.mdl.execute(model\_id,
                    load\_input\_dataset,
                    load\_output\_dataset)
    check\_ret("acl.mdl.execute", ret)

### 5.9 后处理

### 5.9.1释放资源

资源有申请就要有释放，调用以下接口释放之前申请的dataset和databuffer：

ret = acl.mdl.destroy\_dataset(dataset)
ret \= acl.destory\_data\_buffer(data\_buffer)

### 接口介绍：

![](https://pic1.zhimg.com/80/v2-0065340ca2e4105a4d76d84e5bcf2d54_720w.jpg)

### 函数示例：

def \_destroy\_data\_set\_buffer():
    global load\_input\_dataset, load\_output\_dataset
    for dataset in \[load\_input\_dataset, load\_output\_dataset\]:
        if not dataset:
            continue
        num \= acl.mdl.get\_dataset\_num\_buffers(dataset)
        for i in range(num):
            data\_buf \= acl.mdl.get\_dataset\_buffer(dataset, i)
            if data\_buf:
                ret \= acl.destroy\_data\_buffer(data\_buf)
                check\_ret("acl.destroy\_data\_buffer", ret)
        ret \= acl.mdl.destroy\_dataset(dataset)
        check\_ret("acl.mdl.destroy\_dataset", ret)

### 5.9.2 申请host内存

建立outputDataset的时候，您应该使用了device侧的内存，将这部分内存拷贝回host侧，即可直接使用了。

申请Host侧内存：

host\_ptr是host侧内存指针，随后即可使用host\_ptr指向的内存来暂存推理输入数据。把数据从device侧拷贝至host侧：

ret = acl.rt.memcpy(dst, dest\_max, src, count, direction)

参数的顺序是：目的内存地址，目的内存最大大小，源内存地址，拷贝长度，拷贝方向。（支持host->host, host->device, device->host, device->device四种,与申请device内存相同）

使用完别忘了释放申请过的内存：

acl.rt.malloc\_host-> acl.rt.free\_host

### 接口介绍：

![](https://pic3.zhimg.com/80/v2-7734f2435f26b45aa8a26669fcc09ee6_720w.jpg)

### 函数示例：

def \_data\_interaction\_out(dataset):
    global output\_data
    temp\_data\_buffer \= output\_data
    if len(dataset) == 0:
        for item in output\_data:
            temp, ret \= acl.rt.malloc\_host(item\["size"\])
            if ret != 0:
                raise Exception("can't malloc\_host ret={}".format(ret))
            dataset.append({"size": item\["size"\], "buffer": temp})
    for i in range(len(temp\_data\_buffer)):
        item \= temp\_data\_buffer\[i\]
        ptr \= dataset\[i\]\["buffer"\]
        ret \= acl.rt.memcpy(ptr,
                            item\["size"\],
                            item\["buffer"\],
                            item\["size"\],
                            ACL\_MEMCPY\_DEVICE\_TO\_HOST)
        check\_ret("acl.rt.memcpy", ret)

### 5.9.3 获取推理结果并打印

将推理后的结果数据转换为numpy类型，然后按照图片分类置信度前五的顺序打印出来。  
结果示例如下：

![](https://pic1.zhimg.com/80/v2-14768304e54ee5443ab02550cd4e144c_720w.jpg)

### 接口介绍：

![](https://pic1.zhimg.com/80/v2-039ed85052f9d49dbe438e756f2d6c14_720w.jpg)

### 函数示例：

def print\_result(result):
    global images\_list, INDEX
    dataset \= \[\]
    for i in range(len(result)):
        temp \= result\[i\]
        size \= temp\["size"\]
        ptr \= temp\["buffer"\]
        data \= acl.util.ptr\_to\_numpy(ptr, (size,), 1)
        dataset.append(data)
    st \= struct.unpack("1000f", bytearray(dataset\[0\]))
    vals \= np.array(st).flatten()
    top\_k \= vals.argsort()\[-1:-6:-1\]
    print()
    print("\======== image: {} =============".format(images\_list\[INDEX\]))
    print("\======== top5 inference results: =============")
    INDEX+=1
    for n in top\_k:
        object\_class \= get\_image\_net\_class(n)
        print("label:%d  confidence: %f, class: %s" % (n, vals\[n\], object\_class))

6\. 完整样例演示
----------

### ACL完整程序示例:

import argparse
import numpy as np
import struct
import acl
import os
from PIL import Image
import sys

home\_path \= get\_ipython().getoutput('echo ${HOME}')
sys.path.append(os.path.join(home\_path\[0\] , "jupyter-notebook/"))
print('System init success.')

from src.acl\_dvpp import Dvpp
import src.constants as const
from src.acl\_image import AclImage
from src.image\_net\_classes import get\_image\_net\_class
WORK\_DIR \= os.getcwd()
ACL\_MEM\_MALLOC\_HUGE\_FIRST \= 0
ACL\_MEMCPY\_HOST\_TO\_DEVICE \= 1
ACL\_MEMCPY\_DEVICE\_TO\_HOST \= 2
ACL\_ERROR\_NONE \= 0
MODEL\_WIDTH \= 224
MODEL\_HEIGHT \= 224
IMG\_EXT \= \['.jpg', '.JPG', '.png', '.PNG', '.bmp', '.BMP', '.jpeg', '.JPEG'\]

ret \= acl.init()

# GLOBAL
load\_input\_dataset \= None
load\_output\_dataset \= None
input\_data \= \[\]
output\_data \= \[\]
\_output\_info \= \[\]
images\_list \= \[\]
model\_desc \= 0
run\_mode \= 0
INDEX \= 0

if WORK\_DIR.find("src") == -1:
    MODEL\_PATH \= WORK\_DIR + "/src/model/googlenet\_yuv.om"
    DATA\_PATH \= WORK\_DIR + "/src/data"
else:
    MODEL\_PATH \= WORK\_DIR + "/model/googlenet\_yuv.om"
    DATA\_PATH \= WORK\_DIR + "/data"

buffer\_method \= {
    "in": acl.mdl.get\_input\_size\_by\_index,
    "out": acl.mdl.get\_output\_size\_by\_index
    }

def check\_ret(message, ret):
    if ret != ACL\_ERROR\_NONE:
        raise Exception("{} failed ret={}"
                        .format(message, ret))
def init():
    ret \= acl.init()
    check\_ret("acl.init", ret)
    print("init success")
def allocate\_res(device\_id):   
    ret \= acl.rt.set\_device(device\_id)
    check\_ret("acl.rt.set\_device", ret)
    context, ret \= acl.rt.create\_context(device\_id)
    check\_ret("acl.rt.create\_context", ret)
    print("allocate\_res success")
    return context
def load\_model(model\_path):
    model\_id, ret \= acl.mdl.load\_from\_file(model\_path)
    check\_ret("acl.mdl.load\_from\_file", ret)
    print("load\_model success")
    return model\_id

def get\_model\_data(model\_id):
    global model\_desc
    model\_desc \= acl.mdl.create\_desc()
    ret \= acl.mdl.get\_desc(model\_desc, model\_id)
    check\_ret("acl.mdl.get\_desc", ret)

    input\_size \= acl.mdl.get\_num\_inputs(model\_desc)
    output\_size \= acl.mdl.get\_num\_outputs(model\_desc)
    print("get\_model\_data success")
    return input\_size, output\_size

def gen\_data\_buffer(num, des):
    global model\_desc
    func \= buffer\_method\[des\]
    for i in range(num):
        #temp\_buffer\_size \= (model\_desc, i)
        temp\_buffer\_size  \= acl.mdl.get\_output\_size\_by\_index(model\_desc, i)
        temp\_buffer, ret \= acl.rt.malloc(temp\_buffer\_size,
                                         const.ACL\_MEM\_MALLOC\_NORMAL\_ONLY)
        check\_ret("acl.rt.malloc", ret)
        if des == "in":
            input\_data.append({"buffer": temp\_buffer,
                                    "size": temp\_buffer\_size})
        elif des \== "out":
            output\_data.append({"buffer": temp\_buffer,
                                     "size": temp\_buffer\_size})
def malloc\_device(input\_num, output\_num):
    gen\_data\_buffer(input\_num, des\="in")
    gen\_data\_buffer(output\_num, des\="out")
def image\_process\_dvpp(dvpp):
    global run\_mode
    global images\_list   
 
   # \_dvpp.init\_resource()
    IMG\_EXT \= \['.jpg', '.JPG', '.png', '.PNG', '.bmp', '.BMP', '.jpeg', '.JPEG'\]
    images\_list \= \[os.path.join(DATA\_PATH, img)
                    for img in os.listdir(DATA\_PATH)
                    if os.path.splitext(img)\[1\] in IMG\_EXT\]
    img\_list \= \[\]
    for image\_file in images\_list:
        #读入图片
        image \= AclImage(image\_file)
        image\_input \= image.copy\_to\_dvpp()
        #对图片预处理
        yuv\_image \= dvpp.jpegd(image\_input)
        resized\_image \= dvpp.resize(yuv\_image, 
                        MODEL\_WIDTH, MODEL\_HEIGHT)
        img\_list.append(resized\_image)
 
        print("dvpp\_process image: {} success".format(image\_file))
    return img\_list

def \_data\_interaction\_in(dataset):
    global input\_data
    temp\_data\_buffer \= input\_data
    for i in range(len(temp\_data\_buffer)):
        item \= temp\_data\_buffer\[i\]
        ptr \= acl.util.numpy\_to\_ptr(dataset)
        ret \= acl.rt.memcpy(item\["buffer"\],
                            item\["size"\],
                            ptr,
                            item\["size"\],
                            ACL\_MEMCPY\_HOST\_TO\_DEVICE)
        check\_ret("acl.rt.memcpy", ret)
    print("data\_interaction\_in success")

def create\_buffer(dataset, type\="in"):
    global input\_data, output\_data
    if type == "in":    
        temp\_dataset \= input\_data
    else:
        temp\_dataset \= output\_data
    for i in range(len(temp\_dataset)):
        item \= temp\_dataset\[i\]
        data \= acl.create\_data\_buffer(item\["buffer"\], item\["size"\])
        if data is None:
            ret \= acl.destroy\_data\_buffer(dataset)
            check\_ret("acl.destroy\_data\_buffer", ret)
        \_, ret \= acl.mdl.add\_dataset\_buffer(dataset, data)
        if ret != ACL\_ERROR\_NONE:
            ret \= acl.destroy\_data\_buffer(dataset)
            check\_ret("acl.destroy\_data\_buffer", ret)
    #print("create data\_buffer {} success".format(type))

def \_gen\_dataset(type\="in"):
    global load\_input\_dataset, load\_output\_dataset
    dataset \= acl.mdl.create\_dataset()
    #print("create data\_set {} success".format(type))
    if type == "in":    
        load\_input\_dataset \= dataset
    else:
        load\_output\_dataset \= dataset
    create\_buffer(dataset, type)

def inference(model\_id, \_input, \_output):
    global load\_input\_dataset, load\_output\_dataset
    ret \= acl.mdl.execute(model\_id,
                    load\_input\_dataset,
                    load\_output\_dataset)
    check\_ret("acl.mdl.execute", ret)
def \_destroy\_data\_set\_buffer():
    global load\_input\_dataset, load\_output\_dataset
    for dataset in \[load\_input\_dataset, load\_output\_dataset\]:
        if not dataset:
            continue
        num \= acl.mdl.get\_dataset\_num\_buffers(dataset)
        for i in range(num):
            data\_buf \= acl.mdl.get\_dataset\_buffer(dataset, i)
            if data\_buf:
                ret \= acl.destroy\_data\_buffer(data\_buf)
                check\_ret("acl.destroy\_data\_buffer", ret)
        ret \= acl.mdl.destroy\_dataset(dataset)
        check\_ret("acl.mdl.destroy\_dataset", ret)

def \_data\_interaction\_out(dataset):
    global output\_data
    temp\_data\_buffer \= output\_data
    if len(dataset) == 0:
        for item in output\_data:
            temp, ret \= acl.rt.malloc\_host(item\["size"\])
            if ret != 0:
                raise Exception("can't malloc\_host ret={}".format(ret))
            dataset.append({"size": item\["size"\], "buffer": temp})
    for i in range(len(temp\_data\_buffer)):
        item \= temp\_data\_buffer\[i\]
        ptr \= dataset\[i\]\["buffer"\]
        ret \= acl.rt.memcpy(ptr,
                            item\["size"\],
                            item\["buffer"\],
                            item\["size"\],
                            ACL\_MEMCPY\_DEVICE\_TO\_HOST)
        check\_ret("acl.rt.memcpy", ret)

def print\_result(result):
    global images\_list, INDEX
    dataset \= \[\]
    for i in range(len(result)):
        temp \= result\[i\]
        size \= temp\["size"\]
        ptr \= temp\["buffer"\]
        data \= acl.util.ptr\_to\_numpy(ptr, (size,), 1)
        dataset.append(data)
    st \= struct.unpack("1000f", bytearray(dataset\[0\]))
    vals \= np.array(st).flatten()
    top\_k \= vals.argsort()\[-1:-6:-1\]
    print()
    print("\======== image: {} =============".format(images\_list\[INDEX\]))
    print("\======== top5 inference results: =============")
    INDEX+=1
    for n in top\_k:
        object\_class \= get\_image\_net\_class(n)
        print("label:%d  confidence: %f, class: %s" % (n, vals\[n\], object\_class))

def release(model\_id, context):
    global input\_data, output\_data
    ret \= acl.mdl.unload(model\_id)
    check\_ret("acl.mdl.unload", ret)
    while input\_data:
        item \= input\_data.pop()
        ret \= acl.rt.free(item\["buffer"\])
        check\_ret("acl.rt.free", ret)
    while output\_data:
        item \= output\_data.pop()
        ret \= acl.rt.free(item\["buffer"\])
        check\_ret("acl.rt.free", ret)
    if context:
        ret \= acl.rt.destroy\_context(context)
        check\_ret("acl.rt.destroy\_context", ret)
        context \= None
    ret \= acl.rt.reset\_device(0)
    check\_ret("acl.rt.reset\_device", ret)
    print('release source success')
def main():
    global input\_data 
    #init()
    context \= allocate\_res(0)
    model\_id \= load\_model(MODEL\_PATH)
    input\_num, output\_num \= get\_model\_data(model\_id)
    malloc\_device(input\_num, output\_num) 
    dvpp \= Dvpp()
    img\_list \= image\_process\_dvpp(dvpp)
    for image  in img\_list:
        image\_data \= {"buffer":image.data(), "size":image.size}
        input\_data\[0\] = image\_data
        \_gen\_dataset("in")
        \_gen\_dataset("out")
        inference(model\_id, load\_input\_dataset, load\_output\_dataset)
        \_destroy\_data\_set\_buffer()
        res \= \[\]
        \_data\_interaction\_out(res)
        print\_result(res)
    release(model\_id,context)

if \_\_name\_\_ == '\_\_main\_\_':
    main()

更多有关ACL的介绍，请详见官方[参考文档](https://support.huaweicloud.com/aclpythondevg-cann502alpha5infer/atlaspython_01_0001.html) 。

**[点击关注，第一时间了解华为云新鲜技术~](https://bbs.huaweicloud.com/blogs?utm_source=cnblog&utm_medium=bbs-ex&utm_campaign=other&utm_content=content)**