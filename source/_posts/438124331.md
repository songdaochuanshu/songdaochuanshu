---
layout: post
title: "论文解读（MGAE）《MGAE: Masked Autoencoders for Self-Supervised Learning on Graphs》"
date: "2022-06-18T03:22:06.851Z"
---
论文解读（MGAE）《MGAE: Masked Autoencoders for Self-Supervised Learning on Graphs》
============================================================================

论文信息
====

> 论文标题：MGAE: Masked Autoencoders for Self-Supervised Learning on Graphs  
> 论文作者：Qiaoyu Tan, Ninghao Liu, Xiao Huang, Rui Chen, Soo-Hyun Choi, Xia Hu  
> 论文来源：2022, ArXiv  
> 论文地址：[download](https://arxiv.org/abs/2201.02534)   
> 论文代码：download

1 Introduction
==============

 　　MAE 在图上的应用。

2 Method
========

　　整体框架：

　　![](https://img2022.cnblogs.com/blog/1664108/202206/1664108-20220617165419653-1561053538.png)

2.1 Encoder
-----------

　　本文的掩藏目标是随机掩藏一部分（30%）边，然后考虑 GCN、GraphSage 作为主干网络提取特征信息，对于被掩藏的边将通过 Decoder 训练得到。

　　掩藏策略：

*   *   Undirected masking：将图看成无向图，删除 $(u,v)$ 之间的边，对应于 $A$ 中的两条边；
    *   Directed masking：将图看成有向图，删除 $(u,v)$ 之间的边，对应于 $A$ 中的一条有向边；

　　注意：上述两种策略边掩藏率是设置一样的。

2.2 Cross-correlation decoder
-----------------------------

　　由于Encoder 采用的是基于消息传递机制的 Encoder，所以最终只得到被保留部分的节点潜在嵌入。

　　Encoder $K$ 层传播结构共生成的保留节点嵌入矩阵 $\\left\\{\\mathbf{H}^{(1)}, \\mathbf{H}^{(2)}, \\cdots, \\mathbf{H}^{(K)}\\right\\}$，对于存在的保留节点进行 cross-correlations 操作，即

　　　　$\\mathbf{h}\_{e\_{v, u}}=\\|\_{k, j=1}^{K} \\mathbf{h}\_{v}^{(k)} \\odot \\mathbf{h}\_{u}^{(j)}$

　　其中：

*   *   $\\|$ 表示连接；
    *   $\\odot$ 表示元素乘法；
    *   $\\mathbf{h}\_{e\_{v, u}} \\in \\mathbb{R}^{d K^{2}}$ 表示节点 $v$ 和节点 $u$ 之间的交叉表示，分别考虑它们的 $k$ 阶邻域和 $j$ 阶邻域；

　　为避免过于复杂，通常 $K=2$。

　　假设剩余的节点有 $m$ 个，那么输入到对应的 MLP Decoder  的将有 $m(m-1)$ （无向图）个特征向量，最终预测 $(u,v)$ 直接边存在的概率通过下式生成：

　　　　$y\_{v, u}=\\operatorname{MLP}\\left(\\mathbf{h}\_{v}^{(K)}, \\mathbf{h}\_{u}^{(K)}\\right)$

2.3 Reconstruction target
-------------------------

　　MGAE解码器，**只重建掩码的边**，目标函数如下：

　　　　$\\mathcal{L}=-\\sum\\limits \_{(v, u) \\in \\mathcal{E}\_{\\text {mask }}} \\log \\frac{\\exp \\left(\\mathbf{y}\_{v u}\\right)}{\\sum\_{z \\in \\mathcal{V}} \\exp \\left(\\mathbf{y}\_{v z}\\right)}$

　　为加速训练，本文采用负采样策略。

2.4 Algorithm
-------------

 　　整体算法如下：

　　![](https://img2022.cnblogs.com/blog/1664108/202206/1664108-20220617175557235-16270258.png)

3 Experiments
=============

数据集

　　![](https://img2022.cnblogs.com/blog/1664108/202206/1664108-20220617175702277-514734744.png)

**Link prediction**

　　![](https://img2022.cnblogs.com/blog/1664108/202206/1664108-20220617175824317-1300679909.png)

**Node classifification**

　　![](https://img2022.cnblogs.com/blog/1664108/202206/1664108-20220617175933373-162334377.png)

4 Conclusion
============

　　图上边掩码AE。

修改历史
====

2022-06-17 创建文章

[论文解读目录](https://www.cnblogs.com/BlairGrowing/p/16351810.html)

因上求缘，果上努力~~~~ 作者：[Learner-](https://www.cnblogs.com/BlairGrowing/)，转载请注明原文链接：[https://www.cnblogs.com/BlairGrowing/p/16386259.html](https://www.cnblogs.com/BlairGrowing/p/16386259.html)