---
layout: post
title: "PyTorch复现VGG学习笔记"
date: "2022-12-16T09:15:09.541Z"
---
PyTorch复现VGG学习笔记
================

PyTorch复现ResNet学习笔记
===================

一篇简单的学习笔记，实现**五类花分类，**这里只介绍复现的一些细节

如果想了解更多有关网络的细节，请去看论文《VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION》

简单说明下数据集，[下载链接](https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz),这里用的数据与AlexNet的那篇是一样的所以不在说明

一、环境准备
------

可以去看之前的[一篇博客](https://www.cnblogs.com/zhangjie123/p/16753740.html)，里面写的很详细了，并且推荐了一篇炮哥的环境搭建环境

*   Anaconda3（建议使用）
*   python=3.6/3.7/3.8
*   pycharm (IDE)
*   pytorch=1.11.0 (pip package)
*   torchvision=0.12.0 (pip package)
*   cudatoolkit=11.3

二、模型搭建、训练
---------

### 1.整体框图

**模型输入为224\*224**，采用的预处理方式：从每个像素中减去在训练集上计算的RGB均值

vgg11层到19层的结构

其中最常用的是VGG-16，在本文中用的也是16层的D网络，全是步长为3的卷积

**计算层数：只计算有参数的层，池化层没参数不计入这里16=13(卷积层)+3(全连接)**

#### ![](https://img2023.cnblogs.com/blog/2992995/202212/2992995-20221216160234161-1545104004.png)

 **总结：**

1.局部相应归一化LRN对模型没有改善，A与A-LRN比较

2.1×1的卷积核带来非线性函数有帮助(C优于B)，但也可以用(non-trivial receptive fields)来代替，非平凡，无法证明

3.具有**小滤波器**的深层网络优于具有较大滤波器的浅层网络。

4**.深度越深**效果越好(A 与 B, C, D, E 比较),19层饱和(需要更多的数据集)

### 2.net.py

网络整体结构代码

![](https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif)![](https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif)

 1 #迁移学习，使用vgg与训练权重vgg16.pth
 2 import torch.nn as nn 3 import torch 4 
 5 # official pretrain weights
 6 model\_urls = { 7     'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',
 8     'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',
 9     'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',
10     'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth'
11 }
12 
13 class VGG(nn.Module):
14     def \_\_init\_\_(self, features, num\_classes=1000, init\_weights=False):
15         super(VGG, self).\_\_init\_\_()
16         self.features = features
17         self.classifier = nn.Sequential(
18             nn.Linear(512\*7\*7, 4096),
19 nn.ReLU(True),
20             nn.Dropout(p=0.5),
21             nn.Linear(4096, 4096),
22 nn.ReLU(True),
23             nn.Dropout(p=0.5),
24             nn.Linear(4096, num\_classes)
25 )
26         if init\_weights:
27 self.\_initialize\_weights()
28 
29     def forward(self, x):
30         # N x 3 x 224 x 224
31         x = self.features(x)
32         # N x 512 x 7 x 7
33         x = torch.flatten(x, start\_dim=1)
34         # N x 512\*7\*7
35         x = self.classifier(x)
36         return x
37 
38     def \_initialize\_weights(self):
39         for m in self.modules():
40             if isinstance(m, nn.Conv2d):
41                 # nn.init.kaiming\_normal\_(m.weight, mode='fan\_out', nonlinearity='relu')
42 nn.init.xavier\_uniform\_(m.weight)
43                 if m.bias is not None:
44 nn.init.constant\_(m.bias, 0)
45             elif isinstance(m, nn.Linear):
46 nn.init.xavier\_uniform\_(m.weight)
47                 # nn.init.normal\_(m.weight, 0, 0.01)
48 nn.init.constant\_(m.bias, 0)
49 
50 
51 def make\_features(cfg: list):
52     layers = \[\]
53     in\_channels = 3
54     for v in cfg:
55         if v == "M":
56             layers += \[nn.MaxPool2d(kernel\_size=2, stride=2)\]
57         else:
58             conv2d = nn.Conv2d(in\_channels, v, kernel\_size=3, padding=1)
59             layers += \[conv2d, nn.ReLU(True)\]
60             in\_channels = v
61     return nn.Sequential(\*layers)
62 
63 
64 cfgs = {
65     'vgg11': \[64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'\],
66     'vgg13': \[64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'\],
67     'vgg16': \[64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'\],
68     'vgg19': \[64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'\],
69 }
70 
71 
72 def vgg(model\_name="vgg16", \*\*kwargs):
73     assert model\_name in cfgs, "Warning: model number {} not in cfgs dict!".format(model\_name)
74     cfg = cfgs\[model\_name\]
75 
76     model = VGG(make\_features(cfg), \*\*kwargs)
77     return model
78 if \_\_name\_\_ =="\_\_main\_\_":
79     x = torch.rand(\[1, 3, 224, 224\])
80     model = vgg(num\_classes=5)
81     y = model(x)
82     #print(y)
83 
84     #统计模型参数
85     sum = 0
86     for name, param in model.named\_parameters():
87         num = 1
88         for size in param.shape:
89             num \*= size
90         sum += num
91         #print("{:30s} : {}".format(name, param.shape))
92     print("total param num {}".format(sum))#total param num 134,281,029

net.py

写完后保存，运行可以检查是否报错

如果需要打印模型参数，将代码注释去掉即可，得到googlenet的参数为134,281,029,有一亿多的参数，可以说是很多了

### 3.数据划分

这里与AlexNet用的一样

分好后的数据集

![](https://img2022.cnblogs.com/blog/2992995/202211/2992995-20221122170308098-990678595.png)

 运行下面代码将数据按一定比例，划分为训练集和验证集

![](https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif)数据划分的代码

### 4.train.py

这里训练我们使用迁移学习，来减少训练时间

因为要自己训练的话不仅要花大量时间，而且博主也尝试了训练大概有50个epoch，发现模型一直没在训练

![](https://img2023.cnblogs.com/blog/2992995/202212/2992995-20221216163251321-1463834026.png)

可以看到训练集和验证集的准确率一直在24%左右跳动

所以我们加载vgg的预训练权重，这里给上vgg16的预训练权重

链接：https://pan.baidu.com/s/1U-fOe2Hll368CQIFLS-SNw?pwd=gfxp  
提取码：gfxp

![](https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif)![](https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif)

  1 import torch  2 from torch import nn  3 from torchvision import transforms,datasets  4 from torch import optim  5 from torch.optim import lr\_scheduler  6 from net import vgg  7 import os  8 import sys  9 import json 10 from torch.utils.data import DataLoader 11 from tqdm import tqdm#用于画进度条
 12 import matplotlib.pyplot as plt 13 from matplotlib.ticker import MaxNLocator 14 
 15 # 如果显卡可用，则用显卡进行训练
 16 device = 'cuda' if torch.cuda.is\_available() else 'cpu'
 17 print("using {} device".format(device))
 18 print(device)
 19 
 20 data\_transform = { 21     "train":transforms.Compose(\[
 22         transforms.RandomResizedCrop(224),#随机裁剪
 23         transforms.RandomVerticalFlip(),#随机垂直翻转
 24         transforms.ToTensor(),#转换为tensor格式
 25         transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))#RGB三通道
 26                                 \]),
 27     "val":transforms.Compose(\[
 28         transforms.Resize((224,224)),
 29         transforms.ToTensor(),
 30         transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))
 31     \])
 32 }
 33 #数据集路径
 34 ROOT\_TRAIN = 'data/train'
 35 ROOT\_TEST = 'data/val'
 36 
 37 batch\_size = 16
 38 
 39 train\_dataset = datasets.ImageFolder(ROOT\_TRAIN,transform=data\_transform\["train"\])
 40 val\_dataset = datasets.ImageFolder(ROOT\_TEST,transform=data\_transform\["val"\])
 41 
 42 train\_dataloader = DataLoader(train\_dataset,batch\_size=batch\_size,shuffle=True)
 43 val\_dataloader = DataLoader(val\_dataset,batch\_size=batch\_size,shuffle=True)
 44 
 45 train\_num = len(train\_dataset)#计数
 46 val\_num = len(val\_dataset) 47 print("using {} images for training, {} images for validation.".format(train\_num,val\_num))
 48 
 49 #将#{'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}键值对值反转，并保存
 50 flower\_list = train\_dataset.class\_to\_idx 51 cla\_dict = dict((val, key) for key, val in flower\_list.items()) 52 # write dict into json file
 53 json\_str = json.dumps(cla\_dict, indent=4)
 54 with open('class\_indices.json', 'w') as json\_file:
 55     json\_file.write(json\_str)#保存json文件(好处，方便转换为其它类型数据)用于预测用
 56 
 57 model\_name = "vgg16"
 58 model = vgg(model\_name,num\_classes=5,init\_weights=True)
 59 
 60 # 加载预训练模型
 61 model\_weights\_path = './vgg16.pth'
 62 ckpt = torch.load(model\_weights\_path) 63 ckpt.pop('classifier.6.weight')
 64 ckpt.pop('classifier.6.bias')
 65 missing\_keys, unexpected\_keys = model.load\_state\_dict(ckpt, strict=False)
 66 
 67 model.to(device)
 68 
 69 loss\_fn = nn.CrossEntropyLoss() 70 #定义优化器
 71 optimizer = optim.SGD(model.parameters(),lr=0.003)
 72 #学习率每隔10epoch变为原来的0.1
 73 lr\_s = lr\_scheduler.StepLR(optimizer, step\_size=10, gamma=0.5)
 74 
 75 #定义训练函数
 76     def train(dataloader,model,loss\_fn,optimizer): 77         model.train()
 78         loss,acc,n = 0.0,0.0,0
 79         train\_bar = tqdm(dataloader,file=sys.stdout)
 80         for batch,(x,y) in enumerate(train\_bar): 81             #前向传播
 82             x,y = x.to(device),y.to(device) 83             output = model(x) 84             cur\_loss = loss\_fn(output,y) 85             \_,pred = torch.max(output,axis=-1)
 86             cur\_acc = torch.sum(y==pred)/output.shape\[0\]
 87             #反向传播
 88             optimizer.zero\_grad()#梯度清零
 89             cur\_loss.backward()
 90             optimizer.step()
 91             loss += cur\_loss 92             acc += cur\_acc 93             n += 1
 94             train\_bar.desc = "train epoch\[{}/{}\] loss:{:.3f}".format(i+1,epoch,cur\_loss)
 95         train\_loss = loss / n 96         train\_acc = acc / n 97         print(f"train\_loss:{train\_loss}")
 98         print(f"train\_acc:{train\_acc}")
 99         return train\_loss,train\_acc
100 
101 def val(dataloader,model,loss\_fn):
102     #验证模式
103 model.eval()
104     loss, current,n = 0.0, 0.0,0
105 with torch.no\_grad():
106         val\_bar = tqdm(dataloader, file=sys.stdout)
107         for batch, (x, y) in enumerate(val\_bar):
108             # 前向传播
109             image, y = x.to(device), y.to(device)
110             output = model(image)
111             cur\_loss = loss\_fn(output, y)
112             \_, pred = torch.max(output, axis=-1)
113             cur\_acc = torch.sum(y == pred) / output.shape\[0\]
114             loss += cur\_loss
115             current += cur\_acc
116             n += 1
117             val\_bar.desc = "val epoch\[{}/{}\] loss:{:.3f}".format(i + 1, epoch, cur\_loss)
118         val\_loss = loss / n
119         val\_acc = current / n
120         print(f"val\_loss:{val\_loss}")
121         print(f"val\_acc:{val\_acc}")
122         return val\_loss,val\_acc
123 
124 # 解决中文显示问题
125 plt.rcParams\['font.sans-serif'\] = \['SimHei'\]
126 plt.rcParams\['axes.unicode\_minus'\] = False
127 
128 #画图函数
129 def matplot\_loss(train\_loss,val\_loss):
130     plt.figure()  # 声明一个新画布，这样两张图像的结果就不会出现重叠
131     plt.plot(train\_loss,label='train\_loss')#画图
132     plt.plot(val\_loss, label='val\_loss')
133     plt.legend(loc='best')#图例
134     plt.gca().xaxis.set\_major\_locator(MaxNLocator(integer=True))
135     plt.ylabel('loss',fontsize=12)
136     plt.xlabel('epoch',fontsize=12)
137     plt.title("训练集和验证集loss对比图")
138     folder = 'result'
139     if not os.path.exists(folder):
140         os.mkdir('result')
141     plt.savefig('result/loss.jpg')
142 
143 def matplot\_acc(train\_acc,val\_acc):
144     plt.figure()  # 声明一个新画布，这样两张图像的结果就不会出现重叠
145     plt.plot(train\_acc, label='train\_acc')  # 画图
146     plt.plot(val\_acc, label='val\_acc')
147     plt.legend(loc='best')  # 图例
148     plt.gca().xaxis.set\_major\_locator(MaxNLocator(integer=True))
149     plt.ylabel('acc', fontsize=12)
150     plt.xlabel('epoch', fontsize=12)
151     plt.title("训练集和验证集acc对比图")
152     plt.savefig('result/acc.jpg')
153 
154 #开始训练
155 train\_loss\_list = \[\]
156 val\_loss\_list = \[\]
157 train\_acc\_list = \[\]
158 val\_acc\_list = \[\]
159 
160 epoch = 20
161 
162 max\_acc = 0
163 
164 for i in range(epoch):
165     lr\_s.step()#学习率迭代，10epoch变为原来的0.1
166     train\_loss,train\_acc=train(train\_dataloader,model,loss\_fn,optimizer)
167     val\_loss,val\_acc=val(val\_dataloader,model,loss\_fn)
168 
169 train\_loss\_list.append(train\_loss)
170 train\_acc\_list.append(train\_acc)
171 val\_loss\_list.append(val\_loss)
172 val\_acc\_list.append(val\_acc)
173     # 保存最好的模型权重
174     if val\_acc > max\_acc:
175         folder = 'save\_model'
176         if not os.path.exists(folder):
177             os.mkdir('save\_model')
178         max\_acc = val\_acc
179         print(f'save best model,第{i + 1}轮')
180         torch.save(model.state\_dict(), 'save\_model/best\_model.pth')  # 保存网络权重
181     # 保存最后一轮
182     if i == epoch - 1:
183         torch.save(model.state\_dict(), 'save\_model/last\_model.pth')  # 保存
184 print("done")
185 
186 # 画图
187 matplot\_loss(train\_loss\_list, val\_loss\_list)
188 matplot\_acc(train\_acc\_list, val\_acc\_list)

train.py

训练结束后可以得到训练集和验证集的loss，acc对比图

![](https://img2023.cnblogs.com/blog/2992995/202212/2992995-20221216163518212-73572704.png)![](https://img2023.cnblogs.com/blog/2992995/202212/2992995-20221216163525273-1211845770.png)

**简单的评估下：**可以看到加载预训练权重后，即使只训练20轮，验证集的准确率高达90%多，这足以证明迁移学习的强大之处。

总结
--

VGG-16除了参数很多，需要较长的训练时间外，模型相比AlexNet还是进步挺大的

自己敲一下代码，会学到很多不懂的东西

**最后，多看，多学，多试，总有一天你会称为大佬！**