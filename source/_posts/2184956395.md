---
layout: post
title: "Spark基本知识"
date: "2022-10-30T13:33:54.788Z"
---
Spark基本知识
=========

Spark基本知识
---------

Spark 是一种基于内存的快速、通用、可扩展的大数据分析计算引擎。

### spark与hadoop的区别

Hadoop

*   Hadoop 是由 java 语言编写的，在分布式服务器集群上存储海量数据并运行分布式

分析应用的开源框架

*   作为 Hadoop 分布式文件系统，HDFS 处于 Hadoop 生态圈的最下层，存储着所有

的 数 据 ， 支 持 着 Hadoop 的 所 有 服 务 。 它 的 理 论 基 础 源 于 Google 的

TheGoogleFileSystem 这篇论文，它是 GFS 的开源实现。

*   MapReduce 是一种编程模型，Hadoop 根据 Google 的 MapReduce 论文将其实现，

作为 Hadoop 的分布式计算模型，是 Hadoop 的核心。基于这个框架，分布式并行

程序的编写变得异常简单。综合了 HDFS 的分布式存储和 MapReduce 的分布式计

算，Hadoop 在处理海量数据时，性能横向扩展变得非常容易。

*   HBase 是对 Google 的 Bigtable 的开源实现，但又和 Bigtable 存在许多不同之处。

HBase 是一个基于 HDFS 的分布式数据库，擅长实时地随机读/写超大规模数据集。

它也是 Hadoop 非常重要的组件。

Spark

*   Spark 是一种由 Scala 语言开发的快速、通用、可扩展的大数据分析引擎
    
*   Spark Core 中提供了 Spark 最基础与最核心的功能
    
*   Spark SQL 是 Spark 用来操作结构化数据的组件。通过 Spark SQL，用户可以使用
    

SQL 或者 Apache Hive 版本的 SQL 方言（HQL）来查询数据。

*   Spark Streaming 是 Spark 平台上针对实时数据进行流式计算的组件，提供了丰富的

处理数据流的 API。

### Spark的四大特性

*   Simple（易用性）  
    Spark 提供了丰富的高级运算操作，支持丰富的算子，并支持 Java、Python、Scala、R、SQL 等语言的 API，使用户可以快速构建不同的应用。

开发人员只需调用 Spark 封装好的 API 来实现即可，无需关注 Spark 的底层架构。

*   Fast(速度快)  
    Spark 将处理的每个任务都构造成一个DAG（Directed Acyclic Graph, 有向无环图）来执行，实现原理是基于RDD（Resilient Distributed Dataset, 弹性分布式数据集）在内存中对数据进行迭代计算，以实现批量和流式数据的高性能快速计算处理。
    
*   Spark比MR速度快的原因  
    基于内存  
    mapreduce任务后期再计算的时候，每一个job的输出结果会落地到磁盘，后续有其他的job需要依赖于前面job的输出结果，这个时候就需要进行大量的磁盘io操作。性能就比较低。  
    spark任务后期再计算的时候，job的输出结果可以保存在内存中，后续有其他的job需要依赖于前面job的输出结果，这个时候就直接从内存中获取得到，避免了磁盘io操作，性能比较高  
    对于spark程序和mapreduce程序都会产生shuffle阶段，在shuffle阶段中它们产生的数据都会落地到磁盘。  
    进程与线程  
    mapreduce任务以进程的方式运行在yarn集群中，比如程序中有100个MapTask，一个task就需要一个进程，这些task要运行就需要开启100个进程。  
    spark任务以线程的方式运行在进程中，比如程序中有100个MapTask，后期一个task就对应一个线程，这里就不再是进程，这些task需要运行，这里可以极端一点：只需要开启1个进程，在这个进程中启动100个线程就可以了。  
    进程中可以启动很多个线程，而开启一个进程与开启一个线程需要的时间和调度代价是不一样。 开启一个进程需要的时间远远大于开启一个线程。## Scalable（可融合性）  
    Unified（通用性）  
    大数据处理的传统方案需要维护多个平台，比如，离线任务是放在 Hadoop MapRedue 上运行，实时流计算任务是放在 Storm 上运行。
    

而Spark 提供了一站式的统一解决方案，可用于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）等。这些不同类型的处理都可以在同一个应用中无缝组合使用。

*   Scalable(兼容性)  
    Spark 可以非常方便地与其他的开源产品进行融合。比如：Spark 可以使用 Hadoop 的 YARN 和 Apache Mesos 作为它的资源管理和调度器；可以处理所有 Hadoop 支持的数据，包括 HDFS、HBase 和 Cassandra 等。

### Spark运行模式

运行模式

运行类型

说明

Local

本地模式

常用于本地开发，分为Local单线程和Local-Cluster多线程模式

Standalone

集群模式

独立模式，在Spark自己的资源调度管理框架上运行，该框架采用master/salve结构

**ON YARN**

集群模式

用于生产环境，在YARN资源管理器框架上运行，由YARN负责资源管理，Spark负责任务调度和计算

ON Mesos

集群模式

用于生产环境，在Mesos资源管理器框架上运行，由Mesos责资源管理，Spark负责任务调度和计算

ON Cloud

集群模式

运行在AWS、阿里云等环境

​

### Spark核心模块

![image-20221030204910084](https://img2022.cnblogs.com/blog/2943439/202210/2943439-20221030205235111-1406494059.png)

**Spark Core**

Spark Core 中提供了 Spark 最基础与最核心的功能，Spark 其他的功能如：Spark SQL，

Spark Streaming，GraphX, MLlib 都是在 Spark Core 的基础上进行扩展的

**Spark SQL**

Spark SQL 是 Spark 用来操作结构化数据的组件。通过 Spark SQL，用户可以使用 SQL

或者 Apache Hive 版本的 SQL 方言（HQL）来查询数据。

**Spark Streaming**

Spark Streaming 是 Spark 平台上针对实时数据进行流式计算的组件，提供了丰富的处理

数据流的 API。

**Spark MLlib**

MLlib 是 Spark 提供的一个机器学习算法库。MLlib 不仅提供了模型评估、数据导入等

额外的功能，还提供了一些更底层的机器学习原语。

**Spark GraphX**

GraphX 是 Spark 面向图计算提供的框架与算法库。