---
layout: post
title: "L2M-GAN: Learning to Manipulate Latent Space Semantics for Facial Attribute Editing阅读笔记"
date: "2022-05-22T03:09:35.178Z"
---
L2M-GAN: Learning to Manipulate Latent Space Semantics for Facial Attribute Editing阅读笔记
=======================================================================================

L2M-GAN: Learning to Manipulate Latent Space Semantics for Facial Attribute Editing

2021 CVPR　　[L2M-GAN: Learning To Manipulate Latent Space Semantics for Facial Attribute Editing (thecvf.com)](https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_L2M-GAN_Learning_To_Manipulate_Latent_Space_Semantics_for_Facial_Attribute_CVPR_2021_paper.pdf)

（个人理解，欢迎指正错误）

Introduction

　　本文是一篇面部属性编辑的文章，虽然与人脸匿名是两个角度，但是任务是相通的。

![](https://img2022.cnblogs.com/blog/1470774/202205/1470774-20220515152108609-588907436.png)

　　面部属性编辑有两点要求：1、目标属性特征应当正确出现在编辑后的人脸上；2、任何不相关的面部特征均不应当在编辑后被修改。针对以上两点要求，面部属性编辑的解决方案有两类：1、空间感知；2、潜在空间的因子分解。空间感知假设被编辑特征有良好的局部性，但对于诸如性别、年龄等全局特征效果不好。潜在空间的因子分解旨在探索一个已经训练好的GAN模型的潜在空间，将其分解为与不同属性相关的部分。但这种策略不是端到端的训练，容易陷入局部最优解。 文章的L2M-GAN以一种端到端的方式实现了对潜在空间的任意特征的正交化拆解。

Methodology

![](https://img2022.cnblogs.com/blog/1470774/202205/1470774-20220516144318125-499952131.png)

　　文中并未提过网络细节，源代码也未公开训练代码，通过前项传播的evaluate过程汇总出如下网络细节，仅供参考。

![](https://img2022.cnblogs.com/blog/1470774/202205/1470774-20220522101444140-74848993.png)

![](https://img2022.cnblogs.com/blog/1470774/202205/1470774-20220522101444215-394904272.png)

![](https://img2022.cnblogs.com/blog/1470774/202205/1470774-20220522101852209-1477883538.png)

PersonalOpinions

　　本文的特征解耦网络style transformer结构简单直观，用正交作损失进行优化，效果良好。人脸中的特征相互关联，尤其是一些全局特征，如年龄，身份，性别等无法通过空间感知进行特征分割，L2M-GAN为复杂全局特征的分割提供了一条可行路径，实现了编辑目标属性特征的同时，任何不相关的特征均不应当被明显修改。