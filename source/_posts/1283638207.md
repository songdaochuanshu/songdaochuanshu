---
layout: post
title: "（数据科学学习手札150）基于dask对geopandas进行并行加速"
date: "2023-03-19T01:17:39.255Z"
---
（数据科学学习手札150）基于dask对geopandas进行并行加速
===================================

> 本文示例代码已上传至我的`Github`仓库[https://github.com/CNFeffery/DataScienceStudyNotes](https://github.com/CNFeffery/DataScienceStudyNotes)

1 简介
====

　　大家好我是费老师，`geopandas`作为我们非常熟悉的`Python GIS`利器，兼顾着高性能和易用性，特别是在其`0.12.0`版本开始使用全新的`shapely`2.0矢量计算后端后，性能表现更是一路狂飙。

　　而我们作为使用者，当然是希望`geopandas`处理分析矢量数据越快越好。在今天的文章中，我将为大家简要介绍如何基于`dask`对`geopandas`进一步提速，从而更从容的应对更大规模的`GIS`分析计算任务。

![](https://img2023.cnblogs.com/blog/1344061/202303/1344061-20230318203905286-102967698.png)

2 dask-geopandas的使用
===================

　　很多朋友应该听说过`dask`，它是`Python`生态里非常知名的高性能计算框架，可以针对大型数组、数据框及机器学习模型进行并行计算调度优化，而`dask-geopandas`就是由`geopandas`团队研发的，基于`dask`对`GeoDataFrame`进行并行计算优化的框架，本质上是对`dask`和`geopandas`的封装整合。

　　`dask-geopandas`的安装非常简单，在已经安装了`geopandas`的虚拟环境中，执行下列命令即可：

    conda install dask-geopandas -c conda-forge -y
    

2.1 基础使用
--------

　　`dask-geopandas`与`geopandas`的常用计算API是相通的，但调用方式略有不同，举一个实际例子，其中示例文件`demo_points.gdb`由以下代码随机生成并写出：

    import numpy as np
    import geopandas as gpd
    from shapely import Point, Polygon
    
    # 生成示例用矢量数据
    demo_points = gpd.GeoDataFrame(
        {
            'id': range(1000000),
            'geometry': [
                Point(np.random.uniform(0, 90),
                      np.random.uniform(0, 90))
                for i in range(1000000)
            ]
        }
    )
    
    # 写出到本地gdb
    demo_points.to_file('./demo_points.gdb', driver='OpenFileGDB')
    

　　在使用`dask-geopandas`时，我们首先还是需要用`geopandas`进行目标数据的读入，再使用`from_geopandas()`将其转换为`dask-geopandas`中可以直接操作的数据框对象，其中参数`npartitions`用于将原始数据集划分为n个数据块，理论上分区越多并行运算速度越快，但受限于机器的CPU瓶颈，通常建议设置`npartitions`为机器可调度的CPU核心数：

    demo_points = gpd.read_file('./demo_points.gdb', driver='OpenFileGDB')
    demo_points_ddf = dgpd.from_geopandas(demo_points, npartitions=4)
    demo_points_ddf
    

![](https://img2023.cnblogs.com/blog/1344061/202303/1344061-20230318203907446-30364486.png)

　　在此基础上，后续执行各种运算都需要在代码末尾衔接`.compute()`，从而真正执行前面编排好的运算逻辑，以非矢量和矢量运算分别为例：

![](https://img2023.cnblogs.com/blog/1344061/202303/1344061-20230318203909432-1913475710.png)

2.2 性能比较
--------

　　既然使用了`dask-geopandas`就是奔着其针对大型数据集的计算优化而去的，我们来比较一下其与原生`geopandas`在常见`GIS`计算任务下的性能表现，可以看到，在与`geopandas`的计算比较中，`dask-geopandas`取得了约3倍的计算性能提升，且这种提升幅度会随着数据集规模的增加而愈发明显，因为`dask`可以很好的处理内存紧张时的计算优化：

![](https://img2023.cnblogs.com/blog/1344061/202303/1344061-20230318203909432-1913475710.png)

　　当然，这并不代表我们可以在任何场景下用`dask-geopandas`代替`geopandas`，在常规的中小型数据集上`dask-geopandas`反而要慢一些，因为徒增了额外的分块调度消耗。

　　除了上述的内容外，`dask-geopandas`还有一些实验性质的功能，如基于地理空间分布的`spatial_partitions`数据分块策略优化等，待它们稳定之后我会另外发文为大家介绍😉。

* * *

　　以上就是本文的全部内容，欢迎在评论区与我进行讨论~

​