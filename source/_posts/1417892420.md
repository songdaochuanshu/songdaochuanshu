---
layout: post
title: "百倍加速IO读写！快使用Parquet和Feather格式！⛵"
date: "2022-12-21T16:23:27.632Z"
---
百倍加速IO读写！快使用Parquet和Feather格式！⛵
===============================

![百倍加速IO读写！快使用Parquet和Feather格式！⛵](https://img2023.cnblogs.com/blog/2637458/202212/2637458-20221221135805552-1000452162.png) 本文介绍了 Parquet 和 Feather 两种文件类型，可以提高本地存储数据时的读写速度，并压缩存储在磁盘上的数据大小。大型 CSV 文件的克星！用起来~

![](https://img-blog.csdnimg.cn/img_convert/49012ed95c62f9aae05592f39315b43c.png)

> 💡 作者：[韩信子](https://github.com/HanXinzi-AI)@[ShowMeAI](https://www.showmeai.tech/)  
> 📘 [数据分析实战系列](https://www.showmeai.tech/tutorials/40)：[https://www.showmeai.tech/tutorials/40](https://www.showmeai.tech/tutorials/40)  
> 📘 [本文地址](https://www.showmeai.tech/article-detail/409)：[https://www.showmeai.tech/article-detail/409](https://www.showmeai.tech/article-detail/409)  
> 📢 声明：版权所有，转载请联系平台与作者并注明出处  
> 📢 收藏[ShowMeAI](https://www.showmeai.tech/)查看更多精彩内容

💡 引言
=====

![](https://img-blog.csdnimg.cn/img_convert/61f155f030e90bf86749174311dd2b7b.png)

我们在处理本地存储的数据时遇到了一些问题。在相对较小的数据集上，**读取-处理-写入**操作可能很舒服，但对于大型 .csv 文件来说，这些操作非常麻烦，可能会消耗大量时间和资源。

为了解决这个问题，我将介绍两种文件类型，它们可以提高您的数据读写速度，并压缩存储在磁盘上的数据大小：

*   📘[**Parquet**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_parquet.html)
*   📘[**Feather**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_feather.html)

![](https://img-blog.csdnimg.cn/img_convert/2bd2df5da5cf59184ebdb45999d64b1a.png)

![](https://img-blog.csdnimg.cn/img_convert/026b9effa8ff0ece80f5679c86b79fb9.png)

这两种文件类型都具有以下特点：

*   默认情况下可以使用 Python-Pandas 访问。不过，您可能需要额外安装 pyarrow 和它的一些扩展，具体取决于您的数据类型。
*   支持基于列的 I/O 管理。这样，您可以防止在读取所有数据时临时使用额外的 RAM，然后删除不需要的列。
*   以二进制格式以自己的类型而不是原始格式存储数据，您最多可以节省 50% 的存储空间，并且可以在读写操作中获得高达 x100 的加速。

这两种文件类型都非常易于使用。更改您当前使用的代码行即可。让我们来看看它们！

💦 Parquet格式
------------

    import pandas as pd
    
    df = pd.read_csv("some_data.csv")
    
    # Saving Parquet files
    df.to_parquet("df.parquet")
    
    # Reading Parquet files
    df_parq = pd.read_parquet("df.parquet")
    

💦 Feather格式
------------

    import pandas as pd
    
    df = pd.read_csv("some_data.csv")
    
    # Saving Feather files
    df.to_feather("df.feather")
    
    # Reading Feather files
    df_feat = pd.read_feather("df.feather")
    

💡 总结
=====

在本篇内容中，[ShowMeAI](https://www.showmeai.tech)给大家介绍了提高读写速度的数据格式，如果您不想使用 Excel 原始格式存储数据，那么建议您使用并行读取和写入数据的方法，这样可以提高数据处理的速度和效率。

参考资料
====

*   📘[**Parquet**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_parquet.html)
*   📘[**Feather**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_feather.html)

推荐阅读
====

*   🌍 [**数据分析实战系列**](https://www.showmeai.tech/tutorials/40)：[https://www.showmeai.tech/tutorials/40](https://www.showmeai.tech/tutorials/40)
*   🌍 [**机器学习数据分析实战系列**](https://www.showmeai.tech/tutorials/41)：[https://www.showmeai.tech/tutorials/41](https://www.showmeai.tech/tutorials/41)
*   🌍 [**深度学习数据分析实战系列**](https://www.showmeai.tech/tutorials/42)：[https://www.showmeai.tech/tutorials/42](https://www.showmeai.tech/tutorials/42)
*   🌍 [**TensorFlow数据分析实战系列**](https://www.showmeai.tech/tutorials/43)：[https://www.showmeai.tech/tutorials/43](https://www.showmeai.tech/tutorials/43)
*   🌍 [**PyTorch数据分析实战系列**](https://www.showmeai.tech/tutorials/44)：[https://www.showmeai.tech/tutorials/44](https://www.showmeai.tech/tutorials/44)
*   🌍 [**NLP实战数据分析实战系列**](https://www.showmeai.tech/tutorials/45)：[https://www.showmeai.tech/tutorials/45](https://www.showmeai.tech/tutorials/45)
*   🌍 [**CV实战数据分析实战系列**](https://www.showmeai.tech/tutorials/46)：[https://www.showmeai.tech/tutorials/46](https://www.showmeai.tech/tutorials/46)
*   🌍 [**AI 面试题库系列**](https://www.showmeai.tech/tutorials/48)：[https://www.showmeai.tech/tutorials/48](https://www.showmeai.tech/tutorials/48)

[![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e9190f41b8de4af38c8a1a0c96f0513b~tplv-k3u1fbpfcp-zoom-1.image)](https://www.showmeai.tech/)