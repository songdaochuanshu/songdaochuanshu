---
layout: post
title: "状态估计和KalmanFilter公式的推导与应用"
date: "2022-11-04T05:24:39.730Z"
---
状态估计和KalmanFilter公式的推导与应用
=========================

![状态估计和KalmanFilter公式的推导与应用](https://img2022.cnblogs.com/blog/2820663/202211/2820663-20221104130641318-1197531314.png) 状态估计和KalmanFilter公式的推导与应用。

状态估计的概率解释
---------

运动和观测方程：

\\\[\\left\\lbrace \\begin{array}{l} x\_k = f(x\_{k\_1}, u\_k) + w\_k \\\\ z\_k = h(y\_j, x\_k) + v\_{k,j} \\end{array} \\right. \\qquad {k = 1,\\dots,N, j = 1,\\dots,M} \\tag{1.1} \\\]

其中，各个参数的含义如下：

*   \\(x\_k\\) ：机器人的位姿。
    
*   \\(u\_k\\) ：系统在k时刻的输入量。
    
*   \\(w\_k\\)：位姿变化的随机噪声。
    
*   \\(z\_k\\) ：系统的观测值，传感器采集的观测数据。
    
*   \\(y\_j\\) ：路标，或者说是观测点。
    
*   \\(v\_{k,j}\\)：观测过程中的随机噪声。
    

我们的目标则是利用系统在k时刻的输入量\\(u\_k\\)和系统的观测量\\(z\_k\\)，估计机器的位姿\\(x\_k\\)和路标点\\(y\_j\\)的概率分布。

> 在比较常见且合理的情况下，我们可以假设状态量和噪声项服从高斯分布——这意味这我们在程序中只需要存储他们的均值和协方差矩阵即可。均值可以看作变量的最最优估计，协方差则可以度量变量的不确定性。

由于位姿\\(x\_k\\)和路标点\\(y\_j\\)都是需要我们估计的变量，这里我们改变符号的意义。令\\(x\_k\\)为k时刻所有的未知量，记作：

\\\[x\_k \\overset{\\text{def}}{=} \\{x\_k, y\_1,\\dots,y\_m\\} \\tag{1.2} \\\]

根据上述(1.1)和(1.2)可以将运动方程和观测方程写成如下形式：

\\\[\\left\\lbrace \\begin{array}{l} x\_k = f(x\_{k\_1}, u\_k) + w\_k \\\\ z\_k = h(x\_k) + v\_{k,j} \\end{array} \\right. \\qquad {k = 1,\\dots,N} \\tag{1.3} \\\]

现在考虑第k时刻的情况，我们希望使用过去0到时刻的数据来估计现在的状态分布：

\\\[P(x\_k|x\_0,u\_{1:k}, z\_{1:k}) \\tag{1.4} \\\]

根据**贝叶斯公式**，可以得到如下公式：

\\\[P(x\_k|x\_0,u\_{1:k}, z\_{1:k}) \\propto P(z\_k|x\_k) P(x\_k|x\_0,u\_{1:k}, z\_{1:k-1}) \\tag{1.5} \\\]

这里的第一项称为**似然**，第二项称为**先验**。似然由观测方程给定，而先验部分，\\(x\_k\\)是基于过去所有状态估计而来的。至少，它会受到\\(x\_{k-1}\\)的影响，于是我们以\\(x\_{k-1}\\)时刻为条件概率展开：

\\\[P(x\_k|x\_0,u\_{1:k}, z\_{1:k-1})= \\int P(x\_k|x\_{k-1},x\_0, u\_{1:k}, z\_{1:k-1}) P(x\_{k-1}|x\_0,u\_{1:k}, z\_{1:k-1}) dx\_{k-1} \\tag{1.6} \\\]

对于后续的操作，有很多的方法。

*   其中一种方法就是假设**马尔可夫性**。
    
    > **一阶马尔可夫性：** k时刻的状态只和k-1时刻的状态有关，而与再之前的无关。
    
    如果这样假设，我们得到的是以**扩展卡尔曼滤波**（**EKF**）为代表的滤波器方法。
    
*   另一种方法是依然考虑k时刻和**之前所有状态**的关系，此时得到的是**非线性优化**为主体的优化框架。
    

在这里，我们先了解**卡尔曼滤波**的原理和应用。

线性系统和卡尔曼滤波
----------

根据上文，我们假设了这个系统符合马尔可夫性，我们可以对公式(1.6)做出一些简化。

*   公式右侧第一部分可以简化成如下形式：
    
    \\\[P(x\_k|x\_{k-1},x\_0, u\_{1:k}, z\_{1:k-1}) = P(x\_k|x\_{k-1}, u\_{1:k}) \\tag{2.1} \\\]
    
*   公式右侧第二部分：(已知k时刻只和k-1时刻的状态相关)
    
    \\\[P(x\_{k-1}|x\_0,u\_{1:k}, z\_{1:k-1}) = P(x\_{k-1}|x\_0,u\_{1:k-1}, z\_{1:k-1}) \\tag{2.2} \\\]
    

观察上述公式，我们可以知道，我们实际上在做“**如何把k-1时刻的状态分布推导至k时刻**”这一件事请。

我们假设状态量服从高斯分布，从最简单的**线性高斯系统**开始，得到如下公式：

\\\[\\left\\lbrace \\begin{array}{l} x\_k = A\_kx\_{k-1} + u\_k + w\_k \\\\ z\_k = C\_kx\_k + v\_{k,j} \\end{array} \\right. \\qquad {k = 1,\\dots,N} \\tag{2.3} \\\]

假设所有的状态和噪声都符合高斯分布，这里的噪声可以记作：（这里省略了R和Q的下标）

\\\[w\_k \\sim N(0, R) \\quad v\_k \\sim N(0, Q) \\tag{2.4} \\\]

利用马尔可夫性，假设我们已知k-1时刻的状态，也就是k-1时刻的后验状态估计\\(\\hat{x}\_{k-1}\\)及其协方差\\(\\hat{P}\_{k-1}\\)，现在要根据k时刻的输入，确认\\(x\_k\\)的后验。

> 这里我们使用\\(\\hat{x}\_{k}\\)表示后验分布，使用\\(\\tilde{x}\_k\\)表示先验分布。

**卡尔曼滤波第一步：** 通过运动方程确认\\(x\_k\\)的先验分布。这一步是线性的，高斯分布的线性变换依然是高斯分布，所以可以得到如下公式：

\\\[P(x\_k|x\_{k-1},x\_0, u\_{1:k}, z\_{1:k-1}) = N(A\_k\\hat{x}\_{k-1} + u\_k, A\_k\\hat{P}\_{k-1}A^T\_k + R) \\tag{2.5} \\\]

> 这里协方差的推导可以参考《概率论与数理统计》的P112页，关于n维正态随机变量的协方差矩阵。

这一步称为**预测**。可以记作：

\\\[\\tilde{x}\_k = A\_k\\hat{x}\_{k-1} + u\_k, \\quad \\tilde{P}\_k = A\_k\\hat{P}\_{k-1}A^T\_k + R \\tag{2.6} \\\]

**卡尔曼滤波第二步：** 根据观测方程，我们可以计算莫格时刻应该产生怎样的观测数据：

\\\[P(z\_k| x\_k) = N(C\_kx\_k, Q) \\tag{2.7} \\\]

我们已经假设状态量符合高斯分布，根据贝叶斯公式，可以得到如下公式：

\\\[N(\\hat{x}\_k, \\hat{P}\_k) = \\eta N(C\_kx\_k, Q) \\cdot N(\\tilde{x}\_k, \\tilde{P}\_k) \\tag{2.8} \\\]

两侧都是高斯分布，我们带入高斯分布的公式，只需要保证指数部分相同，无需理会前面的因子部分。可以得到如下公式：

\\\[{(x\_k - \\hat{x}\_k)}^T {\\hat{P}^{-1}}\_k (x\_k - \\hat{x}\_k) = {(z\_k -C\_kx\_k)}^T \\hat{Q}^{-1}\_k (z\_k - C\_kx\_k) + {(x\_k - \\tilde{x}\_k)^T} {\\tilde{P}^{-1}\_{k}} (x\_k - \\tilde{x}\_k) \\tag{2.9} \\\]

我们需要根据上述这个公式推导出\\(\\hat{x}\_k\\)和\\(\\hat{P}\_k\\)。

这里是通过系数相等进行了化简，我在这里简写一下：

\\\[\\left\\lbrace \\begin{array}{l} \\hat{P}^{-1}\_k = C^T\_kQ^{-1}C\_k + \\tilde{P}^{-1}\_k \\\\ \\\\ -2\\hat{x}^T\_k\\hat{P}^{-1}\_kx\_k = -2z^T\_k Q^{-1}C\_kx\_k - 2\\tilde{x}^T\_k\\tilde{P}^{-1}\_kx\_k \\end{array} \\right. \\tag{2.10} \\\]

我们记作\\(K = \\hat{P}\_kC^T\_kQ^{-1}\\)得到如下公式：

\\\[\\left\\lbrace \\begin{array}{l} \\hat{P}\_k =(I - KC\_k) \\tilde{P}\_k \\\\ \\\\ \\hat{x}\_k = \\tilde{x}\_k + K(z\_k - C\_k \\hat{x}\_k) \\end{array} \\right. \\tag{2.11} \\\]

这个部称为**更新**。

总结kalmanFilter的用法
-----------------

1.  预测
    
    \\\[\\tilde{x}\_k = A\_k\\hat{x}\_{k-1} + u\_k, \\quad \\tilde{P}\_k = A\_k\\hat{P}\_{k-1}A^T\_k + R \\tag{2.12} \\\]
    
2.  更新：先计算K（卡尔曼增益）， 然后更新后验概率的分布。
    
    \\\[\\begin{array}{l} K = \\hat{P}\_kC^T\_k(C\_k\\tilde{P}\_kC^T\_k + Q\_k)^{-1} \\\\ \\\\ \\hat{P}\_k =(I - KC\_k) \\tilde{P}\_k \\\\ \\\\ \\hat{x}\_k = \\tilde{x}\_k + K(z\_k - C\_k \\hat{x}\_k) \\end{array} \\tag{2.13} \\\]
    

本文来自博客园，作者：[qi-xmu](https://www.cnblogs.com/qi-xmu/)，转载请注明原文链接：[https://www.cnblogs.com/qi-xmu/p/16857417.html](https://www.cnblogs.com/qi-xmu/p/16857417.html)