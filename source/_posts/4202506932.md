---
layout: post
title: "Hadoop-全分布式配置"
date: "2022-03-26T03:22:51.340Z"
---
Hadoop-全分布式配置
=============

目录

*   [一、配置基础环境](#一配置基础环境)
    *   [1、配置网络信息](#1配置网络信息)
    *   [2、配置主机名](#2配置主机名)
    *   [3、主机名与IP的映射关系](#3主机名与ip的映射关系)
    *   [4、测试互通性](#4测试互通性)
*   [二、关闭防火墙和SELinux](#二关闭防火墙和selinux)
    *   [1、关闭防火墙](#1关闭防火墙)
    *   [2、关闭SELinux](#2关闭selinux)
*   [三、安装 Hadoop](#三安装-hadoop)
    *   [1、解压hadoop和jdk安装包](#1解压hadoop和jdk安装包)
    *   [2、重命名为hadoop和jdk](#2重命名为hadoop和jdk)
    *   [3、配置Hadoop环境变量](#3配置hadoop环境变量)
    *   [4、使环境变量生效](#4使环境变量生效)
    *   [5、修改hadoop-env.sh配置文件](#5修改hadoop-envsh配置文件)
*   [四、配置hdfs-site.xml文件](#四配置hdfs-sitexml文件)
    *   [hdfs-site.xml配置文件主要参数](#hdfs-sitexml配置文件主要参数)
*   [五、配置core-site.xml文件](#五配置core-sitexml文件)
    *   [core-site.xml配置文件主要参数](#core-sitexml配置文件主要参数)
*   [六、配置mapred-site.xml文件](#六配置mapred-sitexml文件)
    *   [mapred-site.xml配置文件主要参数](#mapred-sitexml配置文件主要参数)
*   [七、配置yarn-site.xml文件](#七配置yarn-sitexml文件)
    *   [yarn-site.xml配置文件主要参数](#yarn-sitexml配置文件主要参数)
*   [八、Hadoop其他相关配置](#八hadoop其他相关配置)
    *   [1、配置masters和slaves文件](#1配置masters和slaves文件)
    *   [2、创建Hadoop用户](#2创建hadoop用户)
    *   [3、修改目录权限](#3修改目录权限)
    *   [4、配置免密登录slave节点](#4配置免密登录slave节点)
    *   [5、将配置文件复制到slave节点](#5将配置文件复制到slave节点)
    *   [6、slave节点的配置](#6slave节点的配置)

一、配置基础环境
========

需要用到三台主机，一台做master节点，两台做slave节点。三个节点分别配置网络、主机名、及主机名与IP的映射关系

1、配置网络信息
--------

master\_wzg节点的IP为192.168.100.10  
slave1\_wzg节点的IP为192.168.100.20  
slave2\_wzg节点的IP为192.168.100.30

以master\_wzg节点为例**（在所有节点上执行）**

    [root@localhost ~]# vi /etc/sysconfig/network-scripts/ifcfg-ens33 
    TYPE=Ethernet
    BOOTPROTO=static
    DEFROUTE=yes
    PEERDNS=yes
    PEERROUTES=yes
    IPV4_FAILURE_FATAL=no
    IPV6INIT=yes
    IPV6_AUTOCONF=yes
    IPV6_DEFROUTE=yes
    IPV6_PEERDNS=yes
    IPV6_PEERROUTES=yes
    IPV6_FAILURE_FATAL=no
    IPV6_ADDR_GEN_MODE=stable-privacy
    NAME=ens33
    UUID=da1a701d-8cee-4e1d-9423-56280232e595
    DEVICE=ens33
    ONBOOT=yes
    IPADDR=192.168.100.10
    PREFIX=24
    GATEWAY=192.168.100.2
    DNS1=114.114.114.114
    
    [root@localhost ~]# systemctl restart network
    [root@localhost ~]# ip a
    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
        inet 127.0.0.1/8 scope host lo
           valid_lft forever preferred_lft forever
        inet6 ::1/128 scope host 
           valid_lft forever preferred_lft forever
    2: ens33: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000
        link/ether 00:0c:29:af:2f:d2 brd ff:ff:ff:ff:ff:ff
        inet 192.168.100.10/24 brd 192.168.100.255 scope global ens33
           valid_lft forever preferred_lft forever
        inet6 fe80::9ef7:e697:cc63:418b/64 scope link 
           valid_lft forever preferred_lft forever
    

2、配置主机名
-------

以master\_wzg节点为例**（在所有节点上执行）**

    [root@localhost ~]# hostnamectl set-hostname master_wzg.example.com
    [root@localhost ~]# bash
    [root@master_wzg ~]# hostname
    master_wzg.example.com
    

3、主机名与IP的映射关系
-------------

以master\_wzg节点为例**（在所有节点上执行）**

    [root@master_wzg ~]# vi /etc/hosts
    127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
    ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
    192.168.100.10  master_wzg  master_wzg.example.com
    192.168.100.20  slave1_wzg  slave1_wzg.example.com
    192.168.100.30  slave2_wzg  slave2_wzg.example.com
    

4、测试互通性
-------

以master\_wzg节点为例**（在所有节点上执行）**

    [root@master_wzg ~]# ping master_wzg
    PING master_wzg (192.168.100.10) 56(84) bytes of data.
    64 bytes from master_wzg (192.168.100.10): icmp_seq=1 ttl=64 time=0.031 ms
    64 bytes from master_wzg (192.168.100.10): icmp_seq=2 ttl=64 time=0.017 ms
    ^C
    --- master_wzg ping statistics ---
    2 packets transmitted, 2 received, 0% packet loss, time 1000ms
    rtt min/avg/max/mdev = 0.017/0.024/0.031/0.007 ms
    
    [root@master_wzg ~]# ping slave1_wzg
    PING slave1_wzg (192.168.100.20) 56(84) bytes of data.
    64 bytes from slave1_wzg (192.168.100.20): icmp_seq=1 ttl=64 time=0.207 ms
    64 bytes from slave1_wzg (192.168.100.20): icmp_seq=2 ttl=64 time=0.394 ms
    ^C
    --- slave1_wzg ping statistics ---
    2 packets transmitted, 2 received, 0% packet loss, time 1000ms
    rtt min/avg/max/mdev = 0.207/0.300/0.394/0.095 ms
    
    [root@master_wzg ~]# ping slave2_wzg
    PING slave2_wzg (192.168.100.30) 56(84) bytes of data.
    64 bytes from slave2_wzg (192.168.100.30): icmp_seq=1 ttl=64 time=0.342 ms
    64 bytes from slave2_wzg (192.168.100.30): icmp_seq=2 ttl=64 time=0.464 ms
    ^C
    --- slave2_wzg ping statistics ---
    2 packets transmitted, 2 received, 0% packet loss, time 999ms
    rtt min/avg/max/mdev = 0.342/0.403/0.464/0.061 ms
    

二、关闭防火墙和SELinux
===============

以master\_wzg节点为例**（在所有节点上执行）**

1、关闭防火墙
-------

    [root@master_wzg ~]# systemctl stop firewalld
    [root@master_wzg ~]# systemctl enabled firewalld
    

2、关闭SELinux
-----------

    [root@master_wzg ~]# setenforce 0
    [root@master_wzg ~]# vi /etc/selinux/config
    SELINUX=disabled
    

三、安装 Hadoop
===========

首先连接SecureCRT，传输压缩包jdk-8u152-linux-x64.tar.gz和hadoop-2.7.1.tar.gz到/root目录下

**（以下5步只在master\_wzg节点上执行）**

1、解压hadoop和jdk安装包
-----------------

需要解压hadoop和jdk安装包到/usr/local/src/目录下

    [root@master_wzg ~]# tar -zxf hadoop-2.7.1.tar.gz -C /usr/local/src/
    [root@master_wzg ~]# tar -zxf jdk-8u152-linux-x64.tar.gz -C /usr/local/src/         
    [root@master_wzg ~]# cd /usr/local/src/
    [root@master_wzg src]# ls
    hadoop-2.7.1  jdk1.8.0_152
    

2、重命名为hadoop和jdk
----------------

    [root@master_wzg src]# mv hadoop-2.7.1/ hadoop
    [root@master_wzg src]# mv jdk1.8.0_152/ jdk
    [root@master_wzg src]# ls
    hadoop  jdk
    

3、配置Hadoop环境变量
--------------

因为每个节点的配置信息可能不一样，所以我们可以自己创建一个文件，方便后面复制到slave节点

    [root@master_wzg ~]# vi /etc/profile.d/hadoop.sh
    export JAVA_HOME=/usr/local/src/jdk
    export HADOOP_HOME=/usr/local/src/hadoop
    export PATH=${JAVA_HOME}/bin:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:$PATH
    

4、使环境变量生效
---------

    [root@master_wzg ~]# source /etc/profile.d/hadoop.sh 
    [root@master_wzg ~]# echo $PATH
    /usr/local/src/jdk/bin:/usr/local/src/hadoop/bin:/usr/local/src/hadoop/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
    

看到jdk/bin:，hadoop/bin:，hadoop/sbin:，就说明环境变量地址配置正确了

5、修改hadoop-env.sh配置文件
---------------------

将JAVA\_HOME环境变量地址修改为/usr/local/src/jdk

    [root@master_wzg ~]# vi /usr/local/src/hadoop/etc/hadoop/hadoop-env.sh 
    将
    export JAVA_HOME=${JAVA_HOME}
    改为：
    export JAVA_HOME=/usr/local/src/jdk
    

四、配置hdfs-site.xml文件
===================

对于 Hadoop 的分布式文件系统 HDFS 而言，一般都是采用冗余存储，冗余因子通常为 3，也就是说，一份数据保存三份副本，实验环境下可以设置为2。

hdfs-site.xml配置文件主要参数
---------------------

参数名

默认值

参数解释

dfs.namenode.secondary.http-address

0.0.0.0:50090

定义 HDFS 对应的 HTTP 服务器地址和端口

dfs.namenode.name.dir

file://${hadoop.tmp.dir}/dfs/name

定义 DFS 的名称节点在本地文件系统的位置

dfs.datanode.data.dir

file://${hadoop.tmp.dir}/dfs/data

定义 DFS 数据节点存储数据块时存储在本地文件系统的位置

dfs.replication

3

缺省的块复制数量

dfs.webhdfs.enabled

true

是否通过 http 协议读取 hdfs 文件， 如果选是，则集群安全性较差

**（只在master\_wzg节点执行）**

    [root@master_wzg ~]# vi /usr/local/src/hadoop/etc/hadoop/hdfs-site.xml 
    <configuration>
            <property>
                    <name>dfs.namenode.name.dir</name>
                    <value>file:/usr/local/src/hadoop/dfs/name</value>
            </property>
            <property>
                    <name>dfs.datanode.data.dir</name>
                    <value>file:/usr/local/src/hadoop/dfs/data</value>
            </property>
            <property>
                    <name>dfs.replication</name>
                    <value>2</value>
            </property>
    </configuration>
    
    # 创建路径中的文件夹
    [root@master_wzg ~]# mkdir -p /usr/local/src/hadoop/dfs/{name,data}
    

五、配置core-site.xml文件
===================

如没有配置 hadoop.tmp.dir 参数，此时系统默认的临时目录为：/tmp/hadoop-hadoop。 该目录在每次 Linux 系统重启后会被删除，必须重新执行 Hadoop 文件系统格式化命令，否则 Hadoop 运行会出错。

core-site.xml配置文件主要参数
---------------------

参数名

默认值

参数解释

fs.defaultFS

file:///

文件系统主机和端口

io.file.buffer.size

4096

流文件的缓冲区大小

hadoop.tmp.dir

/tmp/hadoop-${user.name}

临时文件夹

**（只在master\_wzg节点执行）**

    [root@master_wzg ~]# vi /usr/local/src/hadoop/etc/hadoop/core-site.xml
    <configuration>
    	<property>
    		<name>fs.defaultFS</name>
    		<value>hdfs://master_wzg:9000</value>
    	</property>
    	<property>
    		<name>io.file.buffer.size</name>
    		<value>131072</value>
    	</property>
    	<property>
    		<name>hadoop.tmp.dir</name>
    		<value>file:/usr/local/src/hadoop/tmp</value>
    	</property>
    </configuration>
    
    # 创建路径中的文件夹
    [root@master_wzg ~]# mkdir -p /usr/local/src/hadoop/tmp
    

六、配置mapred-site.xml文件
=====================

> Hadoop 提供了一种机制，管理员可以通过该机制配置 NodeManager 定期运行管理员提供的脚本，以确定节点是否健康。

> 管理员可以通过在脚本中执行他们选择的任何检查来确定节点是否处于健康状态。如果脚本检测到节点处于不健康状态，则必须打印以字符串 ERROR 开始的一行信息到标准输出。NodeManager 定期生成脚本并检查该脚本的输出。如果脚本的输出包含如上所述的字符串 ERROR，就报告该节点的状态为不健康的，且由 NodeManager 将该节点列入黑名单，没有进一步的任务分配给这个节点。但是，NodeManager 继续运行脚本，如果该节点再次变得正常， 该节点就会从 ResourceManager 黑名单节点中自动删除。节点的健康状况随着脚本输出，如果节点有故障，管理员可用 ResourceManager Web 界面报告，节点健康的时间也在 Web 界面上显示。

**注意：**默认是没有mapred-site.xml文件的，需要将mapred-site.xml.template复制一份命名为 mapred-site.xml

mapred-site.xml配置文件主要参数
-----------------------

参数名

默认值

参数解

mapreduce.framework.name

local

取值local、classic或 yarn 其中之一，如果不是yarn，则不会使用 YARN 集群来实现资源的分配

mapreduce.jobhistory.address

0.0.0.0:10020

定义历史服务器的地址和端口，通过历史服务器查看已经运行完的Mapreduce作业记录

mapreduce.jobhistory.webapp.addres

0.0.0.0:19888

定义历史服务器 web 应用访问的地址和端口

**（只在master\_wzg节点执行）**

    [root@master_wzg ~]# cd /usr/local/src/hadoop/etc/hadoop/
    [root@master_wzg hadoop]# cp mapred-site.xml.template mapred-site.xml
    [root@master_wzg hadoop]# ls
    capacity-scheduler.xml      httpfs-env.sh            mapred-env.sh
    configuration.xsl           httpfs-log4j.properties  mapred-queues.xml.template
    container-executor.cfg      httpfs-signature.secret  mapred-site.xml
    core-site.xml               httpfs-site.xml          mapred-site.xml.template
    hadoop-env.cmd              kms-acls.xml             slaves
    hadoop-env.sh               kms-env.sh               ssl-client.xml.example
    hadoop-metrics2.properties  kms-log4j.properties     ssl-server.xml.example
    hadoop-metrics.properties   kms-site.xml             yarn-env.cmd
    hadoop-policy.xml           log4j.properties         yarn-env.sh
    hdfs-site.xml               mapred-env.cmd           yarn-site.xml
    [root@master_wzg hadoop]# vi /usr/local/src/hadoop/etc/hadoop/mapred-site.xml
    <configuration>
    	<property>
    		<name>mapreduce.framework.name</name>
    		<value>yarn</value>
    	</property>
    	<property>
    		<name>mapreduce.jobhistory.address</name>
    		<value>master_wzg:10020</value>
    	</property>
    	<property>
    		<name>mapreduce.jobhistory.webapp.address</name>
    		<value>master_wzg:19888</value>
    	</property>
    </configuration>
    

七、配置yarn-site.xml文件
===================

> yarn-site.xml文件参数中很多参数没有专门配置，多数情况下使用默认值。例如，可以追加以下两个参数配置项 yarn.resourcemanager.hostname( 即 资 源 管 理 器 主 机 ) 和 “yarn.nodemanager.aux-services”（即 YARN 节点管理器辅助服务），若要将主节点也作为资源管理主机配置，则配置值分别为“Master\_hadoop”、“mapreduce\_shuffle”。

> 在 yarn-site.xml 中可以配置相关参数来控制节点的健康监测脚本。如果只有一些本地磁盘出现故障，健康检查脚本不应该产生错误。NodeManager 有能力定期检查本地磁盘的 健康状况（特别是检查 NodeManager 本地目录和 NodeManager 日志目录），并且在达到基于 “yarn.nodemanager.disk-health-checker.min-healthy-disks”属性的值设置的坏目录数量阈值之后，整个节点标记为不健康，并且这个信息也发送到资源管理器。无论是引导磁盘受到攻击，还是引导磁盘故障，都会在健康检查脚本中标识。

yarn-site.xml配置文件主要参数
---------------------

参数名

默认值

参数解释

yarn.resourcemanager.address

0.0.0.0:8032

ResourceManager提供给客户端访问的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等

yarn.resourcemanager.scheduler.address

0.0.0.0:8030

定义调度器的地址和端口，通过历史服务器查看已经运行完的Mapreduce作业记录

yarn.resourcemanager.resource-tracker.address

0.0.0.0:8031

ResourceManager提供给NodeManager的地址.NodeManager通过该地址向RM汇报心跳，领取任务等

yarn.resourcemanager.admin.address

0.0.0.0:8033

ResourceManager提供给管理员的访问地址。管理员通过该地址向RM发送管理命令等

yarn.resourcemanager.webapp.address

0.0.0.0:8088

ResourceManager对 web 服务提供地址。用户可通过该地址在浏览器中查看集群各类信息

yarn.nodemanager.aux-services

org.apache.hadoop.mapred.ShuffleHandler

通过该配置项，用户可以自定义一些服务，例如Map-Reduce的shuffle功能就是采用这种方式实现的，这样就可以在NodeManager上扩展自己的服务。

**（只在master\_wzg节点执行）**

    [root@master_wzg hadoop]# vi /usr/local/src/hadoop/etc/hadoop/yarn-site.xml
    <configuration>
    	<property>
    		<name>yarn.resourcemanager.address</name>
    		<value>master_wzg:8032</value>
    	</property>
    	<property>
    		<name>yarn.resourcemanager.scheduler.address</name>
    		<value>master_wzg:8030</value>
    	</property>
    	<property>
    		<name>yarn.resourcemanager.resource-tracker.address</name>
    		<value>master_wzg:8031</value>
    	</property>
    	<property>
    		<name>yarn.resourcemanager.admin.address</name>
    		<value>master_wzg:8033</value>
    	</property>
    	<property>
    		<name>yarn.resourcemanager.webapp.address</name>
    		<value>master_wzg:8088</value>
    	</property>
    	<property>
    		<name>yarn.nodemanager.aux-services</name>
    		<value>mapreduce_shuffle</value>
    	</property>
    	<property>
    		<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
    		<value>org.apache.hadoop.mapred.ShuffleHandler</value>
    	</property>
    </configuration>
    

八、Hadoop其他相关配置
==============

1、配置masters和slaves文件
--------------------

> slaves 文件默认为 localhost（即把本机作为数据节点），在伪分布式配置时，就采用了这种默认的配置，使得节点既作为名称节点也作为数据节点。在进行分布式配置时，可以保留 localhost，让 Master 节点同时充当名称节点和数据节点，或者也可以删掉 localhost 这行，让 Master 节点仅作为名称节点使用。本实验 Master 节点仅作为名称节点使用，因此将 slaves 文件中原来的 localhost 删除，并添加 slave1、slave2 节点的 IP 地址。

**注意：**默认是没有masters和slaves文件的，并且 slaves 文件中默认有 localhost

**（在master\_wzg节点执行）**

    [root@master_wzg hadoop]# vi /usr/local/src/hadoop/etc/hadoop/masters
    192.168.100.10
    [root@master_wzg hadoop]# vi /usr/local/src/hadoop/etc/hadoop/slaves
    192.168.100.20
    192.168.100.30
    

2、创建Hadoop用户
------------

**（在master\_wzg节点执行）**

    [root@master_wzg hadoop]# useradd hadoop
    [root@master_wzg hadoop]# echo 'hadoop' | passwd --stdin hadoop
    Changing password for user hadoop.
    passwd: all authentication tokens updated successfully.
    

3、修改目录权限
--------

修改/usr/local/src/目录的权限，使这个目录的所属用户和所属组为hadoop

**（在master\_wzg节点执行）**

    [root@master_wzg hadoop]# chown -R hadoop.hadoop /usr/local/src/
    [root@master_wzg hadoop]# ll /usr/local/src/
    total 0
    drwxr-xr-x. 11 hadoop hadoop 171 Mar 25 16:33 hadoop
    drwxr-xr-x.  8 hadoop hadoop 255 Sep 14  2017 jdk
    

4、配置免密登录slave节点
---------------

**（在master\_wzg节点执行）**

    [root@master_wzg hadoop]# ssh-keygen -t rsa
    [root@master_wzg hadoop]# ssh-copy-id root@slave1_wzg
    [root@master_wzg hadoop]# ssh-copy-id root@slave2_wzg
    

5、将配置文件复制到slave节点
-----------------

**（在master\_wzg节点执行）**

    #将/usr/local/src下的所有文件复制到slave节点
    [root@master_wzg hadoop]# scp -r /usr/local/src/* root@slave1_wzg:/usr/local/src/
    ……
    [root@master_wzg hadoop]# scp -r /usr/local/src/* root@slave2_wzg:/usr/local/src/
    ……
    
    #将环境变量的配置文件复制到slave节点
    [root@master_wzg hadoop]# scp /etc/profile.d/hadoop.sh  root@slave1_wzg:/etc/profile.d/
    hadoop.sh                                             100%  151     0.2KB/s   00:00    
    [root@master_wzg hadoop]# scp /etc/profile.d/hadoop.sh  root@slave2_wzg:/etc/profile.d/
    hadoop.sh                                             100%  151     0.2KB/s   00:00    
    
    

6、slave节点的配置
------------

**（在slave1\_wzg节点执行）**

    1、创建Hadoop用户
    [root@slave1_wzg ~]# useradd hadoop
    [root@slave1_wzg ~]# echo 'hadoop' | passwd --stdin hadoop
    Changing password for user hadoop.
    passwd: all authentication tokens updated successfully.
    
    2、修改/usr/local/src/目录的权限
    [root@slave1_wzg ~]# chown -R hadoop.hadoop /usr/local/src/
    [root@slave1_wzg ~]# ll /usr/local/src/
    total 0
    drwxr-xr-x. 11 hadoop hadoop 171 Mar 25 17:32 hadoop
    drwxr-xr-x.  8 hadoop hadoop 255 Mar 25 17:32 jdk
    
    # 3、使配置的Hadoop的环境变量生效
    [root@slave1_wzg ~]# source /etc/profile.d/hadoop.sh 
    [root@slave1_wzg ~]# echo $PATH
    /usr/local/src/jdk/bin:/usr/local/src/hadoop/bin:/usr/local/src/hadoop/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
    

**（在slave2\_wzg节点执行）**

    1、创建Hadoop用户
    [root@slave2_wzg ~]# useradd hadoop
    [root@slave2_wzg ~]# echo 'hadoop' | passwd --stdin hadoop
    更改用户 hadoop 的密码 。
    passwd：所有的身份验证令牌已经成功更新。
    
    2、修改/usr/local/src/目录的权限
    [root@slave2_wzg ~]# chown -R hadoop.hadoop /usr/local/src/
    [root@slave2_wzg ~]# ll /usr/local/src/
    总用量 0
    drwxr-xr-x. 11 hadoop hadoop 171 3月  25 17:33 hadoop
    drwxr-xr-x.  8 hadoop hadoop 255 3月  25 17:33 jdk
    
    # 3、使配置的Hadoop的环境变量生效
    [root@slave2_wzg ~]# source /etc/profile.d/hadoop.sh
    [root@slave2_wzg ~]# echo $PATH
    /usr/local/src/jdk/bin:/usr/local/src/hadoop/bin:/usr/local/src/hadoop/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
    

**声明：未经许可，禁止转载**