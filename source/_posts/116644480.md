---
layout: post
title: "Apache Ranger安装部署"
date: "2022-03-27T07:16:39.464Z"
---
Apache Ranger安装部署
=================

1.概述
====

Apache Ranger提供了一个集中式的安全管理框架，用户可以通过操作Ranger Admin页面来配置各种策略，从而实现对Hadoop生成组件，比如HDFS、YARN、Hive、HBase、Kafka等进行细粒度的数据访问控制。本篇博客，笔者将为大家介绍如何Apache Ranger的安装部署、以及使用。

2.内容
====

Apache Ranger提供以下核心功能，它们分别是：

*   通过统一的中心化管理界面或者REST接口来管理所有安全任务，从而实现集中化的安全管理；
*   通过统一的中心化管理界面，对Hadoop生态圈组件或者工具的操作进行更加细粒度级别的控制；
*   提供了统一的、标准化的授权方式；
*   支持基于角色的访问控制，基于属性的访问控制等多种访问控制手段；
*   支持对用户访问和管理操作的集中审计。

2.1 架构
------

Ranger的主要由以下几个核心模块组成，它们分别是：

*   Ranger Admin：该模块是Ranger的核心，它内置了一个Web管理界面，用户可以通过这个Web管理界面或者REST接口来制定安全策略；
*   Agent Plugin：该模块是嵌入到Hadoop生态圈组件的插件，它定期从Ranger Admin拉取策略并执行，同时记录操作以供审计使用；
*   User Sync：该模块是将操作系统用户/组的权限数据同步到Ranger数据库中。

它们之间的流程关系，如下图所示：

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327133230557-821529661.png)

 2.2 工作流程
---------

Ranger Admin是Apache Ranger和用户交互的主要界面，用户登录Ranger Admin时，可以针对不同的Hadoop组件定制不同的安全策略，当策略制定并保存后，Agent Plugin会定期从Ranger Admin拉取该组件配置的所有策略，并缓存到本地。

这样，当有用户来请求Hadoop组件的数据服务时，Agent Plugin就提供鉴权服务，并将鉴权结果反馈给相应的组件，从而实现了数据服务的权限控制功能。当用户在Ranger Admin中修改了配置策略后，Agent Plugin会拉取新策略并更新，如果用户在Ranger Admin中删除了配置策略，那么Agent Plugin的鉴权服务也无法继续使用。

以Hive为例子，具体流程如下所示：

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327133733719-52995634.png)

3.安装部署
======

3.1 基础环境准备
----------

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327133953409-1597239532.png)

 3.2 下载源代码
----------

下载源代码地址渠道，如下所示：

*   官网：https://ranger.apache.org/download.html
*   Github：https://github.com/apache/ranger

3.3 编译源代码
---------

Apache Ranger源代码使用Java语言开发，编译时需要使用Java环境，这里我们使用Maven命令来进行编译。Apache Ranger存储数据库支持MySQL数据库，我们直接使用MySQL数据库来作为Apache Ranger系统的存储数据库即可。

\# 使用Maven命令编译
mvn \-DskipTests=true clean package

编译成功后，会出现如下所示的截图：

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327134356885-1977050540.png)

3.4 安装Ranger Admin
------------------

编辑install.properties文件，具体内容如下所示：

\# 指明使用数据库类型
DB\_FLAVOR\=MYSQL 
# 数据库连接驱动
SQL\_CONNECTOR\_JAR\=/appcom/ranger-admin/jars/mysql-connector-java-5.1.32\-bin.jar
# 数据库root用户名
db\_root\_user\=root
# 数据库密码
db\_root\_password\=Hive123@
# 数据库主机
db\_host\=nns:3306 

# 以下三个属性是用于设置ranger数据库的
#数据库名
db\_name\=ranger
# 管理该数据库用户        
db\_user\=root
# 管理该数据库密码
db\_password\=Hive123@

# 不需要保存，为空，否则生成的数据库密码为'\_'
cred\_keystore\_filename\=

# 审计日志，如果没有安装solr，对应的属性值为空即可
audit\_store\=

audit\_solr\_urls\=
audit\_solr\_user\=
audit\_solr\_password\=
audit\_solr\_zookeepers\=

# 策略管理配置，配置ip和端口，默认即可
policymgr\_external\_url\=http://nna:6080
# 配置hadoop集群的core\-site.xml文件，把core-site.xml文件拷贝到该目录
hadoop\_conf\=/data/soft/new/hadoop-conf

# rangerAdmin、rangerTagSync、rangerUsersync、keyadmin密码配置。
# 默认为空，可以不配，对应的内部组件该属性也要为空
rangerAdmin\_password\=ranger123
rangerTagsync\_password\=ranger123
rangerUsersync\_password\=ranger123
keyadmin\_password\=ranger123

执行setup.sh脚本命令后，如果成功，会出现如图所示的结果：

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327134540555-638219834.png)

然后，执行set\_globals.sh脚本命令，会出现如下所示的结果。

\[root@nna ranger-admin\]# ./set\_globals.sh 
usermod: no changes
\[2022/03/26 21:45:26\]:  \[I\] Soft linking /etc/ranger/admin/conf 
to ews/webapp/WEB-INF/classes/conf
\[root@nna ranger\-admin\]#

然后，在登录界面输入“admin/ranger123”，成功进入主界面，如下图所示：

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327134723385-2031737686.png)

 3.5 安装ranger-usersync
----------------------

编辑install.properties文件，具体内容如下所示：

\# 配置ranger admin的地址
POLICY\_MGR\_URL \= http://nna:6080
# 同步源系统类型
SYNC\_SOURCE \= unix

# 同步间隔时间，1分钟
SYNC\_INTERVAL \= 1

# usersync程序运行的用户和用户组
unix\_user\=ranger
unix\_group\=ranger

# 修改rangerusersync用户的密码。注意，此密码应与ranger\-admin中
# install.properties的rangerusersync\_password相同。
# 此处可以为空，同样ranger\-admin的也要为空
rangerUsersync\_password\=ranger123

# 配置hadoop的core\-site.xml路径
hadoop\_conf\=/data/soft/new/hadoop-config

# 配置usersync的log路径
logdir\=logs

执行setup.sh脚本命令后，如果成功，会出现如图所示的结果：

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327134845066-127074204.png)

 在Ranger Admin管理界面，出现如下所示的截图，表名安装成功。

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327134955471-947127869.png)

4.配置Hive插件
==========

4.1 启动插件
--------

编辑install.properties文件，具体内容如下所示：

\# 配置ranger admin的地址
POLICY\_MGR\_URL \= http://nna:6080
# 配置hive的仓库名
REPOSITORY\_NAME\=hive-ranger

# 配置hive组件的HIVE\_HOME
COMPONENT\_INSTALL\_DIR\_NAME\=/data/soft/new/hive

# 配置ranger\-hive-plugin的所属用户、用户组
CUSTOM\_USER\=hadoop
CUSTOM\_GROUP\=hadoop

执行enable-hive-plugin.sh脚本命令，使HDFS插件生效。结果如下图所示：

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327135914490-1845935387.png)

4.2 创建新用户
---------

在一台Hadoop的Client节点上创建一个新用户（hduser1024），具体操作命令如下所示：

\# 新增一个用户
\[hadoop@nna ~\]$ adduser hduser1024
# 将新增的用户添加到已有的hadoop组中
\[hadoop@nna ~\]$ usermod -a -G hadoop hduser1024
# 复制hadoop用户下的环境变量
\[hadoop@nna ~\]$ cp /home/hadoop/.bash\_profile /home/hduser1024/

进入Ranger Admin管理界面添加新用户，如下图所示：

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327135320628-330715182.png)

4.3 配置Hive策略
------------

 在Ranger Admin中选择Hive策略模块，配置内容如下图所示：

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327135406383-823700391.png)

 这里策略名称、用户名和密码可以任意填写，JDBC驱动类和URL地址填写内容如下所示：

\# 驱动类
org.apache.hive.jdbc.HiveDriver

# URL地址，使用Zookeeper模式连接方式
jdbc:hive2://dn1:2181,dn2:2181,dn3:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2

接着，进入到具体的数据库、表以及列的权限设置页面，如下图所示：

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327135452956-177348522.png)

4.4 Hive表权限验证
-------------

设置数据库game\_user\_db，选择表user\_visit\_pv，然后指定该表下的所有列（使用\*号）授予hduser1024用户拥有查询权限（select）。接着，我们可以在Hive的客户端中执行查询语句验证权限：

\# 进入到Hive客户端，并切换到指定数据库
hive\> use game\_user\_db;
# 查询表内容
hive\> select \* from user\_visit\_pv limit 2;

结果如下所示：

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327135618086-40167459.png)

 然后，我们进入到Hive策略中，修改只授予hduser1024用户读取uid字段的权限：

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327135637721-1028563792.png)

 接着，我们可以在Hive的客户端中执行查询语句验证权限：

\# 进入到Hive客户端，并切换到指定数据库
hive\> use game\_user\_db;
# 查询表内容
hive\> select uid from user\_visit\_pv limit 2;
hive\> select uid,pv from user\_visit\_pv limit 2;

结果如下图所示：

![](https://img2022.cnblogs.com/blog/666745/202203/666745-20220327135722010-1033414032.png)

 可以看到hduser1024用户只拥有读取uid字段的权限，读取pv字段则会抛出权限异常的错误。

5.总结
====

综合考虑，Apache Ranger能够很好的和现有系统集成，比如：

*   支持多组件，比如HDFS、Hive、Kafka等，基本能覆盖现有大数据组件；
*   支持日志审计，便于问题排查；
*   用于自己的用户管理体系，方便和其他系统集成。

6.结束语
=====

这篇博客就和大家分享到这里，如果大家在研究学习的过程当中有什么问题，可以加群进行讨论或发送邮件给我，我会尽我所能为您解答，与君共勉！

另外，博主出书了《[Kafka并不难学](https://item.jd.com/12455361.html)》和《[Hadoop大数据挖掘从入门到进阶实战](https://item.jd.com/12371763.html)》，喜欢的朋友或同学， 可以在公告栏那里点击购买链接购买博主的书进行学习，在此感谢大家的支持。关注下面公众号，根据提示，可免费获取书籍的教学视频。

联系方式：  
邮箱：smartloli.org@gmail.com  
Twitter：[https://twitter.com/smartloli](https://twitter.com/smartloli)  
QQ群（Hadoop - 交流社区1）：[424769183](http://shang.qq.com/wpa/qunwpa?idkey=b07c12828ed6963fe79078c78bbd1aba7e61b8f5d8fc5ee4ed26809f40b35c37)  
QQ群（Kafka并不难学）： [825943084](http://shang.qq.com/wpa/qunwpa?idkey=788249d47071a1f6c45233f50ecfd33c629c6a40d74a1254442c0fcdc6afa7a2)  
温馨提示：请大家加群的时候写上加群理由（姓名＋公司/学校），方便管理员审核，谢谢！  

### 热爱生活，享受编程，与君共勉！

  

### 公众号：

### ![](https://www.cnblogs.com/images/cnblogs_com/smartloli/1324636/t_qr.png)

  

### 作者：哥不是小萝莉 ［[关于我](http://www.kafka-eagle.org/)］［[犒赏](http://www.cnblogs.com/smartloli/p/4241701.html)］

### 出处：[http://www.cnblogs.com/smartloli/](http://www.cnblogs.com/smartloli/)

### 转载请注明出处，谢谢合作！