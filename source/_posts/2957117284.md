---
layout: post
title: "论文解读（BGRL）《Large-Scale Representation Learning on Graphs via Bootstrapping》"
date: "2022-04-14T18:22:04.810Z"
---
论文解读（BGRL）《Large-Scale Representation Learning on Graphs via Bootstrapping》
===========================================================================

论文信息
====

> 论文标题：Large-Scale Representation Learning on Graphs via Bootstrapping  
> 论文作者：Shantanu Thakoor, Corentin Tallec, Mohammad Gheshlaghi Azar, Rémi Munos, Petar Veličković, Michal Valko  
> 论文来源：2021, ICLR  
> 论文地址：[download](https://arxiv.org/pdf/2102.06514v2.pdf)   
> 论文代码：[download](https://github.com/nerdslab/bgrl)

　　早先版本名字叫《Bootstrapped Representation Learning on Graphs》

1 介绍
====

　　研究目的：对比学习中不适用负样本。

　　本文贡献：

*   *   对图比学习不使用负样本

2 方法
====

2.1 整体框架（节点级对比）
---------------

　　 ![](https://img2022.cnblogs.com/blog/1664108/202204/1664108-20220414150223764-252420403.png)

　　　　上面是 online network，下面是 target network 。

　　**步骤：**

*   *   步骤一：分别应用随机图增强函数 $\\mathcal{A}\_{1}$ 和 $\\mathcal{A}\_{2}$，产生 $G$ 的两个视图：$\\mathbf{G}\_{1}=   \\left(\\widetilde{\\mathbf{X}}\_{1}, \\widetilde{\\mathbf{A}}\_{1}\\right)$ 和 $\\mathbf{G}\_{2}=\\left(\\widetilde{\\mathbf{X}}\_{2}, \\widetilde{\\mathbf{A}}\_{2}\\right) $；
    *   步骤二：在线编码器从其增广图中生成一个在线表示 $\\widetilde{\\mathbf{H}}\_{1}:=\\mathcal{E}\_{\\theta}\\left(\\widetilde{\\mathbf{X}}\_{1}, \\widetilde{\\mathbf{A}}\_{1}\\right)$；目标编码器从其增广图生成目标表示 $\\widetilde{\\mathbf{H}}\_{2}:=\\mathcal{E}\_{\\phi}\\left(\\widetilde{\\mathbf{X}}\_{2}, \\widetilde{\\mathbf{A}}\_{2}\\right) $；
    *   步骤三：在线表示被输入到一个预测器 $p\_{\\theta}$ 中，该预测器  $p\_{\\theta}$  输出对目标表示的预测  $\\widetilde{\\mathbf{Z}}\_{1}:=   p\_{\\theta}\\left(\\widetilde{\\mathbf{H}}\_{1}, \\widetilde{\\mathbf{A}}\_{1}\\right)$，除非另有说明，预测器在节点级别工作，不考虑图信息(仅在 $\\widetilde{\\mathbf{H}}\_{1}$ 上操作，而不是 $\\widetilde{\\mathbf{A}}\_{1}$)。

2.2 BGRL更新步骤
------------

**更新 $\\theta$**

　　在线参数 $\\theta$（而不是 $\\phi$），通过余弦相似度的梯度，使预测的目标表示 $\\mathbf{Z}\_{1}$ 更接近每个节点的真实目标表示 $\\widetilde{\\mathbf{H}}\_{2}$。

　　　　$\\ell(\\theta, \\phi)=-\\frac{2}{N} \\sum\\limits \_{i=0}^{N-1} {\\large \\frac{\\widetilde{\\mathbf{Z}}\_{(1, i)} \\widetilde{\\mathbf{H}}\_{(2, i)}^{\\top}}{\\left\\|\\widetilde{\\mathbf{Z}}\_{(1, i)}\\right\\|\\left\\|\\widetilde{\\mathbf{H}}\_{(2, i)}\\right\\|}} \\quad\\quad\\quad(1)$

　　$\\theta$ 的更新公式：

　　　　$\\theta \\leftarrow \\operatorname{optimize}\\left(\\theta, \\eta, \\partial\_{\\theta} \\ell(\\theta, \\phi)\\right)\\quad\\quad\\quad(2)$

　　其中 $ \\eta $ 是学习速率，最终更新仅从目标对 $\\theta$ 的梯度计算，使用优化方法如 SGD 或 Adam 等方法。在实践中，

　　我们对称了训练，也通过使用第二个视图的在线表示来预测第一个视图的目标表示。

**更新 $\\phi$**

　　目标参数 $\\phi$ 被更新为在线参数 $\\theta$ 的指数移动平均数，即：

　　　　$\\phi \\leftarrow \\tau \\phi+(1-\\tau) \\theta\\quad\\quad\\quad(3)$

　　其中 $\\tau$ 是控制 $\\phi$ 与 $ \\theta$ 的距离的衰减速率。

　　只有在线参数被更新用来减少这种损失，而目标参数遵循不同的目标函数。根据经验，与BYOL类似，BGRL不会崩溃为平凡解，而 $\\ell(\\theta, \\phi)$ 也不收敛于 $0$ 。

2.3. 完全非对比目标
------------

　　对比学习常用的负样本带来的问题是：

*   *   如何定义负样本　　
    *   随着负样本数量增多，带来的内存瓶颈；

　　本文损失函数定义的好处：

*   *   不需要对比负对 $\\{(i, j) \\mid i \\neq j\\} $ ；
    *   计算方便，只需要保证余弦相似度大就行；

2.4.图增强函数
---------

　　本文采用以下两种数据增强方法：

*   *   节点特征掩蔽（node feature masking）
    *   边缘掩蔽（edge masking）

3 实验
====

**数据集**

　　![](https://img2022.cnblogs.com/blog/1664108/202204/1664108-20220414160954289-1952690015.png)

　　数据集划分：

*   *   WikiCS： 20 canonical train/valid/test splits
    *   Amazon Computers, Amazon Photos——train/validation/test—10/10/80%
    *   Coauthor CS, Coauthor Physics——train/validation/test—10/10/80%

**直推式学习——基线实验**

　　图编码器采用 $\\text{GCN$ Encoder 。

　　![](https://img2022.cnblogs.com/blog/1664108/202204/1664108-20220414162243124-164678940.png)

****大图上的直推式**学习——基线实验**

　　结果：

　　![](https://img2022.cnblogs.com/blog/1664108/202204/1664108-20220414163425942-1751249027.png)

**归纳式学习——基线实验**

　　编码器采用 GraphSAGE-GCN （平均池化）和 GAT 。 

　　结果：

　　![](https://img2022.cnblogs.com/blog/1664108/202204/1664108-20220414163508058-1508747499.png)

4 结论
====

　　介绍了一种新的自监督图表示学习方法BGRL。通过广泛的实验，我们已经证明了我们的方法与最先进的方法具有竞争力，尽管不需要负例，并且由于不依赖于投影网络或二次节点比较而大大降低了存储需求。此外，我们的方法可以自然地扩展到学习图级嵌入，其中定义消极的例子是具有挑战性的，并且所有的目标不具有规模。

因上求缘，果上努力~~~~ 作者：[Learner-](https://www.cnblogs.com/BlairGrowing/)，转载请注明原文链接：[https://www.cnblogs.com/BlairGrowing/p/16144566.html](https://www.cnblogs.com/BlairGrowing/p/16144566.html)