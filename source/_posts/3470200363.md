---
layout: post
title: "CVPR2022 | 重新审视池化：你的感受野不是最理想的"
date: "2022-06-07T14:17:04.261Z"
---
CVPR2022 | 重新审视池化：你的感受野不是最理想的
=============================

> 前言 本文提出了一种简单而有效的动态优化池操作（ Dynamically Optimized Pooling operation），称为DynOPool，它通过学习每一层感受野的最佳大小和形状来优化特征映射的端到端比例因子。  
> 深度神经网络中任何类型的调整大小模块都可以用DynOPool操作以最小的成本替换。此外，DynOPool通过引入一个限制计算成本的附加损失项来控制模型的复杂性。

欢迎关注公众号[CV技术指南](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495585%26idx%3D2%26sn%3D5df76c5d0956cc998e9bbb21b86ca460%26chksm%3Dc19450bff6e3d9a9d72330f85cf37ffb446cbc70f3a83c492ad8214c82005605c196a875b148%26token%3D1526765687%26lang%3Dzh_CN%23rd "CV技术指南")，专注于计算机视觉的技术总结、最新技术跟踪、经典论文解读、CV招聘信息。

![](https://img-blog.csdnimg.cn/img_convert/3d181a82b61180d6e7effac0dd1c393a.png)​

论文：[https://arxiv.org/abs/2205.15254](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2205.15254 "https://arxiv.org/abs/2205.15254")

代码：未发布

背景
--

尽管深度神经网络在计算机视觉、自然语言处理、机器人、生物信息学等各种应用中取得了前所未有的成功，但最优网络结构的设计仍然是一个具有挑战性的问题。而感受野的大小和形状决定了网络如何聚集本地信息，并对模型的整体性能产生显著影响。神经网络中的许多组成部分，例如用于卷积和池化运算的内核大小和步长，都会影响感受野的配置。然而，它们仍然依赖于超参数，现有模型的感受野会导致形状和大小不理想。

本文通过介绍固定大小和形状的传统感受野是次优的问题，讨论了DynOPool如何通过CIFAR-100上的VGG-16玩具实验解决这个问题。

固定大小和形状的传统感受野存在的问题：

1.不对称分布的信息

最佳感受野形状会根据数据集中固有的空间信息不对称性而改变。而大多数情况下固有的不对称性是不可测量的。此外，通常用于预处理的输入大小调整有时也会导致信息不对称。在人工设计的网络中，图像的长宽比经常被调整以满足模型的输入规格。然而，这种网络中的感受野不是用来处理操作的。

为了验证所提出的方法，作者在CIFAR-stretch-V上进行实验，如图1（a）所示，相较于人工设计模型，形状通过DynOPool动态优化的特征映射通过在水平方向上提取更具有价值的信息提高性能。

![](https://img-blog.csdnimg.cn/img_convert/3f9b63f6f4c0c88f070031af1cd9b198.png)​

图1 用来自CIFAR-100的三个不同的合成数据集进行玩具实验:

(a)随机裁剪垂直拉伸的图像 (b)在4×4网格中平铺缩小的图像 (c)放大缩小的图像。

2.密集分布或稀疏分布信息

局部性是设计最优模型的组成部分。CNN通过级联的方式聚合局部信息来学习图像的复杂表示。而局部信息的重要性很大程度上取决于每个图像的属性。例如，当一个图像被模糊化时，大多数有意义的微观模式，如物体的纹理，都会被抹去。在这种情况下，最好在早期层中扩展感受野，集中于全局信息。另一方面，如果一幅图像在局部细节中包含大量类特定的信息，例如纹理，则识别局部信息将会更加重要。

为了验证假设，作者构建了CIFAR-100数据集的两个变体，CIFAR-tile和CIFAR-large，如图1(b)和(c)所示。作者模型在很大程度上优于人工设计的模型。

贡献
--

为了缓解人工构建的体系结构和操作的次优性，作者提出了动态优化池操作（DynOPool），这是一个可学习的调整大小模块，可以替代标准的调整大小操作。该模块为在数据集上学习的操作找到感受野的最佳比例因子，从而将网络中的中间特征图调整为适当的大小和形状。

论文的主要贡献：

1、解决了深度神经网络中现有尺度算子依赖于预定超参数的局限性。指出了在中间特征图中寻找最佳空间分辨率和感受野的重要性。

2、提出了一个可学习的调整尺寸大小的模块DynOPool，它可以找到中间特征图的最佳比例因子和感受域。DynOPool使用学习到的比例因子识别某一层的最佳分辨率和感受野，并将信息传播到后续层，从而在整个网络中实现规模优化。

3、证明了在图像分类和语义分割任务中，使用DynOPool的模型在多个数据集和网络架构上优于基线算法。它还显示了精度和计算成本之间的理想权衡。

方法
--

### 1.动态优化池(DynOPool)

![](https://img-blog.csdnimg.cn/img_convert/5da8d18dd5124a72aac65d78cb940396.png)​

图2 DynOPool中的调整大小模块

模块通过优化一对输入和输出特征映射之间的比例因子r来优化查询点q的位置以及获得中间特征映射的最佳分辨率。DynOPool在不影响其他算子的情况下，自适应控制较深层接收域的大小和形状。

![](https://img-blog.csdnimg.cn/img_convert/daf0cf63c77642c86aa5b033c1cbce4e.png)​

图3 DynOPool整个的优化过程

针对比例因子r梯度不稳定，会产生梯度爆炸导致训练过程中分辨率发生显著变化的问题，使用a重新参数化r如下：

![](https://img-blog.csdnimg.cn/img_convert/aa22d5d8adb08e8e2974edf6bc954652.png)​

### 2.模型复杂性约束

为了最大化模型的精度，DynOPool有时会有较大的比例因子，增加了中间特征图的分辨率。因此，为了约束计算代价，减少模型规模，引入了一个额外的损失项LGMACs，它由每次训练迭代t的分层GMACs计数的简单加权和给出，如下所示:

![](https://img-blog.csdnimg.cn/img_convert/4f406e3ceeade0dc275a41a84e34ffc5.png)​

实验
--

表1 人工设计模型与使用DynOPool模型的精度(%)和GMACs比较

![](https://img-blog.csdnimg.cn/img_convert/9ae0ae8d59d0813a5e85a9fa33bfa52e.png)​

图4 在VGG-16上使用人工设计的Shape Adaptor与使用DynOPool的训练模型可视化。

![](https://img-blog.csdnimg.cn/img_convert/9096160712d9e9288a2abf45496540d0.png)​

表2 在CIFAR-100数据集上DynOPool和Shape Adaptor的比较

![](https://img-blog.csdnimg.cn/img_convert/f0e53a09c6d67600ece99ff64342a774.png)​

表3 在ImageNet数据集上EfficientNet-B0+DynOPool的性能

![](https://img-blog.csdnimg.cn/img_convert/627f9068c7d6da1bcda84fbbaf97368b.png)​

表4 基于PascalVOC的HRNet-W48语义分割结果

![](https://img-blog.csdnimg.cn/img_convert/60549b120c790bf346c66092a16354bb.png)​

结论
--

作者提出了一种简单而有效的动态优化池操作（DynOPool），它通过学习每个层中感受野的理想大小和形状来优化端到端的特征映射的比例因子，调整中间特征图的大小和形状，有效提取局部细节信息，从而优化模型的整体性能；

DynOPool还通过引入一个额外的损失项来限制计算成本，从而控制模型的复杂性。实验表明，在多个数据集上，该模型在图像分类和语义分割方面均优于基线网络。

\------------------------------------------------------------------------------------

CV技术指南创建了一个计算机视觉技术交流群和免费版的知识星球，目前星球内人数已经600+，主题数量达到200+。

知识星球内将会每天发布一些作业，用于引导大家去学一些东西，大家可根据作业来持续打卡学习。

技术群内每天都会发最近几天出来的顶会论文，大家可以选择感兴趣的论文去阅读，持续follow最新技术，若是看完后写个解读给我们投稿，还可以收到稿费。

另外，技术群内和本人朋友圈内也将发布各个期刊、会议的征稿通知，若有需要的请扫描加好友，并及时关注。

加群加星球方式：关注公众号CV技术指南，获取编辑微信，邀请加入。

欢迎关注公众号[CV技术指南](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495585%26idx%3D2%26sn%3D5df76c5d0956cc998e9bbb21b86ca460%26chksm%3Dc19450bff6e3d9a9d72330f85cf37ffb446cbc70f3a83c492ad8214c82005605c196a875b148%26token%3D1526765687%26lang%3Dzh_CN%23rd "CV技术指南")，专注于计算机视觉的技术总结、最新技术跟踪、经典论文解读、CV招聘信息。

![](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d776ef156f7b49f2a01c38a8a3711ad0~tplv-k3u1fbpfcp-watermark.image?)

征稿通知：欢迎可以写以下内容的朋友[联系我](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495585%26idx%3D2%26sn%3D5df76c5d0956cc998e9bbb21b86ca460%26chksm%3Dc19450bff6e3d9a9d72330f85cf37ffb446cbc70f3a83c492ad8214c82005605c196a875b148%26token%3D1526765687%26lang%3Dzh_CN%23rd)。（扫描这个链接里的二维码）

1.  TVM入门到实践的教程
    
2.  MNN入门到实践的教程
    
3.  数字图像处理与Opencv入门到实践的教程
    
4.  OpenVINO入门到实践的教程
    
5.  libtorch入门到实践的教程
    
6.  Oneflow入门到实践的教程
    
7.  Detectron入门到实践的教程
    
8.  caffe源码阅读
    
9.  pytorch源码阅读
    
10.  深度学习从入门到精通（从卷积神经网络开始讲起）
    
11.  最新顶会的解读。例如最近的CVPR2022论文。
    
12.  各个方向的系统性综述、主要模型发展演变、各个模型的创新思路和优缺点、代码解析等。
    
13.  若自己有想写的且这上面没提到的，可以跟我联系。
    

声明：有一定报酬，具体请联系详谈。若有想法写但觉得自己能力不够，也可以先联系本人了解

其它文章
----

[计算机视觉入门路线](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247494483%26idx%3D1%26sn%3D7069ade230575cfcb1c1f8c8e8763ecb%26chksm%3Dc194544df6e3dd5bea7a98723b764c7db8591e292a775c4c465f715acc260d5d1fc53aa6487c%26payreadticket%3DHIjWViK3B_NTMPuq4Zzm_wEIyKtyvPbtyDFiQTwJsqOLFvAW28Qv38O0pcR_VdMzz15Xsb0%23rd "计算机视觉入门路线")

[CVPR2022 | 重新审视池化：你的感受野不是最理想的](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495644%26idx%3D1%26sn%3D23d4728e50f911c0eab24aa2073fd4e5%26chksm%3Dc19450c2f6e3d9d4c85eef2243bfd1896529fc8d7de377879b7147623902753a0f325a743e6f%26token%3D1526765687%26lang%3Dzh_CN%23rd "CVPR2022 | 重新审视池化：你的感受野不是最理想的")

[CVPR 2022 | 未知目标检测模块STUD：学习视频中的未知目标](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495622%26idx%3D1%26sn%3D1e57c7ccb630186219e6471b28a159ba%26chksm%3Dc19450d8f6e3d9ceee6acab0867a7decf5ea600e7f9029b2920df3c96051524ee289970d0ba3%26token%3D1526765687%26lang%3Dzh_CN%23rd "CVPR 2022 | 未知目标检测模块STUD：学习视频中的未知目标")

[CVPR2022 | 基于排名的siamese视觉跟踪](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495554%26idx%3D1%26sn%3D74c2069f4db40459f536c9748bcdf190%26chksm%3Dc194509cf6e3d98a957012a496e85701ceef49efe2383917dd6358ae56a0c7d53abd8dfbadf5%26token%3D1526765687%26lang%3Dzh_CN%23rd "CVPR2022 | 基于排名的siamese视觉跟踪")

[CVPR2022 | 通过目标感知Transformer进行知识蒸馏](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495452%26idx%3D1%26sn%3Dd0e99cd3ef9f8ff33695a51931310a2a%26chksm%3Dc1945002f6e3d91490a81ba233a7d2933dc00bcf4ab87cdea04fbc46e41326e2256d7b43d6ec%26token%3D1526765687%26lang%3Dzh_CN%23rd "CVPR2022 | 通过目标感知Transformer进行知识蒸馏")

[CVPR2022丨无监督预训练下的视频场景分割](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495300%26idx%3D1%26sn%3D4429b3293fceeb4754639f21c0727bf7%26chksm%3Dc194519af6e3d88ce4d237e903fce9e37f89f8a03bda4f1179bb6ab72446ff625a66761cd0d6%26token%3D1526765687%26lang%3Dzh_CN%23rd "CVPR2022丨无监督预训练下的视频场景分割")

[从零搭建Pytorch模型教程（六）编写训练过程和推理过程](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495585%26idx%3D1%26sn%3Db29b4fbdea981e6fb0d65b763cf95879%26chksm%3Dc19450bff6e3d9a96de93fb028d29671b2bcbee9c0ddeb20f18bb8b43d0c3d39dcc3e5ab5318%26token%3D1526765687%26lang%3Dzh_CN%23rd "从零搭建Pytorch模型教程（六）编写训练过程和推理过程")

[从零搭建Pytorch模型教程（五）编写训练过程--一些基本的配置](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495346%26idx%3D1%26sn%3D7c6d04843956b9c8364f0e2dbae173b0%26chksm%3Dc19451acf6e3d8bae14df712fdf3f34afa77c1be531f608fd4187d09c06db7b44773f0784c32%26token%3D1448674844%26lang%3Dzh_CN%23rd "从零搭建Pytorch模型教程（五）编写训练过程--一些基本的配置")

[从零搭建Pytorch模型教程（四）编写训练过程--参数解析](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495136%26idx%3D1%26sn%3Db7dfcb870ab03617978d790f3fe7bb60%26chksm%3Dc19452fef6e3dbe83268c1e2185985c039c2ec724b367e933fbee52dc203fd8e3b26fccec645%26scene%3D21%23wechat_redirect "从零搭建Pytorch模型教程（四）编写训练过程--参数解析")

[从零搭建Pytorch模型教程（三）搭建Transformer网络](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247494373%26idx%3D1%26sn%3D98d5967bcf889aa86cc126c3e6eff5b6%26chksm%3Dc19455fbf6e3dced4ccdb561aa06453d6df1b18adb8ee9179ba9c62798bac63839f917413ea7%26scene%3D21%23wechat_redirect "从零搭建Pytorch模型教程（三）搭建Transformer网络")

[从零搭建Pytorch模型教程（二）搭建网络](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247494150%26idx%3D1%26sn%3Dda191e151efb8db5fef1aab64e9bec7d%26chksm%3Dc1945518f6e3dc0e19e5c83f205ae3d24b15c867b9f1038018b18bf7dae597d375f15c13a348%26scene%3D21%23wechat_redirect "从零搭建Pytorch模型教程（二）搭建网络")

[从零搭建Pytorch模型教程（一）数据读取](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247493728%26idx%3D1%26sn%3D3a30e67a71f2c18df697680c6004336b%26chksm%3Dc194577ef6e3de68e47294d8121c4f43c8170b114b5490cc129f212e8baf6aa379365a7a6fd9%26scene%3D21%23wechat_redirect "从零搭建Pytorch模型教程（一）数据读取")

[一份热力图可视化代码使用教程](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247494271%26idx%3D1%26sn%3D6fb284402bc9aad6e9d578e385b59aad%26chksm%3Dc1945561f6e3dc77184450d7ea6c1e71e9d3083946c459298950c1a3d4c900d7184a5a38c440%26scene%3D21%23wechat_redirect "一份热力图可视化代码使用教程")

[一份可视化特征图的代码](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247493864%26idx%3D1%26sn%3D7ad0ec5d43c8cef05c0f05794a547eb8%26chksm%3Dc19457f6f6e3dee07595386289437e74db02231b09261b19c9e419a4e7859565144e88ae2d9e%26scene%3D21%23wechat_redirect "一份可视化特征图的代码")

[关于快速学习一项新技术或新领域的一些个人思维习惯与思想总结](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247493117%26idx%3D1%26sn%3Dfc82e1477d082db07ce74040cfadcb43%26chksm%3Dc1945ae3f6e3d3f578b7590e9dcca4615a4b560a55735f98cb3eb3d0995210fb905d494028f2%26scene%3D21%23wechat_redirect "关于快速学习一项新技术或新领域的一些个人思维习惯与思想总结")

​