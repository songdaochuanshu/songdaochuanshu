---
layout: post
title: "AR手势识别交互，让应用更加“得心应手”"
date: "2022-11-24T02:53:43.261Z"
---
AR手势识别交互，让应用更加“得心应手”
====================

现如今， AR技术不断发展，人们不再满足于运用键盘、鼠标等简单器械来实现传统的人机交互模式。随着用户接触机器的多样化，繁琐的操作不但对一些用户有门槛，而且还增加其学习成本；如果能用自然且符合日常生活习惯的人机交互模式，不仅更好上手，也能让开发者们在应用内开发更多玩法。比如在视频直播或者拍照过程中，一个手势就能增加相应的贴纸或特效，丰富交互体验；面对智能家电等硬件设备时，通过不同的手势可以控制对应的功能。

那么，应用如何才能实现更自然的人机和交互呢？

华为HMS Core [AR Engine](https://developer.huawei.com/consumer/cn/hms/huawei-arengine/?ha_source=hms1)提供多种特定手势的识别，输出识别到的手势类别结果并给出手掌检测框屏幕坐标，左手和右手均可支持。当图像中出现多只手时，只反馈单手（最清晰且置信度最高）识别结果和坐标信息。支持前后置相机切换。

通过手势识别能力，可将虚拟物体叠加到人的手部位置，并根据不同的手势变化来激活某些状态的切换，给开发者的AR应用提供基础的交互功能。

不仅如此[，AR Engine](https://developer.huawei.com/consumer/cn/hms/huawei-arengine/?ha_source=hms1)的手部跟踪功能能识别和跟踪21个手部关节点的位置和姿态，形成手部骨骼模型，并可分辨左右手，同时提供单手关节点和骨骼识别能力，输出手指端点、手部骨骼等手部高级特征。

通过手部骨骼识别能力，开发者们可将虚拟物体叠加到更为精确的手部位置，例如手指尖、手掌心等；利用手部骨骼，能驱动虚拟手做出更为丰富和精细的动作，给开发者们的AR应用提供增强的交互功能和难以置信的新奇玩法。

### 集成步骤

#### 开发环境要求：

JDK 1.8.211及以上。

安装Android Studio 3.0及以上：

minSdkVersion 26及以上

targetSdkVersion 29（推荐）

compileSdkVersion 29（推荐）

Gradle 6.1.1及以上（推荐）

在华为终端设备上的应用市场下载AR Engine服务端APK（需在华为应用市场，搜索“华为AR Engine”）并安装到终端设备。

测试应用的设备：参见[AREngine特性软硬件依赖表](https://developer.huawei.com/consumer/cn/doc/development/graphics-Guides/features-0000001060501339?ha_source=hms1)。如果同时使用多个HMS Core的服务，则需要使用各个Kit对应的最大值。

#### 开发准备

1.  在开发应用前需要在[华为开发者联盟网站](https://developer.huawei.com/consumer/cn/?ha_source=hms1)上注册成为开发者并完成实名认证，具体方法请参见[帐号注册认证。](https://developer.huawei.com/consumer/cn/doc/start/registration-and-verification-0000001053628148?ha_source=hms1)
    
2.  华为提供了Maven仓集成方式的AR Engine SDK包，在开始开发前，需要将AR Engine SDK集成到您的开发环境中。
    
3.  Android Studio的代码库配置在Gradle插件7.0以下版本、7.0版本和7.1及以上版本有所不同。请根据您当前的Gradle插件版本，选择对应的配置过程。
    
4.  以7.0为例：
    

打开Android Studio项目级“build.gradle”文件，添加Maven代码库。

在“buildscript > repositories”中配置HMS Core SDK的Maven仓地址。

    buildscript {
        	repositories {
            	google()
            	jcenter()
            	maven {url "https://developer.huawei.com/repo/" }
        	}
    }
    

打开项目级“settings.gradle”文件，配置HMS Core SDK的Maven仓地址。

    dependencyResolutionManagement {
        repositoriesMode.set(RepositoriesMode.FAIL_ON_PROJECT_REPOS)
        		repositories {
           			 repositories {
               			 	google()
                			jcenter()
                			maven {url "https://developer.huawei.com/repo/" }
           			 }
       			 }
    }
    

5.  添加依赖 在“dependencies”中添加如下编译依赖：

    dependencies {
        implementation 'com.huawei.hms:arenginesdk:{version}
    }
    

#### 应用开发

1.运行前验证：检查当前设备是否安装了AR Engine，若已经安装则正常运行，若没有安装，App应采用合适的方式提醒用户安装AR Engine，如主动跳转应用市场，请求安装AR Engine。具体实现代码如下：

    boolean isInstallArEngineApk =AREnginesApk.isAREngineApkReady(this);
    if (!isInstallArEngineApk) {
        		// ConnectAppMarketActivity.class为跳转应用市场的Activity。
    startActivity(new Intent(this, com.huawei.arengine.demos.common.ConnectAppMarketActivity.class));
       		isRemindInstall = true;
    }
    

2.初始化AR场景：AREngine提供5种场景，包括运动跟踪（ARWorldTrackingConfig）、人脸跟踪（ARFaceTrackingConfig）、手部识别（ARHandTrackingConfig）、人体跟踪（ARBodyTrackingConfig）和图像识别（ARImageTrackingConfig）。

调用ARHandTrackingConfig接口，初始化手部识别。

    mArSession = new ARSession(context);
    ARHandTrackingConfig config = new ARHandTrackingconfig(mArSession);
    

3.  获取到ARhandTrackingconfig后，可以设置使用相机的前置或者后置等等一些可选的方法：

    Config.setCameraLensFacing(ARConfigBase.CameraLensFacing.FRONT);
    

4.  你需要把你获取到的手部识别获取到的config配置到ArSession中，然后启动手部识别场景：

    mArSession.configure(config);
    mArSession.resume();
    

5.  初始化HandSkeletonLineDisplay类，此类是根据手骨架点的坐标来绘制手骨架线：

    Class HandSkeletonLineDisplay implements HandRelatedDisplay{
    //此类需要几个方法
    //初始化方法
    public void init(){
    }
    //绘制手骨架点的方法,这里需要传入ARHand对象，用来获取数据
    public void onDrawFrame(Collection<ARHand> hands,){
    
        //调用getHandskeletonArray()方法用来获取手部关节点坐标数据
            Float[] handSkeletons  =  hand.getHandskeletonArray();
    
            //把handSkeletons传入到实时更新数据方法中
            updateHandSkeletonsData(handSkeletons);
    
    }
    //更新骨架点的连接数据，在更新任何帧的时候调用此方法
    public void updateHandSkeletonLinesData(){
    
    //用来创建并初始化缓冲区对象的数据存储
    GLES20.glBufferData(…,mVboSize,…);
    
    //用来更新缓冲区对象中的数据
    GLES20.glBufferSubData(…,mPointsNum,…);
    
    }
    }
    

6.  初始化HandRenderManager类，此类是来渲染从HUAWEI AREngine获取的数据。

    Public class HandRenderManager implements GLSurfaceView.Renderer{
    	
    	//设置ARSession对象，用于获取onDrawFrame方法中的最新数据。
    	Public void setArSession(){
    	}
    }
    

7.  在HandRenderManager类中，初始化onDrawFrame()方法:

    Public void onDrawFrame(){
    //在这个方法中调用了setCameraTextureName(),update()等方法用来更新ArEngine的计算结果
    //应用在获取到最新数据时来调用此接口。
    mSession.setCameraTextureName();
    ARFrame arFrame = mSession.update();
    ARCamera arCamera = arFrame.getCamera();
    //获取人体手部跟踪时返回的跟踪结果 
    Collection<ARHand> hands =  mSession.getAllTrackables(ARHand.class);
         //把获取到的hands对象循环传入更新手势识别信息方法中,进行处理
         For(ARHand hand  :  hands){
             updateMessageData(hand);
    }
    }
    

8.最后在展示效果的HandActivity页面,给SurfaceView 设置渲染器。

    mSurfaceView.setRenderer(mHandRenderManager);
    设置渲染模式
    mSurfaceView.setRenderMode(GLEurfaceView.RENDERMODE_CONTINUOUSLY);
    

具体实现可参考[示例代码](https://developer.huawei.com/consumer/cn/doc/development/graphics-Examples/sample-code-0000001050148898?ha_source=hms1)。

**了解更多详情>>**

访问[华为开发者联盟官网](http://developer.huawei.com/consumer/cn/hms?ha_source=hms1)  
获取[开发指导文档](http://developer.huawei.com/consumer/cn/doc/development?ha_source=hms1)  
华为移动服务开源仓库地址：[GitHub](http://github.com/HMS-Core)、[Gitee](http://gitee.com/hms-core)

**关注我们，第一时间了解 HMS Core 最新技术资讯~**