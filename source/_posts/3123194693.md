---
layout: post
title: "论文解读（GGD）《Rethinking and Scaling Up Graph Contrastive Learning: An Extremely Efficient Approach with Group Discrimination》"
date: "2022-10-19T19:28:00.833Z"
---
论文解读（GGD）《Rethinking and Scaling Up Graph Contrastive Learning: An Extremely Efficient Approach with Group Discrimination》
==========================================================================================================================

论文信息
====

> 论文标题：Rethinking and Scaling Up Graph Contrastive Learning: An Extremely Efficient Approach with Group Discrimination  
> 论文作者：Yizhen Zheng, Shirui Pan, Vincent Cs Lee, Yu Zheng, Philip S. Yu  
> 论文来源：2022，NeurIPS  
> 论文地址：[download](https://arxiv.org/abs/2206.01535)   
> 论文代码：download 

1 Introduction
==============

　　GCL 需要大量的 Epoch 在数据集上训练，本文的启发来自 GCL 的代表性工作 DGI 和 MVGRL，因为 Sigmoid 函数存在的缺陷，因此，本文提出  Group Discrimination (GD) ，并基于此提出本文的模型 Graph Group Discrimination (GGD)。

　　Graph ContrastiveLearning 和 Group Discrimination 的区别：

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221018220240124-703024051.png)

*   GD directly discriminates a group of positive nodes from a group of negative nodes.
*   GCL maximise the mutual information (MI) between an anchor node and its positive counterparts, sharing similar semantic information while doing the opposite for negative counterparts.

　　贡献：

*   1) We re-examine existing GCL approaches (e.g., DGI and MVGRL), and we introduce a novel and efficient self-supervised GRL paradigm, namely, Group Discrimination (GD).
*   2) Based on GD, we propose a new self-supervised GRL model, GGD, which is fast in training and convergence, and possess high scalability.
*   3) We conduct extensive experiments on eight datasets, including an extremely large dataset, ogbn-papers100M with billion edges.

2 Rethinking Representative GCL Methods
=======================================

　　本节以经典的 DGI 、MVGRL 为例子，说明了互信息最大化并不是对比学习的贡献因素，而是一个新的范式，群体歧视（group discrimination）。

2.1 Rethinking GCL Methods
--------------------------

　　回顾一下 DGI ：

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221018231127202-2120674392.png)

　　代码：

![](https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif)![](https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif)

class DGI(nn.Module):
    def \_\_init\_\_(self, g, in\_feats, n\_hidden, n\_layers, activation, dropout):
        super(DGI, self).\_\_init\_\_()
        self.encoder \= Encoder(g, in\_feats, n\_hidden, n\_layers, activation, dropout)
        self.discriminator \= Discriminator(n\_hidden)
        self.loss \= nn.BCEWithLogitsLoss()

    def forward(self, features):
        positive \= self.encoder(features, corrupt=False)
        negative \= self.encoder(features, corrupt=True)
        summary \= torch.sigmoid(positive.mean(dim=0))
        positive \= self.discriminator(positive, summary)
        negative \= self.discriminator(negative, summary)
        l1 \= self.loss(positive, torch.ones\_like(positive))
        l2 \= self.loss(negative, torch.zeros\_like(negative))
        return l1 + l2

View Code

　　本文研究 DGI 结论：一个 Sigmoid 函数不适用于权重被 Xavier 初始化的 GNN 生成的 summary vector，且 summary vector  中的元素非常接近于相同的值。

　　接着尝试将 Summary vector 中的数值变换成不同的常量 （from 0 to 1）：

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221019093540191-653018485.png)

　　结论：

*   *   将 summary vector 中的数值变成 0，求解相似度时导致所有的 score 变成 0，也就是 postive 项的损失函数变成 负无穷，无法优化；
    *   summary vector 设置其他值，导致 数值不稳定；

　　DGI 的简化：

　　① 将 summary vector 设置为 单位向量（缩放对损失不影响）；

　　② 去掉 Discriminator （Bilinear​ ：先做线性变换，再求内积相似度）的权重向量；【双线性层的 $W$ 其实就是一个线性变换层】

　　　　$\\begin{aligned}\\mathcal{L}\_{D G I} &=\\frac{1}{2 N}\\left(\\sum\\limits \_{i=1}^{N} \\log \\mathcal{D}\\left(\\mathbf{h}\_{i}, \\mathbf{s}\\right)+\\log \\left(1-\\mathcal{D}\\left(\\tilde{\\mathbf{h}}\_{i}, \\mathbf{s}\\right)\\right)\\right) \\\\&\\left.=\\frac{1}{2 N}\\left(\\sum\\limits\_{i=1}^{N} \\log \\left(\\mathbf{h}\_{i} \\cdot \\mathbf{s}\\right)+\\log \\left(1-\\tilde{\\mathbf{h}}\_{i} \\cdot \\mathbf{s}\\right)\\right)\\right) \\\\&=\\frac{1}{2 N}\\left(\\sum\\limits\_{i=1}^{N} \\log \\left(\\operatorname{sum}\\left(\\mathbf{h}\_{i}\\right)\\right)+\\log \\left(1-\\operatorname{sum}\\left(\\tilde{\\mathbf{h}}\_{i}\\right)\\right)\\right)\\end{aligned} \\quad\\quad\\quad(1)$

　　Bilinear ：

　　　　$\\mathcal{D}\\left(\\mathbf{h}\_{i}, \\mathbf{s}\\right)=\\sigma\_{s i g}\\left(\\mathbf{h}\_{i} \\cdot \\mathbf{W} \\cdot \\mathbf{s}\\right)\\quad\\quad\\quad(2)$

　　实验：替换 $\\text{Eq.1}$ 中的 aggregation function ，即 sum 函数

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221019101718563-1710821193.png)

　　替换形式为：

　　　　$\\mathcal{L}\_{B C E}=-\\frac{1}{2 N}\\left(\\sum\\limits \_{i=1}^{2 N} y\_{i} \\log \\hat{y}\_{i}+\\left(1-y\_{i}\\right) \\log \\left(1-\\hat{y}\_{i}\\right)\\right)\\quad\\quad\\quad(3)$

　　其中，$\\hat{y}\_{i}=\\operatorname{agg}\\left(\\mathbf{h}\_{i}\\right)$ ，$y\_{i} \\in \\mathbb{R}^{1 \\times 1}$ ，$\\hat{y}\_{i} \\in \\mathbb{R}^{1 \\times 1}$。论文中阐述 $y\_{i}$ 和 $\\hat{y}\_{i}$ 分别代表 node $i$ 是否是 postive sample ，及其预测输出。Q ：当 aggregation function 采用 $\\text{mean}$ 的时候，对于 postive  sample $i$ ，$\\hat{y}\_{i}$ 值会趋于 $1$ 么？

　　DGI 真正所做的是区分正确拓扑生成的一组节点和损坏拓扑生成的节点，如 Figure 1 所示。可以这么理解，DGI 是使用一个固定的向量 $s$ 去区分两组节点嵌入矩阵（postive and negative）。

　　为解决上述 GD 的问题，本文将考虑使用 $\\text{Eq.3}$ 去替换 DGI 中的损失函数。替换的好处：节省显存和加快计算速度，对于精度没啥改变，说的天花乱坠。

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221019105322273-2126218427.png)

　　Note：方差大的稍微大一点的 method ，就是容易被诋毁。

　　Group Discrimination 定义：GRL method，将不同组别的节点划分给不同的组，对于 postive pair 和 negative pair 分别划分到 "1" 组 和 "0" 组。

3 Methodology 
==============

　　整体框架：

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221019110236398-1727526785.png)

　　**组成部分**：

*   *   Siamese Network ：模仿 MVGRL 的架构；
    *   Data Augmentation ：提供相似意义信息，带来的是时间成本；【dropout edge、feature mask】
    *   Loss function : $\\text{Eq.3}$；

　　模型推断：

　　首先：固定 GNN encoder、MLP predict 的参数，获得初步的节点表示 $\\mathbf{H}\_{\\theta}$；

　　其次：MVGRL 多视图对比工作给本文深刻的启发，所以考虑引入全局信息 ：$ \\mathbf{H}\_{\\theta}^{\\text {global }}=\\mathbf{A}^{n} \\mathbf{H}\_{\\theta}$；

　　最后：得到局部表示和全局表示的聚合 $\\mathbf{H}=\\mathbf{H}\_{\\theta}^{\\text {global }}+\\mathbf{H}\_{\\theta}$ ；

4 Experiments
=============

4.1 Datasets
------------

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221019112858340-267300265.png)

4.2 Result
----------

**节点分类**

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221019123326989-2002289625.png)

**训练时间 和 内存消耗**

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221019123708658-246325265.png)

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221019123728042-1679419717.png)

**4.3 Evaluating on Large-scale datasets**

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221019124025958-7094688.png)

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221019124038794-1669419774.png)

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221019124519375-303978187.png)

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221019124459538-1760782298.png)

5 Future Work
=============

　　 For example, can we extend the current binary Group Discrimination scheme (i.e., classifying nodes generated with different topology) to discrimination among multiple groups?

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221019140818525-1701388039.png)

因上求缘，果上努力~~~~ 作者：[视界~](https://www.cnblogs.com/BlairGrowing/)，转载请注明原文链接：[https://www.cnblogs.com/BlairGrowing/p/16804037.html](https://www.cnblogs.com/BlairGrowing/p/16804037.html)