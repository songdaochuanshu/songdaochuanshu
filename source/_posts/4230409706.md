---
layout: post
title: "手记系列之三 ----- 关于使用Nginx的一些使用方法和经验"
date: "2022-11-14T05:26:08.648Z"
---
手记系列之三 ----- 关于使用Nginx的一些使用方法和经验
================================

前言
--

> 本篇文章主要介绍的关于本人在使用Nginx的一些使用方法和经验~

Nginx介绍
-------

介绍
--

> Nginx("engine x")是一款是由俄罗斯的程序设计师Igor Sysoev所开发高性能的 Web和 反向代理 服务器，也是一个IMAP/POP3/SMTP 代理服务器。 在高连接并发的情况下，Nginx是Apache服务器不错的替代品。

### 正向代理和反向代理

更详细的理论知识可以看这篇文章： [https://www.nginx.org.cn/article/detail/177](https://www.nginx.org.cn/article/detail/177)

> 网上这块的资料很多，个人理解核心，就是用户去访问互联网的服务就是正向代理，互联网服务访问我们部署的服务就是反向代理。

### 负载均衡介绍

相关的使用教程可以看这篇文章：[https://www.cnblogs.com/xuwujing/p/11953697.html](https://www.cnblogs.com/xuwujing/p/11953697.html)

在介绍Nginx的负载均衡实现之前，先简单的说下负载均衡的分类，主要分为**硬件负载均衡和软件负载均衡**，硬件负载均衡是使用专门的软件和硬件相结合的设备，设备商会提供完整成熟的解决方案，比如F5，在数据的稳定性以及安全性来说非常可靠，但是相比软件而言造价会更加昂贵；软件的负载均衡以Nginx这类软件为主，实现的一种消息队列分发机制。

简单来说所谓的负载均衡就是把很多请求进行分流，将他们分配到不同的服务器去处理。比如我有3个服务器，分别为A、B、C，然后使用Nginx进行负载均衡，使用轮询策略，此时如果收到了9个请求，那么会均匀的将这9个请求分发给A、B、Cf服务器，每一个服务器处理3个请求，这样的话我们可以利用多台机器集群的特性减少单个服务器的压力。

Nginx实现负载均衡的示例图:

![在这里插入图片描述](https://img2022.cnblogs.com/blog/1138196/202211/1138196-20221113144940799-1104492786.png)

Nginx相关使用
---------

可以看这篇文章： [https://www.cnblogs.com/xuwujing/p/11899890.html](https://www.cnblogs.com/xuwujing/p/11899890.html)

### 使用Nginx+tomcat+redis做集群

      多个tomcat加上Nginx实现负载均衡，通过redis实现session共享。
    

可以使用github上面的第三方的jar包来实现，少量的配置即可。  
下载地址: [https://github.com/ran-jit/tomcat-cluster-redis-session-manager](https://github.com/ran-jit/tomcat-cluster-redis-session-manager)

![在这里插入图片描述](https://img2022.cnblogs.com/blog/1138196/202211/1138196-20221113144940850-1683172006.png)  
![在这里插入图片描述](https://img2022.cnblogs.com/blog/1138196/202211/1138196-20221113144940772-1121872378.png)

![在这里插入图片描述](https://img2022.cnblogs.com/blog/1138196/202211/1138196-20221113144940842-1133164645.png)

将下载lib包放到tomcat/lib 目录下，配置文件修改的redis地址然后上传到tomcat/conf目录下即可。

Nginx配置:

    #user  nobody;
    worker_processes  10;
    
    #error_log  logs/error.log;
    #error_log  logs/error.log  notice;
    #error_log  logs/error.log  info;
    
    #pid        logs/nginx.pid;
    
    
    events {
        worker_connections  1024;
    }
    
    
    error_log /var/log/nginx-error.log info;
    
    http {
        include       mime.types;
        default_type  application/octet-stream;
    
        #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
        #                  '$status $body_bytes_sent "$http_referer" '
        #                  '"$http_user_agent" "$http_x_forwarded_for"';
    
        #access_log  logs/access.log  main;
    
        sendfile        on;
        #tcp_nopush     on;
    
        #keepalive_timeout  0;
        keepalive_timeout  65;
    
        #gzip  on;
    
         upstream pancm{
           server 192.169.0.24:8085;
           server 192.169.0.24:8084;
        }
    
        server {
            listen      8083;
            server_name  192.169.0.24;
    
            #charset koi8-r;
    
            #access_log  logs/host.access.log  main;
    
            location / {
                root   html;
                proxy_pass http://pancm;
    	     proxy_set_header Host  $host:8083;
                  proxy_set_header X-Forwarded-Host $host:8083;
                 proxy_set_header X-Forwarded-Server $host:8083;
                 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_connect_timeout 3s;
                proxy_read_timeout 5s;
                proxy_send_timeout 3s;		
    	    index  index.html index.htm;
            }
    
    
    	   #============对不同请求的处理=============
            location ~ \.(jsp|html|jspx|do|action)?$ 
            {   
                #=============tomcat的资源位置============
          	   root   html;
    	
               index index.jsp index.jspx index.do;
                #==========Nginx提供的代理============
                proxy_set_header Host  $host:8083;
                proxy_set_header X-Forwarded-Host $host:8083;
                proxy_set_header X-Forwarded-Server $host:8083;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                #=== 如果遇到.jsp .jspx .do .action 的请求就进入该服务器(tomcat)===
                proxy_pass http://pancm;
            }	
    
            #error_page  404              /404.html;
    
            # redirect server error pages to the static page /50x.html
            #
            error_page   500 502 503 504  /50x.html;
            location = /50x.html {
                root   html;
            }
    
            # proxy the PHP scripts to Apache listening on 127.0.0.1:80
            #
            #location ~ \.php$ {
            #    proxy_pass   http://127.0.0.1;
            #}
    
            # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
            #
            #location ~ \.php$ {
            #    root           html;
            #    fastcgi_pass   127.0.0.1:9000;
            #    fastcgi_index  index.php;
            #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
            #    include        fastcgi_params;
            #}
    
            # deny access to .htaccess files, if Apache's document root
            # concurs with nginx's one
            #
            #location ~ /\.ht {
            #    deny  all;
            #}
        }
    
    
        # another virtual host using mix of IP-, name-, and port-based configuration
        #
        #server {
        #    listen       8000;
        #    listen       somename:8080;
        #    server_name  somename  alias  another.alias;
    
        #    location / {
        #        root   html;
        #        index  index.html index.htm;
        #    }
        #}
    
    
        # HTTPS server
        #
        #server {
        #    listen       443 ssl;
        #    server_name  localhost;
    
        #    ssl_certificate      cert.pem;
        #    ssl_certificate_key  cert.key;
    
        #    ssl_session_cache    shared:SSL:1m;
        #    ssl_session_timeout  5m;
    
        #    ssl_ciphers  HIGH:!aNULL:!MD5;
        #    ssl_prefer_server_ciphers  on;
    
        #    location / {
        #        root   html;
        #        index  index.html index.htm;
        #    }
        #}
    
    }
    

启动nginx的命令为：  
/usr/local/nginx/sbin/nginx -t [//测试nginx.conf的配置是否正确](//xn--nginx-qo0ll97o.xn--conf-jo1g986gpvhe9wd4d52v3l0c)

/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf [//根据nginx.conf里的配置](//xn--nginx-vb8j60z.xn--conf-el7jv55b8o4a82a)，启动nginx服务

热加载  
/usr/local/nginx/sbin/nginx -s reload

![在这里插入图片描述](https://img2022.cnblogs.com/blog/1138196/202211/1138196-20221113144940764-157725638.png)

### Nginx作为文件服务器

可以参考这篇文章：  
[https://www.cnblogs.com/xuwujing/p/12811365.html](https://www.cnblogs.com/xuwujing/p/12811365.html)

### Nginx获取真实用户IP配置

核心配置：

    	set_real_ip_from 0.0.0.0/0;
        real_ip_header  X-Forwarded-For;
        real_ip_recursive on;
    

完整配置（仅做参考）：

    http {
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';
        log_format weblog '$msec | $time_local | $host | $status | $bytes_sent | $remote_addr | $upstream_addr | $request | $request_time | $upstream_response_time | $request_length | $http_referer | $http_user_agent';
    
        # 注意，这里我使用的日志格式为我自定义的weblog日志格式，其中会输出$remote_addr 远程客户端地址。
        access_log  /var/log/nginx/access.log  weblog;
    
        # 下面三行为重点，添加后就可以获取到客户端真实IP
        set_real_ip_from 0.0.0.0/0;
        real_ip_header  X-Forwarded-For;
        real_ip_recursive on;
    
        # 下面三行为常见反向代理传递真实客户端IP的配置，配置在http{}中，则全局应用在下面的所有server中
        proxy_set_header Host      $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    
        include             /etc/nginx/mime.types;
        default_type        application/octet-stream;
    
        # Load modular configuration files from the /etc/nginx/conf.d directory.
        # See http://nginx.org/en/docs/ngx_core_module.html#include
        # for more information.
        include /etc/nginx/conf.d/*.conf;
    
    }
    

### Nginx限速控制

限制连接数：  
语法: limit\_conn\_zone key zone=name:size;

详细说明：[https://nginx.org/en/docs/http/ngx\_http\_limit\_conn\_module.html#limit\_conn\_zone](https://nginx.org/en/docs/http/ngx_http_limit_conn_module.html#limit_conn_zone)

例如：

    http  {
        limit_conn_zone $binary_remote_addr zone=perip:10m;
        limit_conn_zone $server_name zone=perserver:10m;
        ...
        server  {
            ...
            # 限制每个IP能够最多建立10个连接
            limit_conn perip 10;
            # 限制每个网站最多接受100个连接
            limit_conn perserver 100;
        } 
    }
    

限制请求速度：  
语法：limit\_req\_zone key zone=name:size rate=rate \[sync\];

详细说明： [https://nginx.org/en/docs/http/ngx\_http\_limit\_req\_module.html#limit\_req\_zone](https://nginx.org/en/docs/http/ngx_http_limit_req_module.html#limit_req_zone)

限制请求速度可用于防止DDoS攻击，或防止上游服务器同时被太多请求淹没。

例如：

    http  {
        limit_req_zone $binary_remote_addr zone=perip:10m rate=2r/s;
        limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;
        limit_req_zone $server_name zone=perserver:10m rate=10r/s;
        ...
        server {
            ...
            # 限制每个IP每秒不超过2个请求，突发不超过5个请求。
            limit_req zone=perip burst=5 nodelay;
            # 限制每个网站每秒不超过10个请求，突发不超过10个请求。
            limit_req zone=perserver burst=10;
            location /search/ {
                # 限制每个IP每秒不超过1个请求。
                limit_req zone=one;
            }
        }
    }
    

限制带宽：  
语法：limit\_rate rate;

单位为：byte/s

详细说明： [https://nginx.org/en/docs/http/ngx\_http\_core\_module.html#limit\_rate](https://nginx.org/en/docs/http/ngx_http_core_module.html#limit_rate)

该设置主要用于限制单个请求的下载速度，以为一个客户端可以建立多个请求，所以一般需要结合限制连接数使用，防止因为个别客户端而耗尽服务器带宽。

    http {
        limit_conn_zone $binary_remote_address zone=perip:10m
        ...
        server {
            ...
            location /download/ {
                # 限制每个IP只能建立一个连接
                limit_conn perip 1;
                # 当请求的流量超500KB后进行限速
                limit_rate_after 500k;
                # 限速 50KB/s
                limit_rate 50k;
            }
        }
    }
    

完整配置：

    http  {
        # 限速IP白名单
        geo $limit {
            default 1;
            10.0.0.0/8 0;
            192.168.0.0/24 0;
            172.20.0.35 0;
        }
        
        # 白名单不限速，非白名单按照客户端IP限速
        map $limit $limit_key {
            0 "";
            1 $binary_remote_addr;
        }
        
        limit_conn_zone $server_name zone=perserver:10m;
        limit_req_zone $server_name zone=perserverreq:10m rate=10r/s;
        limit_conn_zone $limit_key zone=perip:10m;
        limit_req_zone $limit_key zone=two:10m rate=2r/s;
        limit_req_zone $limit_key zone=one:10m rate=1r/s;
        ...
        server  {
            ...
            # 限制每个网站每秒不超过10个请求，突发不超过10个请求。
            limit_req zone=perserverreq burst=10;
            # 限制每个网站最多接受100个请求
            limit_conn perserver 100;
            # 限制每个IP能够最多建立10个请求
            limit_conn perip 10;
            # 限制每个IP每秒不超过1个请求，突发不超过3个请求。
            limit_req zone=one burst=3 nodelay;
            
            location /search/ {
                # 限制每个IP每秒不超过1个请求。
                limit_req zone=one;
            }
            
            location /download/ {
                # 限制每个IP只能建立一个连接
                limit_conn perip 1;
                # 当请求的流量超500KB后进行限速
                limit_rate_after 500k;
                # 限速 50KB/s
                limit_rate 50k;
            }
        } 
    }
    

备注：  
需要注意的是客户端IP使用 $binary\_remote\_addr 变量，而不是 \\(remote\_addr。 \\)remote\_addr 是一个文本型变量，长度为7至15个字节之间。  
$binary\_remote\_addr 是二进制的IP表达形式，对于IPv4地址，变量的大小始终为4个字节，对于IPv6地址，变量的大小始终为16个字节。  
存储状态在32位平台上总是占用32或64字节，在64位平台上占用64字节。 1M的内存空间可以保留大约32000个32字节状态或16000个64位字节。例子中的10M的话换算下来可以保留16万个IP地址信息。当超出请求是服务器将返回错误。

### Nginx监听多端口以及Https

多端口，就是两端server

https则需要配置证书

      server {
       #     listen       8181;
          #  server_name  192.168.0.1
    
            #charset koi8-r;
    
            #access_log  logs/host.access.log  main;
    
         #   rewrite ^(.*)$ https://$host$1 permanent; 
        }
    
    
        # HTTPS server
        #
        server {
            listen       8080 ssl;
            server_name   192.168.0.1 ;
    		
    	
    
            ssl_certificate      /usr/local/nginx/cert/xxx.crt;
            ssl_certificate_key  /usr/local/nginx/cert/xxx.key;
    
            ssl_session_cache    shared:SSL:1m;
            ssl_session_timeout  30m;
    
            #ssl_ciphers  HIGH:!aNULL:!MD5;
            ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;
            ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
            ssl_prefer_server_ciphers  on;
    
            location / {
                root   /home/release/dist;
                index  index.html index.htm;
            }
    
            location ^~ /api/ {
                proxy_pass http://127.0.0.1:9999;
                proxy_cookie_path / /;
                proxy_pass_header Set-Cookie;
                proxy_set_header Host zans;
            }
    
    		
    		 proxy_set_header Host $host;
    		proxy_set_header X-Real-IP $remote_addr;
    		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    		
        }
    	
    	
    	 # HTTPS server
        #
        server {
    		listen       443 ssl;
    		server_name  xxx.com ;
            ssl_certificate      /usr/local/nginx/cert/xxx.crt;
            ssl_certificate_key  /usr/local/nginx/cert/xxx.key;
    
            ssl_session_cache    shared:SSL:1m;
            ssl_session_timeout  30m;
    
            #ssl_ciphers  HIGH:!aNULL:!MD5;
            ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;
            ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
            ssl_prefer_server_ciphers  on;
    
    		location / {
                root   /home/release/app;
                index  index.html index.htm;
            }
    	
    		 location ^~ /api {
                proxy_pass http://127.0.0.1:6666;
                proxy_cookie_path / /;
                proxy_pass_header Set-Cookie;
                proxy_set_header Host zans;
            }
    		
    		 proxy_set_header Host $host;
    		proxy_set_header X-Real-IP $remote_addr;
    		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    		
        }
    

错误处理
----

1，Nginx: error while loading shared libraries: libpcre.so.1

则说明未安装pcre或安装了未设置软链，安装或者设置器软链即可

    ln -s /usr/local/lib/libpcre.so.1 /lib64/
    

2，实现负载均衡之后，页面无法跳转

原因: nginx 默认的端口是80，更改监听的端口之后，也需要更改一下。

也会出现这种错误:net::ERR\_NAME\_NOT\_RESOLVED

解决办法:  
在location 下添`加proxy_set_header Host $host:port` 这个配置，port 和listen 的端口保持一致, 不然是无法跳转的。

3，使用文件服务器的一些问题

1.  nginx需要设置传输的大小;
    
2.  访问若出现了403权限问题，一般情况下是上传的图片用root创建的，但nginx访问使用nginx用户访问的，所以在linux系统出现了问题。  
    解决办法一：nginx使用root用户启动，在nginx的配置改成 use root;  
    解决办法二：全局设置文件夹的权限，并且使nginx拥有读取的权限;
    
3.  nginx限速问题，如果宽带不高，可以对大图片文件进行限速。
    

其他
--

之前写的nginx相关文章：  
[https://www.cnblogs.com/xuwujing/tag/nginx/](https://www.cnblogs.com/xuwujing/tag/nginx/)

一首很带感的动漫钢琴曲~

原创不易，如果感觉不错，希望给个推荐！您的支持是我写作的最大动力！  
版权声明:  
作者：虚无境  
博客园出处：[http://www.cnblogs.com/xuwujing](http://www.cnblogs.com/xuwujing)  
CSDN出处：[http://blog.csdn.net/qazwsxpcm](http://blog.csdn.net/qazwsxpcm)　　　　  
个人博客出处：[https://xuwujing.github.io/](https://xuwujing.github.io/)

如果你对生活感觉到了绝望，请不要气馁。因为这样只会让你更加绝望！ 所谓的希望往往都是在绝望中萌发的，所以，请不要放弃希望！