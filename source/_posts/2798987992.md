---
layout: post
title: "Hugging Face发布diffuser模型AI绘画库初尝鲜！"
date: "2022-10-28T10:22:50.615Z"
---
Hugging Face发布diffuser模型AI绘画库初尝鲜！
=================================

![Hugging Face发布diffuser模型AI绘画库初尝鲜！](https://img2022.cnblogs.com/blog/2637458/202210/2637458-20221026182843397-1136063933.png) 本文讲解 Hugging Face 发布的专注于 diffuser 模型的开源库，仅仅通过几行代码就开始生成自己的艺术作画，并对比相同文本提示下各种商业产品生成的结果。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/143a05b90be04f7c816b08fe943b618a~tplv-k3u1fbpfcp-zoom-1.image)

> 💡 作者：[韩信子](https://github.com/HanXinzi-AI)@[ShowMeAI](https://www.showmeai.tech/)  
> 📘 [深度学习实战系列](https://www.showmeai.tech/tutorials/42)：[https://www.showmeai.tech/tutorials/42](https://www.showmeai.tech/tutorials/42)  
> 📘 [TensorFlow 实战系列](https://www.showmeai.tech/tutorials/43)：[https://www.showmeai.tech/tutorials/43](https://www.showmeai.tech/tutorials/43)  
> 📘 [本文地址](https://www.showmeai.tech/article-detail/312)：[https://www.showmeai.tech/article-detail/312](https://www.showmeai.tech/article-detail/312)  
> 📢 声明：版权所有，转载请联系平台与作者并注明出处  
> 📢 收藏[ShowMeAI](https://www.showmeai.tech/)查看更多精彩内容

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/69dc3270c6cf40e88f2f60d7401db4cc~tplv-k3u1fbpfcp-zoom-1.image)

工具库 transformers 的开源方 Hugging Face 刚刚发布了一个用于构建 diffuser 模型的全新库。如果您不知道diffuser模型是什么，你可以查看 [ShowMeAI](https://www.showmeai.tech/) 的另外一篇文章介绍 📘 [**你给文字描述，** **AI** **艺术作画，精美无比！附源码，快来试试！**](https://www.showmeai.tech/article-detail/313) 。

随着 AI 技术的发展，我们现在在互联网上看到的那些美丽、富有创意、极具艺术美感的绘画与视频，很多是来自 AI 之手！典型的AI艺术创作例如 OpenAI 的 DALL-E2、谷歌的 Imagen 和 Midjourney 的产品，所有这些产品服务都使用 diffuser 模型，下图为一些创作结果。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ec4c416b49024ea38f4440df20350224~tplv-k3u1fbpfcp-zoom-1.image)

Hugging Face 发布了一个专注于 diffuser 模型的开源库，我们可以基于它，仅仅通过几行代码就开始生成自己的艺术作画。不过这个 diffuser 库是一个基础实现版本，训练和学习的数据也没有上面提到的几个大厂商业产品多，在本篇文章中，[ShowMeAI](https://www.showmeai.tech/) 就带大家来探索新库，并生成一些我们自己的艺术画作，也对比一下相同文本提示下的大厂商业产品生成的结果。

💡 快速尝鲜
=======

我们先在命令行通过 `pip install diffusers` 安装本次使用到的工具库，然后导入我们需要用到的模块和功能（在这里我们调用整个扩散模型流水线 DiffusionPipeline），并且我们导入一个小型预训练模型`ldm-text2im-large-256`：

    from diffusers import DiffusionPipeline
    
    model_id = "CompVis/ldm-text2im-large-256"
    
    # 预训练模型
    ldm = DiffusionPipeline.from_pretrained(model_id)
    

接着我们就可以基于这个预训练模型作画啦，我们唯一需要做的事情就是给模型一句文本提示（在 diffuser 模型里叫 prompt 提示）。下面我们尝试生成一幅『**松鼠吃香蕉**』的画作。

    # 给定文本提示和作画
    prompt = "A painting of a squirrel eating a banana"
    images = ldm([prompt], num_inference_steps=50, eta=.3, guidance_scale=6)
    images[0]
    

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0ab7d7e6afcd42349c826b59bc8628df~tplv-k3u1fbpfcp-zoom-1.image)

上面就是模型最终生成的图像，当然受限于我们的计算资源和预训练模型大小，我们生成的图像不像 DALL-E 2 那样令人惊艳，但是我们仅仅用 5 行代码也生成了一副和提示文本匹配的图像，还是很让人感觉神奇。

下面是『**松鼠吃香蕉**』的另一幅画：

    images = ldm(
        [prompt],
        num_inference_steps=100,
        eta=.3,
        guidance_scale=6
    )
    images['sample'][0]
    

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8baba137fd0243168afd36daf520b6d8~tplv-k3u1fbpfcp-zoom-1.image)

💡 文本提示
=======

📌 高分辨率
-------

自三大扩散模型（DALL-E 2、Imagen 和 Midjourney）发布以来，大家都开始发挥想象力，尝试各种各样的文本提示，让模型生成艺术图。例如，许多人发现添加『4K画质』或『在Unity中渲染』可以增强三巨头生成的图像的真实感（尽管它们都没有以 4K 分辨率生成）。

如果我们对 Hugging Face 的 diffuser 模型进行同样的尝试，会发生什么？

    prompt = "a photorealistic image of a squirrel eating a banana"
    images = ldm(
        [prompt],
        num_inference_steps=100,
        eta=.3,
        guidance_scale=6
    )
    images['sample'][0]
    

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/96de856546d14c9eab222e082e561dd1~tplv-k3u1fbpfcp-zoom-1.image)

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6472bd80f0f74061a540076ef262bc89~tplv-k3u1fbpfcp-zoom-1.image)

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a11a01e0f71e43359c9c3421c0daa6c2~tplv-k3u1fbpfcp-zoom-1.image)

很显然它还不能生成高清的 4K 图，但是图像中的一些细节有丰富一些。

📌 场景与逻辑
--------

我们把场景做得复杂一点点，比如给到的文本提示中，有不同的物体和位置关系，我们看看会生成什么样的结果，提示文字为`an italian person eating pizza on top of the colosseum in rome`。

    prompt = "an italian person eating pizza on top of the colosseum in rome"
    images = ldm(
        [prompt],
        num_inference_steps=100,
        eta=.3,
        guidance_scale=6
    )
    images['sample'][0]
    

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a38e215440ab486380b3ba5fe5ada853~tplv-k3u1fbpfcp-zoom-1.image)

看得出来，这个简单的 diffuser 模型在很努力地复现我们文本中提到的人、斗兽场、披萨，但是对于更细节的位置关系，似乎它还没有做得非常好，这里的人并没有坐在罗马斗兽场顶部，而且斗兽场的拱门颜色和天空颜色也不完全匹配。

📌 更抽象的情况
---------

回到松鼠，尝试生成更抽象的图像，例如 `a giant squirrel destroying a city`『一只巨大的松鼠摧毁一座城市』，我们随机采样了一些结果如下，好坏参半：

    prompt = "a giant squirrel destroying a city" 
    images = ldm(
        [prompt],
        num_inference_steps=100,
        eta=.3,
        guidance_scale=6
    )
    images['sample'][0]
    

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/abb452c5e35d41c88c210206ee1f5ad5~tplv-k3u1fbpfcp-zoom-1.image)

    prompt = "a giant squirrel destroying a city"
    images = ldm(
        [prompt],
        num_inference_steps=50,
        eta=.3,
        guidance_scale=6
    )
    images['sample'][0]
    

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/de77cebe69f9498c8601a0149d0ff505~tplv-k3u1fbpfcp-zoom-1.image)

    prompt = "a giant squirrel destroying a city"
    images = ldm(
        [prompt],
        num_inference_steps=100,
        eta=.3,
        guidance_scale=2
    )
    images['sample'][0]
    

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8298c7818ba54e02a8d410f258436ccb~tplv-k3u1fbpfcp-zoom-1.image)

我们似乎观察到，目前这个小模型似乎很难融合两个通常相关度没那么高的概念，即『（巨型）松鼠』和『城市』。我们从一些生成的效果不是特别好的图片可以观察出这一点，下面的结果中，要么对城市与天际线做了很好的描述却忽略了松鼠，要么对松鼠和自然环境做了很好的描述，却没有特别强的城市背景：

    prompt = "a landscape image showing a giant squirrel destroying a city"
    images = ldm(
        [prompt],
        num_inference_steps=50,
        eta=.8,
        guidance_scale=2
    )
    images['sample'][0]
    

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1460dea771f14737a00bdbb35fdae02b~tplv-k3u1fbpfcp-zoom-1.image)

    prompt = "a landscape image showing a giant squirrel destroying a city"
    images = ldm(
        [prompt],
        num_inference_steps=50,
        eta=.8,
        guidance_scale=2
    )
    images['sample'][0]
    

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b5d3301646924d12a7d0fd0331b01736~tplv-k3u1fbpfcp-zoom-1.image)

多次运行这些提示后，我们发现当前这个小模型下，总是在主体之间切换但很难将两者融合在一起。

💡 DALL-E 2的结果
==============

我们把同样的内容`"a dramatic shot of a giant squirrel destroying a modern city"`灌给 DALL-E 2 ，让它从提示做图，得到的结果如下：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4be3e98615ca4363a98c29b3b290cb9e~tplv-k3u1fbpfcp-zoom-1.image)

果然在更庞大的AI模型下，生成的结果更自然，也能把不同的细节关联起来。

💡 总结
=====

这就是 Hugging Face 新库的初尝鲜！尽管目前开源的小模型上，还有一系列的问题，但是这类模型就像一把钥匙，解锁一些令人敬畏的人工智能类人的艺术创造水平。

短期看，这个小小的预训练模型当然无法取代 DALL-E 2、Imagen 或 Midjourney，但随着开源社区的强大，它会表现越来越好。

参考资料
====

*   📘 **你给文字描述，AI艺术作画，精美无比！附源码，快来试试！**：[https://www.showmeai.tech/article-detail/313](https://www.showmeai.tech/article-detail/313)

[![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e9190f41b8de4af38c8a1a0c96f0513b~tplv-k3u1fbpfcp-zoom-1.image)](https://www.showmeai.tech/)