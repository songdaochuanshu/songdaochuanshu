---
layout: post
title: "不care工具，在大数据平台中Hive能自动处理SQL"
date: "2022-04-19T12:37:14.023Z"
---
不care工具，在大数据平台中Hive能自动处理SQL
===========================

> **摘要：**有没有更简单的办法，可以直接将SQL运行在大数据平台？

本文分享自华为云社区《[Hive执行原理](https://bbs.huaweicloud.com/blogs/348195?utm_source=cnblog&utm_medium=bbs-ex&utm_campaign=other&utm_content=content)》，作者： JavaEdge 。

MapReduce简化了大数据编程的难度，使得大数据计算不再是高不可攀的技术圣殿，普通工程师也能使用MapReduce开发大数据程序。但是对于经常需要进行大数据计算的人，比如从事研究商业智能（BI）的数据分析师来说，他们通常使用SQL进行大数据分析和统计，MapReduce编程还是有一定的门槛。而且如果每次统计和分析都开发相应的MapReduce程序，成本也确实太高了。

有没有更简单的办法，可以直接将SQL运行在大数据平台？

先看如何用MapReduce实现SQL数据分析。

MapReduce实现SQL的原理
-----------------

常见的一条SQL分析语句，MapReduce如何编程实现？

 SELECT pageid, age, count(1) FROM pv\_users GROUP BY pageid, age;

统计分析语句，统计不同年龄用户访问不同网页的兴趣偏好，具体数据输入和执行结果：

![](https://pic2.zhimg.com/80/v2-18ac5cb9401270baea028eec797258fd_720w.jpg)

*   左边，要分析的数据表
*   右边，分析结果

把左表相同的行求和，即得右表，类似WordCount计算。该SQL的MapReduce的计算过程，按MapReduce编程模型

*   map函数的输入K和V，主要看V

V就是左表中每行的数据，如<1, 25>

*   map函数的输出就是以输入的V作为K，V统一设为1

比如<<1, 25>, 1>

map函数的输出经shuffle后，相同的K及其对应的V被放在一起组成一个<K, V集合>，作为输入交给reduce函数处理。比如<<2, 25>, 1>被map函数输出两次，那么到了reduce这里，就变成输入<<2, 25>, <1, 1>>，这里的K是<2, 25>，V集合是<1, 1>。

在reduce函数内部，V集合里所有的数字被相加，然后输出。所以reduce的输出就是<<2, 25>, 2>

![](https://pic4.zhimg.com/80/v2-11b822bb971a4c7729dba4886a94d3db_720w.jpg)

如此，一条SQL就被MapReduce计算好了。

在数据仓库中，SQL是最常用的分析工具，既然一条SQL可以通过MapReduce程序实现，那有无工具能自动将SQL生成MapReduce代码？这样数据分析师只要输入SQL，即可自动生成MapReduce可执行的代码，然后提交Hadoop执行。这就是Hadoop大数据仓库Hive。

Hive架构
------

Hive能直接处理我们输入的SQL（Hive SQL语法和数据库标准SQL略不同），调用MapReduce计算框架完成数据分析操作。

![](https://pic3.zhimg.com/80/v2-d8333f261ee099ad4d7a0e76e159b9c6_720w.jpg)

通过Hive Client（Hive的命令行工具，JDBC等）向Hive提交SQL命令：

*   若为DDL，Hive会通过执行引擎Driver将数据表的信息记录在Metastore元数据组件，该组件通常用一个关系数据库实现，记录表名、字段名、字段类型、关联HDFS文件路径等这些数据库的元信息
*   若为DQL，Driver就会将该语句提交给自己的编译器Compiler进行语法分析、语法解析、语法优化等一系列操作，最后生成一个MapReduce执行计划。然后根据执行计划生成一个MapReduce的作业，提交给Hadoop MapReduce计算框架处理。

对一个简单的SQL命令：

 SELECT \* FROM status\_updates WHERE status LIKE ‘michael jackson’;

其对应的Hive执行计划：

![](https://pic2.zhimg.com/80/v2-23021d8ebe4cc6c7f2d312b9229c061d_720w.jpg)

Hive内部预置了很多函数，Hive执行计划就是根据SQL语句生成这些函数的DAG（有向无环图），然后封装进MapReduce的map、reduce函数。该案例中的map函数调用了三个Hive内置函数TableScanOperator、FilterOperator、FileOutputOperator，就完成了map计算，而且无需reduce函数。

Hive如何实现join操作
--------------

除了简单的聚合（group by）、过滤（where），Hive还能执行连接（join on）操作。

pv\_users表的数据在实际中无法直接得到，因为pageid数据来自用户访问日志，每个用户进行一次页面浏览，就会生成一条访问记录，保存在page\_view表中。而age年龄信息则记录在用户表user。

![](https://pic4.zhimg.com/80/v2-da19706fc7f53ad3fdde31fe5021abcb_720w.jpg)

这两张表都有一个相同的字段userid，据该字段可连接两张表，生成前面例子的pv\_users表：

 SELECT pv.pageid, u.age FROM page\_view pv JOIN user u ON (pv.userid = u.userid);

该SQL命令也能转化为MapReduce计算，连接过程如下：

![](https://pic2.zhimg.com/80/v2-c55f7bb2a0533793399f102528e71419_720w.jpg)

join的MapReduce计算过程和前面的group by稍有不同，因为join涉及两张表，来自两个文件（夹），所以需要在map输出的时候进行标记，比如来自第一张表的输出Value就记录为<1, X>，这里的1表示数据来自第一张表。这样经过shuffle以后，相同的Key被输入到同一个reduce函数，就可以根据表的标记对Value数据求笛卡尔积，用第一张表的每条记录和第二张表的每条记录连接，输出就是join的结果。

所以打开Hive源码，看join相关代码，会看到一个两层for循环，对来自两张表的记录进行连接操作。

总结
--

开发无需经常编写MapReduce程序，因为网站最主要的大数据处理就是SQL分析，因此Hive在大数据应用很重要。

随Hive普及，我们对在Hadoop上执行SQL的需求越强，对大数据SQL的应用场景也多样化起来，于是又开发了各种大数据SQL引擎。

Cloudera开发了Impala，运行在HDFS上的MPP架构的SQL引擎。和MapReduce启动Map和Reduce两种执行进程，将计算过程分成两个阶段进行计算不同，Impala在所有DataNode服务器上部署相同的Impalad进程，多个Impalad进程相互协作，共同完成SQL计算。在一些统计场景中，Impala可做到ms级计算速度。

后来Spark诞生，也推出自己的SQL引擎Shark，即Spark SQL，将SQL语句解析成Spark的执行计划，在Spark上执行。由于Spark比MapReduce快很多，Spark SQL也相应比Hive快很多，并且随着Spark的普及，Spark SQL也逐渐被人们接受。后来Hive推出了Hive on Spark，将Hive的执行计划转换成Spark的计算模型。

我们还希望在NoSQL执行SQL，毕竟SQL发展几十年，积累庞大用户，很多人习惯用SQL解决问题。于是Saleforce推出了Phoenix，一个执行在HBase上的SQL引擎。

这些SQL引擎只支持类SQL语法，并不能像数据库那样支持标准SQL，特别是数据仓库领域几乎必然会用到嵌套查询SQL：在where条件里面嵌套select子查询，但几乎所有的大数据SQL引擎都不支持。然而习惯于传统数据库的使用者希望大数据也能支持标准SQL。

回到Hive。Hive本身的技术架构其实并没有什么创新，数据库相关的技术和架构已经非常成熟，只要将这些技术架构应用到MapReduce上就得到了Hadoop大数据仓库Hive。**但是想到将两种技术嫁接到一起，却是极具创新性的，**通过嫁接产生出的Hive极大降低大数据的应用门槛，也使Hadoop得到普及。

参考
--

*   https://learning.oreilly.com/library/view/hadoop-the-definitive/9781491901687/ch17.html#TheMetastore
    

**[点击关注，第一时间了解华为云新鲜技术~](https://bbs.huaweicloud.com/blogs?utm_source=cnblog&utm_medium=bbs-ex&utm_campaign=other&utm_content=content)**