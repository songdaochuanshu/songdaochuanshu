---
layout: post
title: "迁移学习（IIMT）——《Improve Unsupervised Domain Adaptation with Mixup Training》"
date: "2023-01-10T01:21:56.408Z"
---
迁移学习（IIMT）——《Improve Unsupervised Domain Adaptation with Mixup Training》
========================================================================

论文信息
====

> 论文标题：Improve Unsupervised Domain Adaptation with Mixup Training  
> 论文作者：Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, Liu Ren  
> 论文来源：arxiv 2020  
> 论文地址：[download](https://arxiv.org/abs/2001.00677)   
> 论文代码：download  
> 引用次数：93

1 Introduction
==============

　　现有方法分别对源域和目标域施加约束，忽略了它们之间的重要相互作用。本文使用 mixup 来加强训练约束来直接解决目标域的泛化性能。

　　当前工作假设：当在表示级处理域差异时，训练后的源分类器能够在目标域上自动取得良好的性能。然而，当前研究表明，在两个域上都表现良好的分类器可能不存在 \[6,7\]，所以仅依赖源分类器可能导致目标域的显著错误分类。现有最先进的方法在对抗学习过程中寻求额外的训练约束，不过他们都是在所选择的域独立地使用训练约束，而不是联合约束。这使得这两个域之间的重要相互作用尚未被探索，并可能会显著限制训练约束的潜力。

　　本文通过简单的 $\\text{mixup training}$，证明了引入该训练约束可以显著提高模型适应性能。

　　$\\text{Mixup}$：给定一对样本 $\\left(x\_{i}, y\_{i}\\right)$、$\\left(x\_{j}, y\_{j}\\right)$ ，生成的增强表示为：

　　　　$\\begin{array}{c}x^{\\prime}=\\lambda x\_{i}+(1-\\lambda) x\_{j} \\\\y^{\\prime}=\\lambda y\_{i}+(1-\\lambda) y\_{j}\\end{array} $

　　其中，$\\lambda \\in\[0,1\]$。

　　通过使用 $\\left(x^{\\prime}, y^{\\prime}\\right)$ 训练，鼓励了模型的线性行为，其中原始数据中的线性插值导致预测的线性插值。

　　受半监督学习\[9\] 的启发，本文通过在目标数据上推断标签来实现跨域的 $\\text{mixup}$。通过这种方式，与只使用源标签来训练分类器不同，本文还可以使用域之间的插值（虚拟）标签来提供额外的监督。随着 $\\text{mixup}$ 训练和领域对抗性训练的进展，该模型推断出虚拟标签。该过程对于直接提高目标域分类器的泛化具有关重要。此外，为了在非常大的域差异下有效地加强线性约束，本文开发了一个特征级一致性正则化器，以更好地促进 $\\text{mixup}$ 训练。除了域间约束外，$\\text{mixup}$ 也可以在每个域内应用。域间和域内混合训练构成了所提出的 IIMT 框架，用于加强多方面约束以提高目标域性能。

2 Problem Statement
===================

　　The overview of IIMT framework is shown in $\\text{Figure 1}$. We denote the labeled source domain as set  $\\left\\{\\left(x\_{i}^{s}, y\_{i}^{s}\\right)\\right\\}\_{i=1}^{m\_{s}} \\sim \\mathcal{S}$  and unlabeled target domain as set  $\\left\\{x\_{i}^{t}\\right\\}\_{i=1}^{m\_{t}} \\sim \\mathcal{T}$ . Here  $y\_{i}$  denotes one-hot labels. The overall classification model is denoted as  $h\_{\\theta}: \\mathcal{S} \\mapsto \\mathcal{C}$  with the parameterization by  $\\theta$ . Following prominent approaches in UDA \[6, 7\], we consider the classification model as the composite of an embedding encoder  $f\_{\\theta}$  and an embedding classifier  $g\_{\\theta}: h=f \\circ g$ . Note that encoder is shared by the two domains. The core component in our framework is mixup, imposed both across domains (Inter-domain in $\\text{Figure 1}$) and within each domain (Intra-domain (source) and Intradomain (target) in $\\text{Figure 1}$. All mixup training losses and the domain adversarial loss are trained end-to-end.

　　　　![](https://img2023.cnblogs.com/blog/1664108/202301/1664108-20230105224838165-2104688456.png)

3 Method
========

3.1 Inter-domain Mixup Training
-------------------------------

　　本文框架中的关键组件：源域和目标域之间的 $\\text{mixup}$ 训练。在 $h$ 的训练中，$\\text{mixup}$ 提供了插值标签来强制分类器跨域的线性预测行为。与单独使用源标签训练相比，它们导致了一种简单的归纳偏差，但本文可以直接提高分类器对目标域的泛化能力。

　　$\\text{mixup}$ 训练需要样本标签来进行插值，本文利用推断出的标签作为对目标域的弱监督。类似的想法在半监督学习设置\[10,9\]中被证明在开发相关的未标记数据方面是非常有效的。

　　首先，对目标域每个数据样本执行 $K$ 个任务相关的随机增强，以获得转换后的样本 $\\left\\{\\hat{x}\_{i, k}\\right\\}\_{k=1}^{K}$。然后，计算目标域的虚拟标签：$\\bar{q}\_{i}=\\frac{1}{K} \\sum\\limits \_{k=1}^{K} h\_{\\theta}\\left(\\hat{x}\_{i, k}\\right)$，归一化为 $q\_{i}=\\bar{q}\_{i}^{\\frac{1}{T}} / \\sum\\limits \_{c} \\bar{q}\_{i, c}^{\\frac{1}{T}}$，使用较小的 $T<1$ 产生更清晰的预测分布。

　　![](https://img2023.cnblogs.com/blog/1664108/202301/1664108-20230106091742264-1186810351.png)

　　给定一对源样本和目标样本 $\\left(x\_{i}^{s}, x\_{i}^{t}\\right)$，标签级 $\\text{mixup}$ 以加强各域之间的线性一致性：

　　　　$\\begin{array}{l}x\_{i}^{s t}=\\lambda^{\\prime} x\_{i}^{s}+\\left(1-\\lambda^{\\prime}\\right) x\_{i}^{t} \\quad\\quad(1) \\\\q\_{i}^{s t}=\\lambda^{\\prime} y\_{i}^{s}+\\left(1-\\lambda^{\\prime}\\right) q\_{i}^{t} \\quad\\quad(2) \\\\\\mathcal{L}\_{q}=\\frac{1}{B} \\sum\_{i} H\\left(q\_{i}^{s t}, h\_{\\theta}\\left(x\_{i}^{s t}\\right)\\right)\\quad\\quad(3) \\end{array}$

　　其中，$\\text{B}$ 代表 $\\text{batch size}$ ，$\\text{H}$ 为交叉熵损失，$\\text{mixup}$ 加权参数根据：$\\lambda \\sim \\operatorname{Beta}(\\alpha, \\alpha)$ 和 $\\lambda^{\\prime}=\\max (\\lambda, 1-\\lambda)$ 选择。

　　当设置 $\\alpha$ 接近于 $1$ 时，从范围 $\[0,1\]$ 中选择 $\\lambda$ 为中间值的概率更大，使得两个域之间的插值水平更高。请注意，$\\lambda^{\\prime}$ 始终超过 $0.5$，以确保源域占主导地位。同样地，也可产生目标域主导的 $\\text{mixup}$，只需要通过在 $\\text{Eq.1}$ 中切换 $x^{s}$ 和 $x^{t}$ 的系数，对应地形成 $\\left(x^{t s}, q^{t s}\\right)$。使用目标域主导的 $\\left(x^{t s}, q^{t s}\\right)$，采用均方误差（MSE）损失，因为它更能容忍目标域中的虚假虚拟标签。

### 3.1.1  Consistency Regularizer

　　在域差异非常大的情况下，域间 $\\text{mixup}$ 所施加的线性约束可能效果较差。具体来说，当异构的原始输入在 $\\text{Eq.1}$ 中被插值时，迫使模型 $h$ 产生相应的插值预测变得更加困难。同时，对于特征级域混淆的域对抗损失的联合训练会增加训练难度。

　　因此，本文为潜在特征设计一个一致性正则化器，以更好地促进域间 $\\text{mixup}$ 训练：

　　　　$\\begin{aligned}z\_{i}^{s t} & =\\lambda^{\\prime} f\_{\\theta}\\left(x\_{i}^{s}\\right)+\\left(1-\\lambda^{\\prime}\\right) f\_{\\theta}\\left(x\_{i}^{t}\\right) \\quad\\quad(4)    \\\\\\mathcal{L}\_{z} & =\\frac{1}{B} \\sum\\limits \_{i}\\left\\|z\_{i}^{s t}-f\_{\\theta}\\left(x\_{i}^{s t}\\right)\\right\\|\_{2}^{2}\\quad\\quad(5)\\end{aligned}$

　　即：通过两个向量之间的 $\\text{MSE}$ 损失，使混合特征更接近于混合输入的特征。这个正则化器的作用：当 $\\text{Eq.5}$ 强制 $z\_{i}^{s t}$， $f\_{\\theta}\\left(x\_{i}^{s t}\\right)$ 通过浅分类器 $g$，模型预测的线性更容易满足。

　　　　![](https://img2023.cnblogs.com/blog/1664108/202301/1664108-20230110000538823-716942708.png)

### 3.1.2 Domain Adversarial Training

　　最后一个组成部分是使用标准的域对抗性训练来减少域的差异。本文的实现限制在更基本的 DANN 框架\[1\]上，以试图集中于评估混合线性约束。在DANN中，一个域鉴别器和共享嵌入编码器（生成器）在对抗性目标下进行训练，使编码器学习生成域不变特征。本文的源和目标样本 $\\text{mixup}$ 的域对抗性损失：

　　　　$\\mathcal{L}\_{d}=\\frac{1}{B} \\sum\_{i} \\ln D\\left(f\_{\\theta}\\left(x\_{i}^{s t}\\right)\\right)+\\ln \\left(1-D\\left(f\_{\\theta}\\left(x\_{i}^{s t}\\right)\\right)\\right)\\quad\\quad(6)$

3.2 Intra-domain Mixup Training
-------------------------------

　　给定源标签和目标虚拟标签，$\\text{mixup}$ 训练也可以在每个域内执行。由于在同一域内的样本遵循相似的分布，因此不需要应用特征级的线性关系。因此，只对这两个领域使用标签级 $\\text{mixup}$ 训练，并定义它们相应的损失：

　　　　$\\begin{array}{l}x\_{i}^{s^{\\prime}}=\\lambda^{\\prime} x\_{i}^{s}+\\left(1-\\lambda^{\\prime}\\right) x\_{j}^{s} \\\\y\_{i}^{s^{\\prime}}=\\lambda^{\\prime} y\_{i}^{s}+\\left(1-\\lambda^{\\prime}\\right) y\_{j}^{s} \\\\\\mathcal{L}\_{s}=\\frac{1}{B} \\sum\\limits \_{i} H\\left(y\_{i}^{s^{\\prime}}, h\_{\\theta}\\left(x\_{i}^{s^{\\prime}}\\right)\\right)\\end{array}\\quad\\quad(7)$

　　　　$\\begin{array}{l}x\_{i}^{t^{\\prime}}=\\lambda^{\\prime} x\_{i}^{t}+\\left(1-\\lambda^{\\prime}\\right) x\_{j}^{t} \\\\q\_{i}^{t^{\\prime}}=\\lambda^{\\prime} q\_{i}^{t}+\\left(1-\\lambda^{\\prime}\\right) q\_{j}^{t} \\\\\\mathcal{L}\_{t}=\\frac{1}{B} \\sum\\limits \_{i}\\left\\|q\_{i}^{t^{\\prime}}-h\_{\\theta}\\left(x\_{i}^{t^{\\prime}}\\right)\\right\\|\_{2}^{2}\\end{array}\\quad\\quad(8)$

　　虽然域内混合作为一种数据增强策略是直观的，但它对 UDA 特别有用。正如在\[6\]中所讨论的，没有局部约束的条件熵的最小化会导致数据样本附近的预测突变。在\[6\]中，利用虚拟对抗训练\[10\]来增强邻域的预测平滑性。不同的是，我们发现域内混合训练能够实现相同的目标。

3.3 Training Objective
----------------------

　　训练目标：

　　　　$\\mathcal{L}=w\_{q} \\mathcal{L}\_{q}+w\_{d} \\mathcal{L}\_{d}+w\_{z} \\mathcal{L}\_{z}+w\_{s} \\mathcal{L}\_{s}+w\_{t} \\mathcal{L}\_{t}\\quad\\quad(9)$

　　由于 $\\mathcal{L}\_{t}$ 只涉及虚拟标签，因此很容易受到目标域的不确定性的影响。本文为训练中的 $w\_{t}$ 设置了一个线性时间表，从 $0$ 到一个预定义的最大值。从初始实验中，观察到该算法对其他加权参数具有良好的鲁棒性。因此，只搜索 $w\_{t}$，而简单地将所有其他权重固定为 $1$。

4 Experiment
============

　　For **image classification experiments**, we evaluate on MNIST, MNIST-M, Street View House Numbers (SVHN), Synthetic Digits (SYN DIGITS), CIFAR-10 and STL-10.

　　**A → B** to denote the domain adaptation task with source domain A and target domain B.

　　前三：手写数组识别；后二：目标检测：

　　![](https://img2023.cnblogs.com/blog/1664108/202301/1664108-20230110083838751-1287175809.png)

　　消融实验：

　　![](https://img2023.cnblogs.com/blog/1664108/202301/1664108-20230110083811349-1397168478.png)

* * *

**Note**

**条件熵**：条件熵 $H(Y|X)$ 表示在已知随机变量 $X$ 的条件下随机变量 $Y$ 的不确定性。

　　　　$\\begin{aligned}H(Y \\mid X) & =\\sum\\limits\_{x \\in X} p(x) H(Y \\mid X=x) \\\\& =-\\sum\\limits\_{x \\in X} p(x) \\sum\\limits\_{y \\in Y} p(y \\mid x) \\log p(y \\mid x) \\\\& =-\\sum\\limits\_{x \\in X} \\sum\\limits\_{y \\in Y} p(x, y) \\log p(y \\mid x)\\end{aligned}$

[DANN](https://www.cnblogs.com/BlairGrowing/p/17020391.html)

import torch
from torch.autograd import Function
import torch.nn as nn
import torch.nn.functional as F

class ReverseLayerF(Function):
    @staticmethod
    def forward(ctx, x, alpha):
        print("forward===========================")
        print("xx = ",x)
        ctx.alpha \= alpha
        ctx.feature \= x
        return x.view\_as(x)

    @staticmethod
    def backward(ctx, grad\_output):
        print("backward===========================")
        print("grad\_output = ",grad\_output)
        output \= grad\_output.neg() \* ctx.alpha
        return output, None

class Net(nn.Module):
    def \_\_init\_\_(self):
        super(Net, self).\_\_init\_\_()
        self.featurizer \= nn.Linear(4,3)

        self.classifier \= nn.Linear(3,2)
        self.discriminator \= nn.Linear(3,2)
        self.alpha \= 1

    def forward(self,x,disc\_labels,label):
        # 特征提取
        z = self.featurizer(x)
        print("z = ",z)

        disc\_input \= z
        disc\_input \= ReverseLayerF.apply(disc\_input, self.alpha)
        disc\_out \= self.discriminator(disc\_input)
        disc\_loss \= F.cross\_entropy(disc\_out, disc\_labels)

        all\_preds \= self.classifier(z)
        classifier\_loss \= F.cross\_entropy(all\_preds,label)
        loss \= classifier\_loss + disc\_loss
        loss.backward()
        return

x \= torch.tensor(\[\[ 1.1118,  1.8797, -0.9592, -0.6786\],
        \[ 0.4843,  0.4395, -0.2360, -0.6523\],
        \[ 0.7377,  1.4712, -2.3062, -0.9620\],
        \[\-0.7800,  1.8482,  0.0786,  0.0179\]\], requires\_grad=True)
disc\_labels \= torch.LongTensor(\[0,0,1,1\])
label \=  torch.LongTensor(\[0,0,1,1\])

print("x = ",x)
print("disc\_labels = ",disc\_labels)
print("label = ",label)
print("+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++")
model \= Net()
model(x,disc\_labels,label)

[GAN](https://www.cnblogs.com/BlairGrowing/p/15853567.html)

# Loss function
adversarial\_loss = torch.nn.BCELoss()

# Initialize generator and discriminator
generator = Generator()
discriminator \= Discriminator()

# Optimizers
optimizer\_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))
optimizer\_D \= torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))

for epoch in range(opt.n\_epochs):
    for i, (imgs, \_) in enumerate(dataloader):

        # Adversarial ground truths
        valid = Variable(Tensor(imgs.size(0), 1).fill\_(1.0), requires\_grad=False)  #torch.Size(\[64, 1\])
        fake = Variable(Tensor(imgs.size(0), 1).fill\_(0.0), requires\_grad=False)   #torch.Size(\[64, 1\])

        # Configure input
        real\_imgs = Variable(imgs.type(Tensor))     #torch.Size(\[64, 1, 28, 28\])

        # Train Generator   ========================
        optimizer\_G.zero\_grad()

        # Sample noise as generator input
        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape\[0\], opt.latent\_dim))))    #torch.Size(\[64, 100\])

        # Generate a batch of images
        gen\_imgs = generator(z)        #torch.Size(\[64, 1, 28, 28\])

        # Loss measures generator's ability to fool the discriminator
        g\_loss = adversarial\_loss(discriminator(gen\_imgs), valid)

        g\_loss.backward()
        optimizer\_G.step()

        #Train Discriminator     ========================
        optimizer\_D.zero\_grad()

        # Measure discriminator's ability to classify real from generated samples
        real\_loss = adversarial\_loss(discriminator(real\_imgs), valid)
        fake\_loss \= adversarial\_loss(discriminator(gen\_imgs.detach()), fake)
        d\_loss \= (real\_loss + fake\_loss) / 2

        d\_loss.backward()
        optimizer\_D.step()

因上求缘，果上努力~~~~ 作者：[加微信X466550探讨](https://www.cnblogs.com/BlairGrowing/)，转载请注明原文链接：[https://www.cnblogs.com/BlairGrowing/p/17028724.html](https://www.cnblogs.com/BlairGrowing/p/17028724.html)