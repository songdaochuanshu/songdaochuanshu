---
layout: post
title: "论文翻译：2020_TinyLSTMs: Efficient Neural Speech Enhancement for Hearing Aids"
date: "2022-04-18T06:24:03.541Z"
---
论文翻译：2020\_TinyLSTMs: Efficient Neural Speech Enhancement for Hearing Aids
==========================================================================

> 论文地址：[TinyLSTMs：助听器的高效神经语音增强](https://arxiv.org/abs/2005.11138)
> 
> 音频地址：[https://github.com/Bose/efficient-neural-speech-enhancement](https://github.com/Bose/efficient-neural-speech-enhancement)
> 
> 引用格式：Fedorov I，Stamenovic M，Jensen C，et al. TinyLSTMs：Efficient neural speech enhancement for hearing aids\[J\]. arXiv preprint arXiv：2005.11138，2020.

摘要
==

　　现代语音增强算法利用大量递归神经网络(RNNs)实现了显著的噪声抑制。然而，大型RNN限制了助听器硬件(hearing aid hardware，HW)的实际部署，这些硬件是电池供电的，运行在资源受限的微控制器单元(microcontroller units，MCU)上，内存和计算能力有限。在这项工作中，我们使用模型压缩技术来弥补这一差距。我们在HW上对RNN施加约束，并描述了一种方法来满足它们。虽然模型压缩技术是一个活跃的研究领域，但我们是第一个证明其有效性的RNN语音增强，使用剪裁和权重/激活的整型量化。我们还演示了状态更新跳跃，它可以减少计算负载。最后，我们对压缩模型进行感知评估，人类评分员对语音进行打分。结果显示，与基线相比，压缩模型的模型size和operation(操作)分别减少了11.9和2.9，在听力偏好上没有统计差异，只损失了0.55dB SDR。我们的模型实现了2.39ms的计算延迟，在10 ms的目标范围内，比之前的工作好351\*。

**关键词**：噪声抑制，语音增强，循环神经网络，剪枝，量化

1  引言
=====

　　健康的耳朵是一个复杂的非线性系统，能够在大的动态范围内工作。当耳朵受损时，听觉系统可以用助听器(HA)增强，它可以执行一些耳朵不再能做的放大和过滤功能。语音增强(SE)可以缓解嘈杂环境中的听力困难，这是HA用户最关注的问题之一\[1,2,3\]。

　　最近的SE方法通常由循环神经网络(RNN)体现\[5,6\]。SE模型必须实现低音频延迟，以确保测听者舒适。音频延迟被定义为噪声到达HA和助听器产生的纯净语音之间的延迟。可以容忍的延迟量取决于HA类型和如何处理用户自己的语音\[7,8,9\]。使用之前的工作\[7,8,9\]作为指导方针，我们的目标是最大音频延迟为30 ms。对于我们使用的基于帧的方法，由于帧和因果模型之间有50%的重叠，处理每帧的计算延迟约束为10ms。

　　HA形式因素强加了另一组约束，特别是在结合帧处理需求时。由于其体积小，采用了单片机(MCU)硬件平台。MCU实现了廉价、低功耗的计算，但代价是严重的内存和计算约束\[10\]。MCU Flash内存限制了最大允许模型尺寸(maximum allowed model size，MS)，而SRAM内存限制了模型工作内存(upper bounds model working memory，WM)，即用于存储中间结果的内存。为了实现高效的计算，SE模型必须量化为整型数据类型，我们必须最小化每秒所需的操作(ops)数量(ops/s)，其中op表示单个加法或乘法。本文以STM32F746VE MCU\[4\]作为典型的HW平台，该MCU包含一个216MHz Arm Cortex-M7 \[11\]，512KB Flash内存，320KB SRAM。我们使用Mbed OS\[12\]和CMSIS内核\[13,14\]。表1总结了SE模型约束。

![](https://img2022.cnblogs.com/blog/1433301/202201/1433301-20220124114111831-1417864906.png)

表1：模型约束。MOps/inf表示每帧推理有$10^6$个操作。目标MCU为STM32F746VE\[4\]

　　最近的一些论文考虑了类似的限制。 例如，威尔逊等人\[6\]使用黑盒优化器在一系列因果和非因果模型中搜索 SE 模型，这些**模型包括对模型输入的计算量大的卷积**。 模型复杂性在搜索中没有明确限制，报告的模型在 3.7-248 MB 范围内，违反了 MS 限制。 此外，一些模型在前端包含许多层扩张卷积，这需要大约 4.4 MB 的 WM，违反了 WM 约束。

　　其他的研究试图剪裁\[15\]和量化\[16\]RNN，但没有将他们的技术应用于SE。尽管参数在\[16\]中是量化的，但激活不是量化的，因此计算结果不适合整型算法。此外，\[15,16\]也不清楚剪枝和量化是否可以联合应用于RNNs。在Wu等人的\[17\]中，对一个非循环卷积SE模型进行了剪枝和量化。然而，它们对非均匀量化的使用需要非标准HW支持\[18\]，以避免在从内存中加载每个权值后对其进行解码，从而产生重大的性能开销。对于大的感受野，卷积模型可能还需要以音频采样率运行的大缓冲区。 这极大地扩张了 WM ，并极大地缩短了计算时间的限制。 最后，Hsu等人\[19\]分别对循环SE模型\[19\]和卷积SE模型\[19\]的浮点尾数和指数值进行了量化研究，但这些量化的权值仍然需要在浮点HW中运行，并导致了解压的开销。

　　在本工作中，我们提出了一种方法来生成满足表1要求的优化RNN SE模型。首先，我们演示了对SE LSTM进行剪枝，以减少MS、WM和ops，而不会导致SE性能下降。通过扩展\[15\]，**我们直接学习优化范围内的剪裁阈值，避免了超参数搜索的开销**，与之前的工作\[6\]相比，减少了255个GPU小时(GPUH)。其次，我们首次**证明了标准加权和激活量化技术可以很好地应用于SE RNNs**。此外，我们还证明了剪枝和量化可以联合应用于SE RNNs，这也是我们工作的独特之处。最后，**我们提出了一个跳过RNN状态更新的方案，以减少平均操作次数**。

　　我们优化的SE模型使用传统的客观指标进行评估，以及对音频输出的主观感知评估。我们的音频源文件可以在[online](https://github.com/Bose/efficient-neural-speech-enhancement)上找到。相对于\[5,6,17,19,20,21\]，我们的感知研究是对 \[5, 6, 17, 19, 20, 21\] 的显着改进，因为（压缩的）SE 模型通常会表现出未反映在诸如 SNR 等客观指标中的声学伪影。 最后，我们在 MCU 上分析我们的模型，以验证它们是否满足硬件约束，如表 1 所示。

2  背景
=====

　　设小写和大写符号分别表示向量和矩阵，设$X=\[x^1...x^N\]\\in R^{M\*N}$。

2.1  语音增强
---------

　　设$x\\in R^N$表示N个采样点的单通道时域信号，在语音增强中，$x$被噪声破坏，目标是从$y=x+v$中提取$x$，**在这项工作中，是在时频域中应用降噪**，其中$y$使用短时傅里叶变换(STFT)转换为 $Y\\in C^{B\_f\*B\_t}$。其中$B\_f$是频点数。在这项工作中，降噪器是将掩码$M\\in R\_+^{B\_f\*B\_t}$应用于频谱图，得到target的近似值$\\hat{X}=M\\odot |Y|exp(\\measuredangle Y)$。其中$\\odot$表示hadamard乘积(就是矩阵乘积)，$\\measuredangle Y$是输入带噪语音的相位\[22\]，mask是$Y$，可学习参数是$\\theta $，即$M=f\_{\\theta}(Y)$。具体来说，$f\_{\\theta}(·)$是一个神经网络，其参数是通过最小化相位敏感频谱近似损失来学习的 \[20\]：

$$公式1：L(\\theta)=\\left\\||X|^{0.3}-|\\hat{X}|^{0.3}\\right\\|\_{F}^{2}+0.113\\left\\|X^{0.3}-\\hat{X}^{0.3}\\right\\|\_{F}^{2}$$

其中帧是幂律压缩，指数为0.3，以减少大值的优势。

2.2  基线模型架构
-----------

　　由于延迟的要求，我们把注意力放在因果模型\[5\]上，因此$m^t=f\_{\\theta }(\[y^1...Y^t\])$。我们使用的体系结构由一系列循环层和全连接(FC)层组成。这些循环层用来模拟跨越时间的交互作用。对于循环层，我们使用长短期记忆(LSTM)单元，它是有状态的，具有更新规则$i^{t}=\\sigma(W\_{x i} x^{t}+h^{t-1} W\_{h i}+b\_{i})$，$r^t=\\sigma\\left(W\_{x r} x^{t}+h^{t-1} W\_{h r}+b\_{r}\\right)$，$o^{t}=\\sigma(W\_{x o} x^{t}+h^{t-1} W\_{h o}+b\_{o})$，$u^{t}=\\tanh (W\_{x u} x^{t}+h^{t-1} W\_{h u}+b\_{u})$，

$$公式2：c^{t}=r^{t} \\odot c^{t-1}+i^{t} \\odot u^{t}，\\quad h^{t}=o^{t} \\odot \\tanh \\left(c^{t}\\right)$$

其中$\\sigma $为S形函数\[23\]。**基线体系结构由2个单向LSTM层(每个256个单元)和2个FC层(每个128个单元)组成，最后一个LSTM层和第一个FC层之间进行批归一化(Batch Normalization，BN)。第1层FC后进行ReLU激活，第2层FC后进行Sigmoid**。**在所有情况下，网络的频谱输入都映射到 128 维mel空间 \[24\] 和幂律压缩，指数为 0.3。共享输入维数的网络输出使用相应的转置 mel 矩阵进行反转，以生成频谱掩码$M$**。

3  为HA硬件优化LSTM
==============

　　本节介绍了SE模型的优化，如2.2节中的优化，以满足表1中给出的约束条件。我们开始描绘MS(model size)和计算成本的依赖于模型的性质。然后，在3.2-3.3节中，我们描述了我们提出的方法。

　　MS是所有层中参数的总数，乘以每个矩阵的数据类型。每次推理所需的操作数量也取决于参数的数量，因为(几乎)在我们的模型中执行的所有操作都是矩阵向量乘法，每个参数需要2个操作(乘和加)。尽管操作计数与模型量化无关，但在实际**硬件上实现的吞吐量在精度较低的整型数据类型下要高得多**。因此，为了减少总体延迟，我们采用了两种优化方法：1)剪枝以减少操作，2)权值/激活量化(weight/activation quantification)，从而减少MS，并支持使用低精度整型算法\[25\]进行部署。

3.1  结构化剪枝
----------

　　剪枝是一种成熟的网络优化方法\[26,27\]。**我们使用结构化剪枝**，因为它在模型大小和吞吐量方面都有直接的好处\[28\]。这与随机剪枝不同，**随机剪枝在真实的HW上更难利用，除非稀疏性非常高**。我们首先将$\\theta $中的权重分组为集合$\\Gamma $，其中$w\_g\\in \\Gamma $表示特定组中的权重集合，堆叠成一个向量。小组的组织决定了我们可以学习的结构类型。对于 FC 层，我们根据它们在前一层中连接的神经元对权重进行分组。对于 LSTM 层，我们根据它们所连接的$h^t$元素对权重进行分组 \[15\]。我们给$k$层的每一组权重赋一个二元掩码$r\_{g}=\\mathbb{1}\\left(\\left\\|w\_{g}\\right\\|\_{2}-\\tau\_{k} \\geq 0\\right)$，其中$1\[·\]$表示指示函数，$\\tau\_k\\geq 0$是一个可学习阈值。设$P=\\{r\_g,1\\leq g\\leq |\\Gamma |\\}$为剪裁掩码集合，$\\theta \\odot P$为模型权值集合的简写形式，每个权值乘以相应的二进制掩码。然后我们修改(1)中的学习目标来惩罚非零权值的能量：

$$公式3：\\min \_{\\theta,\\left\\{\\tau\_{k}，1 \\leq k \\leq K\\right\\}} L(\\theta \\odot P)+\\lambda \\sum\_{g=1}^{|\\Gamma|} r\_{g}\\left\\|w\_{g}\\right\\|\_{2}$$

其中$\\lambda$是控制剪裁程度的超参数，K是层数。为了区分指示函数，我们在反向传递\[29\]时用sigmoid函数近似它。上面描述的剪裁方法在剪裁文献中是独特的，特别适合我们的特定任务。我们采用\[15\]中LSTM权值的结构分组，但我们通过直接学习\[15\]中人工选择的剪枝阈值，对其进行了改进。结果是，我们不需要对$\\{\\tau\_k,1\\leq k\\leq k\\}$执行超参数搜索，这可能是非常昂贵的，因为SE RNN大约需要14个GPUH来训练，而且超参数空间随$K$呈指数增长。

3.2  量化
-------

　　令$w\\in R$表示实值（浮点）值，$Q\_{\\alpha ,\\beta}(w)$表示其量化值，其中量化在$(\\alpha ,\\beta)$范围内以$2^{bit}-1$级均匀执行，即$Q\_{\\alpha ,\\beta}(w)=\\zeta $ 大约$((clip(w,\\alpha ,\\beta)-\\alpha)/\\zeta)+\\alpha$，其中$\\alpha<\\beta$且$\\zeta=(2^{bit-1})(\\beta-\\alpha)$。 为简洁起见，我们省略了向前移动的$\\alpha$和$\\beta$下标。 我们采用一种标准方法，通过执行训练感知量化 \[25\]，使模型对量化张量具有弹性。 这将模型输出暴露给量化噪声，同时仍然允许模型在实值权重上反向传播。 具体来说，(3) 变为

$$公式4：\\min \_{\\theta，\\Omega \\atop\\left\\{\\tau\_{k}，1 \\leq k \\leq K\\right\\}} L\_{Q}(Q(\\theta \\odot P))+\\lambda \\sum\_{g=1}^{|\\Gamma|} r\_{g}\\left\\|Q\\left(w\_{g}\\right)\\right\\|\_{2}$$

其中，$\\Omega$是所有权值和激活的量化参数集，$Q(\\theta \\odot P)$表示掩码网络权值被量化的事实，而$L\_Q$表示激活被量化。在反向传播时，round(·)操作被忽略\[25\]。我们将权重、激活和模型输入量化为8-bit，掩码本身被量化为16-bit。

3.3  skip RNN 单元(cell)
----------------------

　　最后，我们评估了skip RNN方法\[30\]，它可以被认为是一种动态时间剪枝的形式。在{0,1}中引入一个二进制神经元$g^t\\in \\{0,1\\}$，它作为候选LSTM状态$\\tilde{s}$的状态更新门，表示(2)中的$c^t$和$h^t$。

$$公式5：g^{t}=\\operatorname{round}\\left(\\tilde{g}^{t}\\right)，\\quad s^{t}=g^{t} \\tilde{s}^{t}+\\left(1-g^{t}\\right) s^{t-1}$$

其中$\\tilde{g}^t$是更新概率，使用

$$公式6：\\Delta \\tilde{g}^{t}=\\sigma\\left(W\_{b} c\_{\*}^{t-1}+b\_{b}\\right)$$

$$公式7：\\tilde{g}^{t+1}=g^{t} \\Delta \\tilde{g}^{t}+\\left(1-g^{t}\\right)\\left(\\tilde{g}^{t}+\\min \\left(\\Delta \\tilde{g}^{t}，1-\\tilde{g}^{t}\\right)\\right)$$

其中$c\_\*^{t-1}$为最后LSTM层的状态。每当跳跃状态更新时，状态更新概率$\\tilde{g}^t$增加$\\triangle \\tilde{g}^t$，直到$\\tilde{g}^t$高到足以发生更新，在这种情况下$\\tilde{g}^{t+1}$变成$\\triangle \\tilde{g}^t$。由于$\\tilde{g}^t$在LSTM不更新时是固定的，所以(6)只需要在LSTM更新时计算。

　　实际上，这种跳过更新的方法在训练和评估指标上执行得很好，但是会产生音频伪影，因为当LSTM skip时，掩码本身没有更新。为了弥补这一点，引入了两个指数移动平均线(EMAs)来及时平滑模型。首先，一个上下文向量，$c\_x^t=0.9c\_x^{t-1}+0.1(W\_cx^t+b\_c)$，被计算为从输入频谱帧，$x\_t$连接到LSTM输出。其次，将EMA应用于掩模，$m\_t$，以计算平滑掩模$\\tilde{m}\_t=0.15\\tilde{m}^{t-1}+0.85m^t$。

4  实验结果
=======

　　在所有的实验中，我们使用Tensorflow中的随机梯度下降(Stochastic Gradient Descent，SGD)来优化目标。我们使用32ms帧，16ms帧移和16kHz采样率进行基线、剪枝和量化实验。对于skip RNN实验，我们使用的帧长和帧移分别为25ms和6.25ms。所有方法都使用CHiME2 WSJ0数据集\[31\]进行训练和评估，该数据集分别包含7138个训练词、2560个开发词和1980个测试词。这三个子集都包括信噪比(SNRs)在-6到9dB范围内的话语。噪音数据由记录在客厅环境中的高度不稳定的干扰源组成，包括真空吸尘器、电视和儿童。虽然数据集是在双耳立体声中提供的，**但我们通过对通道维数求和来进行预处理，以获得单耳输入和目标**，而\[6\]使用完整的双耳输入来预测双耳掩模。对于最终的客观评估，我们使用信号失真比(SDR)\[32\]。然而，在训练过程中，我们使用更简单的比例不变信号失真比(SI-SDR)，因为它的计算成本更低，并且与SDR\[33\]很好地相关。

4.1  基线模型
---------

　　我们首先确认我们的基线SE模型与最新技术相比具有竞争力。我们的基线在CHiME2开发集上实现了12.77dB SDR(表2)，在测试集上实现了13.70dB SDR(表3)，与\[34,20\]相当。

![](https://img2022.cnblogs.com/blog/1433301/202201/1433301-20220124114235789-1569956613.png)

表2：在CHiME2开发集和STM32F746VE上的模型性能，在绘制0.54W时以155MOps/s的速度运行。符号\*表示最佳情况估计，因为基础模型是浮点的，测量是为整型算法。

符号$\\dagger $表示平均性能，反映了skip RNN模型的随机性。蓝色(红色)表示通过(违反)表1中的一个约束的度量。测量不包括STFT或Mel变换的成本。

4.2  结构化剪枝和量化
-------------

　　接下来，我们检查结构剪枝和量化对基线模型的影响。在所有情况下，我们设$\\lambda=10^{-9}$。模型大小和性能之间的权衡如图1所示，其中每个点代表优化过程中的一个快照。我们绘制了相对于MS的SISDR值的pareto边界。我们的实验表明，结构剪枝可以实现47%剪枝模型的性能与基线相同。此外，在同时进行剪枝和量化的情况下，37%的剪枝模型在SISDR (pruned (INT8) 1)中实现了约0.2dB的降低，66%的剪枝模型显示了约0.5dB的衰减(pruned (INT8) 2)。表3显示了我们模型在CHiME2测试集上的SDR评估。

![](https://img2022.cnblogs.com/blog/1433301/202201/1433301-20220124114514784-394428404.png)

表3：在CHiME2测试集上评估的模型性能

![](https://img2022.cnblogs.com/blog/1433301/202201/1433301-20220124114625066-27348256.png)

 图1：MS 与 SISDR。每个点代表一个模型检查点，线代表一个帕累托前沿

　　我们优化的模型实现了适合于音频管道中更小的帧处理时间(帧移)的延迟。然而，较小的帧移会增加推理频率和能量消耗。因此，为了解决这个挑战，我们在压缩模型上应用skip RNN架构。 Pruned Skip RNN (INT8) 的结果显示，在 CHiME2 开发集（表 2）上为 12.07dB SDR，在测试集上为 12.96dB SDR（表 3）。 尽管跳过 RNN 每秒需要更多推理，但与 Pruned (INT8) 2 相比，63% 的skip rate导致每次推理的平均能量消耗减少。

　　最后，表2详细描述了每个模型。尽管\[20,6\]中的模型取得了稍好的SISDR/SDR性能，但其MS、WM和MOps/inf严重违反了HA HW约束。相比之下，Pruned (INT8)模型2和Pruned Skip RNN (INT8)可以部署在真正的HA MCU上，并提供显著的SE功能。与\[20,6\]相比，我们的模型实现了2.39-6.71ms范围的计算延迟，满足了10ms的要求。此外，与\[20,6\]相比，本文提出的模型每推理消耗的能量显著减少，从而提高了HA电池寿命。

4.3  感知评价
---------

　　人类对音频质量的感知是高度主观的，并不总是与客观指标相关。因此，为了理解真实世界的表现，我们进行了感知研究，以获得与基线相比，优化模型质量的主观反馈。我们对两个Pruned (INT8)模型进行了调查(表2)，每个模型由50名参与者组成的不相交集合组成。从CHiME2评估集的6个信噪比级别中随机选择两个样本，共12个样本话语。每个参与者被随机呈现原始和处理后的话语的配对比较基线和修剪和量化模型，导致每个参与者有 24 个配对比较。 鉴于提示考虑到语音的清晰度和质量，您更喜欢哪种录音？ ，参与者在 7 分Likert scale表 \[35\] 上对比较偏好进行评分，范围从强烈喜欢未处理到强烈喜欢增强，以无偏好为中点。

　　图2的结果显示，参与者平均表现出对增强音频的中度偏好。我们注意到，与提高HA噪声语音性能的行业标准方法相比，这一方法效果更好，在类似的研究中，与未处理的\[36\]相比，参与者表达了对定向处理音频的轻微偏好。我们使用aWilcoxon符号秩检验\[37\]比较了对未压缩(基线)和压缩(剪裁和量化)模型的偏好与原始未处理的话语，发现SNRs之间的评级没有统计学差异(调查1：Z = 0.09，p = 0.92；调查2：Z = 0.19，p = 0.85)，表明参与者更喜欢增强的音频，不管它是由基线模型还是优化模型产生的。

![](https://img2022.cnblogs.com/blog/1433301/202201/1433301-20220124114822300-896006030.png)

图2  知觉研究参与者对增强音频和未处理音频(包括未压缩和剪裁)的偏好左为Pruned (INT8) 1，右为Pruned (INT8) 2。

5  结论
=====

　　神经语音增强技术是未来HA产品的关键技术。然而，由于要获得令人满意的音频性能需要大量的网络网络，因此对于电池供电的小型HW来说，延迟和功耗的限制是非常难以满足的。在这项工作中，我们应用了结构剪裁和整数量化的输入，权重和激活，以减少11.9模型大小，与基线相比。与最小的压缩模型相比，我们还应用了skip RNN技术，进一步减少了每次推理的运算量1.78。我们优化的模型显示在客观(SISDR)指标上可以忽略不计的退化，在主观的人类感知评价上没有统计差异。虽然我们的基线模型在我们的目标HW平台上的计算延迟为12.52ms，但优化后的实现达到了4.26ms，这足以满足10ms的计算延迟目标。

6  参考文献
=======

\[1\] S. Kochkin，MarkeTrak V：Why my hearing aids are in the drawer the consumers perspective，The Hearing Journal，vol. 53，no. 2，pp. 34 36，2000.

\[2\] H. B. Abrams and J. Kihm，An introduction to marketrak ix：A new baseline for the hearing aid market，Hearing Review，vol. 22，no. 6，p. 16，2015.

\[3\] (2020) Hearing aids，the ultimate guide：Types，features，prices，reviews，and more. \[Online\]. Available：https：//www. hearingtracker.com/hearing-aids

\[4\] ST Microelectronics STM32F746VE. \[Online\]. Available：https：//www.st.com/content/ st com/en/products/microcontrollers-microprocessors/ stm32-32-bit-arm-cortex-mcus/stm32-high-performance-mcus/ stm32f7-series/stm32f7x6/stm32f746ve.html

\[5\] D. Takeuchi，K. Yatabe，Y. Koizumi，Y. Oikawa，and N. Harada，Real-time speech enhancement using equilibriated rnn，in ICASSP 2020 - 2020 IEEE International Conference on Acoustics，Speech and Signal Processing (ICASSP)，2020，pp. 851 855.

\[6\] K. Wilson，M. Chinen，J. Thorpe，B. Patton，J. Hershey，R. A. Saurous，J. Skoglund，and R. F. Lyon，Exploring tradeoffs in models for low-latency speech enhancement，in 2018 16th International Workshop on Acoustic Signal Enhancement (IWAENC). IEEE，2018，pp. 366 370.

\[7\] M. A. Stone and B. C. J. Moore，Tolerable hearing aid delays. i. estimation of limits imposed by the auditory path alone using simulated hearing losses，Ear and Hearing，vol. 20，no. 3，pp. 182 192，1999.

\[8\] ，Tolerable hearing aid delays. ii. estimation of limits imposed during speech production，ear and hearing，Ear and Hearing，vol. 23，no. 4，pp. 325 338，2002.

\[9\] ，Tolerable hearing aid delays. iii. effects on speech production and perception of across-frequency variation in delay，Ear and Hearing，vol. 24，no. 2，pp. 175 183，2003.

\[10\] I. Fedorov，R. P. Adams，M. Mattina，and P. N. Whatmough，SpArSe：Sparse architecture search for CNNs on resourceconstrained microcontrollers，in Advances in Neural Information Processing Systems (NeurIPS)，2019，pp. 4978 4990.

\[11\] Arm Cortex-M7 Embedded Processor. \[Online\]. Available：https：//developer.arm.com/ip-products/processors/cortex-m/cortex-m7

\[12\] Arm Mbed. \[Online\]. Available：https：//os.mbed.com/

\[13\] Arm CMSIS Library. \[Online\]. Available：https：//github.com/ ARM-software/CMSIS

\[14\] L. Lai，N. Suda，and V. Chandra，CMSIS-NN：efficient neural network kernels for arm cortex-m cpus，CoRR，vol. abs/1801.06601，2018.

\[15\] W. Wen，Y. He，S. Rajbhandari，M. Zhang，W. Wang，F. Liu，B. Hu，Y. Chen，and H. Li，Learning intrinsic sparse structures within long short-term memory，in International Conference on Learning Representations，2018.

\[16\] L. Hou，J. Zhu，J. Kwok，F. Gao，T. Qin，and T.-y. Liu，Normalization helps training of quantized LSTM，in Advances in Neural Information Processing Systems，2019，pp. 7344 7354.

\[17\] J. Wu，C. Yu，S. Fu，C. Liu，S. Chien，and Y. Tsao，Increasing compactness of deep learning based speech enhancement models with parameter pruning and quantization techniques，IEEE Signal Processing Letters，vol. 26，no. 12，pp. 1887 1891，2019.

\[18\] S. Han，X. Liu，H. Mao，J. Pu，A. Pedram，M. A. Horowitz，and W. J. Dally，Eie：efficient inference engine on compressed deep neural network，ACM SIGARCH Computer Architecture News，vol. 44，no. 3，pp. 243 254，2016.

\[19\] Y.-T. Hsu，Y.-C. Lin，S.-W. Fu，Y. Tsao，and T.-W. Kuo，A study on speech enhancement using exponent-only floating point quantized neural network (eofp-qnn)，in 2018 IEEE Spoken Language Technology Workshop (SLT). IEEE，2018，pp. 566 573.

\[20\] H. Erdogan，J. R. Hershey，S. Watanabe，and J. Le Roux，Phasesensitive and recognition-boosted speech separation using deep recurrent neural networks，in 2015 IEEE International Conference on Acoustics，Speech and Signal Processing (ICASSP). IEEE，2015，pp. 708 712.

\[21\] F. Weninger，H. Erdogan，S. Watanabe，E. Vincent，J. Le Roux，J. R. Hershey，and B. Schuller，Speech enhancement with LSTM recurrent neural networks and its application to noise-robust asr，in International Conference on Latent Variable Analysis and Signal Separation. Springer，2015，pp. 91 99.

\[22\] Y. Wang，A. Narayanan，and D. Wang，On training targets for supervised speech separation，IEEE/ACM transactions on audio，speech，and language processing，vol. 22，no. 12，pp. 1849 1858，2014.

\[23\] S. Hochreiter and J. Schmidhuber，Long short-term memory，Neural computation，vol. 9，no. 8，pp. 1735 1780，1997.

\[24\] S. S. Stevens，J. Volkmann，and E. B. Newman，A scale for the measurement of the psychological magnitude pitch，Journal of the Acoustical Society of America，vol. 8，pp. 185 190，1937.

\[25\] B. Jacob，S. Kligys，B. Chen，M. Zhu，M. Tang，A. Howard，H. Adam，and D. Kalenichenko，Quantization and training of neural networks for efficient integer-arithmetic-only inference，in 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition，2018，pp. 2704 2713.

\[26\] Y. LeCun，J. S. Denker，and S. A. Solla，Optimal brain damage，in Advances in neural information processing systems，1990，pp. 598 605.

\[27\] M. C. Mozer and P. Smolensky，Skeletonization：A technique for trimming the fat from a network via relevance assessment，in Advances in neural information processing systems，1989，pp. 107 115.

\[28\] W. Wen，C. Wu，Y. Wang，Y. Chen，and H. Li，Learning structured sparsity in deep neural networks，in Advances in neural information processing systems，2016，pp. 2074 2082.

\[29\] D. Stamoulis，R. Ding，D. Wang，D. Lymberopoulos，N. B. Priyantha，J. Liu，and D. Marculescu，Single-path mobile automl：Efficient convnet design and nas hyperparameter optimization，IEEE Journal of Selected Topics in Signal Processing，pp. 1 1，2020.

\[30\] V. Campos，B. Jou，X. Gir o i Nieto，J. Torres，and S. Chang，Skip RNN：learning to skip state updates in recurrent neural networks，in International Conference on Learning Representations，2018.

\[31\] E. Vincent，J. Barker，S. Watanabe，J. Le Roux，F. Nesta，and M. Matassoni，The second chimespeech separation and recognition challenge：Datasets，tasks and baselines，in 2013 IEEE International Conference on Acoustics，Speech and Signal Processing. IEEE，2013，pp. 126 130.

\[32\] E. Vincent，R. Gribonval，and C. F evotte，Performance measurement in blind audio source separation，IEEE transactions on audio，speech，and language processing，vol. 14，no. 4，pp. 1462 1469，2006.

\[33\] J. Le Roux，S. Wisdom，H. Erdogan，and J. R. Hershey，Sdr half-baked or well done? in ICASSP 2019-2019 IEEE International Conference on Acoustics，Speech and Signal Processing (ICASSP). IEEE，2019，pp. 626 630.

\[34\] F. Weninger，J. R. Hershey，J. Le Roux，and B. Schuller，Discriminatively trained recurrent neural networks for single-channel speech separation，in 2014 IEEE Global Conference on Signal and Information Processing (GlobalSIP). IEEE，2014，pp. 577 581.

\[35\] R. Likert，A technique for the measurement of attitudes，Archives of Psychology，vol. 140，pp. 1 55，1932.

\[36\] J. M. Vaisberg，A. Sabin，and S. Banerjee，Speech-in-noise benefits using Bose directional technology，in American Academy of Audiology Conference，2020. \[37\] F. Wilcoxon，Individual comparisons by ranking methods，Biometrics，vol. 1，pp. 80 83，1945.