---
layout: post
title: "Python技法：用re模块实现简易tokenizer"
date: "2022-04-29T16:27:59.206Z"
---
Python技法：用re模块实现简易tokenizer
===========================

![Python技法：用re模块实现简易tokenizer](https://img2022.cnblogs.com/blog/1784958/202204/1784958-20220429154741611-269407898.png) 分词（tokenization）任务是Python字符串处理中最为常见任务了。我们这里讲解用正则表达式构建简单的表达式分词器（tokenizer），它能够将表达式字符串从左到右解析为标记(tokens)流。要完成这样的分词操作，我们首先需要定义出所有可能的标记模式（所谓模式（pattern），为用来描述或者匹配/系列匹配某个句法规则的字符串，这里我们用正则表达式来做为模式），注意此处要包括空格whitespace，否则字符串中出现任何模式中没有的字符后，扫描就会停止。因为我们还需要给标记以NAME、EQ等名称，我们采用正则表达式中的命名捕获组来实现。

一个简单的tokenizer
--------------

分词（tokenization）任务是Python字符串处理中最为常见任务了。我们这里讲解用正则表达式构建简单的表达式分词器（tokenizer），它能够将表达式字符串从左到右解析为标记(tokens)流。

给定如下的表达式字符串：

    text = 'foo = 12 + 5 * 6'
    

我们想要将其转换为下列以序列对呈现的分词结果：

    tokens = [('NAME', 'foo'), ('EQ', '='), ('NUM', '12'), ('PLUS', '+'),\
        ('NUM', '5'), ('TIMES', '*'), ('NUM', '6')]
    

要完成这样的分词操作，我们首先需要定义出所有可能的标记模式（所谓模式（pattern），为用来描述或者匹配/系列匹配某个句法规则的字符串，这里我们用正则表达式来做为模式），注意此处要包括空格whitespace，否则字符串中出现任何模式中没有的字符后，扫描就会停止。因为我们还需要给标记以NAME、EQ等名称，我们采用正则表达式中的命名捕获组来实现。

    import re
    NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)' 
    # 这里?P<NAME>表示模式名称，()表示一个正则表达式捕获组，合在一起即一个命名捕获组
    EQ = r'(?P<EQ>=)'
    NUM = r'(?P<NUM>\d+)' #\d表示匹配数字，+表示任意数量
    PLUS = r'(?P<PLUS>\+)' #需要用\转义
    TIMES = r'(?P<TIMES>\*)' #需要用\转义
    WS = r'(?P<WS>\s+)' #\s表示匹配空格， +表示任意数量
    master_pat = re.compile("|".join([NAME, EQ, NUM, PLUS, TIMES, WS]))  # | 用于选择多个模式，表示"或"
    

接下来我们用模式对象中的`scanner()`方法来完成分词操作，该方法创建一个扫描对象：

    scanner = master_pat.scanner(text)
    

然后可以用`match()`方法获取单次匹配结果，一次匹配一个模式：

    scanner = master_pat.scanner(text)
    m = scanner.match() 
    print(m.lastgroup, m.group()) # NAME foo
    m = scanner.match()
    print(m.lastgroup, m.group()) # WS
    

当然这样一次一次调用过于麻烦，我们可以使用迭代器来批量调用，并将单次迭代结果以具名元组形式存储

    Token = namedtuple('Token', ['type', 'value'])
    def generate_tokens(pat, text):
        scanner = pat.scanner(text)
        for m in iter(scanner.match, None):
            #scanner.match做为迭代器每次调用的方法，
            #None为哨兵的默认值，表示迭代到None停止
            yield Token(m.lastgroup, m.group())
        
    for tok in generate_tokens(master_pat, "foo = 42"):
        print(tok)
    

最终显示表达式串`"foo = 12 + 5 * 6"`的tokens流为：

    Token(type='NAME', value='foo')
    Token(type='WS', value=' ')
    Token(type='EQ', value='=')
    Token(type='WS', value=' ')
    Token(type='NUM', value='12')
    Token(type='WS', value=' ')
    Token(type='PLUS', value='+')
    Token(type='WS', value=' ')
    Token(type='NUM', value='5')
    Token(type='WS', value=' ')
    Token(type='TIMES', value='*')
    Token(type='WS', value=' ')
    Token(type='NUM', value='6')
    

过滤tokens流
---------

接下来我们想要过滤掉空格标记，使用生成器表达式即可：

    tokens = (tok for tok in generate_tokens(master_pat, "foo = 12 + 5 * 6")
              if tok.type != 'WS')
    for tok in tokens:
        print(tok)
    

可以看到空格被成功过滤：

    Token(type='NAME', value='foo')
    Token(type='EQ', value='=')
    Token(type='NUM', value='12')
    Token(type='PLUS', value='+')
    Token(type='NUM', value='5')
    Token(type='TIMES', value='*')
    Token(type='NUM', value='6')
    

注意子串匹配陷阱
--------

tokens在正则表达式(即`"|".join([NAME, EQ, NUM, PLUS, TIMES, WS])`)中顺序也非常重要。因为在进行匹配时，`re`模块就会按照指定的顺序对模式做匹配。故若碰巧某个模式是另一个较长模式的子串时，必须保证较长的模式在前面优先匹配。如下面分别展示正确的和错误的匹配方法：

    LT = r'(?P<LT><)'
    LE = r'(?P<LE><=)'
    EQ = r'(?P<EQ>>=)'
    master_pat = re.compile("|".join([LE, LT, EQ]))  # 正确的顺序
    master_pat = re.compile("|".join([LT, LE, EQ]))  # 错误的顺序
    

第二种顺序的错误之处在于，这样会把`'<='`文本匹配为LT(`'<'`)紧跟着EQ(`'='`)，而没有匹配为单独的LE(`<=`)。

我们对于“有可能”形成子串的模式也要小心，比如下面这样：

    PRINT = r'(?P<PRINT>print)'
    NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'
    
    master_pat = re.compile("|".join([PRINT, NAME]))  # 正确的顺序
    
    for tok in generate_tokens(master_pat, "printer"):
        print(tok)
    
    

可以看到被`print`实际上成了另一个模式的子串，导致另一个模式的匹配出现了问题：

    # Token(type='PRINT', value='print')
    # Token(type='NAME', value='er')
    

更高级的语法分词，建议采用像PyParsing或PLY这样的包。特别地，对于英文自然语言文章的分词，一般被集成到各类NLP的包中（一般分为按空格拆分、处理前后缀、去掉停用词三步骤）。对于中文自然语言处理分词也有丰富的工具（比如`jieba`分词工具包）。

引用
--

*   \[1\] Martelli A, Ravenscroft A, Ascher D. Python cookbook\[M\]. " O'Reilly Media, Inc.", 2015.

数学是符号的艺术，音乐是上界的语言。