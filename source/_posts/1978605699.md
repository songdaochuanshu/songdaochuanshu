---
layout: post
title: "极简组调度-CGroup如何限制cpu"
date: "2023-04-15T01:07:15.501Z"
---
极简组调度-CGroup如何限制cpu

**1\. 说明**

1> linux内核关于task调度这块是比较复杂的，流程也比较长，要从源码一一讲清楚很容易看晕，因此需要简化，抓住主要的一个点，抛开无关的部分才能讲清楚核心思想

2> 本篇文章主要是讲清楚在cfs公平调度算法中，CGroup如何限制cpu使用的主要过程，所以与此无关的代码一律略过

3> 本篇源码来自CentOS7.6的3.10.0-957.el7内核

4> 本篇内容以[《极简cfs公平调度算法》](https://www.cnblogs.com/organic/p/17320040.html)为基础，里面讲过的内容这里就不重复了

5> 为了极简，这里略去了CGroup嵌套的情况

**2\. CGroup控制cpu配置**

CGroup控制cpu网上教程很多，这里就不重点讲了，简单举个创建名为test的CGroup的基本流程

1> 创建一个/sys/fs/cgroup/cpu/test目录

2> 创建文件cpu.cfs\_period\_us并写入100000，创建cpu.cfs\_quota\_us并写入10000

表示每隔100ms(cfs\_period\_us)给test group分配一次cpu配额10ms(cfs\_quota\_us)，在100ms的周期内，group中的进程最多使用10ms的cpu时长，这样就能限制这个group最多使用单核10ms/100ms = 10%的cpu

3> 最后创建文件cgroup.procs，写入要限制cpu的pid即生效

**3\. CGroup控制cpu基本思想**

1> 《极简cfs公平调度算法》中我们讲过cfs调度是以se为调度实例的，而不是task，因为group se也是一种调度实例，所以将调度实例抽象为se，统一以se进行调度

![](https://img2023.cnblogs.com/blog/818872/202304/818872-20230415084851148-243944255.png)

2> CGroup会设置一个cfs\_period\_us的时长的定时器，定时给group分配cfs\_quota\_us指定的cpu配额

3> 每次group下的task执行完一个时间片后，就会从group的cpu quota减去该task使用的cpu时长

4> 当group的cpu quota用完后，就会将整个group se throttle，即将其从公平调度运行队列中移出，然后等待定时器触发下个周期重新分配cpu quota后，重启将group se移入到cpu rq上，从而达到控制cpu的效果。

一句话说明CGroup的控制cpu基本思想：

进程执行完一个时间片后，从cpu quota中减去其执行时间，当quota使用完后，就将其从rq中移除，这样在一个period内就不会再调度了。

**4. 极简CGroup控制cpu相关数据结构**

**4.1 名词解释**

**说明**

task group

进程组，为了支持CGroup控制cpu，引入了组调度的概念，task group即包含所有要控制cpu的task集合以及配置信息。

group task

本文的专有名词，是指一个进程组下的task，这些task受一个CGroup控制

cfs\_bandwidth

task\_group的重要成员，包含了所要控制cpu的period，quota，定时器等信息

throttle

当group se在一个设定的时间周期内，消耗完了指定的cpu配额，则将其从cpu运行队列中移出，并不再调度。

注意：处于throttled状态的task仍是Ready状态的，只是不在rq上。

unthrottle

将throttle状态的group se，重新加入到cpu运行队列中调度。

**4.2 cfs调度相关数据结构**

struct cfs\_rq
{
    struct rb\_root tasks\_timeline;                      // 以vruntime为key，se为value的红黑树根节点，schedule时，cfs调度算法每次从这里挑选vruntime最小的se投入运行
    struct rb\_node\* rb\_leftmost;                        // 最左的叶子节点，即vruntime最小的se，直接取这个节点以加快速度
    sched\_entity\* curr;                                 // cfs\_rq中当前正在运行的se
    struct rq\* rq;                                       /\* cpu runqueue to which this  cfs\_rq is attached \*/
    struct task\_group\* tg;                              /\* group that "owns" this  runqueue \*/
    int throttled;                                      // 表示该cfs\_rq所属的group se是否被throttled
    s64 runtime\_remaining;                              // cfs\_rq从全局时间池申请的时间片剩余时间，当剩余时间小于等于0的时候，就需要重新申请时间片
};
 
struct sched\_entity
{
    unsigned int            on\_rq;                          // se是否在rq上，不在的话即使task是Ready状态也不会投入运行的
    u64              vruntime;                              // cpu运行时长，cfs调度算法总是选择该值最小的se投入运行
    /\* rq on which this entity is (to be) queued: \*/
    struct cfs\_rq\* cfs\_rq;                        // se所在的cfs\_rq，如果是普通task  se，等于rq的cfs\_rq，如果是group中的task，则等于group的cfs\_rq
    /\* rq "owned" by this entity/group: \*/
    struct cfs\_rq\* my\_q;                          // my\_q == NULL表示是一个普通task se，否则表示是一个group se，my\_q指向group的cfs\_rq
};
 
struct task
{
    struct sched\_entity se;
};
 
struct rq
{
    struct cfs\_rq cfs;                          // 所有要调度的se都挂在cfs rq中
    struct task\_struct\* curr;                   // 当前cpu上运行的task
};

本文中的sched\_entity定义比[《极简cfs公平调度算法》](https://www.cnblogs.com/organic/p/17320040.html)中的要复杂些，各种cfs\_rq容易搞混，这里讲一下cfs公平调度挑选group task调度流程（只用到了my\_q这个cfs\_rq），以梳理清楚其关系

1> 当se.my\_q为NULL时，表示一个task se，否则是group se

2> 选择当group task3的流程

![](https://img2023.cnblogs.com/blog/818872/202304/818872-20230415084851184-756979868.png)

3> 选择当group task的代码

task\_struct \*pick\_next\_task\_fair(struct rq \*rq)
{
    struct cfs\_rq \*cfs\_rq = &rq->cfs;       // 开始的cfs\_rq为rq的cfs
    do {
        se \= pick\_next\_entity(cfs\_rq);      // 《极简cfs公平调度算法》中讲过这个函数，其就是取cfs\_rq->rb\_leftmost，即最小vruntime的se
        cfs\_rq = group\_cfs\_rq(se);          // 取se.my\_q，如果是普通的task se，cfs\_rq = NULL，这里就会退出循环，如果是group se，cfs\_rq = group\_se.my\_q，然后在group se的cfs\_rq中继续寻找vruntime最小的se
    } while (cfs\_rq);
  
    return task\_of(se);
}
 
cfs\_rq \*group\_cfs\_rq(struct sched\_entity \*grp)
{
    return grp->my\_q;
}

**4.3 CGroup控制cpu的数据结构**

struct cfs\_bandwidth
{
    ktime\_t period;                             // cpu.cfs\_period\_us的值
    u64 quota;                                  // cpu.cfs\_quota\_us的值
    u64 runtime;                                // 当前周期内剩余的quota时间
    int timer\_active;                           // period\_timer是否激活
    struct hrtimer period\_timer;                // 定时分配cpu quota的定时器，定时器触发时会更新runtime
};
 
struct task\_group
{
    struct sched\_entity\*\* se;                   /\* schedulable entities of this group  on each cpu \*/
    struct cfs\_rq\*\* cfs\_rq;                     /\* runqueue "owned" by this group on  each cpu \*/
    struct cfs\_bandwidth cfs\_bandwidth;         // 管理记录CGroup控制cpu的信息
};

1> task\_group.se是一个数组，每个cpu都有一个其对应的group se

![](https://img2023.cnblogs.com/blog/818872/202304/818872-20230415084851157-1952351171.png)

2>task\_group.cfs\_rq也是一个数组，每个cpu都有一个其对应的cfs\_rq，每个cpu上的group se.my\_q指向该cpu上对应的group cfs\_rq，group下的task.se.cfs\_rq也指向该group cfs\_rq

![](https://img2023.cnblogs.com/blog/818872/202304/818872-20230415084851179-802681373.png)

3> cfs\_bandwidth是CGroup管理控制cpu的关键数据结构，具体用途见定义

**5\. 极简流程图**

从throttle到unthrottle：

![](https://img2023.cnblogs.com/blog/818872/202304/818872-20230415084851183-844823687.png)

**6. 极简code**

**6.1 检测group se cpu quota的使用**

1>[《极简cfs公平调度算法》](https://www.cnblogs.com/organic/p/17320040.html)中我们讲过，task调度的发动机时钟中断触发后，经过层层调用，会到update\_curr()这里，update\_curr()不仅++了当前se的vruntime，还调用 account\_cfs\_rq\_runtime()统计并检测group se是否使用完了cpu quota

void update\_curr(struct cfs\_rq\* cfs\_rq)
{
    struct sched\_entity\* curr = cfs\_rq->curr;
    curr\->vruntime += delta\_exec;   // 增加se的运行时间
    account\_cfs\_rq\_runtime(cfs\_rq, delta\_exec);
}

2> account\_cfs\_rq\_runtime()--了cfs\_rq->runtime\_remaining，如果runtime\_remaining不足就调用assign\_cfs\_rq\_runtime()从task group中分配，当分配不到（即表示当前周期的cpu quota用完了）就设置resched标记

void account\_cfs\_rq\_runtime(struct cfs\_rq\* cfs\_rq, u64 delta\_exec)
{
    cfs\_rq\->runtime\_remaining -= delta\_exec;
    if (cfs\_rq->runtime\_remaining > 0)
        return;
    // 如果runtime\_remaining不够了，则要向task group分配cpu quota，分配失败则设置task的thread flag为TIF\_NEED\_RESCHED，表示需要重新调度
    if (!assign\_cfs\_rq\_runtime(cfs\_rq) && likely(cfs\_rq->curr))
        resched\_curr(cfs\_rq\->rq);
}

3> assign\_cfs\_rq\_runtime()就是从task\_group.cfs\_bandwidth.runtime减去要分配的时间片，如果其为0就分配失败

/\* returns 0 on failure to allocate runtime \*/
int assign\_cfs\_rq\_runtime(struct cfs\_rq\* cfs\_rq)
{
    struct cfs\_bandwidth\* cfs\_b = cfs\_rq->tg->cfs\_bandwidth;;
 
    // 如果有限制cpu，则减去最小分配时间，如果cfs\_b->runtime为0，那就没有时间可分配了，本函数就会返回0，表示分配失败
    amount = min(cfs\_b->runtime, min\_amount);
    cfs\_b\->runtime -= amount;
    cfs\_rq\->runtime\_remaining += amount;
    return cfs\_rq->runtime\_remaining > 0;
}

**6.2 throttle**

6.1中我们看到cpu quota被使用完了，标记了resched，要进行重新调度了，但并没有看到throttle。这是因为上面的代码还在中断处理函数中，是不能进行实际调度的，所以只设置resched标记，真正throttle干活的还是在schedule()中（还记得[《极简cfs公平调度算法》](https://www.cnblogs.com/organic/p/17320040.html)中讲的task运行时间片到了后，进行task切换，也是这样干的吗？）

![](https://img2023.cnblogs.com/blog/818872/202304/818872-20230415084851149-600469685.png "点击下载")

1> 每次中断返回返回或系统调用返回时(见ret\_from\_intr)，都会判定TIF\_NEED\_RESCHED标记，如有则会调用schedule()重新调度，《极简cfs公平调度算法》中未暂开讲put\_prev\_task\_fair()，而throttle就是在这里干的

void schedule()
{
    prev \= rq->curr;
    put\_prev\_task\_fair(rq, prev);
    // 选择下一个task并切换运行
    next = pick\_next\_task(rq);
    context\_switch(rq, prev, next);
}

2> put\_prev\_task\_fair() → put\_prev\_entity() → check\_cfs\_rq\_runtime()

void put\_prev\_task\_fair(struct rq\* rq, struct task\_struct\* prev)
{
    struct sched\_entity\* se = &prev->se;
    put\_prev\_entity(se\->cfs\_rq, se);
}
 
void put\_prev\_entity(struct cfs\_rq\* cfs\_rq, struct sched\_entity\* prev)
{
    check\_cfs\_rq\_runtime(cfs\_rq);
}

3> check\_cfs\_rq\_runtime()这里判定runtime\_remaining不足时，就要调用throttle\_cfs\_rq()进行throttle

void check\_cfs\_rq\_runtime(struct cfs\_rq\* cfs\_rq)
{
    if (cfs\_rq->runtime\_remaining > 0)
        return;
    throttle\_cfs\_rq(cfs\_rq);
}

4> throttle\_cfs\_rq()将group se从rq.cfs\_rq中移除，这样整个group下的task就不再会被调度了

void throttle\_cfs\_rq(struct cfs\_rq\* cfs\_rq)
{
    struct sched\_entity\*  se = cfs\_rq->tg->se\[cpu\_of(rq\_of(cfs\_rq))\];       // 取对应cpu rq上的group se
    dequeue\_entity(se->cfs\_rq, se, DEQUEUE\_SLEEP);                          //从cpu rq中删除group se
    cfs\_rq->throttled = 1;                                                  // 标记group cfs\_rq被throttled
}

**6.3 cpu quota重新分配**

6.2中group se被从rq移除后，不再会被调度，这时经过一个period周期，定时器激活后，就会再次加入到rq中重新调度

![](https://img2023.cnblogs.com/blog/818872/202304/818872-20230415084851157-523974700.png)

1> cfs\_bandwidth的定期器初始化回调函数为sched\_cfs\_period\_timer()

viod init\_cfs\_bandwidth(struct cfs\_bandwidth\* cfs\_b)
{
    hrtimer\_init(&cfs\_b->period\_timer, CLOCK\_MONOTONIC, HRTIMER\_MODE\_REL);
    cfs\_b\->period\_timer.function = sched\_cfs\_period\_timer;
}

2> 定时器到期后回调sched\_cfs\_period\_timer()，其只是简单调用实际干活的do\_sched\_cfs\_period\_timer()

enum hrtimer\_restart sched\_cfs\_period\_timer(struct hrtimer\* timer)
{
    idle \= do\_sched\_cfs\_period\_timer(cfs\_b, overrun);
    return idle ? HRTIMER\_NORESTART : HRTIMER\_RESTART;
}

3> do\_sched\_cfs\_period\_timer()调用\_\_refill\_cfs\_bandwidth\_runtime()重新分配task\_group的runtime，然后调用distribute\_cfs\_runtime()进行unthrottle

int do\_sched\_cfs\_period\_timer(struct cfs\_bandwidth\* cfs\_b, int overrun)
{
    \_\_refill\_cfs\_bandwidth\_runtime(cfs\_b);
    distribute\_cfs\_runtime(cfs\_b, runtime, runtime\_expires);
}

4> \_\_refill\_cfs\_bandwidth\_runtime()就是将task\_group.cfs\_bandwidth.runtime重置为设置的cpu quota

void \_\_refill\_cfs\_bandwidth\_runtime(struct cfs\_bandwidth\* cfs\_b)
{
    cfs\_b\->runtime = cfs\_b->quota;
}

5> distribute\_cfs\_runtime()调用unthrottle\_cfs\_rq()将所有se加回到rq上去，这样group下的task就能重新调度了

u64 distribute\_cfs\_runtime(struct cfs\_bandwidth\* cfs\_b, u64 remaining, u64  expires)
{
    struct cfs\_rq\* cfs\_rq;
    list\_for\_each\_entry\_rcu(cfs\_rq, &cfs\_b->throttled\_cfs\_rq, throttled\_list)
    {
        unthrottle\_cfs\_rq(cfs\_rq);
    }
}
 
void unthrottle\_cfs\_rq(struct cfs\_rq\* cfs\_rq)
{
    se \= cfs\_rq->tg->se\[cpu\_of(rq\_of(cfs\_rq))\];
    enqueue\_entity(cfs\_rq, se, ENQUEUE\_WAKEUP);     // 将se加回rq.cfs\_rq的红黑树上
}

本文为博主原创文章，如需转载请说明转至http://www.cnblogs.com/organic/

posted on 2023-04-15 08:52  [organic](https://www.cnblogs.com/organic/)  阅读(0)  评论(0)  [编辑](https://i.cnblogs.com/EditPosts.aspx?postid=17320490)  [收藏](javascript:void(0))  [举报](javascript:void(0))