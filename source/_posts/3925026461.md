---
layout: post
title: "è¯„ä¼°æŒ‡æ ‡ä¸è¯„åˆ†ï¼ˆä¸Šï¼‰ï¼šäºŒåˆ†ç±»æŒ‡æ ‡"
date: "2022-05-28T21:16:49.605Z"
---
è¯„ä¼°æŒ‡æ ‡ä¸è¯„åˆ†ï¼ˆä¸Šï¼‰ï¼šäºŒåˆ†ç±»æŒ‡æ ‡
================

ç²¾åº¦å¯ä»¥ä½œä¸ºåº¦é‡æ¨¡å‹å¥½åçš„ä¸€ä¸ªæŒ‡æ ‡ï¼Œå®ƒè¡¨ç¤ºé¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°å æ‰€æœ‰æ ·æœ¬æ•°çš„æ¯”ä¾‹ã€‚

ä½†æ˜¯åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¸ä»…å¯¹ç²¾ç¡®çš„é¢„æµ‹æ„Ÿå…´è¶£ï¼Œè¿˜å¸Œæœ›å°†è¿™äº›é¢„æµ‹ç»“æœç”¨äºæ›´å¤§çš„å†³ç­–è¿‡ç¨‹

1ã€ äºŒåˆ†ç±»æŒ‡æ ‡
--------

æˆ‘ä»¬å…ˆçœ‹ä¸€ä¸‹æµ‹é‡ç²¾åº¦å¯èƒ½ä¼šæ€ä¹ˆè¯¯å¯¼æˆ‘ä»¬

### 1.1é”™è¯¯ç±»å‹

â­ç²¾åº¦å¹¶ä¸èƒ½å¾ˆå¥½åœ°åº¦é‡é¢„æµ‹æ€§èƒ½ï¼Œå› ä¸ºæˆ‘ä»¬æ‰€çŠ¯å¾—é”™è¯¯å¹¶ä¸åŒ…æ‹¬æˆ‘ä»¬æ„Ÿå…´è¶£çš„æ‰€æœ‰ä¿¡æ¯ï¼š

ä¾‹å¦‚ï¼šæœ‰ä¸€ä¸ªè‡ªåŠ¨åŒ–æµ‹è¯•ç­›é€‰ç™Œç—‡ï¼Œå¦‚æœæµ‹è¯•ç»“æœä¸ºé˜´æ€§ï¼Œåˆ™è®¤ä¸ºè¯¥æ‚£è€…æ˜¯å¥åº·çš„ï¼Œè‹¥æ˜¯é˜³æ€§åˆ™éœ€è¦è¿›ä¸€æ­¥ç­›æŸ¥ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å°†é˜³æ€§æµ‹è¯•ç»“æœç§°ä¸ºæ­£ç±»ï¼Œé˜´æ€§ç»“æœç§°ä¸ºè´Ÿç±»ï¼Œ

äºæ˜¯å°±æœ‰äº†ä»¥ä¸‹**ä¸¤ç§å¸¸è§çš„é”™è¯¯ç±»å‹**ï¼š

ç¬¬ä¸€ç±»é”™è¯¯ï¼š**å‡æ­£ä¾‹**ï¼ˆé”™è¯¯çš„é˜³æ€§é¢„æµ‹ï¼Œå¯èƒ½å¯¼è‡´é¢å¤–è´¹ç”¨ï¼‰  
ç¬¬äºŒç±»é”™è¯¯ï¼š**å‡åä¾‹**ï¼ˆé”™è¯¯çš„é˜´æ€§é¢„æµ‹ï¼Œå¯èƒ½ä½¿å¾—ç—…äººæ— æ³•åŠæ—©å‘ç°ç—…æƒ…ï¼Œé€ æˆä¸¥é‡åæœï¼‰

### 1.2ä¸å¹³è¡¡æ•°æ®é›†

â­**ä¸å¹³è¡¡æ•°æ®é›†**ï¼šä¸€ä¸ªç±»åˆ«æ¯”å¦ä¸€ä¸ªç±»åˆ«å‡ºç°æ¬¡æ•°å¤šå¾ˆå¤šçš„æ•°æ®é›†

*   ç²¾åº¦æ— æ³•å¸®åŠ©æˆ‘ä»¬åŒºåˆ†ï¼š**ä¸å˜çš„â€˜æœªç‚¹å‡»â€™æ¨¡å‹**ä¸**æ½œåœ¨çš„ä¼˜ç§€æ¨¡å‹**

ä¸‹é¢å°†ç”¨åˆ°ï¼š

*   ä¸¤ä¸ª**è™šæ‹Ÿ**åˆ†ç±»å™¨ï¼šdummy\_majority(å§‹ç»ˆé¢„æµ‹å¤šæ•°ç±»)ï¼Œdummyï¼ˆäº§ç”Ÿéšæœºè¾“å‡ºï¼‰
*   ä¸¤ä¸ª**å¸¸ç”¨çš„**åˆ†ç±»æ¨¡å‹ï¼šLogisticRegressionï¼ŒDecissionTree

åˆ›å»ºæ•°æ®é›†

      #åˆ›å»ºä¸€ä¸ªä¸å¹³è¡¡æ•°æ®é›†
    
      from sklearn.datasets import load_digits
      import numpy as np
    
      digits = load_digits()
      y = digits.target==9
    
      print("ç±»åˆ«ï¼š{}".format(np.bincount(y)))
    
      '''
      `ç±»åˆ«ï¼š[1617  180]`
      '''
    

  

å»ºç«‹å››ä¸ªæ¨¡å‹

      from sklearn.dummy import DummyClassifier
      from sklearn.model_selection import train_test_split
      from sklearn.linear_model import LogisticRegression
      from sklearn.tree import DecisionTreeClassifier
    
    
      X_train,X_test,y_train,y_test = train_test_split(digits.data,y,random_state=0)
    
      #æ„å»ºå§‹ç»ˆé¢„æµ‹å¤§å¤šæ•°çš„æ¨¡å‹
    
    
    
      #å§‹ç»ˆé¢„æµ‹å¤šæ•°ç±»
      dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train,y_train)
      pred_most_frequent = dummy_majority.predict(X_test)
    
      print("å§‹ç»ˆé¢„æµ‹å¤šæ•°ç±» Test score:{:.2f}".format(dummy_majority.score(X_test,y_test)))
    
      #äº§ç”Ÿéšæœºè¾“å‡º
      dummy = DummyClassifier().fit(X_train,y_train)
      pred_dummy = dummy.predict(X_test)
      print("äº§ç”Ÿéšæœºè¾“å‡º Test score:{:.2f}".format(dummy.score(X_test,y_test)))
    
    
      #å†³ç­–æ ‘
      tree = DecisionTreeClassifier(max_depth=2).fit(X_train,y_train)
      pred_tree = tree.predict(X_test)
      print("å†³ç­–æ ‘ Test score:{:.2f}".format(tree.score(X_test,y_test)))
    
      #çº¿æ€§å›å½’
    
      lrg = LogisticRegression(C=0.1).fit(X_train,y_train)
      pred_logreg = lrg.predict(X_test)
      print("çº¿æ€§å›å½’ Test score:{:.2f}".format(lrg.score(X_test,y_test)))
    
    
      '''
      ```
      å§‹ç»ˆé¢„æµ‹å¤šæ•°ç±» Test score:0.90
      äº§ç”Ÿéšæœºè¾“å‡º Test score:0.82
      å†³ç­–æ ‘ Test score:0.92
      çº¿æ€§å›å½’ Test score:0.98
      ```
      '''
    

ğŸ“£

ä»ä¸Šé¢æˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œæƒ³è¦å¯¹è¿™ç§ä¸å¹³è¡¡çš„æ•°æ®é›†è¯„ä¼°æ€§èƒ½ï¼Œç²¾åº¦å¹¶ä¸æ˜¯ä¸€ç§åˆé€‚çš„åº¦é‡

*   å› ä¸ºç«Ÿç„¶è¿éšæœºè¾“å‡ºçš„é¢„æµ‹ç²¾åº¦éƒ½è¾¾åˆ°äº†0.81

æˆ‘ä»¬å¸Œæœ›æœ‰ä¸€ä¸ªæŒ‡æ ‡å¯ä»¥æ·˜æ±°è¿™äº›æ— æ„ä¹‰çš„é¢„æµ‹ï¼ˆæ¯”å¦‚ï¼Œé¢„æµ‹å¤šæ•°ç±»ã€éšæœºé¢„æµ‹ç­‰ï¼‰

### 1.3 æ··æ·†çŸ©é˜µ

â­å¯¹äºäºŒåˆ†ç±»é—®é¢˜çš„è¯„ä¼°ç»“æœï¼Œå¯ä»¥ä½¿ç”¨ï¼š**æ··æ·†çŸ©é˜µ**

      from sklearn.metrics import confusion_matrix
    
      #æ£€æŸ¥ä¸Šé¢çš„LogisticRegressionçš„è¯„ä¼°ç»“æœ
    
      confusion = confusion_matrix(y_test,pred_logreg)
      print("Confusion metrix:\n{}".format(confusion))
    
      '''
      ```
      Confusion metrix:
      [[402   1]
       [  6  41]]
      ```
      '''
    

  

      #æ··æ·†çŸ©é˜µçš„å«ä¹‰
      mglearn.plots.plot_confusion_matrix_illustration()
    

![](https://img2022.cnblogs.com/blog/2145457/202205/2145457-20220528162653347-1730915386.png)

ğŸ“£

æ··æ·†çŸ©é˜µä¸»å¯¹è§’çº¿ä¸Šçš„å…ƒç´ å¯¹åº”æ­£ç¡®çš„åˆ†ç±»ï¼Œ

è€Œå…¶ä»–å…ƒç´ åˆ™å‘Šè¯‰æˆ‘ä»¬ä¸€ä¸ªç±»åˆ«ä¸­æœ‰å¤šå°‘æ ·æœ¬è¢«é”™è¯¯åœ°åˆ’åˆ†åˆ°å…¶ä»–ç±»åˆ«ä¸­

![](https://img2022.cnblogs.com/blog/2145457/202205/2145457-20220528162744533-1874969428.png)

ğŸ“£

äºŒåˆ†ç±»å½“ä¸­

æˆ‘ä»¬å°†æ­£ç±»ä¸­æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬ç§°ä¸ºçœŸæ­£ä¾‹ï¼ˆTPï¼‰ï¼Œå°†åç±»ä¸­æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬ç§°ä¸ºçœŸåä¾‹ï¼ˆTNï¼‰

TP+FP+TN+FNï¼šæ ·æœ¬æ€»æ•°ã€‚  
TP+FNï¼šå®é™…æ­£æ ·æœ¬æ•°ã€‚  
TP+FPï¼šé¢„æµ‹ç»“æœä¸ºæ­£æ ·æœ¬çš„æ€»æ•°ï¼ŒåŒ…æ‹¬é¢„æµ‹æ­£ç¡®çš„å’Œé”™è¯¯çš„ã€‚  
FP+TNï¼šå®é™…è´Ÿæ ·æœ¬æ•°ã€‚  
TN+FNï¼šé¢„æµ‹ç»“æœä¸ºè´Ÿæ ·æœ¬çš„æ€»æ•°ï¼ŒåŒ…æ‹¬é¢„æµ‹æ­£ç¡®çš„å’Œé”™è¯¯çš„

â­æ€»ç»“æ··æ·†çŸ©é˜µæœ€å¸¸è§çš„æ–¹æ³•ï¼šå‡†ç¡®ç‡å’Œå¬å›ç‡

#### ï¼ˆ1ï¼‰å‡†ç¡®ç‡

![](https://img2022.cnblogs.com/blog/2145457/202205/2145457-20220528163902804-1104278304.png)

â­è¡¨ç¤ºçš„æ˜¯é¢„æµ‹ä¸ºæ­£çš„æ ·æœ¬ä¸­æœ‰å¤šå°‘æ˜¯çœŸæ­£çš„æ­£æ ·æœ¬

ç›®æ ‡ï¼šé™åˆ¶å‡æ­£ä¾‹çš„æ•°é‡

#### ï¼ˆ2ï¼‰å¬å›ç‡

![](https://img2022.cnblogs.com/blog/2145457/202205/2145457-20220528163916895-1765587458.png)

â­è¡¨ç¤ºçš„æ˜¯æ ·æœ¬ä¸­çš„æ­£ä¾‹æœ‰å¤šå°‘è¢«é¢„æµ‹ä¸ºæ­£ç±»ã€‚

ç›®æ ‡ï¼šæ‰¾å‡ºæ‰€æœ‰æ­£ç±»æ ·æœ¬ï¼Œé¿å…å‡åä¾‹

**ç™Œç—‡è¯Šæ–­å¾ˆé€‚åˆï¼**

#### ï¼ˆ3ï¼‰f1åˆ†æ•°

â­F1åˆ†æ•°ï¼ˆF1 Scoreï¼‰ï¼Œæ˜¯ç»Ÿè®¡å­¦ä¸­ç”¨æ¥è¡¡é‡äºŒåˆ†ç±»æ¨¡å‹ç²¾ç¡®åº¦çš„ä¸€ç§æŒ‡æ ‡ã€‚

*   å®ƒåŒæ—¶å…¼é¡¾äº†åˆ†ç±»æ¨¡å‹çš„ç²¾ç¡®ç‡å’Œå¬å›ç‡ã€‚
    
*   F1åˆ†æ•°å¯ä»¥çœ‹ä½œæ˜¯æ¨¡å‹ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„ä¸€ç§è°ƒå’Œå¹³å‡ï¼Œå®ƒçš„æœ€å¤§å€¼æ˜¯1ï¼Œæœ€å°å€¼æ˜¯0ã€‚
    
        from sklearn.metrics import f1_score
        
        print("f1 score most frequent:{:.2f}".format(f1_score(y_test,pred_most_frequent)))
        print("f1 score dummy:{:.2f}".format(f1_score(y_test,pred_dummy)))
        print("f1 score tree:{:.2f}".format(f1_score(y_test,pred_tree)))
        print("f1 score logisticregression:{:.2f}".format(f1_score(y_test,pred_logreg)))
        
        '''
        ```
        f1 score most frequent:0.00
        f1 score dummy:0.12
        f1 score tree:0.55
        f1 score logisticregression:0.92
        ```
        '''
        
    

ğŸ“£  
åˆ©ç”¨f1åˆ†æ•°ï¼Œæˆ‘ä»¬å¯ä»¥æ€»ç»“é¢„æµ‹æ€§èƒ½ï¼Œè¿™ä¸ªåˆ†æ•°æ›´åŠ ç¬¦åˆæˆ‘ä»¬å¯¹å¥½æ¨¡å‹çš„ç›´è§‰

  

      #ç”¨classification_reportåŒæ—¶è®¡ç®—å‡†ç¡®ç‡ï¼Œå¬å›ç‡ï¼Œf1åˆ†æ•°
    
      from sklearn.metrics import classification_report
    
      print(classification_report(y_test,pred_most_frequent,target_names=['not nine','nine']))
    
      '''
      ```
                precision    recall  f1-score   support
    
          not nine       0.90      1.00      0.94       403
              nine       0.00      0.00      0.00        47
    
          accuracy                           0.90       450
         macro avg       0.45      0.50      0.47       450
      weighted avg       0.80      0.90      0.85       450
      ```
      '''
    

#### ï¼ˆ4ï¼‰è€ƒè™‘ä¸ç¡®å®šæ€§

åœ¨skleanä¸­å¤§å¤šæ•°åˆ†ç±»å™¨æä¾›äº†ä¸€ä¸ªdecision\_fuctionæˆ–è€…predict\_probaæ–¹æ³•æ¥è¯„ä¼°é¢„æµ‹çš„ä¸ç¡®å®šåº¦

é¢„æµ‹å¯ä»¥è¢«çœ‹åšæ˜¯:ä»¥æŸä¸ªå›ºå®šç‚¹ä½œä¸ºdecision\_fuctionæˆ–è€…predict\_probaè¾“å‡ºçš„é˜ˆå€¼ï¼Œæ ·æœ¬ç‚¹é¢„æµ‹çš„ä¸ç¡®å®šæ€§è¶…è¿‡é˜ˆå€¼åˆ™è¢«åˆ’åˆ†ä¸ºæ­£ç±»/è´Ÿç±»

è€Œä¸”ï¼Œé€šè¿‡ä¿®æ”¹é˜ˆå€¼æˆ‘ä»¬å¯ä»¥æ”¹å˜æ¨¡å‹çš„å‡†ç¡®ç‡å’Œå¬å›ç‡

åœ¨äºŒåˆ†ç±»é—®é¢˜ä¸­:

*   ä½¿ç”¨0ä½œä¸ºå†³ç­–å‡½æ•°çš„é˜ˆå€¼
*   0.5ä½œä¸ºpredict\_probaçš„é˜ˆå€¼

from sklearn.model\_selection import train\_test\_split  
from mglearn.datasets import make\_blobs  
from sklearn.svm import SVC

X,y=make\_blobs(n\_samples=(400,50), centers=2, cluster\_std=(7,2), random\_state=22)

X\_train, X\_test, y\_train, y\_test=train\_test\_split(X, y, random\_state=22)

svc=SVC(gamma=0.5).fit(X\_train, y\_train)

mglearn.plots.plot\_decision\_threshold()

![](https://img2022.cnblogs.com/blog/2145457/202205/2145457-20220528163042703-1255431076.png)

classification\_reportå‡½æ•°

      #ä½¿ç”¨classification_reportå‡½æ•°æ¥è¯„ä¼°ä¸¤ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡ä¸å¬å”¤ç‡
    
      print("Classification report values:")
    
      print(classification_report(y_test, svc.predict(X_test)))
    
      '''
      ```
      Classification report values:
                    precision    recall  f1-score   support
    
                 0       0.92      0.95      0.94       102
                 1       0.38      0.27      0.32        11
    
          accuracy                           0.88       113
         macro avg       0.65      0.61      0.63       113
      weighted avg       0.87      0.88      0.88       113
      ```
      '''
    

ğŸ“£

ä»è¿è¡Œç»“æœå¾—çŸ¥ï¼Œå¯¹äºç±»åˆ«1ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªç›¸å½“ä½çš„å‡†ç¡®ç‡ï¼Œ  
ä¸è¿‡ç±»åˆ«0çš„å‡†ç¡®ç‡å´æ˜¯ä¸é”™ï¼Œæ‰€ä»¥åˆ†ç±»å™¨å°†é‡ç‚¹æ”¾åœ¨ç±»åˆ«0åˆ†ç±»æ­£ç¡®ï¼Œè€Œä¸æ˜¯ç±»åˆ«1.

å‡è®¾æˆ‘ä»¬åœ¨åº”ç”¨ä¸­ï¼Œç±»åˆ«1å…·æœ‰é«˜å¬å›ç‡æ›´åŠ é‡è¦ï¼Œå¦‚ç™Œç—‡ç­›æŸ¥(æˆ‘ä»¬å…è®¸è‡ªåŠ¨ç­›æŸ¥çš„æ—¶å€™è‡ªåŠ¨æ£€æŸ¥åˆ°çš„ä¸ºç™Œç—‡çš„äººé€šè¿‡äººå·¥æ£€æŸ¥æ²¡æœ‰å¾—åˆ°ç™Œç—‡ï¼Œä½†æ˜¯ä¸å…è®¸æœ¬äººå·²ç»å¾—åˆ°ç™Œç—‡äº†ä½†æ˜¯è‡ªåŠ¨æ£€æŸ¥å´å°†å…¶æ¼è¿‡ï¼Œè¿™æ ·ä¼šä½¿å¾—ç—…äººé”™è¿‡æœ€ä½³æ²»ç–—æ—¶æœŸ)ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬æ›´æ„¿æ„å†’é™©æœ‰æ›´å¤šçš„å‡æ­£ä¾‹(å‡çš„ç±»åˆ«ä¸º1)ï¼Œä»¥æ¢å–æ›´å¤šçš„çœŸæ­£ä¾‹(å¯ä»¥å¢å¤§å¬å›ç‡)ã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼Œdecision\_functionå€¼å¤§äº0çš„ç‚¹å°†è¢«è§„åˆ’ä¸ºç±»åˆ«1ï¼Œæˆ‘ä»¬å¸Œæœ›å°†æ›´å¤šçš„ç‚¹åˆ’ä¸ºç±»åˆ«1ï¼Œæ‰€ä»¥éœ€è¦å‡å°‘é˜ˆå€¼ã€‚å¯¹åº”ä»£ç å¦‚ä¸‹ï¼š

      y_pred_lower_threshold = svc.decision_function(X_test) > -.8
    
      #æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹è¿™ä¸ªé¢„æµ‹æŠ¥å‘Šï¼š
    
      print("The new Classification report values:")
    
      print(classification_report(y_test, y_pred_lower_threshold))
    
      '''
      ```
      The new Classification report values:
                    precision    recall  f1-score   support
    
                 0       0.94      0.87      0.90       102
                 1       0.28      0.45      0.34        11
    
          accuracy                           0.83       113
         macro avg       0.61      0.66      0.62       113
      weighted avg       0.87      0.83      0.85       113
      ```
      '''
    

ğŸ“£

é€šè¿‡è°ƒæ•´åï¼Œç±»åˆ«1çš„å¬å›ç‡å¢å¤§ï¼Œå‡†ç¡®ç‡é™ä½ã€‚  
ä½†æ˜¯å¾—åˆ°äº†æ›´å¤§çš„ç©ºé—´åŒºåŸŸåŒ–ä¸ºç±»åˆ«1.  
å¦‚æœéœ€è¦çš„æ˜¯æ›´é«˜çš„å‡†ç¡®ç‡çš„è¯ï¼Œé‚£ä¹ˆä¹Ÿé€šè¿‡æ”¹å˜ä¸ä¹‹çš„æ–¹æ³•å¾—åˆ°æ›´å¥½çš„ç»“æœã€‚

#### ï¼ˆ5ï¼‰å‡†ç¡®ç‡-å¬å›ç‡æ›²çº¿

â­ä¸€æ—¦è®¾å®šäº†ä¸€ä¸ªå…·ä½“ç›®æ ‡ï¼ˆæ¯”å¦‚å¯¹æŸä¸€ç±»åˆ«çš„ç‰¹å®šå¬å›ç‡æˆ–å‡†ç¡®ç‡ï¼‰ï¼Œå°±å¯ä»¥é€‚å½“çš„è®¾å®šä¸€ä¸ªé˜ˆå€¼

å·¥ä½œç‚¹ï¼šå¯¹åˆ†ç±»å™¨è®¾ç½®è¦æ±‚ï¼ˆæ¯”å¦‚90%çš„å¬å›ç‡ï¼‰

butï¼Œåœ¨å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¹¶ä¸å®Œå…¨æ¸…æ¥šå·¥ä½œç‚¹åœ¨å“ªé‡Œã€‚å› æ­¤ï¼Œä¸ºäº†æ›´å¥½åœ°ç†è§£å»ºæ¨¡é—®é¢˜ï¼Œå¾ˆæœ‰å¯å‘æ€§çš„åšæ³•æ˜¯ï¼š

*   åŒæ—¶æŸ¥çœ‹æ‰€æœ‰å®Œå…¨å¯èƒ½çš„é˜ˆå€¼æˆ–è€…å‡†ç¡®ç‡å’Œå¬å›ç‡ï¼š
    *   å‡†ç¡®ç‡-å¬å›ç‡æ›²çº¿
    *   sklearn.metricsæ¨¡å—(å‚æ•°ï¼šçœŸå®æ ‡ç­¾ï¼Œé¢„æµ‹çš„ä¸ç¡®å®šåº¦ï¼Œåè€…ç”±decision\_functionæˆ–è€…predict\_probaç»™å‡º)

  

      from sklearn.metrics import precision_recall_curve
      import numpy as np
      from matplotlib import pyplot as plt
    
    
      #åˆ©ç”¨è¿”å›çš„å‡†ç¡®ç‡å’Œå¬å›ç‡ï¼Œé˜ˆå€¼ï¼Œæˆ‘ä»¬å¯ä»¥ç»˜åˆ¶ä¸€æ¡æ›²çº¿
      X,y=make_blobs(n_samples=(4000,500), centers=2, cluster_std=(7,2), random_state=22)
    
      X_train, X_test, y_train, y_test=train_test_split(X, y, random_state=22)
    
      svc=SVC(gamma=0.05).fit(X_train, y_train)
    
    
      precision,recall,thresholds = precision_recall_curve(y_test,svc.decision_function(X_test))
    
      close_zero = np.argmin(np.abs(thresholds)) #æ‰¾åˆ°æœ€æ¥è¿‘0çš„é˜ˆå€¼
    
      plt.plot(precision[close_zero],recall[close_zero],'o',markersize=10,label="threshold zero",fillstyle='none',c='k',mew=2)
      plt.plot(precision,recall,label='precision recall curve')
      plt.xlabel("precision")
      plt.ylabel("recall")
      plt.legend()
    

![](https://img2022.cnblogs.com/blog/2145457/202205/2145457-20220528163617520-1984462911.png)

ğŸ“£

é»‘è‰²åœ†åœˆè¡¨ç¤ºé˜ˆå€¼ä¸º0çš„ç‚¹ï¼Œ0æ˜¯decision\_functionçš„é»˜è®¤å€¼  
åˆ©ç”¨è¿™ä¸ªæ¨¡å‹å¯ä»¥å¾—åˆ°çº¦0.5çš„å‡†ç¡®ç‡ï¼ŒåŒæ—¶ä¿æŒå¾ˆé«˜çš„å¬å›ç‡ã€‚  
æ›²çº¿å·¦ä¾§ç›¸å¯¹å¹³å¦ï¼Œè¯´æ˜åœ¨å‡†ç¡®ç‡æé«˜çš„åŒæ—¶å¬å›ç‡æ²¡æœ‰ä¸‹é™å¾ˆå¤šã€‚

æ›²çº¿è¶Šé è¿‘å³ä¸Šè§’ï¼Œåˆ™åˆ†ç±»å™¨è¶Šå¥½ï¼ˆæœ‰é«˜recallå’Œé«˜precisionï¼‰

â­

f1-åˆ†æ•°åªåæ˜ äº†å‡†ç¡®ç‡-å¬å›ç‡æ›²çº¿ä¸Šçš„ä¸€ä¸ªç‚¹ï¼Œå³é»˜è®¤é˜ˆå€¼å¯¹åº”çš„é‚£ä¸ªç‚¹ã€‚  
å¯¹äºè‡ªåŠ¨åŒ–æ¨¡å‹å¯¹æ¯”ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›æ€»ç»“æ›²çº¿ä¸­åŒ…å«çš„ä¿¡æ¯ï¼Œè€Œä¸é™äºæŸä¸ªç‰¹å®šçš„é˜ˆå€¼æˆ–å·¥ä½œç‚¹

æ€»ç»“å‡†ç¡®ç‡-å¬å›ç‡æ›²çº¿çš„ä¸€ç§æ–¹æ³•æ˜¯ï¼šè®¡ç®—è¯¥æ›²çº¿ä¸‹çš„ç§¯åˆ†æˆ–é¢ç§¯ï¼Œä¹Ÿå«åšå¹³å‡å‡†ç¡®ç‡

*   average\_precision\_scoreå‡½æ•°æ¥è®¡ç®—å¹³å‡å‡†ç¡®ç‡

#### ï¼ˆ6ï¼‰å—è¯•è€…å·¥ä½œç‰¹å¾ï¼ˆROCï¼‰ä¸AUC

â­ROCæ›²çº¿å›¾æ˜¯åæ˜ æ•æ„Ÿæ€§ä¸ç‰¹å¼‚æ€§ä¹‹é—´å…³ç³»çš„æ›²çº¿ã€‚  
æ¨ªåæ ‡Xè½´ä¸º 1 â€“ ç‰¹å¼‚æ€§ï¼Œä¹Ÿç§°ä¸ºå‡é˜³æ€§ç‡ï¼ˆè¯¯æŠ¥ç‡ï¼‰ï¼ŒXè½´è¶Šæ¥è¿‘é›¶å‡†ç¡®ç‡è¶Šé«˜ï¼›  
çºµåæ ‡Yè½´ç§°ä¸ºæ•æ„Ÿåº¦ï¼Œä¹Ÿç§°ä¸ºçœŸé˜³æ€§ç‡ï¼ˆæ•æ„Ÿåº¦ï¼‰ï¼ŒYè½´è¶Šå¤§ä»£è¡¨å‡†ç¡®ç‡è¶Šå¥½ã€‚

æ ¹æ®æ›²çº¿ä½ç½®ï¼ŒæŠŠæ•´ä¸ªå›¾åˆ’åˆ†æˆäº†ä¸¤éƒ¨åˆ†ï¼Œæ›²çº¿ä¸‹æ–¹éƒ¨åˆ†çš„é¢ç§¯è¢«ç§°ä¸ºAUCï¼ˆArea Under Curveï¼‰ï¼Œç”¨æ¥è¡¨ç¤ºé¢„æµ‹å‡†ç¡®æ€§ï¼Œ  
AUCå€¼è¶Šé«˜ï¼Œä¹Ÿå°±æ˜¯æ›²çº¿ä¸‹æ–¹é¢ç§¯è¶Šå¤§ï¼Œè¯´æ˜é¢„æµ‹å‡†ç¡®ç‡è¶Šé«˜ã€‚  
æ›²çº¿è¶Šæ¥è¿‘å·¦ä¸Šè§’ï¼ˆXè¶Šå°ï¼ŒYè¶Šå¤§ï¼‰ï¼Œé¢„æµ‹å‡†ç¡®ç‡è¶Šé«˜ã€‚

      from sklearn.metrics import roc_curve
      fpr,tpr,thresholds = roc_curve(y_test,svc.decision_function(X_test))
    
      #ç”»å›¾
      plt.plot(fpr,tpr,label='ROC Curve')
      plt.xlabel("FPR")
      plt.ylabel("TPR(recall)")
    
      #æ‰¾åˆ°æœ€æ¥è¿‘äº0çš„é˜ˆå€¼
      close_zero = np.argmin(np.abs(thresholds)) #æ‰¾åˆ°æœ€æ¥è¿‘0çš„é˜ˆå€¼
      plt.plot(fpr[close_zero],tpr[close_zero],'o',markersize=10,label="threshold zero",fillstyle='none',c='k',mew=2)
      plt.legend()
    

![](https://img2022.cnblogs.com/blog/2145457/202205/2145457-20220528163721087-1305646157.png)

ğŸ“£

ROCæ›²çº¿ï¼šç†æƒ³çš„æ›²çº¿è¦é è¿‘å·¦ä¸Šè§’

*   åˆ†ç±»å™¨çš„å¬å›ç‡å¾ˆé«˜ï¼ŒåŒæ—¶ä¿è¯å‡æ­£ç‡å¾ˆä½
    
        #ç”¨ä¸€ä¸ªæ•°å­—æ¥æ€»ç»“ROCæ›²çº¿ï¼šæ›²çº¿ä¸‹çš„é¢ç§¯ï¼ˆAUCï¼‰
        #roc_auc_score
        
        from sklearn.metrics import roc_auc_score
        
        svc_auc = roc_auc_score(y_test,svc.decision_function(X_test))
        print("AUC for SVC:{:.3f}".format(svc_auc))
        
        '''
        `AUC for SVC:0.936`
        '''
        
    

å¯¹äºä¸å¹³è¡¡çš„åˆ†ç±»é—®é¢˜æ¥è¯´ï¼ŒAUCæ˜¯ä¸€ä¸ªæ¯”ç²¾åº¦å¥½å¾—å¤šçš„æŒ‡æ ‡.

2ã€å‚è€ƒæ–‡çŒ®
------

ã€Špythonæœºå™¨å­¦ä¹ åŸºç¡€æ•™ç¨‹ã€‹