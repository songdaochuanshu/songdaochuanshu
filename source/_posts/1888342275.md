---
layout: post
title: "Flink基础概念入门"
date: "2022-09-18T12:37:21.544Z"
---
Flink基础概念入门
===========

Flink 概述
--------

### 什么是 Flink

    Apache Apache Flink 是一个开源的流处理框架，应用于分布式、高性能、高可用的数据流应用程序。可以处理有限数据流和无限数据，即能够处理有边界和无边界的数据流。无边界的数据流就是真正意义上的流数据，所以 Flink 是支持流计算的。有边界的数据流就是批数据，所以也支持批处理的。不过 Flink 在流处理上的应用比在批处理上的应用更加广泛，统一批处理和流处理也是 Flink 目标之一。Flink 可以部署在各种集群环境，可以对各种大小规模的数据进行快速计算。

*   2010~2014Flink 起源于柏林理工大学的研究性项目 Stratosphere
*   2014 年该项目被捐赠给 Apache 软件基金会
*   2014 年 12 月 Flink 一跃成为 Apache 软件基金会的顶级项目之一

> 在德语中，Flink 一词表示快速和灵巧，项目采用一只松鼠的彩色图案作为 logo，这不仅是因为松鼠具有快速和灵巧的特点，还因为柏林的松鼠有一种迷人的红棕色，而 Flink 的松鼠 logo 拥有可爱的尾巴，尾巴的颜色与 Apache 软件基金会的 logo 颜色相呼应，也就是说，这是一只 Apache 风格的松鼠  
> ![](https://img2022.cnblogs.com/blog/1178991/202209/1178991-20220917230831502-1634248185.png)

### Flink 的特点

Flink 有如下特点：

*   批流一体：统一批处理和流处理
*   分布式：Flink 程序可以运行在分布式环境下
*   高性能
*   高可用
*   准确性：Flink 可以保证数据处理的准确性

### Flink 应用场景

Flink 主要应用于流式数据分析场景

*   实时 ETL

> Extraction-Transformation-Loading 的缩写,中文名称为数据抽取、转换和加载.

集成流计算现有的诸多数据通道和 SQL 灵活的加工能力，对流式数据进行实时清晰、归并和结构化处理；同时，对离线数仓进行有效的补充和优化，并为数据实时传输提供可计算通道。

*   实时报表

实时化采集，加工流式数据存储；实时监控和展现业务、客户各类指标，让数据化运营实时化。

*   监控预警

对系统和用户行为进行实时监测和分析，以便及时发现危险行为。

*   在线系统

实时计算各类数据指标，并利用实时结果及时调整在线系统的相关策略，并应用于内容投放、智能推送领域。

### Flink 核心组成及生态发展

![](https://img2022.cnblogs.com/blog/1178991/202209/1178991-20220917232030529-454350059.png)

**Flink 核心组成**

*   Deploy 层：  
    Flink 支持本地运行、能在独立集群或者在被 YARN 或 Mesos 管理的集群上运行，也能部署在云上
*   Core 层：  
    Flink 的核心是分布式流式数据引擎，意味着数据以一次一个事件的形式被处理
*   API 层：  
    DataStream、DataSet、Table、SQL API
*   扩展库：Flink 还包括了用于复杂事件处理、机器学习、图像处理和 Apache Storm 兼容的专用代码库

**Flink 生态发展**

![](https://img2022.cnblogs.com/blog/1178991/202209/1178991-20220917233341835-393984834.png)

*   输入 Connectors(左侧部分)
    
    *   流处理方式：包含 Kafka、AWS kinesis（实时数据流服务）、RabbitMQ、NIFI（数据管道）、Twitter（API）
        
    *   批处理方式：包含 HDFS、HBase、Amazon S3（文件系统）、MapR FS（文件系统）、ALLuxio（基于内存的分布式文件系统）
        
*   中间是 Flink 核心部分
    
*   输出 Connectors(右侧部分)
    
    *   流处理方式：包含 Kafka、AWS kinesis（实时数据流服务）、RabbitMQ、NIFI（数据管道）、Cassandra（NoSQL 数据库）、ES、HDFS rolling file（滚动文件）
        
    *   批处理方式：包含 HBase、HDFS
        

### 流处理引擎的技术选型

**计算框架对比图**：

产品

模型

API

保证次数

容错机制

状态管理

延时

吞吐量

storm

Native(数据进入立即处理)

组合式

At-least-once

Record ACKS

无

Low

Low

Trident

mirco-batching（划分为小批处理）

组合式

Exectly-once

Record ACKs

基于操作（每次操作由一个状态）

Medium

Medium

Spark streaming

mirco-batching

声明式（提供封装后的高阶函数）

Exectly-once

RDD Checkpoint

基于 DStream

Medium

High

Flink

Native

声明式

Exectly-once

Checkpoint

基于操作

Low

Hign

市面上的流处理引擎不止 Flink 一种，其他的比如 Storm、SparkStreaming、Trident 等，如何进行选型，给大家一些建议：

*   流数据要进行状态管理，选择使用 Trident、Spark Streaming 或者 Flink
*   消息传递需要保证 At-least-once（至少一次）或者 Exacly-once（仅一次）不能选择 Storm
*   对于小型独立项目，有低延迟要求，可以选择使用 Storm，更简单
*   如果项目已经引入了 Spark，实时处理需求可以满足的话，建议直接使用 Spark 中的 Spark Streaming
*   消息投递要满足 Exactly-once(仅一次)，数据量大、有高吞吐、低延迟要求，要进行状态管理或窗口统计，建议使用 Flink

书山有路勤为径，学海无涯苦作舟