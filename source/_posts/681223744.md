---
layout: post
title: "CVPR2022 | 弱监督多标签分类中的损失问题"
date: "2022-06-22T01:55:51.206Z"
---
CVPR2022 | 弱监督多标签分类中的损失问题
=========================

> 前言 本文提出了一种新的弱监督多标签分类（WSML）方法，该方法拒绝或纠正大损失样本，以防止模型记忆有噪声的标签。由于没有繁重和复杂的组件，提出的方法在几个部分标签设置（包括Pascal VOC 2012、MS COCO、NUSWIDE、CUB和OpenImages V3数据集）上优于以前最先进的WSML方法。各种分析还表明，方法的实际效果很好，验证了在弱监督的多标签分类中正确处理损失很重要。

欢迎关注公众号[CV技术指南](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495585%26idx%3D2%26sn%3D5df76c5d0956cc998e9bbb21b86ca460%26chksm%3Dc19450bff6e3d9a9d72330f85cf37ffb446cbc70f3a83c492ad8214c82005605c196a875b148%26token%3D1526765687%26lang%3Dzh_CN%23rd "CV技术指南")，专注于计算机视觉的技术总结、最新技术跟踪、经典论文解读、CV招聘信息。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/085c7c95232048c08c430a9500b26916~tplv-k3u1fbpfcp-zoom-1.image)​

论文：Large Loss Matters in Weakly Supervised Multi-Label Classification

论文：[http://arxiv.org/pdf/2206.03740](https://link.zhihu.com/?target=http%3A//arxiv.org/pdf/2206.03740 "http://arxiv.org/pdf/2206.03740")

代码：[https://github.com/snucml/LargeLossMatters](https://link.zhihu.com/?target=https%3A//github.com/snucml/LargeLossMatters "https://github.com/snucml/LargeLossMatters")

背景
--

弱监督多标签分类（WSML）任务是利用每幅图像的部分观察标签来学习多标签分类，由于其巨大的标注成本，变得越来越重要。

目前，有两种简单的方法可以使用部分标签来训练模型。一种是只使用观察到的标签来训练模型，而忽略未观察到的标签。另一种是假设所有未观察到的标签都是负面的，并将其纳入训练，因为在多标签设置中，大多数标签都是负面的。

但第二种方法有一个局限性，即这种假设会在标签中产生一些噪声，从而妨碍模型学习，因此之前的工作大多遵循第一种方法，并尝试使用各种技术（如引导或正则化）探索未观察标签的线索。然而，这些方法包括大量计算或复杂的优化管道。

基于以上思路，作者假设，如果标签噪声能够得到妥善处理，第二种方法可能是一个很好的起点，因为它具有将许多真正的负面标签纳入模型训练的优势。因此，作者就从噪声标签学习的角度来看待WSML问题。

众所周知，当训练带有噪声标签的模型时，该模型首先适应干净的标签，然后开始记忆噪声标签。虽然之前的研究表明记忆效应仅在有噪声的多类别分类场景中存在，但作者发现，在有噪声的多标签分类场景中也存在同样的效应。如图1所示，在训练期间，来自干净标签（真负样本）的损失值从一开始就减小，而来自噪声标签（假负样本）的损失从中间减小。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cc903c24885541ec8d46914f3f53d09e~tplv-k3u1fbpfcp-zoom-1.image)​

图1 WSML中的记忆效应

基于这一发现，作者开发了三种不同的方案，通过在训练过程中拒绝或纠正大损失样本，防止误报标签被记忆到多标签分类模型中。

贡献
--

1） 首次通过实验证明，记忆效应发生在有噪声的多标签分类过程中。

2） 提出了一种新的弱监督多标签分类方案，该方案明确利用了带噪声标签的学习技术。

3）提出的方法轻巧且简单，在各种部分标签数据集上实现了最先进的分类性能。

方法
--

在本文中，作者提出了新的WSML方法，其动机是基于噪声多类学习的思想，它忽略了模型训练过程中的巨大损失。通过在损失函数中进一步引入了权重项λi：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ea1e25e58c4042f5b8925c6db6a21199~tplv-k3u1fbpfcp-zoom-1.image)​

作者提出了三种提供权重λi的不同方案，示意图描述如图2所示。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d8967fe6a96f464d8ef00b0e7fbb0159~tplv-k3u1fbpfcp-zoom-1.image)​

图2 提出的方法的总体管道

### 1.损失拒绝

处理大损耗样本的一种方法是通过设置λi=0来拒绝它。在有噪声的多类任务中，B.Han等人提出了一种在训练过程中逐渐增加拒绝率的方法。作者同样设置函数λi，

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0958bb96e77c45ca8dab9a6443bb5781~tplv-k3u1fbpfcp-zoom-1.image)​

由于模型在初始阶段学习干净的模式，因此在t=1时不拒绝任何损失值。在每次迭代中使用小批量而不是完整批量D′来组成损失集。作者将此方法称为LL-R。

### 2\. 损失纠正（临时）

处理大损失样本的另一种方法是纠正而不是拒绝它。在多标签设置中，可以通过将相应的注释从负值切换到正值来轻松实现这一点。“临时”一词的意思是，它不改变实际标签，而只使用根据修改后的标签计算的损失，将函数λi定义为

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/78f917f5750d43d2a52f2bd5b0a532f6~tplv-k3u1fbpfcp-zoom-1.image)​

作者将此方法命名为LL-Ct。这种方法的优点是，它从未观察到的标签中增加了真实阳性标签的数量。

### 3\. 损失纠正（永久）

通过永久更正标签来更积极地处理较大的损失值。直接将标签从阴性改为阳性，并在下一个训练过程中使用修改后的标签。为此，为每种情况定义λi=1，并修改标签如下：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f21a3ec096b044a49cf11ab7ab0284b8~tplv-k3u1fbpfcp-zoom-1.image)​

作者将此方法命名为LL-Cp。

实验
--

表2 人为创建的部分标签数据集的定量结果

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c81ca5a3746241e49aac12bdcdfba344~tplv-k3u1fbpfcp-zoom-1.image)​

表3 OpenImages V3数据集中的定量结果

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f86e2cf91c0f4642a4f05dda70d6ee42~tplv-k3u1fbpfcp-zoom-1.image)​

图3 人为生成COCO部分标签数据集的定性结果

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f5a544f2c60341a28f9e495a3a89d97a~tplv-k3u1fbpfcp-zoom-1.image)​

图4 COCO数据集上建议的方法的精度分析

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/22020f8278cc424c9208a21e22e035d2~tplv-k3u1fbpfcp-zoom-1.image)​

图5 LL-Ct对COCO数据集的超参数效应

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5b5e7914a8634352968badf11079f8bd~tplv-k3u1fbpfcp-zoom-1.image)​

图6 使用较少数量的图像进行训练

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8a8afbaa735a4174bea11d47192b5dd8~tplv-k3u1fbpfcp-zoom-1.image)​

表4 Pointing Game

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5e2edfff3241435193a7aebadbf013b3~tplv-k3u1fbpfcp-zoom-1.image)​

结论
--

在本文中，作者提出了损失修改方案，该方案拒绝或纠正了在训练带有部分标记注释的多标签分类模型时出现的大损失样本。这源于经验观察，即记忆效应也发生在嘈杂的多标签分类场景中。

虽然不包括繁重的和复杂的组件，但作者的方案成功地防止了多标签分类模型记忆有噪声的假阴性标签，在各种部分标记的多标签数据集上实现了最先进的性能。

\---------------------------------------------------------------------------------

CV技术指南创建了一个计算机视觉技术交流群和免费版的知识星球，目前星球内人数已经700+，主题数量达到200+。

知识星球内将会每天发布一些作业，用于引导大家去学一些东西，大家可根据作业来持续打卡学习。CV技术群内每天都会发最近几天出来的顶会论文，大家可以选择感兴趣的论文去阅读，持续follow最新技术，若是看完后写个解读给我们投稿，还可以收到稿费。 另外，技术群内和本人朋友圈内也将发布各个期刊、会议的征稿通知，若有需要的请扫描加好友，并及时关注。

加群加星球方式：关注公众号CV技术指南，获取编辑微信，邀请加入。

欢迎关注公众号[CV技术指南](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495585%26idx%3D2%26sn%3D5df76c5d0956cc998e9bbb21b86ca460%26chksm%3Dc19450bff6e3d9a9d72330f85cf37ffb446cbc70f3a83c492ad8214c82005605c196a875b148%26token%3D1526765687%26lang%3Dzh_CN%23rd "CV技术指南")，专注于计算机视觉的技术总结、最新技术跟踪、经典论文解读、CV招聘信息。

![](https://img2022.cnblogs.com/blog/1432790/202206/1432790-20220621211804180-1034739751.png)

欢迎可以写以下内容的朋友联系我（关注公众号后获取联系方式）。

1.  **最新顶会的解读。例如最近的CVPR2022论文。**
2.  **各个方向的系统性综述、主要模型发展演变、各个模型的创新思路和优缺点、代码解析等**。如目标检测大总结：对目标检测从传统方法到深度学习的所有大总结，主要包括传统方法检测、RCNN系列、YOLO系列、anchor-free系列、小目标检测方法总结、小样本目标检测方法总结、视频中的目标检测方法总结、目标检测使用的损失函数总结等内容。**支持边学边写**。
3.  TVM入门到实践的教程
4.  MNN入门到实践的教程
5.  OpenVINO入门到实践的教程
6.  libtorch入门到实践的教程
7.  Oneflow入门到实践的教程
8.  Detectron入门到实践的教程
9.  caffe源码阅读
10.  深度学习从入门到精通（从卷积神经网络开始讲起）
11.  若自己有想写的且这上面没提到的，可以跟我联系。声明：有报酬，具体请联系详谈。

公众号其它文章
-------

[计算机视觉入门路线](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247494483%26idx%3D1%26sn%3D7069ade230575cfcb1c1f8c8e8763ecb%26chksm%3Dc194544df6e3dd5bea7a98723b764c7db8591e292a775c4c465f715acc260d5d1fc53aa6487c%26payreadticket%3DHIjWViK3B_NTMPuq4Zzm_wEIyKtyvPbtyDFiQTwJsqOLFvAW28Qv38O0pcR_VdMzz15Xsb0%23rd "计算机视觉入门路线")

[计算机视觉中的论文常见单词总结](https://mp.weixin.qq.com/s?__biz=MzkyMDE2OTA3Mw==&mid=2247496011&idx=2&sn=6d48b3e084a73f521a6e372809cfa1e0&chksm=c1944e55f6e3c7433a6a7f8a3354125c5c8a2ea46020fa30d5fdfbf7c52cf148d627a94d59fa&token=1421245552&lang=zh_CN#rd "计算机视觉中的论文常见单词总结")

[YOLO系列梳理（四）关于YOLO的部署](https://mp.weixin.qq.com/s?__biz=MzkyMDE2OTA3Mw==&mid=2247495965&idx=1&sn=d111ac563865f101b39bad6f949e333e&chksm=c1944e03f6e3c71599b359defe93b955c3b0e2f8147f24cb197a84d05a442362e47b9275a6c7&token=1421245552&lang=zh_CN#rd "YOLO系列梳理（四）关于YOLO的部署")

[YOLO系列梳理（三）YOLOv5](https://mp.weixin.qq.com/s?__biz=MzkyMDE2OTA3Mw==&mid=2247494638&idx=1&sn=ac84cfb2e3d2e346aa766ff5c5185609&chksm=c19454f0f6e3dde67258380c28b9882b7453a37f0d657bdbf85e407e0e8f4d2650d7384f037e&token=1421245552&lang=zh_CN#rd "YOLO系列梳理（三）YOLOv5")

[YOLO系列梳理（二）YOLOv4](https://mp.weixin.qq.com/s?__biz=MzkyMDE2OTA3Mw==&mid=2247494393&idx=1&sn=cdbad1b535816a06213cac31e7d8e4db&chksm=c19455e7f6e3dcf19d9eb19ed8aa22ddc23d2c5553ebfe5ff46f82b2534894316363975a603a&token=1421245552&lang=zh_CN#rd "YOLO系列梳理（二）YOLOv4")

[YOLO系列梳理（一）YOLOv1-YOLOv3](https://mp.weixin.qq.com/s?__biz=MzkyMDE2OTA3Mw==&mid=2247494324&idx=1&sn=8e8eeb92ede34988d7b7c46837c3d308&chksm=c19455aaf6e3dcbc91020d6c559a7539e3ece7b0fa13104b486c48cf9662ef2ce2188cfebb91&token=1421245552&lang=zh_CN#rd "YOLO系列梳理（一）YOLOv1-YOLOv3")

[CVPR2022 | 基于自我中心数据的OCR评估](https://mp.weixin.qq.com/s?__biz=MzkyMDE2OTA3Mw==&mid=2247496273&idx=2&sn=55c822931d8ab2ddc7e1d1d51e7ac71b&chksm=c1944d4ff6e3c4590d05e9fb6f46b4d7fc5f2eaf539d0a45387025c2805961b0313de048ddae&token=1421245552&lang=zh_CN#rd "CVPR2022 | 基于自我中心数据的OCR评估")

[CVPR 2022 | 使用对比正则化方法应对噪声标签](https://mp.weixin.qq.com/s?__biz=MzkyMDE2OTA3Mw==&mid=2247495946&idx=1&sn=85ba25eee4db64dbd88b95fa2ccc7e36&chksm=c1944e14f6e3c702818f5ef87cb7a981969d9fa90e63850668318a11f6ae87d8a5bcd8f37ac8&token=1421245552&lang=zh_CN#rd "CVPR 2022 | 使用对比正则化方法应对噪声标签")

[CVPR2022 | 弱监督多标签分类中的损失问题](https://mp.weixin.qq.com/s?__biz=MzkyMDE2OTA3Mw==&mid=2247496143&idx=1&sn=878fe644077193937ad07ceb87b0809f&chksm=c1944ed1f6e3c7c7dab4e312981a68cca45c43165852c3763a3e95538a703331d97a057ea862&token=1421245552&lang=zh_CN#rd "CVPR2022 | 弱监督多标签分类中的损失问题")

[CVPR2022 | iFS-RCNN：一种增量小样本实例分割器](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495819%26idx%3D1%26sn%3Dc5fd1d9fc523964b4cd557f8351ea0a0%26chksm%3Dc1944f95f6e3c6839a94da66493635489352ed4f49a1eeb33ab4dc2624be6eac379ab136e3d9%26token%3D1812044639%26lang%3Dzh_CN%23rd "CVPR2022 | iFS-RCNN：一种增量小样本实例分割器")

[CVPR2022 | Time 3D:用于自动驾驶的端到端联合单目三维物体检测与跟踪](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495789%26idx%3D2%26sn%3D2c82d7a5ff6a27b1904528c69f0a5f08%26chksm%3Dc1944f73f6e3c6658f03c2cf14f04784c4753146e7d8e4e43fbe8caa7d678ae919258eec64ed%26token%3D1812044639%26lang%3Dzh_CN%23rd "CVPR2022 | Time 3D:用于自动驾驶的端到端联合单目三维物体检测与跟踪")

[CVPR2022 | A ConvNet for the 2020s & 如何设计神经网络总结](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495738%26idx%3D1%26sn%3De480949d62c3183da82c08bc9b67293b%26chksm%3Dc1944f24f6e3c6327f1768aa8035807d9b5fe47a07ec272edffe331455aefb1f8ae0b60e3ef2%26token%3D1812044639%26lang%3Dzh_CN%23rd "CVPR2022 | A ConvNet for the 2020s & 如何设计神经网络总结")

[CVPR2022 | PanopticDepth：深度感知全景分割的统一框架](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495700%26idx%3D1%26sn%3D61afff6b3b5a545a433de5d2cd95f52b%26chksm%3Dc1944f0af6e3c61c8a6a22bbe4e3e4f5604d46225723bafc0b3592ef6910334ceb766b9aa2af%26token%3D1812044639%26lang%3Dzh_CN%23rd "CVPR2022 | PanopticDepth：深度感知全景分割的统一框架")

[CVPR2022 | 重新审视池化：你的感受野不是最理想的](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495644%26idx%3D1%26sn%3D23d4728e50f911c0eab24aa2073fd4e5%26chksm%3Dc19450c2f6e3d9d4c85eef2243bfd1896529fc8d7de377879b7147623902753a0f325a743e6f%26token%3D1526765687%26lang%3Dzh_CN%23rd "CVPR2022 | 重新审视池化：你的感受野不是最理想的")

[CVPR2022 | 未知目标检测模块STUD：学习视频中的未知目标](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495622%26idx%3D1%26sn%3D1e57c7ccb630186219e6471b28a159ba%26chksm%3Dc19450d8f6e3d9ceee6acab0867a7decf5ea600e7f9029b2920df3c96051524ee289970d0ba3%26token%3D1526765687%26lang%3Dzh_CN%23rd "CVPR2022 | 未知目标检测模块STUD：学习视频中的未知目标")

[CVPR2022 | 基于排名的siamese视觉跟踪](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495554%26idx%3D1%26sn%3D74c2069f4db40459f536c9748bcdf190%26chksm%3Dc194509cf6e3d98a957012a496e85701ceef49efe2383917dd6358ae56a0c7d53abd8dfbadf5%26token%3D1526765687%26lang%3Dzh_CN%23rd "CVPR2022 | 基于排名的siamese视觉跟踪")

[从零搭建Pytorch模型教程（六）编写训练过程和推理过程](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495585%26idx%3D1%26sn%3Db29b4fbdea981e6fb0d65b763cf95879%26chksm%3Dc19450bff6e3d9a96de93fb028d29671b2bcbee9c0ddeb20f18bb8b43d0c3d39dcc3e5ab5318%26token%3D1526765687%26lang%3Dzh_CN%23rd "从零搭建Pytorch模型教程（六）编写训练过程和推理过程")

[从零搭建Pytorch模型教程（五）编写训练过程--一些基本的配置](http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495346%26idx%3D1%26sn%3D7c6d04843956b9c8364f0e2dbae173b0%26chksm%3Dc19451acf6e3d8bae14df712fdf3f34afa77c1be531f608fd4187d09c06db7b44773f0784c32%26token%3D1448674844%26lang%3Dzh_CN%23rd "从零搭建Pytorch模型教程（五）编写训练过程--一些基本的配置")

[从零搭建Pytorch模型教程（四）编写训练过程--参数解析](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247495136%26idx%3D1%26sn%3Db7dfcb870ab03617978d790f3fe7bb60%26chksm%3Dc19452fef6e3dbe83268c1e2185985c039c2ec724b367e933fbee52dc203fd8e3b26fccec645%26scene%3D21%23wechat_redirect "从零搭建Pytorch模型教程（四）编写训练过程--参数解析")

[从零搭建Pytorch模型教程（三）搭建Transformer网络](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247494373%26idx%3D1%26sn%3D98d5967bcf889aa86cc126c3e6eff5b6%26chksm%3Dc19455fbf6e3dced4ccdb561aa06453d6df1b18adb8ee9179ba9c62798bac63839f917413ea7%26scene%3D21%23wechat_redirect "从零搭建Pytorch模型教程（三）搭建Transformer网络")

[从零搭建Pytorch模型教程（二）搭建网络](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247494150%26idx%3D1%26sn%3Dda191e151efb8db5fef1aab64e9bec7d%26chksm%3Dc1945518f6e3dc0e19e5c83f205ae3d24b15c867b9f1038018b18bf7dae597d375f15c13a348%26scene%3D21%23wechat_redirect "从零搭建Pytorch模型教程（二）搭建网络")

[从零搭建Pytorch模型教程（一）数据读取](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247493728%26idx%3D1%26sn%3D3a30e67a71f2c18df697680c6004336b%26chksm%3Dc194577ef6e3de68e47294d8121c4f43c8170b114b5490cc129f212e8baf6aa379365a7a6fd9%26scene%3D21%23wechat_redirect "从零搭建Pytorch模型教程（一）数据读取")

[关于快速学习一项新技术或新领域的一些个人思维习惯与思想总结](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzkyMDE2OTA3Mw%3D%3D%26mid%3D2247493117%26idx%3D1%26sn%3Dfc82e1477d082db07ce74040cfadcb43%26chksm%3Dc1945ae3f6e3d3f578b7590e9dcca4615a4b560a55735f98cb3eb3d0995210fb905d494028f2%26scene%3D21%23wechat_redirect "关于快速学习一项新技术或新领域的一些个人思维习惯与思想总结")

​