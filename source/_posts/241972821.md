---
layout: post
title: "手把手教你使用LabVIEW实现Mask R-CNN图像实例分割"
date: "2022-11-02T06:30:11.608Z"
---
手把手教你使用LabVIEW实现Mask R-CNN图像实例分割
================================

前言
==

前面给大家介绍了使用LabVIEW工具包实现图像分类，目标检测，今天我们来看一下如何使用LabVIEW实现Mask R-CNN图像实例分割。

* * *

一、什么是图像实例分割？
============

图像实例分割(Instance Segmentation)是在语义检测(Semantic Segmentation)的基础上进一步细化，分离对象的前景与背景，实现像素级别的对象分离。并且图像的语义分割与图像的实例分割是两个不同的概念，语义分割仅仅会区别分割出不同类别的物体，而实例分割则会进一步的分割出同一个类中的不同实例的物体。

计算机视觉中常见的一些任务（分类，检测，语义分割，实例分割）

![在这里插入图片描述](https://img-blog.csdnimg.cn/976d64f60afe425083a8980fddbeff5c.png#pic_center)

二、什么是Mask R-CNN
===============

![在这里插入图片描述](https://img-blog.csdnimg.cn/d8702a1648a449c9bd3c563205a840ff.png#pic_center)

Mask R-CNN是一个实例分割（Instance segmentation）算法，可以用来做“目标检测”、“目标实例分割”、“目标关键点检测”。 Mask R-CNN算法步骤：

*   首先，输入一幅你想处理的图片，然后进行对应的预处理操作，或者预处理后的图片；
    
*   将其输入到一个预训练好的神经网络中（ResNeXt等）获得对应的feature map；
    
*   对这个feature map中的每一点设定预定的ROI，从而获得多个候选ROI；
    
*   将这些候选的ROI送入RPN网络进行二值分类（前景或背景）和BB回归，过滤掉一部分候选的ROI
    
*   接着，对这些剩下的ROI进行ROIAlign操作（即先将原图和feature map的pixel对应起来，然后
    
*   feature map和固定的feature对应起来）；
    
*   最后，对这些ROI进行分类（N类别分类）、BB回归和MASK生成（在每一个ROI里面进行FCN操作）
    

三、LabVIEW调用Mask R-CNN图像实例分割模型
=============================

1、Mask R-CNN模型获取及转换
-------------------

*   安装pytorch和torchvision
    
*   获取torchvision中的模型(我们获取预训练好的模型)：
    

model = models.detection.maskrcnn\_resnet50\_fpn(pretrained=True) 

*   转onnx
    

 1 def get\_pytorch\_onnx\_model(original\_model): 2     model=original\_model
 3     # define the directory for further converted model save
 4     onnx\_model\_path = dirname 5     
 6     # define the name of further converted model
 7     onnx\_model\_name = "maskrcnn\_resnet50.onnx"
 8 ​
 9     # create directory for further converted model
10     os.makedirs(onnx\_model\_path, exist\_ok=True)
11 ​
12     # get full path to the converted model
13     full\_model\_path = os.path.join(onnx\_model\_path, onnx\_model\_name)
14 model.eval()
15 ​
16     x = torch.rand(1, 3, 640, 640)
17     # model export into ONNX format
18 torch.onnx.export(
19 original\_model,
20 x,
21 full\_model\_path,
22         input\_names=\["input"\],
23         output\_names=\["boxes", "labels", "scores", "masks"\],
24         dynamic\_axes={"input": \[0, 1, 2, 3\],"boxes": \[0, 1\],"labels": \[0\],"scores": \[0\],"masks": \[0, 1, 2, 3\]},
25         verbose=True,opset\_version=11
26 )
27 ​
28     return full\_model\_path

完整获取及模型转换python代码如下：

 1 import os 2 import torch 3 import torch.onnx 4 from torch.autograd import Variable 5 from torchvision import models 6 ​
 7 dirname, filename = os.path.split(os.path.abspath(\_\_file\_\_))
 8 print(dirname)
 9 ​
10 def get\_pytorch\_onnx\_model(original\_model):
11     model=original\_model
12     # define the directory for further converted model save
13     onnx\_model\_path = dirname
14     
15     # define the name of further converted model
16     onnx\_model\_name = "maskrcnn\_resnet50.onnx"
17 ​
18     # create directory for further converted model
19     os.makedirs(onnx\_model\_path, exist\_ok=True)
20 ​
21     # get full path to the converted model
22     full\_model\_path = os.path.join(onnx\_model\_path, onnx\_model\_name)
23 model.eval()
24 ​
25     x = torch.rand(1, 3, 640, 640)
26     # model export into ONNX format
27 torch.onnx.export(
28 original\_model,
29 x,
30 full\_model\_path,
31         input\_names=\["input"\],
32         output\_names=\["boxes", "labels", "scores", "masks"\],
33         dynamic\_axes={"input": \[0, 1, 2, 3\],"boxes": \[0, 1\],"labels": \[0\],"scores": \[0\],"masks": \[0, 1, 2, 3\]},
34         verbose=True,opset\_version=11
35 )
36 ​
37     return full\_model\_path
38 ​
39 ​
40 model = models.detection.maskrcnn\_resnet50\_fpn(pretrained=True)
41 print(get\_pytorch\_onnx\_model(model))

2、LabVIEW调用 Mask R-CNN （mask rcnn.vi）
-------------------------------------

注意：Mask R-CNN模型是没办法使用OpenCV dnn去加载的，因为有些算子不支持，所以我们主要使用LabVIEW开放神经网络交互工具包（ONNX)来加载推理模型。

*   onnxruntime调用onnx模型并选择加速方式
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/54e82d89553748bfa827dd37e3ea8e8d.png#pic_center)

*   图像预处理
    

    ![在这里插入图片描述](https://img-blog.csdnimg.cn/201fccf2ea7f4e92a865c6d2a7eef183.png#pic_center)

*   执行推理 我们使用的模型是：maskrcnn\_resnet50\_fpn，其输出有四层，分别为boxes,labels,scores,masks,数据类型如下：
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/ffafed2a5ba7414dbd1e1b384c50da22.png#pic_center)

*   可以看到，labels的类型为INT64,所以我们的源码中需要“Get\_Rresult\_int64.vi,index为1，因为labels为第二层，即下标为1;
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/2285b17293a84c1ab5bdba28ea5a2a6e.png#pic_center)

*   另外三个输出我们都可以使用float32来获取了，masks虽然数据类型是uint8,但在实操过程中发现，它其实做过归一化处理了，也可以使用float32.
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/c4f5bc472b43456b8dfbedf69f48f4ed.png#pic_center)

*   后处理并实现实例分割 因为后处理内容较多，所以直接封装为了一个子VI， mask\_rcnn\_post\_process.vi，源码如下：
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/62618bd671154921b4a83e8ef0504640.png)

*   整体的程序框架如下：
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/fe3cb5aa0691445999bb431b33b28915.png#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/fe3cb5aa0691445999bb431b33b28915.png#pic_center)

*   实例分割结果如下，我们会发现这个模型跑起来，他花的时间比之前就更长了。因为他不但要获取每一个对象的区域，还要也要把这个区域的轮廓给框出来，我们可以看到五个人及篮球都框出来了，使用不同的颜色分割出来了。
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/c913a91b08d8478a9fcd3d6374d0f36e.png#pic_center)

3、LabVIEW调用 Mask R-CNN 实现实时图像分割（mask rcnn\_camera.vi）
-----------------------------------------------------

整体思想和上面检测图片的实力分割差不多，不过使用了摄像头，并加了一个循环，对每一帧对象进行实力分割，3080系列显卡可选择TensorRT加速推理，分割会更加流畅。我们发现这个模型其实很考验检测数量的，所以如果你只是对人进行分割，那可以选择一个干净一些的背景，整体检测速度就会快很多。  ![在这里插入图片描述](https://img-blog.csdnimg.cn/38a7920bab41448da1da456e1808a818.png#pic_center) ![在这里插入图片描述](https://img-blog.csdnimg.cn/0928fa1223e2465f957519a94b1734ff.png#pic_center)  

四、Mask-RCNN训练自己的数据集（检测行人）
=========================

1.准备工作
------

*   训练需要jupyterlab环境，没有安装的同学需要通过pip install jupyterlab 安装
    
*   如果无法解决jupyterlab环境 可以使用colab或者kaggle提供的免费gpu环境进行训练
    
*   训练源码：mask-rcnn.ipynb
    

2.开始训练
------

*   根据提示运行这段代码，自动或手动下载依赖文件数据集并建立数据集解析类
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/fb6e945708004b3897f0e96034fc4e90.png#pic_center)

*   定义单轮训练的函数：网络结构直接采用torchvison里现有的，不再重新定义
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/ee4fc007c42640029e2eeae49aa8880d.png#pic_center)

*   出现如下输出表示训练进行中
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/fc9016add68746e4923fd7995fbba853.png#pic_center)

*   修改这个文件名，改成自己的图片名字，运行看下训练效果
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/ef01f205c52c4819b40ca531886963eb.png#pic_center)

3、训练效果
------

![在这里插入图片描述](https://img-blog.csdnimg.cn/9f7ce7d9e0be44e9beb3d5a67b0a6cb1.png#pic_center)

4、导出ONNX
--------

![在这里插入图片描述](https://img-blog.csdnimg.cn/90c049fb68fe451d8304611b8b513e7d.png#pic_center)

* * *

总结
==

以上就是今天要给大家分享的内容。大家可关注微信公众号: **VIRobotics**，回复关键字：**Mask R-CNN图像实例分割源码**  获取本次分享内容的完整项目源码及模型。

如果有问题可以在评论区里讨论，提问前请先点赞支持一下博主哦，如您想要探讨更多关于LabVIEW与人工智能技术，欢迎加入我们的技术交流群：705637299，进群请备注暗号：LabVIEW 机器学习。

> **如果文章对你有帮助，欢迎关注、点赞、收藏**