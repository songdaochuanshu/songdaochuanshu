---
layout: post
title: "OVS-DPDK 流表查询详解"
date: "2023-03-16T01:13:25.374Z"
---
OVS-DPDK 流表查询详解
===============

一图胜千言：
======

![](https://img2023.cnblogs.com/blog/1756496/202303/1756496-20230315171509441-2124031730.png)

flow和miniflow
=============

在介绍之前先说一些概念：里面有两个结构很重要，一个是flow一个是miniflow这里介绍一下他们的数据结构和构造函数。

**flow：**
---------

flow的特点是8字节对齐的，存储报文相关字段和其他原数据，用于匹配流表，数据包含四个层次：

1.  metadata: 入端口号，寄存器等信息
2.  l2: 源目的mac，vlan和mpls等信息
3.  l3: ipv4/ipv6源目的ip，ttl等信息
4.  l4: 源目的端口号，icmp code和type等信息。

flow的坏处就是占用了很大的字节，并且有很多字段都是0，在2.8版本中flow的大小是672字节。

miniflow
--------

miniflow是flow的压缩版，因为flow占用字节很大，比如可以支持ARP，IP等报文，填充了arp字段，icmp报文就是空的了，浪费了很多信息。过程中用到hash作为key，也是根据miniflow计算hash值，不是用的flow。

struct miniflow {
    struct flowmap map;
};
struct flowmap {
    map\_t bits\[FLOWMAP\_UNITS\];
};

miniflow其包含两部分内容：

1.  struct flowmap map;是bit数组，使用其中的bit表示flow中哪个8字节存在有效数据，flow中占多少个8字节，那么就需要map中多个个bit，并且按照64bit向上取整。
2.  第二部分是有效数据，有效数据动态分配，根据struct flowmap map;中1bit数个数进行分配，大小为bit数\*8字节，该部分直接跟在map后面。该部分存储在netdev\_flow\_key结构中的buf数组。

miniflow数据结构：

//flow是8字节对齐的，除8得到flow中包含8字节的个数
#define FLOW\_U64S (sizeof(struct flow) / sizeof(uint64\_t))

//map大小为8字节，MAP\_T\_BITS 为64位
typedef unsigned long long map\_t;
#define MAP\_T\_BITS (sizeof(map\_t) \* CHAR\_BIT)

//每位表示一个u64，FLOWMAP\_UNITS 表示最少需要几个64位
#define FLOWMAP\_UNITS DIV\_ROUND\_UP(FLOW\_U64S, MAP\_T\_BITS)

struct flowmap {
    map\_t bits\[FLOWMAP\_UNITS\];
};

struct miniflow {
    struct flowmap map;
    /\* Followed by:
     \*     uint64\_t values\[n\];
     \* where 'n' is miniflow\_n\_values(miniflow). \*/
};

struct netdev\_flow\_key {
    uint32\_t hash;     
    uint32\_t len;     
    struct miniflow mf;  // bits
    uint64\_t buf\[FLOW\_MAX\_PACKET\_U64S\];  // 就是上边所说的value
};

// 有些字段是互斥的
#define FLOW\_MAX\_PACKET\_U64S (FLOW\_U64S                                   \\
    /\* Unused in datapath \*/  - FLOW\_U64\_SIZE(regs)                       \\
                              \- FLOW\_U64\_SIZE(metadata)                   \\
    /\* L2.5/3 \*/              - FLOW\_U64\_SIZE(nw\_src)  /\* incl. nw\_dst \*/ \\
                              \- FLOW\_U64\_SIZE(mpls\_lse)                   \\
    /\* L4 \*/                  - FLOW\_U64\_SIZE(tp\_src)                     \\
                             )

![](https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=MzAwM2I0YmFkZjRmMTU4NDUwMzJlY2FkZjBmYjIxYWZfZlM5dE5mQUxwNkZaOXJmSmoyU3ZTQnJVdllDYVByRkVfVG9rZW46Ym94Y253Rm1wMnZLT3J0YUxxVFEwQTNWOXFYXzE2Nzg4NzE4MTU6MTY3ODg3NTQxNV9WNA)

**miniflow优点：**

1.  使用miniflow可以节省内存
2.  如果只想遍历flow中的非0字段时，使用miniflow找到对应的非0字段，可以节省时间

flow->miniflow函数：**miniflow\_extract()**
----------------------------------------

void
miniflow\_extract(struct dp\_packet \*packet, struct miniflow \*dst)
{
    ...
    // 初始化赋值有两个关键，一个是这个values： return (uint64\_t \*)(mf + 1);
    // 就是上边说的
    uint64\_t \*values = miniflow\_values(dst);
    struct mf\_ctx mf = { FLOWMAP\_EMPTY\_INITIALIZER, values,
                         values + FLOW\_U64S };
    ...
    if (md->skb\_priority || md->pkt\_mark) {
        miniflow\_push\_uint32(mf, skb\_priority, md\->skb\_priority);
        miniflow\_push\_uint32(mf, pkt\_mark, md\->pkt\_mark);
    }
    miniflow\_push\_be16(mf, dl\_type, dl\_type);
    miniflow\_pad\_to\_64(mf, dl\_type);
    ...
    
    // 去取网络层信息,从这里可以看出，ovs暂时只支持IP,IPV6,ARP,RARP报文
    if (OVS\_LIKELY(dl\_type == htons(ETH\_TYPE\_IP))){...}
    else if
    ...
    
    // 提取传输层，从这里可以看出，ovs暂时支持传输层协议有TCP,UDP,SCTP,ICMP,ICMPV6
    if (OVS\_LIKELY(nw\_proto == IPPROTO\_TCP)){...}
    else if
    ...
    

**miniflow\_push\_uint32()**

在上面将value保存到miniflow时，用到了几个辅助函数，比如下面的miniflow\_push\_uint32用来将一个32位的值保存到miniflow中FIELD对应的位置。其首先调用offsetof获取field在flow中的偏移字节数，因为flow是8字节对齐的，所以一个四字节的成员变量要么位于8字节的起始位置，要么位于8字节的中间位置，即对8取模值肯定为0或者4，再调用miniflow\_push\_uint32\_保存到对应的位置，并设置map中对应的bit为1。

#define miniflow\_push\_uint32(MF, FIELD, VALUE)                      \\
    miniflow\_push\_uint32\_(MF, offsetof(struct flow, FIELD), VALUE)
    
#define miniflow\_push\_uint32\_(MF, OFS, VALUE)   \\
    {                                           \\
    MINIFLOW\_ASSERT(MF.data < MF.end);          \\
                                                \\
    //成员变量位于起始位置，需要调用miniflow\_set\_map设置对应的bit为1
    if ((OFS) % 8 == 0) {                       \\
        miniflow\_set\_map(MF, OFS / 8);          \\
        \*(uint32\_t \*)MF.data = VALUE;           \\
    } else if ((OFS) % 8 == 4) {                \\
    //成员变量不在起始位置，要判断此变量所在的bit为1
        miniflow\_assert\_in\_map(MF, OFS / 8);    \\
        \*((uint32\_t \*)MF.data + 1) = VALUE;     \\
        MF.data++;                              \\
    }                                           \\
}

miniflow->flow函数：**miniflow\_expand()**
---------------------------------------

/\* Initializes 'dst' as a copy of 'src'. \*/
void
miniflow\_expand(const struct miniflow \*src, struct flow \*dst)
{
    memset(dst, 0, sizeof \*dst);
    flow\_union\_with\_miniflow(dst, src);
}

/\* Perform a bitwise OR of miniflow 'src' flow data with the equivalent
 \* fields in 'dst', storing the result in 'dst'. \*/
static inline void
flow\_union\_with\_miniflow(struct flow \*dst, const struct miniflow \*src)
{
    flow\_union\_with\_miniflow\_subset(dst, src, src\->map);
}

static inline void
flow\_union\_with\_miniflow\_subset(struct flow \*dst, const struct miniflow \*src,
                                struct flowmap subset)
{
    uint64\_t \*dst\_u64 = (uint64\_t \*) dst;
    const uint64\_t \*p = miniflow\_get\_values(src);
    map\_t map;
    //遍历所有的map
    FLOWMAP\_FOR\_EACH\_MAP (map, subset) {
        size\_t idx;
        //遍历map中所有的非0bit
        MAP\_FOR\_EACH\_INDEX(idx, map) {
            dst\_u64\[idx\] |= \*p++;
        }
        dst\_u64 += MAP\_T\_BITS;
    }
}

流表查询过程
======

概要
--

该部分入口在lib/dpif-netdev.c，就是最开始的那个图。

查询的缓存分为两层：一个是DFC，一个是dpcls，相当于microflow和megaflow，DFC由两部分组成，DFC（datapath flow cache）：EMC（Exact match cache）+SMC（Signature match cache），另一部分就是dpcls(datapath classifer)。

SMC默认关闭：bool smc\_enable = smap\_get\_bool(other\_config, "smc-enable", false);

**函数执行流程(不包含****SMC****的)：**

![](https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=MTg3ZDk3NzU3NjI3MGQxM2YwOWU3NDNmNDQ0YWFjNGFfVEZvZVI1R2k2YTRzYVpPNTJNeXd3NFk3eEZXazk2Y01fVG9rZW46Ym94Y240UklHTzF5RFpkNzh4TUkybnR4RlU2XzE2Nzg4NzE5NjQ6MTY3ODg3NTU2NF9WNA)

入口在dp\_netdev\_input\_\_()
--------------------------

static void
dp\_netdev\_input\_\_(struct dp\_netdev\_pmd\_thread \*pmd,
                  struct dp\_packet\_batch \*packets,
                  bool md\_is\_valid, odp\_port\_t port\_no)
{
#if !defined(\_\_CHECKER\_\_) && !defined(\_WIN32)
    const size\_t PKT\_ARRAY\_SIZE = dp\_packet\_batch\_size(packets);
#else
    /\* Sparse or MSVC doesn't like variable length array. \*/
    enum { PKT\_ARRAY\_SIZE = NETDEV\_MAX\_BURST };
#endif
    OVS\_ALIGNED\_VAR(CACHE\_LINE\_SIZE)
        struct netdev\_flow\_key keys\[PKT\_ARRAY\_SIZE\];
    struct netdev\_flow\_key \*missed\_keys\[PKT\_ARRAY\_SIZE\];
    struct packet\_batch\_per\_flow batches\[PKT\_ARRAY\_SIZE\];
    size\_t n\_batches;
    struct dp\_packet\_flow\_map flow\_map\[PKT\_ARRAY\_SIZE\];
    uint8\_t index\_map\[PKT\_ARRAY\_SIZE\];
    size\_t n\_flows, i;

    odp\_port\_t in\_port;

    n\_batches \= 0;
    // 1. dfc\_processing之后会把miss的放到packets里
    //    找到的可能已经batched了，或者放到flow\_map里了
    //    flow\_map里是未bathed的，可能直接是\*flow或者是NULL，是NULL再去下一层cache查
    dfc\_processing(pmd, packets, keys, missed\_keys, batches, &n\_batches,
                   flow\_map, &n\_flows, index\_map, md\_is\_valid, port\_no);
    
    // 2. 如果有miss的，再去找fast-path，也就是查dpcls
    if (!dp\_packet\_batch\_is\_empty(packets)) {  
        in\_port \= packets->packets\[0\]->md.in\_port.odp\_port;
        fast\_path\_processing(pmd, packets, missed\_keys,
                             flow\_map, index\_map, in\_port);
    }

    /\* Batch rest of packets which are in flow map. \*/
    for (i = 0; i < n\_flows; i++) {
        struct dp\_packet\_flow\_map \*map = &flow\_map\[i\];

        if (OVS\_UNLIKELY(!map->flow)) {
            continue;
        }
        dp\_netdev\_queue\_batches(map\->packet, map->flow, map->tcp\_flags,
                                batches, &n\_batches);
    }
     
    for (i = 0; i < n\_batches; i++) {
        batches\[i\].flow\->batch = NULL;
    }
    
    // 执行每个packet的action
    for (i = 0; i < n\_batches; i++) {
        packet\_batch\_per\_flow\_execute(&batches\[i\], pmd);
    }
}

1\. DFC查询：dfc\_processing()
---------------------------

static inline size\_t
dfc\_processing(struct dp\_netdev\_pmd\_thread \*pmd,
               struct dp\_packet\_batch \*packets\_,
               struct netdev\_flow\_key \*keys,
               struct netdev\_flow\_key \*\*missed\_keys,
               struct packet\_batch\_per\_flow batches\[\], size\_t \*n\_batches,
               struct dp\_packet\_flow\_map \*flow\_map,
               size\_t \*n\_flows, uint8\_t \*index\_map,
               bool md\_is\_valid, odp\_port\_t port\_no)
{
    struct netdev\_flow\_key \*key = &keys\[0\];
    size\_t n\_missed \= 0, n\_emc\_hit = 0;
    struct dfc\_cache \*cache = &pmd->flow\_cache;
    struct dp\_packet \*packet;
    size\_t cnt \= dp\_packet\_batch\_size(packets\_);
    // emc的插入概率，如果为0，表示不开启emc
    uint32\_t cur\_min = pmd->ctx.emc\_insert\_min;
    int i;
    uint16\_t tcp\_flags;
    bool smc\_enable\_db;
    // 记录未batched的个数
    size\_t map\_cnt = 0;
    // 这个变量用于保序
    bool batch\_enable = true;
    // 获取smc是否开启参数
    atomic\_read\_relaxed(&pmd->dp->smc\_enable\_db, &smc\_enable\_db);
    pmd\_perf\_update\_counter(&pmd->perf\_stats,
                            md\_is\_valid ? PMD\_STAT\_RECIRC : PMD\_STAT\_RECV,
                            cnt);

    do\_dfc\_hook(pmd, packets\_, batches, n\_batches); 
    cnt \= dp\_packet\_batch\_size(packets\_);     
    
    // 逐个对dp\_packet\_batch中的每一个packet进行处理
    DP\_PACKET\_BATCH\_REFILL\_FOR\_EACH (i, cnt, packet, packets\_) {
        struct dp\_netdev\_flow \*flow;
        // 若packet包长小于以太头的长度直接丢包
        if (OVS\_UNLIKELY(dp\_packet\_size(packet) < ETH\_HEADER\_LEN)) {
            dp\_packet\_delete(packet);
            COVERAGE\_INC(datapath\_drop\_rx\_invalid\_packet);
            continue;
        }
        // 对数据手工预取可减少读取延迟，从而提高性能
        if (i != cnt - 1) {
            struct dp\_packet \*\*packets = packets\_->packets;
            /\* Prefetch next packet data and metadata. \*/
            OVS\_PREFETCH(dp\_packet\_data(packets\[i+1\]));
            pkt\_metadata\_prefetch\_init(&packets\[i+1\]->md);
        }

        // 初始化metadata首先将pkt\_metadata中flow\_in\_port前的字节全部设为0
        // 将in\_port.odp\_port设为port\_no， tunnel.ipv6\_dst设为in6addr\_any
        if (!md\_is\_valid) {
            pkt\_metadata\_init(&packet->md, port\_no);
        }
        // 报文转化为miniflow, 上文有讲
        miniflow\_extract(packet, &key->mf);  
        key\->len = 0; /\* Not computed yet. \*/
        // 计算当前报文miniflow的hash值
        key->hash =
                (md\_is\_valid \== false)
                ? dpif\_netdev\_packet\_get\_rss\_hash\_orig\_pkt(packet, &key->mf)
                : dpif\_netdev\_packet\_get\_rss\_hash(packet, &key->mf);

        // 根据key->hash,emc\_entry alive,miniflow 3个条件得到dp\_netdev\_flow
        // cur\_min = 0,表示不可能插入，后面有讲什么时候才会插入EMC
        flow = (cur\_min != 0) ? emc\_lookup(&cache->emc\_cache, key) : NULL;
        
        if (OVS\_LIKELY(flow)) {
            tcp\_flags \= miniflow\_get\_tcp\_flags(&key->mf);
            n\_emc\_hit++; // 命中次数+1
            // 为了保证报文的顺序，所有的packet对应的flow都用flow\_map存储
            // flow\_map里面就是packet数量对应的(packet,flow,tcp\_flag)
            // 最后会把这些在dp\_netdev\_input\_\_里重新把顺序合并一下
            if (OVS\_LIKELY(batch\_enable)) {
                // 把查到的flow加到batches里第n\_batches个batch里
                dp\_netdev\_queue\_batches(packet, flow, tcp\_flags, batches,
                                        n\_batches);
            } else {
 
                packet\_enqueue\_to\_flow\_map(packet, flow, tcp\_flags,
                                           flow\_map, map\_cnt++);
            }
        } else {
            // 这些数据结构用于smc查询时的记录
            // 没查到把packet放到packets\_里，从下标0再开始放
            // 最后packets\_都是未查到的
            dp\_packet\_batch\_refill(packets\_, packet, i);
            index\_map\[n\_missed\] \= map\_cnt;
            flow\_map\[map\_cnt++\].flow = NULL;
            missed\_keys\[n\_missed\] \= key;
            key \= &keys\[++n\_missed\];
            batch\_enable \= false; // 之后的都是未batched的
        }
    }
    \*n\_flows = map\_cnt;

    pmd\_perf\_update\_counter(&pmd->perf\_stats, PMD\_STAT\_EXACT\_HIT, n\_emc\_hit);
    // 如果没有开启smc，直接返回了
    if (!smc\_enable\_db) {
        return dp\_packet\_batch\_size(packets\_);
    }

    smc\_lookup\_batch(pmd, keys, missed\_keys, packets\_,
                     n\_missed, flow\_map, index\_map);

    return dp\_packet\_batch\_size(packets\_);
}

### 1.1 emc查询：emc\_lookup()

![](https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=ODA5ZDQwMTNjYmM0MjY1MTMzNzZkNDk3YTA1NjI4ZGRfSWZIOW9LamJaSUx5TmQ3NjdxRHdwdmJ0N1p5bUFGbVBfVG9rZW46Ym94Y242TWphZ0VjMk5iYlJYRXBvdHZSckNiXzE2Nzg4NzIwMTY6MTY3ODg3NTYxNl9WNA)![](https://img2023.cnblogs.com/blog/1756496/202303/1756496-20230315172048663-1121875426.png)

static inline struct dp\_netdev\_flow \*
emc\_lookup(struct emc\_cache \*cache, const struct netdev\_flow\_key \*key)
{
    struct emc\_entry \*current\_entry;
    // 这里说一下，一个hash分配两个桶，长度为13位，cache桶的大小为1<<13
    // struct emc\_cache {
    //    struct emc\_entry entries\[EM\_FLOW\_HASH\_ENTRIES\];
    //    int sweep\_idx;                /\* For emc\_cache\_slow\_sweep(). \*/
    // };
    EMC\_FOR\_EACH\_POS\_WITH\_HASH (cache, current\_entry, key->hash) {
        if (current\_entry->key.hash == key->hash
            && emc\_entry\_alive(current\_entry)
            && emc\_flow\_key\_equal\_mf(&current\_entry->key, &key->mf)) {
            /\* We found the entry with the 'key->mf' miniflow \*/
            return current\_entry->flow;
        }
    }
    return NULL;
}

#define EM\_FLOW\_HASH\_SHIFT 13
#define EM\_FLOW\_HASH\_ENTRIES (1u << EM\_FLOW\_HASH\_SHIFT)
#define EM\_FLOW\_HASH\_MASK (EM\_FLOW\_HASH\_ENTRIES - 1)
#define EM\_FLOW\_HASH\_SEGS 2
#define EMC\_FOR\_EACH\_POS\_WITH\_HASH(EMC, CURRENT\_ENTRY, HASH)                 \\
    for (uint32\_t i\_\_ = 0, srch\_hash\_\_ = (HASH);                             \\
         (CURRENT\_ENTRY) \= &(EMC)->entries\[srch\_hash\_\_ & EM\_FLOW\_HASH\_MASK\], \\
         i\_\_ < EM\_FLOW\_HASH\_SEGS;                                            \\
         i\_\_++, srch\_hash\_\_ >>= EM\_FLOW\_HASH\_SHIFT)

// 比较miniflow是否相同
static inline bool
emc\_flow\_key\_equal\_mf(const struct netdev\_flow\_key \*key,
                         const struct miniflow \*mf)
{
    return !memcmp(&key->mf, mf, key->len);
}

**EMC****查询函数执行：**

![](https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=ZDZlNDhkN2VjNDcwZDc0ZDk5NDFmOWY3ODJhNmI0YTlfZE1IWUE2S2FzRXFkVU1MbkhZN1pTMExPWDFWZVJEa1ZfVG9rZW46Ym94Y25KYnM2Y3RNRUx6dWt3VGhhZHdCTWliXzE2Nzg4NzIwNzM6MTY3ODg3NTY3M19WNA)

### 1.2 smc查询：smc\_lookup\_batch()

static inline void
smc\_lookup\_batch(struct dp\_netdev\_pmd\_thread \*pmd,
            struct netdev\_flow\_key \*keys,
            struct netdev\_flow\_key \*\*missed\_keys,
            struct dp\_packet\_batch \*packets\_,
            const int cnt,
            struct dp\_packet\_flow\_map \*flow\_map,
            uint8\_t \*index\_map)
{
    int i;
    struct dp\_packet \*packet;
    size\_t n\_smc\_hit \= 0, n\_missed = 0;
    struct dfc\_cache \*cache = &pmd->flow\_cache;
    struct smc\_cache \*smc\_cache = &cache->smc\_cache;
    const struct cmap\_node \*flow\_node;
    int recv\_idx;
    uint16\_t tcp\_flags;

    /\* Prefetch buckets for all packets \*/
    for (i = 0; i < cnt; i++) {
        OVS\_PREFETCH(&smc\_cache->buckets\[keys\[i\].hash & SMC\_MASK\]);
    }

    DP\_PACKET\_BATCH\_REFILL\_FOR\_EACH (i, cnt, packet, packets\_) {
        struct dp\_netdev\_flow \*flow = NULL;
        // 找到hash相同的flow链表的头节点
        flow\_node = smc\_entry\_get(pmd, keys\[i\].hash);
        bool hit = false;
        /\* Get the original order of this packet in received batch. \*/
        recv\_idx \= index\_map\[i\];
        
        if (OVS\_LIKELY(flow\_node != NULL)) {
            // 遍历一下看看哪一个是相同的，这个通过offsetof找到存放该cmap结构体的首地址
            // dp\_netdev\_flow里面的首地址就是，
            CMAP\_NODE\_FOR\_EACH (flow, node, flow\_node) {
                /\* Since we dont have per-port megaflow to check the port
                 \* number, we need to  verify that the input ports match. \*/
                if (OVS\_LIKELY(dpcls\_rule\_matches\_key(&flow->cr, &keys\[i\]) &&
                flow\->flow.in\_port.odp\_port == packet->md.in\_port.odp\_port)) {
                    tcp\_flags \= miniflow\_get\_tcp\_flags(&keys\[i\].mf);
                    keys\[i\].len \=
                        netdev\_flow\_key\_size(miniflow\_n\_values(&keys\[i\].mf));
                    if (emc\_probabilistic\_insert(pmd, &keys\[i\], flow)) {
                        if (flow->status == OFFLOAD\_NONE) {
                            queue\_netdev\_flow\_put(pmd\->dp->dp\_flow\_offload, \\
                                    pmd\->dp->class, \\
                                    flow, NULL, DP\_NETDEV\_FLOW\_OFFLOAD\_OP\_ADD);
                        }
                    }
                    packet\_enqueue\_to\_flow\_map(packet, flow, tcp\_flags,
                                               flow\_map, recv\_idx);
                    n\_smc\_hit++;
                    hit \= true;
                    break;
                }
            }
            if (hit) {
                continue;
            }
        }
        // SMC也miss了，和之前一样，把miss的放packets\_里，从0开始放
        dp\_packet\_batch\_refill(packets\_, packet, i);
        index\_map\[n\_missed\] \= recv\_idx;
        missed\_keys\[n\_missed++\] = &keys\[i\];
    }

    pmd\_perf\_update\_counter(&pmd->perf\_stats, PMD\_STAT\_SMC\_HIT, n\_smc\_hit);
}

**查找****hash****相同的链表头：smc\_entry\_get()**

static inline const struct cmap\_node \*
smc\_entry\_get(struct dp\_netdev\_pmd\_thread \*pmd, const uint32\_t hash)
{
    struct smc\_cache \*cache = &(pmd->flow\_cache).smc\_cache;
    // smc\_cache桶的大小是（1<<18），SMC\_MASK=（1<<18）- 1
    // 先通过后hash的后18位定位到桶
    struct smc\_bucket \*bucket = &cache->buckets\[hash & SMC\_MASK\];
    // 一个桶有4个16位的sig，存key->hash前16位，正好是64位
    // 遍历4个元素看那个匹配，获得匹配后的cmap的下标
    uint16\_t sig = hash >> 16;
    uint16\_t index \= UINT16\_MAX;

    for (int i = 0; i < SMC\_ENTRY\_PER\_BUCKET; i++) {
        if (bucket->sig\[i\] == sig) {
            index \= bucket->flow\_idx\[i\];
            break;
        }
    }
    // 通过index找到在dpcls里的桶位置
    if (index != UINT16\_MAX) {
        return cmap\_find\_by\_index(&pmd->flow\_table, index);
    }
    return NULL;
}

### 1.3 更新emc：**emc\_probabilistic\_insert()**

**命中****SMC****后，插入回上一层cache（****EMC****）里：emc\_probabilistic\_insert()**

插入EMC的条件:

  默认插入流表的概率是1%，可以通过ovs-vsctl set Open\_vSwitch . other\_config:emc-insert-prob=10 设置概率，表示平均10条流表有1条插入，当为0时禁用EMC，当为1的时候，百分百插入。设置后会在代码里设置**emc\_insert\_min**字段为uint\_max/10，插入的时候生成一个uint\_random()，如果随机数小于**emc\_insert\_min**才会插入。

static inline bool
emc\_probabilistic\_insert(struct dp\_netdev\_pmd\_thread \*pmd,
                         const struct netdev\_flow\_key \*key,
                         struct dp\_netdev\_flow \*flow)
{
    /\* Insert an entry into the EMC based on probability value 'min'. By
     \* default the value is UINT32\_MAX / 100 which yields an insertion
     \* probability of 1/100 ie. 1% \*/
    uint32\_t min \= pmd->ctx.emc\_insert\_min;
    if (min && random\_uint32() <= min) {
        emc\_insert(&(pmd->flow\_cache).emc\_cache, key, flow);
        return true;
    }
    return false;
}

emc\_insert同样有我在内核查询里的问题，如果cache里没有该miniflow，会找一个hash值小的entry，覆盖这个entry，那如果有一个hash很大的flow被插入了，但是这个flow之后就没用过了，那岂不是这个entry就浪费了，不会被用到。

找到了合适的emc\_entry。则将报文对应的netdev\_dev\_flow key信息存储到该表项中。而对于这个表项，原有的emc\_entry.flow有可能还有指向一条旧的流表，需要将这条流表的引用计数减1，如果减1后达到0，则释放该流表空间。同时更新emc\_entry.flow重新指向新的流表。到此为止，EMC表项更新完毕。

static inline void
emc\_insert(struct emc\_cache \*cache, const struct netdev\_flow\_key \*key,
           struct dp\_netdev\_flow \*flow)
{
    struct emc\_entry \*to\_be\_replaced = NULL;
    struct emc\_entry \*current\_entry;

    EMC\_FOR\_EACH\_POS\_WITH\_HASH(cache, current\_entry, key\->hash) {
        if (netdev\_flow\_key\_equal(&current\_entry->key, key)) {
            /\* We found the entry with the 'mf' miniflow \*/
            emc\_change\_entry(current\_entry, flow, NULL);
            return;
        }
        /\* Replacement policy: put the flow in an empty (not alive) entry, or
         \* in the first entry where it can be \*/

        if (!to\_be\_replaced
            || (emc\_entry\_alive(to\_be\_replaced)
                && !emc\_entry\_alive(current\_entry))
            || current\_entry->key.hash < to\_be\_replaced->key.hash) {
            // 这个黄色判断就是我迷惑的地方
            to\_be\_replaced = current\_entry;
        }
    }
    /\* We didn't find the miniflow in the cache.
     \* The 'to\_be\_replaced' entry is where the new flow will be stored \*/
    emc\_change\_entry(to\_be\_replaced, flow, key);
}

### 1.4 EMC的轮训更新

在pmd\_thread\_main()里面：

if (lc++ > 1024) {
    lc \= 0;

    coverage\_try\_clear();
    
    // 这里的optimize是排序一下TSS
    dp\_netdev\_pmd\_try\_optimize(pmd, poll\_list, poll\_cnt); 
    dp\_netdev\_pmd\_hook\_idle\_run(pmd);
#ifdef ENABLE\_EMC
    if (!ovsrcu\_try\_quiesce()) {
        emc\_cache\_slow\_sweep(pmd\->dp, &((pmd->flow\_cache).emc\_cache));
    }
#else
    ovsrcu\_try\_quiesce();
#endif

    for (i = 0; i < poll\_cnt; i++) {
        uint64\_t current\_seq \=
                 netdev\_get\_change\_seq(poll\_list\[i\].rxq\->port->netdev);
        if (poll\_list\[i\].change\_seq != current\_seq) {
            poll\_list\[i\].change\_seq \= current\_seq;
            poll\_list\[i\].rxq\_enabled \=
                         netdev\_rxq\_enabled(poll\_list\[i\].rxq\->rx);
        }
    }
}

1.5 承上启下：OVS的TSS算法
------------------

dpcls是megaflow的查询过程，使用TSS算法，是个很老的算法了，看源码之前，先讲一下ovs里面的TSS，之前内核已经讲过，但是没有讲OVS里做的优化，下边再说一次，然后建议再去看一下这个有很多图的博客[OVS-DPDK Datapath Classifier](https://zhaozhanxu.com/index.php/archives/233/)，这样之后对整个dpcls流程就有所了解了。

### TSS算法原理

OVS 在内核态使用了元组空间搜索算法（Tuple Space Search，简称 TSS）进行流表查找，**元组空间搜索算法的核心思想是，把所****有规则按照每个字段的前缀长度进行组合，并划分为不同的元组中，然后在这些元组集合中进行****哈希****查找**。我们举例说明，假设现有 10 条规则以及 3 个匹配字段，每个匹配字段长度均为 4：

![](https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=OGQ2NjYyNmNkYjkwYTA4MjYwODU5ZTNmYjY1YTdkN2FfbXJwR2NkR09EYU12RkZXTmNmeFduV25BTVVSMVpoMWRfVG9rZW46Ym94Y25rNXF3YkpxTDR4TzVObVllUmFNV0RiXzE2Nzg4NzIxNzE6MTY3ODg3NTc3MV9WNA)

我们将每条规则各匹配字段的前缀长度提取出来，按照前缀长度进行组合，并根据前缀长度组合进行分组：

![](https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=ZDUzZTkzM2FkNzk5NjQzYTBmZTE5N2Q2Yzg4ZTU4ZWFfb1Z4ekdFZk5xdnpIR1ZGbHlwclNrVUtWS2tUUTNvR0tfVG9rZW46Ym94Y25UcktSek1ReWlxOXhSQVVSeU4xWUNZXzE2Nzg4NzIxNzE6MTY3ODg3NTc3MV9WNA)

我们将每个前缀长度组合称为 **元组**，每个元组对应于哈希表的一个桶，同一前缀长度组合内的所有规则放置在同一个哈希桶内：

![](https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=YjgyMjljMDc3Y2ExZjdiMzZlZGU2ZDNjZmIyMjM4NGFfZ2dQaEZLYWNPYVJDWk02Rlh1Mllia2JIMGdCOTROdUFfVG9rZW46Ym94Y25sN1pMRTJtVTBtSzhHRDBtdzRQblpnXzE2Nzg4NzIxNzE6MTY3ODg3NTc3MV9WNA)

10 条规则被划分为 4 个元组，因此最多只需要四次查找，就可以找到对应的规则。

### 算法优缺点

为什么OVS选择TSS，而不选择其他查找算法？论文给出了以下三点解释：

（1）在虚拟化数据中心环境下，流的添加删除比较频繁，TSS支持高效的、常数时间的表项更新； （2）TSS支持任意匹配域的组合； （3）TSS存储空间随着流的数量线性增长，空间复杂度为 O(N)，N 为规则数目。

元组空间搜索算法的缺点是，由于基于哈希表实现，因此查找的时间复杂度不能确定。当所有规则各个字段的前缀长度组合数目过多时，查找性能会大大降低，最坏情况下需要查找所有规则。

### OVS里做的排序优化

查找的过程需要从前向后遍历所有元组，命中了就不用往后查了。OVS给每个元组加了一个命中次数，命中次数越多，元组这个链表越靠前，这样就可以减少了查表次数。

2\. dpcls查询
-----------

### 2.1 dpcls相关数据结构

// 线程安全的
#define OVSRCU\_TYPE(TYPE) struct { ATOMIC(TYPE) p; }

struct cmap {
    OVSRCU\_TYPE(struct cmap\_impl \*) impl;
};

/\* The implementation of a concurrent hash map. \*/
struct cmap\_impl {
    // 补齐64字节
    PADDED\_MEMBERS\_CACHELINE\_MARKER(CACHE\_LINE\_SIZE, cacheline0,
        unsigned int n;             /\* Number of in-use elements. \*/
        unsigned int max\_n;         /\* Max elements before enlarging. \*/
        unsigned int min\_n;         /\* Min elements before shrinking. \*/
        uint32\_t mask;              /\* Number of 'buckets', minus one. \*/
        uint32\_t basis;             /\* Basis for rehashing client's
                                       hash values. \*/
    );
    PADDED\_MEMBERS\_CACHELINE\_MARKER(CACHE\_LINE\_SIZE, cacheline1,
        struct cmap\_bucket buckets\[1\];
    );
};

struct cmap\_bucket {
    /\* Padding to make cmap\_bucket exactly one cache line long. \*/
    PADDED\_MEMBERS(CACHE\_LINE\_SIZE,
        // 锁机制，读和写都会+1，读的时候等到变成偶数再去读，保证安全
        atomic\_uint32\_t counter; 
        // 桶中的每个槽用(hashs\[i\], nodes\[i\])元组来表示
        uint32\_t hashes\[CMAP\_K\];
        struct cmap\_node nodes\[CMAP\_K\];
    );
};
struct cmap\_node {
    OVSRCU\_TYPE(struct cmap\_node \*) next; /\* Next node with same hash. \*/
};

/\* 二级匹配表.每个报文接收端口对应一个 \*/
struct dpcls {
    struct cmap\_node node; /\* 链表节点 \*/
    odp\_port\_t in\_port;    /\* 报文接收端口 \*/
    struct cmap subtables\_map; // 管理下边subtables的索引，用于遍历
    struct pvector subtables;  // 上文TSS算法所说的元组表
}
 
struct pvector {
    // 指向具体子表信息
    OVSRCU\_TYPE(struct pvector\_impl \*) impl; 
    // 平时,temp都是为NULL.只有当pvector扩充时,temp才用来临时缓存数据.
    // 待排好序后,再拷贝到impl中,temp再置NULL
    struct pvector\_impl \*temp;
};

// 相当于vector<pvector\_entry>
struct pvector\_impl {
    size\_t size; /\* Number of entries in the vector \*/
    size\_t allocated; /\* Number allocted entries \*/
    /\* 初始化的时候只有4个元素.后续可能会扩充 \*/
    struct pvector\_entry vector\[\];
}
 
struct pvector\_entry {
        // pvector\_impl中的vector是按照priority从小到大排序的 
        // pmd\_thread\_main里会把priority赋值为hit\_cnt，然后排序
        int priority; 
        /\* 实际指向了struct dpcls\_subtable结构 \*/
        void \*ptr;
}
 
// 子表信息
struct dpcls\_subtable {
    /\* The fields are only used by writers. \*/
    struct cmap\_node cmap\_node OVS\_GUARDED; /\* Within dpcls 'subtables\_map'. \*/

    struct cmap rules; // 该表的bucket内容
    uint32\_t hit\_cnt;  // 命中该子表的次数

    // 下边是mask的miniflow前两个的bits里1的个数
    uint8\_t mf\_bits\_set\_unit0; 
    uint8\_t mf\_bits\_set\_unit1;
    // 根据mf\_bits\_set\_unit01选择最合适的查找算法
    dpcls\_subtable\_lookup\_func lookup\_func;

    /\* Caches the masks to match a packet to, reducing runtime calculations. \*/
    uint64\_t \*mf\_masks; // 由下边的mask->mf->bits\[01\]得来的，
    struct netdev\_flow\_key mask; // 该表的掩码信息
};

关于上边的mf\_masks与mask，举个例子
mf\_bits\_set\_unit0 \= 4， mf\_bits\_set\_unit1 = 0
netdev\_flow\_key.mf.bits\[0\] = 111010 (2进制)
mf\_masks \= \[1, 111, 1111, 11111\]  （2进制）

三个图对应他们的关系，链表三用于遍历的，查找过程中并不会通过链表三方式搜索。查找的时候走的就是链表二的流程。

![](https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=YmQxNDVlMzRmNWVkNzM5Njk5ZDFmNWMyNjdiZjdhMGNfVVFrV1l1NUZ6UGxicFpLeWRyVklVMVdDcmg1OTdIb0tfVG9rZW46Ym94Y25aY2NGSjNZWXJKa3hURkRTTWVaaWNkXzE2Nzg4NzIyNDY6MTY3ODg3NTg0Nl9WNA)

![](https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=MTQxNjE2MTFiMzBjYTY2MGY4NTc0ZjY2MGVkN2E1ZTNfVkpmSll1a0xtQVJ5Z1BaZmlFQU0wTkQ1SUtBcUdKUGpfVG9rZW46Ym94Y25GNm1vSkNXdGpqNm9qTTd6eExwbnNCXzE2Nzg4NzIyNTk6MTY3ODg3NTg1OV9WNA)

![](https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=M2Q4ZmRhNmE4YTQ2YTQyM2VkZGI4ODk1YzA3NGI3MGFfWlNrM1hSdDVYWFJKUWNTbXo5S3hSWnh1UTNsTzlDVDJfVG9rZW46Ym94Y25zQ3NDWVJVZUxvY1RnZ1hldjc5a09nXzE2Nzg4NzIyNzQ6MTY3ODg3NTg3NF9WNA)

### 2.2 dpcls查询入口：fast\_path\_processing->dpcls\_lookup()

static bool
dpcls\_lookup(struct dpcls \*cls, const struct netdev\_flow\_key \*keys\[\],
             struct dpcls\_rule \*\*rules, const size\_t cnt,
             int \*num\_lookups\_p)
{
#define MAP\_BITS (sizeof(uint32\_t) \* CHAR\_BIT)
    BUILD\_ASSERT\_DECL(MAP\_BITS \>= NETDEV\_MAX\_BURST);

    struct dpcls\_subtable \*subtable;
    uint32\_t keys\_map \= TYPE\_MAXIMUM(uint32\_t); /\* Set all bits. \*/

    if (cnt != MAP\_BITS) {
        /\*keys\_map中置1位数为包的总数，并且第i位对应第i个包\*/
        keys\_map \>>= MAP\_BITS - cnt; /\* Clear extra bits. \*/
    }
    memset(rules, 0, cnt \* sizeof \*rules);

    int lookups\_match = 0, subtable\_pos = 1;
    uint32\_t found\_map;

    PVECTOR\_FOR\_EACH (subtable, &cls->subtables) {
        // 查找函数，对应下边的lookup\_generic()
        found\_map = subtable->lookup\_func(subtable, keys\_map, keys, rules);
        
        uint32\_t pkts\_matched \= count\_1bits(found\_map);
        // 搜索的子表个数，加上的是当前这几个key找了多少个表
        lookups\_match += pkts\_matched \* subtable\_pos;

        keys\_map &= ~found\_map; 
        if (!keys\_map) {
            if (num\_lookups\_p) {
                \*num\_lookups\_p = lookups\_match;
            }
            // 全找到了
            return true;
        }
        subtable\_pos++;
    }

    if (num\_lookups\_p) {
        \*num\_lookups\_p = lookups\_match;
    }
    // 没有全找到
    return false;
}

#### lookup\_generic()

ovs-dpdk里面有avx512-gather.c，使用avx512优化了look\_up，整体逻辑还是一样的，这里只说dpif-netdev-lookup-generic

入口在这里，往下走,传进去subtable有效字段有多大
static uint32\_t
dpcls\_subtable\_lookup\_generic(struct dpcls\_subtable \*subtable,
                              uint32\_t keys\_map,
                              const struct netdev\_flow\_key \*keys\[\],
                              struct dpcls\_rule \*\*rules)
{
    return lookup\_generic\_impl(subtable, keys\_map, keys, rules,
                               subtable\->mf\_bits\_set\_unit0,
                               subtable\->mf\_bits\_set\_unit1);
}

static inline uint32\_t ALWAYS\_INLINE
lookup\_generic\_impl(struct dpcls\_subtable \*subtable,      // 当前的subtable
                    uint32\_t keys\_map,                    // miss\_bit\_map
                    const struct netdev\_flow\_key \*keys\[\], // miss\_key
                    struct dpcls\_rule \*\*rules,            // save hit\_rule
                    const uint32\_t bit\_count\_u0,         
                    const uint32\_t bit\_count\_u1)
{
    // 有几个包
    const uint32\_t n\_pkts = count\_1bits(keys\_map);
    ovs\_assert(NETDEV\_MAX\_BURST \>= n\_pkts);
    uint32\_t hashes\[NETDEV\_MAX\_BURST\];

    // 根据mask字段的大小开空间
    const uint32\_t bit\_count\_total = bit\_count\_u0 + bit\_count\_u1;
    // 一个batch最大是NETDEV\_MAX\_BURST
    const uint32\_t block\_count\_required = bit\_count\_total \* NETDEV\_MAX\_BURST;
    uint64\_t \*mf\_masks = subtable->mf\_masks;  
    int i;

    // 申请存储一个batch报文信息的数组，存放
    uint64\_t \*blocks\_scratch = get\_blocks\_scratch(block\_count\_required); 

    // 获得每个key与当前表的mask“与运算”的结果
    ULLONG\_FOR\_EACH\_1 (i, keys\_map) {
            netdev\_flow\_key\_flatten(keys\[i\],
                                    &subtable->mask, // 该表的掩码信息
                                    mf\_masks,  // 由subtable->mask处理后的mask
                                    &blocks\_scratch\[i \* bit\_count\_total\],
                                    bit\_count\_u0,
                                    bit\_count\_u1);
    }

    // 算出来每一个key在该subtable里的hash值，该hash值由“mask字节数，key和mask与运算结果”得出
    ULLONG\_FOR\_EACH\_1 (i, keys\_map) {
        uint64\_t \*block\_ptr = &blocks\_scratch\[i \* bit\_count\_total\];
        uint32\_t hash \= hash\_add\_words64(0, block\_ptr, bit\_count\_total); 
        hashes\[i\] \= hash\_finish(hash, bit\_count\_total \* 8); 
    }

    uint32\_t found\_map;
    const struct cmap\_node \*nodes\[NETDEV\_MAX\_BURST\];

    // 找到每个key在该subtable里的cmap，并且返回每个key有没有被找到，第i位是1则找到
    found\_map = cmap\_find\_batch(&subtable->rules, keys\_map, hashes, nodes);

    ULLONG\_FOR\_EACH\_1 (i, found\_map) {
        struct dpcls\_rule \*rule;
        // 可能不同的rule有相同的hash，看那个是匹配的
        CMAP\_NODE\_FOR\_EACH (rule, cmap\_node, nodes\[i\]) { 
            const uint32\_t cidx = i \* bit\_count\_total;
            /\*rule->mask & keys\[i\]的值与rule->flow相比较\*/
            uint32\_t match \= netdev\_rule\_matches\_key(rule, bit\_count\_total,
                                                     &blocks\_scratch\[cidx\]);
            if (OVS\_LIKELY(match)) {
                rules\[i\] \= rule;
                subtable\->hit\_cnt++;
                goto next;
            }
        }
        ULLONG\_SET0(found\_map, i);  /\* Did not match. \*/
    next:
        ; /\* Keep Sparse happy. \*/
    }
    return found\_map;
}

##### 掩码运算netdev\_flow\_key\_flatten()

// 这个函数对应dpif-netdev.c里面的dpcls\_flow\_key\_gen\_masks()
static inline void
netdev\_flow\_key\_flatten(const struct netdev\_flow\_key \*key,  // 要查找的miss\_key
                        const struct netdev\_flow\_key \*mask, 
                        const uint64\_t \*mf\_masks,
                        uint64\_t \*blocks\_scratch,
                        const uint32\_t u0\_count,
                        const uint32\_t u1\_count)
{
    /\* Load mask from subtable, mask with packet mf, popcount to get idx. \*/
    const uint64\_t \*pkt\_blocks = miniflow\_get\_values(&key->mf);    
    const uint64\_t \*tbl\_blocks = miniflow\_get\_values(&mask->mf); // 获取miss\_key和mask的miniflow

    /\* Packet miniflow bits to be masked by pre-calculated mf\_masks. \*/
    const uint64\_t pkt\_bits\_u0 = key->mf.map.bits\[0\];
    const uint32\_t pkt\_bits\_u0\_pop = count\_1bits(pkt\_bits\_u0);
    const uint64\_t pkt\_bits\_u1 = key->mf.map.bits\[1\];

// 这个函数就是把miss\_key与subtable的掩码进行&运算
// 会运算出该mask在意字段结果，放到blocks\_scratch里
    netdev\_flow\_key\_flatten\_unit(&pkt\_blocks\[0\],   // key-mf的数据段
                                 &tbl\_blocks\[0\],   // mask->mf的数据段
                                 &mf\_masks\[0\],     // mask->mf->bits得来mask
                                 &blocks\_scratch\[0\], // 存放的地址
                                 pkt\_bits\_u0,      // key->mf里的bits\[0\]
                                 u0\_count);        // mask->mf->bits\[0\]里1的个数
    netdev\_flow\_key\_flatten\_unit(&pkt\_blocks\[pkt\_bits\_u0\_pop\], // 上边bits\[0\]的已经算过了，从bits\[1\]开始算
                                 &tbl\_blocks\[u0\_count\],
                                 &mf\_masks\[u0\_count\],
                                 &blocks\_scratch\[u0\_count\],
                                 pkt\_bits\_u1,
                                 u1\_count);
}

static inline void
netdev\_flow\_key\_flatten\_unit(const uint64\_t \*pkt\_blocks, // key-mf的数据段
                             const uint64\_t \*tbl\_blocks, // mask->mf里的数据段
                             const uint64\_t \*mf\_masks,   // mask->mf->bits得来mask
                             uint64\_t \*blocks\_scratch,   // 存放到这里
                             const uint64\_t pkt\_mf\_bits, // key->mf里的bits\[01\]
                             const uint32\_t count)       // mask->mf->bits\[0\]里1的个数
{

// 说一下意思，这个我们流程就是用key和subtable的mask与运算，肯定只需要与运算mask里
// 不为0的字段，其他的mask不关心，然后这个操作就是为了得到key对应字段是key->mf的第几位，
// 比如mask的bits\[0\]=11111, key的bits\[0\] = 10100, mask里的第3个1在key里面是第1个
// 这一位与的结果就是tbl\_blocks\[2\]&pkt\_blocks\[0\], 也就是怎么找到key里的下标0
// 就看key当前位之前有几个1就行了。这里这样做的1010111，
// 蓝色1之前有count\_1bits(1010111 & 0001111) = 3

//  对上边的mask举个例子 count = 4;
//  mask->mf->bits\[0\] = 111010 (2进制)
//  mf\_masks = \[1, 111, 1111, 11111\] (2进制);
//  pkt\_mf\_bits = 010100
//  blocks\_scratch = \[0,0,0,0,pkt\_blocks\[1\]&tbl\_blocks\[4\],0\]
    uint32\_t i;    
    for (i = 0; i < count; i++) {
        // 拿i=2举例
        uint64\_t mf\_mask = mf\_masks\[i\];             // mf\_mask = 001111
        uint64\_t idx\_bits = mf\_mask & pkt\_mf\_bits;  // idx\_bits = 000100
        const uint32\_t pkt\_idx = count\_1bits(idx\_bits); // pkt\_idx = 1
        uint64\_t pkt\_has\_mf\_bit \= (mf\_mask + 1) & pkt\_mf\_bits;  // pkt\_has\_mf\_bit = 010000
        // 是否求掩码：mask当前位对应的key的字段，如果key在当前位是0，下边算掩码就会变成0
        uint64\_t no\_bit = ((!pkt\_has\_mf\_bit) > 0) - 1; // 2^64 - 1

        // mask里第i个字段与运算key对应的字段
        blocks\_scratch\[i\] = pkt\_blocks\[pkt\_idx\] & tbl\_blocks\[i\] & no\_bit; // 
    }
}

##### key对应的cmap：cmap\_find\_batch()

unsigned long
cmap\_find\_batch(const struct cmap \*cmap, unsigned long map,
                uint32\_t hashes\[\], const struct cmap\_node \*nodes\[\])
{
    const struct cmap\_impl \*impl = cmap\_get\_impl(cmap); 
    unsigned long result = map;
    int i;
    // 每一位就是一个包，一字节8个包
    uint32\_t h1s\[sizeof map \* CHAR\_BIT\]; 
    const struct cmap\_bucket \*b1s\[sizeof map \* CHAR\_BIT\];
    const struct cmap\_bucket \*b2s\[sizeof map \* CHAR\_BIT\];
    uint32\_t c1s\[sizeof map \* CHAR\_BIT\];

    // 每个impl里桶的数量为impl->mask+1
    // 为什么mask是桶的个数减1:因为下标从0开始，找下表的时候直接(hash & impl->mask)就行了

    // 至于为什么开两个？因为buckets存放的方法也是一个值对应两个hash
    // 第一次hash1 = rehash(impl->basis, hash), 找buckets\[hash1 & impl->mask\], 遍历里面CMAP\_K个元素
    // 第二次hash2 = other\_hash(hash1), 找buckets\[hash2 & impl->mask\], 遍历里面CMAP\_K个元素
    

    /\* Compute hashes and prefetch 1st buckets. \*/
    ULLONG\_FOR\_EACH\_1(i, map) {
        h1s\[i\] \= rehash(impl, hashes\[i\]);            
        b1s\[i\] \= &impl->buckets\[h1s\[i\] & impl->mask\];
        OVS\_PREFETCH(b1s\[i\]);
    }
    /\* Lookups, Round 1. Only look up at the first bucket. \*/
    ULLONG\_FOR\_EACH\_1(i, map) {
        uint32\_t c1;
        const struct cmap\_bucket \*b1 = b1s\[i\];
        const struct cmap\_node \*node;

        do {
            c1 \= read\_even\_counter(b1);
            // 找一下这个cmap\_bucket里面有没有相同hash的
            node = cmap\_find\_in\_bucket(b1, hashes\[i\]);
        } while (OVS\_UNLIKELY(counter\_changed(b1, c1)));

        if (!node) {
            /\* Not found (yet); Prefetch the 2nd bucket. \*/
            b2s\[i\] \= &impl->buckets\[other\_hash(h1s\[i\]) & impl->mask\];
            OVS\_PREFETCH(b2s\[i\]);
            c1s\[i\] \= c1; /\* We may need to check this after Round 2. \*/
            continue;
        }
        /\* Found. \*/
        ULLONG\_SET0(map, i); /\* Ignore this on round 2. \*/
        OVS\_PREFETCH(node);
        nodes\[i\] \= node;
    }
    /\* Round 2. Look into the 2nd bucket, if needed. \*/
    ULLONG\_FOR\_EACH\_1(i, map) {
        uint32\_t c2;
        const struct cmap\_bucket \*b2 = b2s\[i\];
        const struct cmap\_node \*node;

        do {
            c2 \= read\_even\_counter(b2);
            node \= cmap\_find\_in\_bucket(b2, hashes\[i\]);
        } while (OVS\_UNLIKELY(counter\_changed(b2, c2)));

        if (!node) {
            // 可能被修改了，
            if (OVS\_UNLIKELY(counter\_changed(b1s\[i\], c1s\[i\]))) {
                node \= cmap\_find\_\_(b1s\[i\], b2s\[i\], hashes\[i\]);
                if (node) {
                    goto found;
                }
            }
            /\* Not found. \*/
            ULLONG\_SET0(result, i); /\* Fix the result. \*/
            continue;
        }
found:
        OVS\_PREFETCH(node);
        nodes\[i\] \= node;
    }
    return result;
}

### 2.3 fast\_path\_processing()

static inline void
fast\_path\_processing(struct dp\_netdev\_pmd\_thread \*pmd,
                     struct dp\_packet\_batch \*packets\_,
                     struct netdev\_flow\_key \*\*keys,
                     struct dp\_packet\_flow\_map \*flow\_map,
                     uint8\_t \*index\_map,
                     odp\_port\_t in\_port)
{
    const size\_t cnt = dp\_packet\_batch\_size(packets\_);
#if !defined(\_\_CHECKER\_\_) && !defined(\_WIN32)
    const size\_t PKT\_ARRAY\_SIZE = cnt;
#else
    /\* Sparse or MSVC doesn't like variable length array. \*/
    enum { PKT\_ARRAY\_SIZE = NETDEV\_MAX\_BURST };
#endif
    struct dp\_packet \*packet;
    struct dpcls \*cls;
    struct dpcls\_rule \*rules\[PKT\_ARRAY\_SIZE\];
    struct dp\_netdev \*dp = pmd->dp;
    int upcall\_ok\_cnt = 0, upcall\_fail\_cnt = 0;
    int lookup\_cnt = 0, add\_lookup\_cnt;
    bool any\_miss;

    for (size\_t i = 0; i < cnt; i++) {
        /\* Key length is needed in all the cases, hash computed on demand. \*/
        keys\[i\]\->len = netdev\_flow\_key\_size(miniflow\_n\_values(&keys\[i\]->mf));
    }
    /\* Get the classifier for the in\_port \*/
    // 找到端口对应的dpcls结构，每个port有自己的dpcls，因为每个port收到的报文会更相似
    cls = dp\_netdev\_pmd\_lookup\_dpcls(pmd, in\_port);
    if (OVS\_LIKELY(cls)) {
        // 调用dpcls\_lookup进行匹配
        any\_miss = !dpcls\_lookup(cls, (const struct netdev\_flow\_key \*\*)keys,
                                rules, cnt, &lookup\_cnt);
    } else {
        any\_miss \= true;
        memset(rules, 0, sizeof(rules));
    }
    // 如果有miss的，则需要进行openflow流表查询
    if (OVS\_UNLIKELY(any\_miss) && !fat\_rwlock\_tryrdlock(&dp->upcall\_rwlock)) {
        uint64\_t actions\_stub\[512 / 8\], slow\_stub\[512 / 8\];
        struct ofpbuf actions, put\_actions;

        ofpbuf\_use\_stub(&actions, actions\_stub, sizeof actions\_stub);
        ofpbuf\_use\_stub(&put\_actions, slow\_stub, sizeof slow\_stub);

        DP\_PACKET\_BATCH\_FOR\_EACH (i, packet, packets\_) {
            struct dp\_netdev\_flow \*netdev\_flow;

            if (OVS\_LIKELY(rules\[i\])) {
                continue;
            }
            // 此时可能已经更新了，在进入upcall之前如果再查一次，如果能够查到，会比upcall消耗的少得多
            netdev\_flow = dp\_netdev\_pmd\_lookup\_flow(pmd, keys\[i\],
                                                    &add\_lookup\_cnt);
            if (netdev\_flow) {
                lookup\_cnt += add\_lookup\_cnt;
                rules\[i\] \= &netdev\_flow->cr;
                continue;
            }
            // 第一级和第二级流表查找失败后，就要查找第三级流表了，即openflow流表，这也称为upcall调用。
            // 在普通ovs下是通过netlink实现的，在ovs+dpdk下，直接在pmd线程中调用upcall\_cb即可。
            // 开始查找openflow流表。如果查找openflow流表成功并需要下发到dpcls时，需要判断是否超出最大流表限制
            int error = handle\_packet\_upcall(pmd, packet, keys\[i\],
                                             &actions, &put\_actions);

            if (OVS\_UNLIKELY(error)) {
                upcall\_fail\_cnt++;
            } else {
                upcall\_ok\_cnt++;
            }
        }

        ofpbuf\_uninit(&actions);
        ofpbuf\_uninit(&put\_actions);
        fat\_rwlock\_unlock(&dp->upcall\_rwlock);
    } else if (OVS\_UNLIKELY(any\_miss)) {
        DP\_PACKET\_BATCH\_FOR\_EACH (i, packet, packets\_) {
            if (OVS\_UNLIKELY(!rules\[i\])) {
                dp\_packet\_delete(packet);
                COVERAGE\_INC(datapath\_drop\_lock\_error);
                upcall\_fail\_cnt++;
            }
        }
    }

    DP\_PACKET\_BATCH\_FOR\_EACH (i, packet, packets\_) {
        struct dp\_netdev\_flow \*flow;
        /\* Get the original order of this packet in received batch. \*/
        int recv\_idx = index\_map\[i\];
        uint16\_t tcp\_flags;

        if (OVS\_UNLIKELY(!rules\[i\])) {
            continue;
        }

        flow \= dp\_netdev\_flow\_cast(rules\[i\]);

        bool hook\_cached = false;
        if (pmd->cached\_hook && \\
                pmd\->cached\_hook\_pmd && \\
                pmd\->cached\_hook->hook\_flow\_miss) {
            hook\_cached \= pmd->cached\_hook->hook\_flow\_miss(pmd->cached\_hook\_pmd, packet, flow);
        }

        if (!hook\_cached) {
            bool smc\_enable\_db;
            atomic\_read\_relaxed(&pmd->dp->smc\_enable\_db, &smc\_enable\_db);
            // 查找到了packet，如果开启了smc，更新smc
            if (smc\_enable\_db) {
                uint32\_t hash \=  dp\_netdev\_flow\_hash(&flow->ufid);
                smc\_insert(pmd, keys\[i\], hash);
            }
            // 查到了packet，看是否写会更新上一层cache（EMC）
            if (emc\_probabilistic\_insert(pmd, keys\[i\], flow)) {
                if (flow->status == OFFLOAD\_NONE) {
                    queue\_netdev\_flow\_put(pmd\->dp->dp\_flow\_offload, \\
                            pmd\->dp->class, \\
                            flow, NULL, DP\_NETDEV\_FLOW\_OFFLOAD\_OP\_ADD);
                }
            }
        }
        /\* Add these packets into the flow map in the same order
         \* as received.
         \*/
        tcp\_flags \= miniflow\_get\_tcp\_flags(&keys\[i\]->mf);
        packet\_enqueue\_to\_flow\_map(packet, flow, tcp\_flags,
                                   flow\_map, recv\_idx);
    }
    // 更新各个信息
    pmd\_perf\_update\_counter(&pmd->perf\_stats, PMD\_STAT\_MASKED\_HIT,
                            cnt \- upcall\_ok\_cnt - upcall\_fail\_cnt);
    pmd\_perf\_update\_counter(&pmd->perf\_stats, PMD\_STAT\_MASKED\_LOOKUP,
                            lookup\_cnt);
    pmd\_perf\_update\_counter(&pmd->perf\_stats, PMD\_STAT\_MISS,
                            upcall\_ok\_cnt);
    pmd\_perf\_update\_counter(&pmd->perf\_stats, PMD\_STAT\_LOST,
                            upcall\_fail\_cnt);
}

![](https://bytedance.feishu.cn/space/api/box/stream/download/asynccode/?code=NTM1Mjg4YWZiMGMwNjg4YTA5M2MxMDE3YjQ0NDFiNDJfbG10OU5BN1pBYzFYZUc4OUV4THZONTIyQ1Vya1VoWTVfVG9rZW46Ym94Y25ralZBdmc5blNIVk85a2ludEdWaW1iXzE2Nzg4NzI0MDc6MTY3ODg3NjAwN19WNA)

### 2.4 smc更新smc\_insert()

static inline void
smc\_insert(struct dp\_netdev\_pmd\_thread \*pmd,
           const struct netdev\_flow\_key \*key,
           uint32\_t hash)
{
    struct smc\_cache \*smc\_cache = &(pmd->flow\_cache).smc\_cache;
    struct smc\_bucket \*bucket = &smc\_cache->buckets\[key->hash & SMC\_MASK\];
    uint16\_t index;
    uint32\_t cmap\_index;
    int i;
    
    //布谷鸟算法
    cmap\_index = cmap\_find\_index(&pmd->flow\_table, hash);
    index \= (cmap\_index >= UINT16\_MAX) ? UINT16\_MAX : (uint16\_t)cmap\_index;

    /\* If the index is larger than SMC can handle (uint16\_t), we don't
     \* insert \*/
    if (index == UINT16\_MAX) {
        //表明找到了
        return;
    }

    /\* If an entry with same signature already exists, update the index \*/
    uint16\_t sig \= key->hash >> 16;
    for (i = 0; i < SMC\_ENTRY\_PER\_BUCKET; i++) {
        if (bucket->sig\[i\] == sig) {
            bucket\->flow\_idx\[i\] = index;
            return;
        }
    }
    /\* If there is an empty entry, occupy it. \*/
    for (i = 0; i < SMC\_ENTRY\_PER\_BUCKET; i++) {
        if (bucket->flow\_idx\[i\] == UINT16\_MAX) {
            bucket\->sig\[i\] = sig;
            bucket\->flow\_idx\[i\] = index;
            return;
        }
    }
    /\* Otherwise, pick a random entry. \*/
    i \= random\_uint32() % SMC\_ENTRY\_PER\_BUCKET;
    bucket\->sig\[i\] = sig;
    bucket\->flow\_idx\[i\] = index;
}

3\. upcall到openflow查找，然后更新dpcls
-------------------------------

这里就不讲具体代码了，讲一下大概：到openflow查找后会更新dpcls，执行dp\_netdev\_flow\_add() --> dpcls\_insert() --> **dpcls\_find\_subtable()** \--> cmap\_insert()

**dpcls\_find\_subtable()：**

  找一下是否存在相同mask的subtable，存在返回这个subtable，不存在就创建一个subtable，创建的时候会调用dpcls\_create\_subtable，里面有个dpcls\_subtable\_get\_best\_impl会根据mask的miniflow的bits\[0\]和bits\[1\]选择的查找算法。

cmap\_insert里hash算法用的就是布谷鸟hash，hash两次，插入的核心代码：

static bool
cmap\_try\_insert(struct cmap\_impl \*impl, struct cmap\_node \*node, uint32\_t hash)
{
    uint32\_t h1 \= rehash(impl, hash);
    uint32\_t h2 \= other\_hash(h1);
    // hash两次找到两个桶
    struct cmap\_bucket \*b1 = &impl->buckets\[h1 & impl->mask\];
    struct cmap\_bucket \*b2 = &impl->buckets\[h2 & impl->mask\];
    
    // 插入规则：
    // 1.是否有相同hash的node，就插到对应链上
    // 2.没有相同hash，就看有没有空的node
    // 3.都不行就通过bfs，看能否让b1,b2空出来一个，把这个放进去
    // 都不行就插入失败
    return (OVS\_UNLIKELY(cmap\_insert\_dup(node, hash, b1) ||
                         cmap\_insert\_dup(node, hash, b2)) ||  
            OVS\_LIKELY(cmap\_insert\_bucket(node, hash, b1) ||   
                       cmap\_insert\_bucket(node, hash, b2)) ||  
            cmap\_insert\_bfs(impl, node, hash, b1, b2)); 
}

参考博客：
=====

[OVS-DPDK Datapath Classifier](https://zhaozhanxu.com/index.php/archives/233/) ：这个是理论上的流程，看完就知道这个算法流程了

[ovs分类器 flow和miniflow](https://www.jianshu.com/p/11e269b07841) ：很重要的结构体miniflow

[OVS-DPDK DataPath Classifier反向设计](https://www.sdnlab.com/20901.html) ：这个有很多详细的解释，但不怎么流畅