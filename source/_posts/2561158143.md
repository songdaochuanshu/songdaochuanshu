---
layout: post
title: "论文解读（GLA）《Label-invariant Augmentation for Semi-Supervised Graph Classification》"
date: "2022-10-22T22:22:10.990Z"
---
论文解读（GLA）《Label-invariant Augmentation for Semi-Supervised Graph Classification》
================================================================================

论文信息
====

> 论文标题：Label-invariant Augmentation for Semi-Supervised Graph Classification  
> 论文作者：Han Yue, Chunhui Zhang, Chuxu Zhang, Hongfu Liu  
> 论文来源：2022，NeurIPS  
> 论文地址：[download](https://arxiv.org/abs/2205.09802)  
> 论文代码：download 

1 Introduction
==============

 　　我们提出了一种图对比学习的标签不变增强策略，该策略涉及到下游任务中的标签来指导对比增强。值得注意的是，我们不生成任何图形数据。相反，我们在训练阶段直接生成标签一致的表示作为增广图。

2 Methodology
=============

2.1 Motivation
--------------

　　数据增强在神经网络训练中起着重要的作用。它不仅提高了学习表示的鲁棒性，而且为训练提供了丰富的数据。

　　例子：（使用 $50%$ 的标签做监督信息。数据增强：node dropping, edge perturbation, attribute masking, subgraph sampling）

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221022205047957-1141385316.png)

　　显然有些数据增强策略（或组合）对于模型训练又负面影响。本文进一步使用 MUTAG 中的 $100%$ 标签训练模型，然后以每种数据增强抽样概率 $0.2$ 选择数据增强图，发现 80% 的数据增强图和原始图标签一致，约 $20%$ 的数据增强图和原始图标签不一致。

2.2 Label-invariant Augmentation
--------------------------------

　　整体框架：

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221022210457916-4086184.png)

　　四个组成部分：

*   *   Graph Neural Network Encoder
    *   Classifier
    *   Label-invariant Augmentation
    *   Projection Head

　　出发点：对于一个有标记的图，我们期望由增强表示预测的标签与地面真实标签相同。

### 2.2.1 Graph Neural Network Encoder

　　GCN layer :

　　　　$G^{(l+1)}=\\sigma\\left(\\tilde{D}^{-\\frac{1}{2}} \\tilde{A} \\tilde{D}^{-\\frac{1}{2}} G^{(l)} \\theta\_{G}^{(l)}\\right)\\quad\\quad\\quad\\quad(1)$

　　其中：

*   *   $G^{(l)}$ denotes the matrix in the l -th layer, and $G^{(0)}=X$
    *   $\\sigma(\\cdot)=\\operatorname{ReLU}(\\cdot)$

　　池化 (sum)：

　　　　$H=\\operatorname{Pooling}(G)\\quad\\quad\\quad\\quad(2)$

### 2.2.2 Classifier

　　基于图级表示，我们使用带有参数 $\\theta\_{C}$ 的全连接层进行预测：

　　　　$C^{(l+1)}=\\operatorname{Softmax}\\left(\\sigma\\left(C^{(l)} \\cdot \\theta\_{C}^{(l)}\\right)\\right)\\quad\\quad\\quad\\quad(3)$

　　其中，$C^{(l)}$ 表示第 $l$ 层的嵌入，输入层 $C^{(0)}=H^{O}$ 或 $C^{(0)}=H^{A}$ 分别表示原始表示和增强图表示。实验中，采用了一个 2 层多层感知器，得到了对原始表示 $H^{O}$ 和增强表示 $H^{A}$ 的预测 $C^{O}$ 和 $C^{A}$。

### 2.2.3 Label-invariant Augmentation

　　不对图级表示做数据增强，而是在原始图级表示$H^{O}$上做微小扰动得到增强图级表示。

　　在实验中，首先计算所有图的原始表示的质心，得到每个原始表示与质心之间的欧氏距离的平均值为 $d$，即：

　　　　$d=\\frac{1}{N} \\sum\_{i=1}^{N}\\left\\|H\_{i}^{O}-\\frac{1}{N} \\sum\_{j=1}^{N} H\_{j}^{O}\\right\\|\\quad\\quad\\quad\\quad(4)$

　　然后计算增强图表示 $H^{A}$：

　　　　$H^{A}=H^{O}+\\eta d \\Delta\\quad\\quad\\quad\\quad(5)$

　　其中 $\\eta$ 缩放扰动的大小，$\\Delta$ 是一个随机单位向量。

　　为实现标签不变增强，每次，随机生成多个扰动，并选择符合标签不变属性的合格候选增强。在这些合格的候选对象中，选择了最困难的一个，即最接近分类器的决策边界的一个，以提高模型的泛化能力。

### 2.2.4 Projection Head

　　使用带有参数 $\\theta\_{P}$ 的全连接层，从图级表示中得到对比学习的投影，如下所示：

　　　　$P^{(l+1)}=\\sigma\\left(P^{(l)} \\cdot \\theta\_{P}^{(l)}\\right) \\quad\\quad\\quad\\quad(6)$

　　采用一个 2 层多层感知器，从原始表示 $H^{O}$ 和增广表示 $H^{A}$ 中得到投影 $P^{O}$ 和 $P^{A}$。

### 2.2.5 Objective Function

　　目标函数包括对比损失和分类损失。对比损失采用 NT-Xent，但只保留正对部分如下：

　　　　$\\mathcal{L}\_{P}=\\frac{-\\left(P^{O}\\right)^{\\top} P^{A}}{\\left\\|P^{O}\\right\\|\\left\\|P^{A}\\right\\|} \\quad\\quad\\quad\\quad(7)$

　　对于分类损失，采用交叉熵，其定义为：

　　　　$\\mathcal{L}\_{C}=-\\sum\_{i=1}^{c}\\left(Y\_{i}^{O} \\log P\_{i}^{O}+Y\_{i}^{O} \\log P\_{i}^{A}\\right) \\quad\\quad\\quad\\quad(8)$

　　其中，$Y^{O}$ 是输入图的标签，$c$ 是图类别的数量。本文只计算带标签的图的 $\\mathcal{L}\_{C}$。$\\text{Classifier}$  的改进将有助于标签不变的增强，反过来有利于分类器的训练。

　　结合等式 $\\text{Eq.7}$ 和 $\\text{Eq.8}$ ，总体目标函数可以写成如下：

　　　　$\\underset{\\Theta}{\\text{min}} \\quad\\mathcal{L}\_{P}+\\alpha \\mathcal{L}\_{C}\\quad\\quad\\quad\\quad(9)$

3 Experiments
=============

**3.1 Datasets**

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221022222910171-775057047.png)

**3.2 Semi-supervised graph classification results**

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221022223738319-395118142.png)

3.3 Algorithmic Performance
---------------------------

　　![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221022224729730-819354395.png)

3.4 In-depth Exploration
------------------------

**Negative Pairs**

　　现有的图对比学习方法将来自不同源样本的增广图视为负对，并对这些负对采用实例级判别。由于这些方法分离了 pre-train 阶段和 fine-tuning 阶段，因此负对包含了来自不同源样本的增强样本，但在下游任务中具有相同的类别。

　　Figure 4(a) 显示了我们在四个数据集上有负对和没有负对的 GLA 的性能。可以看到，与没有负对的默认设置相比，有负对的性能显著下降，而负对在所有四个数据集上都表现一致。与现有的图对比方法不同，GLA 集成了预训练阶段和微调阶段，其中以自监督的方式设计的负对不利于下游任务。这一发现也与最近的\[10,9\]在视觉对比学习领域的研究结果相一致。

　　 ![](https://img2022.cnblogs.com/blog/1664108/202210/1664108-20221022231712568-516181943.png)

4 Conclusion
============

　　本文研究了图的对比学习问题。从现有的方法和训练前的方法不同，我们提出了一种新的图标签不变增强（GLA）算法，该算法集成了训练前和微调阶段，通过扰动在表示空间中进行标签不变增强。具体来说，GLA首先检查增广表示是否服从标签不变属性，并从合格的样本中选择最困难的样本。通过这种方法，GLA在不生成任何原始图的情况下实现了对比增强，也增加了模型的泛化。在8个基准图数据集上的半监督设置下的广泛实验证明了我们的GLA的有效性。此外，我们还提供了额外的实验来验证我们的动机，并深入探讨了GLA在负对、增强空间和策略效应中的影响因素。

因上求缘，果上努力~~~~ 作者：[视界~](https://www.cnblogs.com/BlairGrowing/)，转载请注明原文链接：[https://www.cnblogs.com/BlairGrowing/p/16816493.html](https://www.cnblogs.com/BlairGrowing/p/16816493.html)