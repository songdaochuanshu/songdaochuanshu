---
layout: post
title: "kubernetes数据持久化PV-PVC详解（一）"
date: "2022-11-27T15:16:30.764Z"
---
kubernetes数据持久化PV-PVC详解（一）
==========================

官方文档地址: [https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/](https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/)

### 1\. 什么是PV，PVC？

#### 1.1 什么是PV

PresistentVolume(PV)是指集群管理员配置提供的某存储系统上的一段存储空间，它是对底层共享存储的抽象，将共享存储作为一种可由用户申请使用的资源，实现"存储消费"机制，通过存储插件，PV支持使用多种网络存储等多种后端存储系统，例如，NFS、CephFS、RBD。PV是集群级别的资源，不属于任何名称空间，用户对PV资源的使用需要通过PersistentVolumeClaim(PVC)提供的使用申请来完成绑定，PVC是PV资源的消费者，它向PV申请特定大小的空间及访问模式(rw或ro)从而创建出PVC存储卷。然后再由Pod资源通过PersistentVolumeClaim存储卷关联使用。

#### 1.2 什么是PVC？

PersistentVolumeClaim，PVC是存储卷类型的资源，它通过申请占用某个PersistentVolume而创建，它与PV是一对一的关系，用户无须关心其底层实现细节，申请时，用户只需要指定目标空间的大小，访问模式，PV标签选择器和StorageClass等相关信息即可。

### 2\. PV资源实践；

#### 2.1 PV配置字段详解

PresistentVolume Spec支持如下几个通用字段，用于定义PV的容量，访问模式和回收策。  
1.Capacity: PV的容量  
2.volumeMode: 卷类型，用于指定此卷可被用作文件系统还是裸格式的块设备，默认为Filesystem。  
3.accessMode: PV的访问模式[参考官方](https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/#volume-mode "volume-mode")

*   1.ReadWriteOnce: 仅可被单个节点读写挂载；命令行中简写RWO。
*   2.ReadOnlyMany: 仅可被多个节点同时只读挂在；命令行简写ROX。
*   3.ReadyWriteMany: 可被多个节点同时读写挂载；命令行中简写RWX。

4.persistentVolumeReclaimPolicy: PV空间的处理机制，可用类型为Retain(默认)、Recycle或Delete。

*   1.Retain: 保持不动，由管理员手动回收。
*   2.Recycle: 空间回收，即删除存储卷下的所有文件(包括子目录和隐藏文件rm -rf /thevolume/\*)，目前仅NFS和hostpath支持此功能。
*   3.Delete: 删除存储卷，诸如 AWS EBS、GCE PD、Azure Disk 或 OpenStack Cinder 卷这类关联存储资产也被删除。

5.storageClassName: 当前PV所属的StorageClass的名称，默认为空，即不属于任何StorageClass。  
6.mountOptions: 挂载选项组成的列表，如ro，soft和hard等。

#### 2.2 HostPath PV示例

    [root@kn-server-master01-13 pv]# cat hostpath-pv.yaml 
    apiVersion: v1
    kind: PersistentVolume
    metadata:
      name: pv-volume-001    
    spec: 
      storageClassName: "host-storage"   资源类型的标识
      persistentVolumeReclaimPolicy: "Retain"  回收策略默认为Retain
      capacity:    定义空间
        storage: 1Gi  定义空间大小
      accessModes:    访问模式
        - ReadWriteOnce  访问模式为仅被单个节点读写挂载，单路读写
      hostPath:     临时存储在哪个地方
        path: "/mnt/data"
    [root@kn-server-master01-13 pv]# kubectl get pv
    NAME            CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
    pv-volume-001   1Gi        RWO            Retain           Available           host-storage            4m36s
    

#### 2.2 NFS PV示例

    [root@kn-server-master01-13 pv]# cat nfs-pv.yaml 
    apiVersion: v1
    kind: PersistentVolume
    metadata:
      name: nfs-pv
      labels:     标签
        release: nfs-redis
    spec:
      storageClassName: "nfs-storage"  资源类型表示
      persistentVolumeReclaimPolicy: "Recycle"  回收策略为Recycle相当rm -rf /
      capacity: 
        storage: 0.5Gi
      accessModes:
      - ReadWriteMany
      nfs: 
        server: 10.0.0.15
        path: /data/redis
    [root@kn-server-master01-13 pv]# kubectl get pv
    NAME            CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM             STORAGECLASS   REASON   AGE
    nfs-pv          512Mi      RWX            Recycle          Available                     nfs-storage             62m
    pv-volume-001   1Gi        RWO            Retain           Bound       default/001-pvc   host-storage            160m
    

### 3\. PVC资源实践；

#### 3.1 PVC配置清单详解。

PersistentVolumeClaim，PVC是存储卷类型的资源，它通过申请占用某个PersistentVolume而创建，它与PV是一对一的关系，用户无须关心其底层实现细节， 申请时，用户只需要指定目标空间的大小，访问模式，PV标签选择器和StorageClass等相关信息即可。  
PVC的Spec字段可嵌套字段如下，

1.  accessMode: 当前PVC的访问模式，其可用模式与PV相同。
2.  resource当前PVC存储卷需要占用的资源的最大和最小值。
3.  selector绑定时对PV应用的标签选择器，matchlabels或者匹配表达式matchEx-pressions用于挑选要绑定的PV，如果同时指定来两种挑选机制，则必须同时满足两种选择机制的PV才能被选出。
4.  storageClassName: 所依赖的存储卷的名称。
5.  volumeName: 用于直接制定要绑定的PV的卷名。

#### 3.2 hostPath-PVC示例

    [root@kn-server-master01-13 pv]# cat hostpath-pvc.yaml 
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: 001-pvc
    spec:
      storageClassName: "host-storage"  和PV的storageclassname须一致，否则无法识别。
      accessModes:
        - ReadWriteOnce
      resources:     pvc的资源限定仅指其空间大小。
        requests:
          storage: 0.9Gi  大小为0.9Gi；
    [root@kn-server-master01-13 pv]#  kubectl apply -f hostpath-pvc.yaml 
    
    Available: 可用状态的自由资源，尚未被绑定PVC。
    Bound: 已经绑定至某个PVC。
    Released: 绑定的PVC已经被删除，但资源尚被集群回收。
    Failed: 因自动回收资源失败而处于的故障状态。
    [root@kn-server-master01-13 pv]# kubectl get pv pv-volume-001
    NAME            CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM             STORAGECLASS   REASON   AGE
    pv-volume-001   1Gi        RWO            Retain           Bound    default/001-pvc   host-storage            33m
    
    
    [root@kn-server-master01-13 pv]# kubectl describe pv pv-volume-001
    Name:            pv-volume-001
    Labels:          <none>
    Annotations:     pv.kubernetes.io/bound-by-controller: yes
    Finalizers:      [kubernetes.io/pv-protection]
    StorageClass:    host-storage
    Status:          Bound
    Claim:           default/001-pvc
    Reclaim Policy:  Retain
    Access Modes:    RWO
    VolumeMode:      Filesystem
    Capacity:        1Gi
    Node Affinity:   <none>
    Message:         
    Source:
        Type:          HostPath (bare host directory volume)
        Path:          /mnt/data
        HostPathType:  
    Events:            <none>
    [root@kn-server-master01-13 pv]# kubectl describe pvc 001-pvc 
    Name:          001-pvc
    Namespace:     default
    StorageClass:  host-storage
    Status:        Bound   已绑定
    Volume:        pv-volume-001
    Labels:        <none>
    Annotations:   pv.kubernetes.io/bind-completed: yes
                   pv.kubernetes.io/bound-by-controller: yes
    Finalizers:    [kubernetes.io/pvc-protection]
    Capacity:      1Gi
    Access Modes:  RWO
    VolumeMode:    Filesystem
    Used By:       <none>
    Events:        <none>
    

#### 3.3 NFS-PV-PVC实践之准备NFS共享存储。

NFS即是网络文件系统，它是一种分布式文件系统协议，kubernetes中的NFS存储卷用于将某些事先存在的NFS服务器导出(export)的存储空间挂载到Pod中以供容器使用，与临时存储不同的是，NFS存储卷在Pod对象终止后仅仅是被卸载而非删除，NFS是文件系统级共享服务，它支持同时存在多路挂载，定义NFS存储卷时，常用如下字段。  
server nfs服务器的地址或者主机名，必须字段。  
pathnfs服务器导出(共享)的文件系统路径，必须字段。  
readOnly是否以只读方式挂载，默认为false。  
生产环境建议使用Ceph、azureDisk等公有云存储。

    [root@kn-server-node02-15 ~]# yum install nfs-utils -y 
    
    [root@kn-server-node02-15 ~]# cat /etc/exports
    /nfs/data5/ 10.0.0.0/24(rw,no_root_squash)
    /data/redis 10.0.0.0/24
    10.0.0.0/24  pod访问nfs服务会将源IP修改为节点IP，允许所有节点访问NFS服务
    (ro,no_root_squash)访问NFS-SERVER共享目录的用户如果是root，它对共享目录有root权限
    准备数据共享目录
    [root@kn-server-node02-15 ~]# mkdir /data/redis -p 
    
    [root@kn-server-node02-15 ~]# systemctl enable nfs-server
    Created symlink from /etc/systemd/system/multi-user.target.wants/nfs-server.service to /usr/lib/systemd/system/nfs-server.service.
    
    
    服务端配置
    各个工作节点安装nfs-utils
    [root@kn-server-master01-13 pv]# showmount -e 10.0.0.15
    Export list for 10.0.0.15:
    /data/redis 10.0.0.0/24
    master节点和node节点都需要安装
    [root@kn-server-node01-14 ~]# showmount -e 10.0.0.15
    Export list for 10.0.0.15:
    /data/redis 10.0.0.0/24
    

#### 3.4 准备NFS-PVC

    [root@kn-server-master01-13 pv]# cat nfs-pvc.yaml 
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: nfs-pvc
      labels:    首先标签须匹配，不然无法匹配，也可以称为强行绑定。
        release: nfs-redis
    spec:
      storageClassName: "nfs-storage"  须同属一个
      accessModes: 
      - ReadWriteMany
      resources:
        requests:
          storage: 0.5Gi  指定大小。
    
    [root@kn-server-master01-13 pv]# kubectl apply -f nfs-pvc.yaml 
    persistentvolumeclaim/nfs-pvc created
    
    显示已为绑定状态。
    [root@kn-server-master01-13 pv]# kubectl get pv,pvc 
    NAME                             CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM             STORAGECLASS   REASON   AGE
    persistentvolume/nfs-pv          512Mi      RWX            Recycle          Bound    default/nfs-pvc   nfs-storage             78m
    persistentvolume/pv-volume-001   1Gi        RWO            Retain           Bound    default/001-pvc   host-storage            175m
    
    NAME                            STATUS   VOLUME          CAPACITY   ACCESS MODES   STORAGECLASS   AGE
    persistentvolumeclaim/001-pvc   Bound    pv-volume-001   1Gi        RWO            host-storage   143m
    persistentvolumeclaim/nfs-pvc   Bound    nfs-pv          512Mi      RWX            nfs-storage    6s
    
    通过describe来查看
    [root@kn-server-master01-13 pv]# kubectl describe pv nfs-pv
    Name:            nfs-pv
    Labels:          release=nfs-redis   所属标签
    Annotations:     pv.kubernetes.io/bound-by-controller: yes
    Finalizers:      [kubernetes.io/pv-protection]
    StorageClass:    nfs-storage    storageclass名称
    Status:          Bound   绑定状态
    Claim:           default/nfs-pvc   名称空间
    Reclaim Policy:  Recycle  回收策略
    Access Modes:    RWX    访问模式
    VolumeMode:      Filesystem
    Capacity:        512Mi  大小
    Node Affinity:   <none>
    Message:         
    Source:
        Type:      NFS (an NFS mount that lasts the lifetime of a pod)
        Server:    10.0.0.15  来自那个nfs服务器
        Path:      /data/redis   共享的数据目录
        ReadOnly:  false
    Events:        <none>
    

###### 3.4.1准备Pod并使用PVC

    [root@kn-server-master01-13 pv]# cat pod-redis.yaml 
    apiVersion: v1
    kind: Pod
    metadata:
      name: redis
    spec: 
      containers:
      - name: redis
        image: redis
        volumeMounts:
        - name: redis-data
          mountPath: /data
      volumes:
      - name: redis-data
        persistentVolumeClaim:
          claimName: nfs-pvc 
    	  
    [root@kn-server-master01-13 pv]# kubectl describe pods redis
    Containers:
      redis:
        Container ID:   docker://d82061a1a86f56432e9956fc46bc810e577a0d89b91894e266e883bef68f5d9d
        Image:          redis
        Image ID:       docker-pullable://redis@sha256:db485f2e245b5b3329fdc7eff4eb00f913e09d8feb9ca720788059fdc2ed8339
        Port:           <none>
        Host Port:      <none>
        State:          Running
          Started:      Sun, 27 Nov 2022 21:57:34 +0800
        Ready:          True
        Restart Count:  0
        Environment:    <none>
        Mounts:
          /data from redis-data (rw)   已经挂载
    	  
    	  
    [root@kn-server-master01-13 pv]# kubectl describe pvc nfs-pvc
    Name:          nfs-pvc
    Namespace:     default
    StorageClass:  nfs-storage
    Status:        Bound
    Volume:        nfs-pv
    Labels:        release=nfs-redis
    Annotations:   pv.kubernetes.io/bind-completed: yes
                   pv.kubernetes.io/bound-by-controller: yes
    Finalizers:    [kubernetes.io/pvc-protection]
    Capacity:      512Mi
    Access Modes:  RWX
    VolumeMode:    Filesystem
    Used By:       redis  这里可以看到是redis这个Pod正在使用这个PVC
    Events:        <none>
    

###### 3.4.2 测试数据持久性。

    [root@kn-server-master01-13 pv]# redis-cli -h 192.168.1.86
    192.168.1.86:6379> set key haitang 
    OK
    192.168.1.86:6379> get key
    "haitang"
    192.168.1.86:6379> bgsave
    Background saving started
    192.168.1.86:6379> exit
    
    
    可以看到数据是写到nfs-server了
    [root@kn-server-node02-15 redis]# ll
    总用量 4
    -rw-r--r-- 1 polkitd input 110 11月 27 22:14 dump.rdb
    
    
    删除Pod后，数据是不会丢失的。
    [root@kn-server-master01-13 pv]# kubectl delete pods redis
    pod "redis" deleted
    
    数据是还在的。
    [root@kn-server-node02-15 redis]# ll
    总用量 4
    -rw-r--r-- 1 polkitd input 110 11月 27 22:20 dump.rdb
    

我们一直奔跑在进步的旅途