---
layout: post
title: "Atlas2.2.0编译、安装及使用(集成ElasticSearch，导入Hive数据)"
date: "2022-05-11T13:40:01.698Z"
---
Atlas2.2.0编译、安装及使用(集成ElasticSearch，导入Hive数据)
============================================

在数仓项目中，我们常常会选择Apache Atlas进行数据的治理。本文结合笔者在生产环境中遇到的常见问题及解决方法，整合出完整的Atlas编译、部署及使用过程。

### 1、编译阶段

**组件信息：**

组件名称

版本

Atals

2.2.0

HBase

2.2.6

Hive

3.1.2

Hadoop

3.1.1

Kafka

2.11\_2.4.1

Zookeeper

3.6.2

ElasticSearch

7.12.1

   
架构: x86 (已知arm编译时会报node-sass缺少的问题，git上没有对应arm架构的包)  
操作系统：CentOS 7.6

**说明：**  
1、编译不包括其内嵌的HBase和Solr，只编译Atlas本身  
2、下面的步骤中有些并非编译过程报错，而是具体使用中或导入hive元数据时报的错，提前修改

**步骤：**  
step1：官网下载[Atlas-2.2.0源码](https://www.apache.org/dyn/closer.cgi/atlas/2.2.0/apache-atlas-2.2.0-sources.tar.gz),解压  
   
step2：配个国内源。可以在maven的conf目录下settings.xml里配置，也可以在项目的pom.xml里配置，这里贴[阿里源](https://developer.aliyun.com/mvn/guide)做参考  
   
step3：提前从[Here](https://nodejs.org/dist/v12.16.0/node-v12.16.0-linux-x64.tar.gz)下一个nodejs的包放到maven仓库下，目录参考  
`$MAVEN_REPOSITORY/com/github/eirslett/node/12.16.0/node-12.16.0-linux-x64.tar.gz`

> 注意下下来的包名字叫node-v12.16.0-linux-x64.tar.gz，放在maven仓库里的时候要把里面的v去掉。如果不提前下，编译时候自己下载的速度很慢

step4：主pom.xml里添加下面两个依赖

                            <dependency>
                    <groupId>org.restlet.jee</groupId>
                    <artifactId>org.restlet</artifactId>
                    <version>2.4.0</version>
                </dependency>
                
                <dependency>
                    <groupId>org.restlet.jee</groupId>
                    <artifactId>org.restlet.ext.servlet</artifactId>
                    <version>2.4.0</version>
                </dependency>
    

   
step5：修改`./intg/src/main/java/org/apache/atlas/ApplicationProperties.java`  
注释掉line 365 `LOG.info("Setting " + SOLR_WAIT_SEARCHER_CONF + " = " + getBoolean(SOLR_WAIT_SEARCHER_CONF));`

> 这步是因为我们采用es作为查询引擎，solr的相关配置都会注释掉，而这行调用会在导入hive元数据的时候报错

   
step6：把项目里的`jsr311-api`改成`javax.ws.rs-api`  (6处，可以直接在项目目录下`grep -rn`搜)， 并修改主`pom.xml`中`jsr.version`为2.0.1

> 这步主要影响六个支持的组件的数据导入及后续，包括`hbase、hive、sqoop、impala、falcon、storm`  
> 主要原因：`jsr311-api`包中`javax.ws.rs.core`包中没有`Link`类，而Atlas以HBase作为元数据存储，HBase本身使用的为`javax.ws.rs-api`包中的core包，其中有Link类，所以调用脚本导入数据时会报以下错误  
> ![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511144731559-782568937.png)

step7：执行编译命令`mvn clean package -DskipTests -Drat.skip=true -Pdist`

> 编译后的包在./distro/target目下,server包即为Atlas部署包，bin包为集成了常用hook(如hbase-hook)的部署包

### 2、部署阶段

**前置条件：**  
集群内有正常运行且可用的hadoop、hive、hbase、kafka、zk、es，且atlas所在节点必须有hbase及hive的配置文件目录

**步骤：**  
step1:解压atlas-bin包(这里以/data/apps为例，顺便改个名

    tar -zxvf apache-atlas-2.2.0-bin.tar.gz -C /data/apps
    mv apache-atlas-2.2.0 atlas-2.2.0
    

   
step2:解压hook包(这里以hive-hook为例)，并拷贝内容到atlas安装目录下

    tar -zxvf apache-atlas-2.2.0-hive-hook.tar.gz -C /data/apps/
    /usr/bin/cp /data/apps/apache-atlas-hive-hook-2.2.0/* /data/apps/atlas-2.2.0/
    

   
step3:修改atlas配置文件(有的配置是已有的，修改即可；有的配置没有，需要加)  
**atlas-application.properties:**

         #atlas server config
                 atlas.rest.address=http://atlas-ip:21000
            atlas.server.run.setup.on.start=false
          
         #hbase config
            atlas.audit.hbase.tablename=apache_atlas_entiry_audit
            atuls.audit.zookeeper.session.timeout.ms=1000
            atlas.audit.hbase.zookeeper.quorum=zk地址
                 atlas.graph.storage.hostname=zk地址
            
         #solr config
          #注释掉所有和solr相关的配置项
            
         #es config
                  atlas.graph.index.search.backend=elasticsearch
            atlas.graph.index.search.hostname=es-ip:9200
            atlas.graph.index.search.elasticsearch.client-only=true
            atlas.graph.index.search.elasticsearch.http.auth.type=basic
            atlas.graph.index.search.elasticsearch.http.auth.basic.username=elastic
            atlas.graph.index.search.elasticsearch.http.auth.basic.password=Cestc!666
          
        #kafka config
                 atlas.nofification.embedded=false
            atlas.kafka.data=/data/log/kafka
            atlas.kafka.zookeeper.connect=zk地址/kafkaCluster
            atlas.kafka.bootstrap.servers=kafka地址
          
        #hive config
                 atlas.hook.hive.numRetries=3
            atlas.hook.hive.queueSize=10000
            atlas.cluster.name=primary
    

**atlas-env.sh:**

            export HBASE_CONF_DIR=/data/apps/hbase-2.2.6/conf
    

**atlas-log4j.xml:**

            #去掉org.apache.log4j.DailyRollingFileAppender一块的注释来暴露性能指标
    

   
step4:将atlas-application.properties分发到所有hive所在节点的hive/conf目录下  
   
step5:分发hive-hook目录到hive节点下,并修改hive配置文件

    ssh hive-node "mkdir -p /data/apps/atlas-2.2.0/hook"
    scp -r /data/apps/atlas-2.2.0/hook/hive hive-node:$PWD
    

**hive-site.xml**

               <property>
                <name>hive.exec.post.hooks</name>
                <value>org.apache.atlas.hive.hook.HiveHook</value>
            </property>
    

**hive-env.sh**

           export HIVE_AUX_JARS_PATH=/data/apps/atlas-2.2.0/hook/hive
    

   
step6:重启Hive  
   
step7:调用atlas启动脚本启动服务

    $ATLAS_HONE/bin/atlas_start.py
    

启动过程如下图所示  
![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511145650059-1407800091.png)

该过程会耗时较久，包含index创建、数据的初始化等操作  
此时可以跟一下atlas的启动日志，直到日志不再刷新，再lsof或netstat查一下21000是否已经监听了，如已存在，则打开浏览器输入ip:21000登录atlas页面

> 千万不要相信他提示的Apache Atlas Server started!!!和jps显示的Atlas进程，因为启动脚本超过一定时间后一定会报成功，但此时21000端口还未被监听，服务是不可用的，真正可用还是以21000被成功监听，可以进到Atlas登录页面为准  
> ![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511145724010-605312490.png)  
> ![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511145836182-1040729628.png)

### 3、使用阶段

**说明：**  
此处我们以Hive的元数据导入及使用为例，其它数据源使用类似  
 

**步骤：**  
step1:进入atlas安装目录下，执行hook-bin中的import-hive.sh脚本

    $ATLAS_HOME/hook-bin/import-hive.sh 
    

执行后如下图  
![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511145907365-856233432.png)

过程中会提示输入atlas用户名和密码，都输入admin即可  
成功后会提示  
![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511145924885-689544950.png)

> 该过程时间视hive现有数据量大小而定

step2:登录Atlas Web页面  
打开浏览器输入ip:21000登录atlas页面  
![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511145956417-1559863163.png)  
   
登录后如下图  
![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511150026778-1008535876.png)

此时可以点击右上角小图标  
![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511150049258-1631121935.png)

查看总体数据情况  
![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511150108408-552221053.png)  
 

查看所有hive表  
![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511150127777-454476834.png)  
 

随便点击一个表查看详情  
![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511150208253-2020734248.png)

![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511150220559-570260992.png)

![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511150229283-1177522699.png)

可以清楚地看到这个表的各项信息、字段及血缘图等  
   
我们也可以通过左侧搜索栏检索过滤想要查找的项  
![](https://img2022.cnblogs.com/blog/1913320/202205/1913320-20220511150246828-1716910977.png)  
 

以上就是我在生产环境中部署Atlas-2.2.0并集成es、hive的过程，使用时可以点击页面操作，也可通过调用Rest API集成到自己系统里用

> 本文首发于博客园，作者榆天紫夏，希望对大家有所帮助。原文地址https://www.cnblogs.com/yutianzixia/p/16257916.html。如有遗漏或问题欢迎补充指正

本文来自博客园，作者：[榆天紫夏](https://www.cnblogs.com/yutianzixia/)，转载请注明原文链接：[https://www.cnblogs.com/yutianzixia/p/16257916.html](https://www.cnblogs.com/yutianzixia/p/16257916.html)