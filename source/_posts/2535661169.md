---
layout: post
title: "docker搭建Elasticsearch、Kibana、Logstash 同步mysql数据到ES"
date: "2022-12-28T02:36:14.385Z"
---
docker搭建Elasticsearch、Kibana、Logstash 同步mysql数据到ES
==================================================

一、前言
----

在数据量大的企业级实践中，`Elasticsearch`显得非常常见，特别是数据表超过千万级后，无论怎么优化，还是有点力不从心！使用中，最首先的问题就是怎么把千万级数据同步到`Elasticsearch`中，在一些开源框架中知道了，有专门进行同步的！那就是`Logstash` 。在思考，同步完怎么查看呢，这时`Kibana`映入眼帘，可视化的界面，让使用更加的得心应手哈！！这就是三剑客`ELK`。不过大多时候都是进行日志采集的，小编没有用，只是用来解决一个表的数据量大，查询慢的！后面小编在专门搭建日志采集的`ELK`。

二、三者介绍
------

### 1\. Elasticsearch

Elasticsearch 是一个`分布式`、`RESTful` 风格的`搜索`和`数据分析引擎`，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，Elasticsearch 会集中存储您的数据，让您飞快完成搜索，微调相关性，进行强大的分析，并轻松缩放规模。

### 2\. Kibana

Kibana 是一个免费且开放的`用户界面`，能够让您对 Elasticsearch 数据进行`可视化`，并让您在 Elastic Stack 中进行导航。您可以进行各种操作，从跟踪查询负载，到理解请求如何流经您的整个应用，都能轻松完成。

### 3\. Logstash

Logstash 是免费且开放的`服务器端数据处理管道`，能够从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。

三、版本选择
------

现在最新版就是`8.5`，最新的教程少和问题未知，小编选择7版本的，求一手稳定哈！

于是去`hub.docker`查看了一下，经常用的版本，最终确定为：`7.17.7`

[dockerHub官网地址](https://hub.docker.com/_/elasticsearch)

官方规定：  
安装 Elastic Stack 时，您必须在整个堆栈中使用相同的版本。例如，如果您使用的是 Elasticsearch 7.17.7，则安装 Beats 7.17.7、APM Server 7.17.7、Elasticsearch Hadoop 7.17.7、Kibana 7.17.7 和 Logstash 7.17.7

![在这里插入图片描述](https://img-blog.csdnimg.cn/8b7544c614bb40dcab0248c5449dd393.png)

四、搭建mysql
---------

### 1\. 拉去MySQL镜像

    sudo docker pull mysql:5.7
    

![![在这里插入图片描述](https://img-blog.csdnimg.cn/0709ce9181a04bfcb97504cae7189ba5.png](https://img-blog.csdnimg.cn/eb41fad5dfbd4272871feffce4679e3f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5o6J5Y-R55qE5bCP546L,size_20,color_FFFFFF,t_70,g_se,x_16)  
)

### 2\. Docker启动MySQL

    sudo docker run -p 3306:3306 --name mysql \
    -v /mydata/mysql/log:/var/log/mysql \
    -v /mydata/mysql/data:/var/lib/mysql \
    -v /mydata/mysql/conf:/etc/mysql \
    -e MYSQL_ROOT_PASSWORD=root \
    -d mysql:5.7
    ####这里往下是解释,不需要粘贴到linux上#############
    --name 指定容器名字
    -v 将对应文件挂载到linux主机上
    -e 初始化密码
    -p 容器端口映射到主机的端口(把容器的3306映射到linux中3306,这样windows上就可以访问这个数据库)
    -d 后台运行
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/6a175ea2624a43dd9acab54ad242a0a1.png)

### 3\. Docker配置MySQL

    vim /mydata/mysql/conf/my.cnf # 创建并进入编辑
    

    [client]
    default-character-set=utf8
    [mysql]
    default-character-set=utf8
    [mysqld]
    init_connect='SET collation_connection = utf8_unicode_ci'
    init_connect='SET NAMES utf8'
    character-set-server=utf8
    collation-server=utf8_unicode_ci
    skip-character-set-client-handshake
    skip-name-resolve
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/d0506f1620644a78a88a554ad5a10fc6.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5o6J5Y-R55qE5bCP546L,size_20,color_FFFFFF,t_70,g_se,x_16)

### 4\. Docker重启MySQL使配置生效

    docker restart mysql
    

### 5\. 新增数据库

![在这里插入图片描述](https://img-blog.csdnimg.cn/f9d7322213344dfd9844a843d6a2a10e.png)

### 6\. 新建测试表

    DROP TABLE IF EXISTS `sys_log`;
    CREATE TABLE `sys_log`  (
      `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '日志主键',
      `title` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '' COMMENT '模块标题',
      `business_type` int(2) NULL DEFAULT 0 COMMENT '业务类型（0其它 1新增 2修改 3删除）',
      `method` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '' COMMENT '方法名称',
      `request_method` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '' COMMENT '请求方式',
      `oper_name` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '' COMMENT '操作人员',
      `oper_url` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '' COMMENT '请求URL',
      `oper_ip` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '' COMMENT '主机地址',
      `oper_time` datetime(0) NULL DEFAULT NULL COMMENT '操作时间',
      PRIMARY KEY (`id`) USING BTREE
    ) ENGINE = InnoDB AUTO_INCREMENT = 1585197503834284034 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '操作日志记录' ROW_FORMAT = Dynamic;
    
    SET FOREIGN_KEY_CHECKS = 1;
    

五、ELK搭建准备
---------

### 1\. 创建挂载的文件

es挂载：

    mkdir -p /mydata/elk/elasticsearch/{config,plugins,data,logs}
    

kibana挂载：

    mkdir -p /mydata/elk/kibana/config
    

logstash挂载：

    mkdir -p /mydata/elk/logstash/config
    

### 2\. ES挂载具体配置

    vim /mydata/elk/elasticsearch/config/elasticsearch.yml
    

输入下面命令：

    http.host: 0.0.0.0
    xpack.security.enabled: false
    

http.host：任何地址都可以访问。  
xpack.security.enabled：关闭密码认证

### 3\. Kibana挂载具体配置

    vim /mydata/elk/kibana/config/kibana.yml
    

内容：

    server.host: 0.0.0.0
    elasticsearch.hosts: [ "http://192.168.239.131:9200" ]
    

elasticsearch.hosts：指向es地址

### 4\. Logstash挂载具体配置

    vim /mydata/elk/logstash/config/logstash.yml
    

内容：

    http.host: 0.0.0.0
    xpack.monitoring.elasticsearch.hosts: [ "http://192.168.239.131:9200" ]
    

记录存放：

    touch log
    chmod 777 log
    

    vim /mydata/elk/logstash/config/logstash.conf
    

内容：

`jdbc_driver_library`：指定必须要自己下载`mysql-connector-java-8.0.28.jar`，版本自己决定，[下载地址](https://mvnrepository.com/artifact/mysql/mysql-connector-java)；

`statement`：如果sql长，可以指定sql文件，直接指定文件所在位置，这里的位置都为容器内部的地址；

`last_run_metadata_path`：上次记录存放文件对应上方的log。

![在这里插入图片描述](https://img-blog.csdnimg.cn/3a8f3732092e41fc9c4e60fde6410792.png)

    input {
        stdin {
        }
        jdbc {
          jdbc_connection_string => "jdbc:mysql://192.168.239.131:3306/test?useUnicode=true&characterEncoding=utf8&serverTimezone=UTC"
          jdbc_user => "root"
          jdbc_password => "root"
          jdbc_driver_library => "/usr/share/logstash/config/mysql-connector-java-8.0.28.jar"
          jdbc_driver_class => "com.mysql.jdbc.Driver"
          jdbc_paging_enabled => "true"
          jdbc_page_size => "300000"
          statement => "SELECT id, title, business_type, method, request_method, oper_name, oper_url, oper_ip, oper_time FROM sys_log"
          schedule => "*/1 * * * *"
          use_column_value => false
          tracking_column_type => "timestamp"
          tracking_column => "oper_time"
          record_last_run => true
          jdbc_default_timezone => "Asia/Shanghai"
          last_run_metadata_path => "/usr/share/logstash/config/log"
        }
    }
     
    output {
        elasticsearch {
            hosts => ["192.168.239.131:9200"]
            index => "sys_log"
            document_id => "%{id}"
        }
        stdout {
            codec => json_lines
        }
    }
    
    

流水线指定上面的配置文件：

    vim /mydata/elk/logstash/config/pipelines.yml
    

内容：

    - pipeline.id: sys_log
      path.config: "/usr/share/logstash/config/logstash.conf"
    

最终`/mydata/elk/logstash/config/`下的文件

![在这里插入图片描述](https://img-blog.csdnimg.cn/07d49ef0b68844a1822b677b4e47e962.png)

防止保存没有修改权限，可以把上面建的文件夹和文件赋予修改权限：

    chmod 777 文件名称
    

五、运行容器
------

### 0\. docker compose一键搭建

在elk目录创建：

    vim docker-compose.yml
    

内容如下：

    version: '3'
    services:
      elasticsearch:
        image: elasticsearch:7.17.7
        container_name: elasticsearch
        ports:
          - "9200:9200"
          - "9300:9300"
        environment:
          - cluster.name=elasticsearch
          - discovery.type=single-node
          - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
        volumes:
          - /mydata/elk/elasticsearch/plugins:/usr/share/elasticsearch/plugins
          - /mydata/elk/elasticsearch/data:/usr/share/elasticsearch/data
          - /mydata/elk/elasticsearch/logs:/usr/share/elasticsearch/logs
    
      kibana:
        image: kibana:7.17.7
        container_name: kibana
        ports:
          - "5601:5601"
        depends_on:
          - elasticsearch
        environment:
          I18N_LOCALE: zh-CN
        volumes:
          - /mydata/elk/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml
    
      logstash:
        image: logstash:7.17.7
        container_name: logstash
        ports:
          - "5044:5044"
        volumes:
          - /mydata/elk/logstash/config:/usr/share/logstash/config
        depends_on:
          - elasticsearch
    

一定要在`docker-compose.yml`所在目录执行命令！！

运行：

    docker compose up -d
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/3415ba11f9084693b0118bb09346b6ea.png)

完成后可以跳到`5`进行查看kibana！！

### 1\. 运行ES

    docker run --name elasticsearch -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" -e ES_JAVA_OPTS="-Xms64m -Xmx512m" -v /mydata/elk/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /mydata/elk/elasticsearch/data:/usr/share/elasticsearch/data -v  /mydata/elk/elasticsearch/plugins:/usr/share/elasticsearch/plugins -d elasticsearch:7.17.7
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/cbbbbee8620a41f79c531581745e37c6.png)

### 2\. 运行Kibana

    docker run --name kibana -e ELASTICSEARCH_HOSTS=http://192.168.239.131:9200 -p 5601:5601 -d kibana:7.17.7
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/23510fe9fbc54431856db35a66cb3bcd.png)

### 3\. 运行Logstash

    docker run -d -p 5044:5044 -v /mydata/elk/logstash/config:/usr/share/logstash/config --name logstash logstash:7.17.7
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/1d37bc3364be44da9d9eb6c0d64d8b89.png)

### 4\. 容器完结图

![在这里插入图片描述](https://img-blog.csdnimg.cn/ddf5e2186db6455280fe70a49afccfad.png)

### 5\. 访问Kibana

`http://192.168.239.131:5601/app/home#/`

![在这里插入图片描述](https://img-blog.csdnimg.cn/ffc25fd562a644638e95801a84c54eb3.png)

六、新建索引
------

    PUT /sys_log
    {
      "settings": {
        "number_of_shards": 1,
        "number_of_replicas": 0,
        "index": {
          "max_result_window": 100000000
        }
      },
      "mappings": {
        "dynamic": "strict",
        "properties": {
          "@timestamp": {
            "type": "date"
          },
          "@version": {
            "type": "text",
            "fields": {
              "keyword": {
                "type": "keyword",
                "ignore_above": 256
              }
            }
          },
          
          "business_type": {
            "type": "integer"
          },
          "title": {
            "type": "text"
          },
          "method": {
            "type": "text"
          },
          "request_method": {
            "type": "text"
          },
          "oper_name": {
            "type": "text"
          },
          "oper_url": {
            "type": "text"
          },
          "oper_ip": {
            "type": "text"
          },
          "oper_time": {
            "type": "date"
          },
          "id": {
            "type": "long"
          }
        }
      }
    }
    

七、测试
----

新增几条记录，然后查看Logstash日志

    docker logs -f logstash
    

![在这里插入图片描述](https://img-blog.csdnimg.cn/3e2c482181b94c078fb40d8d6f176ac9.png)  
我们去kibana看一下是否已存在：  
输入命令：

    GET /sys_log/_search
    {
      "query": {
        "match_all": {}
      }
    }
    

我们看到存在6条，和mysql一致！！

![在这里插入图片描述](https://img-blog.csdnimg.cn/8f2fdd1cc87d444f9381c620d667e346.png)  
![在这里插入图片描述](https://img-blog.csdnimg.cn/499c184aa333440a8fcd0c1b174912d1.png)

八、总结
----

话费了一天时间，终于搭建完成了，太不容易了！下篇文章搭建ELK日志，欢迎点个关注，等待更新哈！！

如果对你有帮助，还请不要吝啬您的发财小手，一键三连是我写作的动力，谢谢大家哈！！

* * *

可以看下一小编的微信公众号文章首发看，欢迎关注，一起交流哈！！

![](https://img2023.cnblogs.com/blog/2471401/202212/2471401-20221228084923303-697925146.jpg)