---
layout: post
title: "MySQL半同步复制源码解析"
date: "2022-09-13T06:13:30.520Z"
---
MySQL半同步复制源码解析
==============

今天 DBA 同事问了一个问题，MySQL在半同步复制的场景下，当关闭从节点时使得从节点的数量 < rpl\_semi\_sync\_master\_wait\_for\_slave\_count时，show full processlist 的结果不同，具体表现如下：

AFTER\_SYNC表现如下：

![](https://img2022.cnblogs.com/blog/727246/202209/727246-20220905184327030-1841881689.png)

 可以发现，只有一个查询线程处于 Waiting for semi-sync ACK from slave 状态，其他查询线程处于 query end 状态。

AFTER\_COMMIT 表现如下：

![](https://img2022.cnblogs.com/blog/727246/202209/727246-20220905184543057-560463824.png)

 和 AFTER\_SYNC 不同， 所有的查询线程处于 Waiting for semi-sync ACK from slave 状态；

之前已经了解过 MySQL半同步复制，这次从源码的角度来解析MySQL半同步复制到底是如何进行的，同时分析原因。

首先看事务的提交过程，整体的提交流程过长，切之前已经研究过源码，这里仅对关于半同步复制相关的部分做深入分析：

int MYSQL\_BIN\_LOG::ordered\_commit(THD \*thd, bool all, bool skip\_commit)
{  ....
  // 执行 flush 阶段操作。
  /\*
  \* 1. 对 flush 队列进行 fetch, 本次处理的flush队列就固定了
    2. 在 innodb 存储引擎中 flush redo log, 做 innodb 层 redo 持久化。
    3. 为 flush 队列中每个事务生成 gtid。
    4. 将 flush队列中每个线程的 binlog cache flush 到 binlog 日志文件中。这里包含两步:
            1. 将事务的 GTID event直接写入 binlog 磁盘文件中
            2. 将事务生成的别的 event 写入 binlog file cache 中
  \*/
  flush\_error \= process\_flush\_stage\_queue(&total\_bytes, &do\_rotate,
                                          &wait\_queue);
  // 将 binary log cache(IO cache) flush到文件中
  if (flush\_error == 0 && total\_bytes > 0)  
    // 这里获取到 flush 队列中最后一个事务在 binlog 中的 end\_pos
    flush\_error \= flush\_cache\_to\_file(&flush\_end\_pos);
  DBUG\_EXECUTE\_IF("crash\_after\_flush\_binlog", DBUG\_SUICIDE(););
  // sync\_binlog 是否等于 1
  update\_binlog\_end\_pos\_after\_sync = (get\_sync\_period() == 1);

  /\*
    If the flush finished successfully, we can call the after\_flush
    hook. Being invoked here, we have the guarantee that the hook is
    executed before the before/after\_send\_hooks on the dump thread
    preventing race conditions among these plug-ins.
     如果 flush 操作成功, 则调用 after\_flush hook。
  \*/
  if (flush\_error == 0)
  {
    const char \*file\_name\_ptr = log\_file\_name + dirname\_length(log\_file\_name);
    assert(flush\_end\_pos != 0);
    // 观察者模式，调用 Binlog\_storage\_observer 里面的repl\_semi\_report\_binlog\_update函数，将当前的 binlog 文件和最新的 pos 点记录到 active\_tranxs\_ 列表中
    // file\_name\_ptr 当前写入的binlog文件
    // flush\_end\_pos 组提交flush链表里面所有binlog最后的pos点
    if (RUN\_HOOK(binlog\_storage, after\_flush,
                 (thd, file\_name\_ptr, flush\_end\_pos)))
    {
      sql\_print\_error("Failed to run 'after\_flush' hooks");
      flush\_error \= ER\_ERROR\_ON\_WRITE;
    }
　　　// 不等于 1, 通知 dump 线程
    if (!update\_binlog\_end\_pos\_after\_sync)  
　　　 // 更新 binlog end pos, 通知 binlog sender 线程向从库发送 event
      update\_binlog\_end\_pos();
    DBUG\_EXECUTE\_IF("crash\_commit\_after\_log", DBUG\_SUICIDE(););
  }
  ......
  DEBUG\_SYNC(thd, "bgc\_after\_flush\_stage\_before\_sync\_stage");

  /\*
    Stage #2: Syncing binary log file to disk
  \*/

　　/\*\* 释放 Lock\_log mutex, 获取 Lock\_sync mutex

   \*  第一个进入的 flush 队列的 leader 为本阶段的 leader, 其他 flush 队列加入 sync 队列, 其他 flush 队列的

   \* leader会被阻塞, 直到 commit 阶段被 leader 线程唤醒。

   \* \*/

  if (change\_stage(thd, Stage\_manager::SYNC\_STAGE, wait\_queue, &LOCK\_log, &LOCK\_sync))
  {
    DBUG\_RETURN(finish\_commit(thd));
  }

  /\*  

    根据 delay 的设置来决定是否延迟一段时间, 如果 delay 的时间越久, 那么加入 sync 队列的

    事务就越多【last commit 是在 binlog prepare 时生成的, 尚未更改, 因此加入 sync 队列的

    事务是同一组事务】, 提高了从库 mts 的效率。

\*/
  if (!flush\_error && (sync\_counter + 1 >= get\_sync\_period()))
    stage\_manager.wait\_count\_or\_timeout(opt\_binlog\_group\_commit\_sync\_no\_delay\_count,
                                        opt\_binlog\_group\_commit\_sync\_delay,
                                        Stage\_manager::SYNC\_STAGE);

    // fetch sync 队列, 对 sync 队列进行固化.

  final\_queue \= stage\_manager.fetch\_queue\_for(Stage\_manager::SYNC\_STAGE);

    // 这里 sync\_binlog file到磁盘中

if (flush\_error == 0 && total\_bytes > 0)
  {  

      // 根据 sync\_binlog 的设置决定是否刷盘

    std::pair<bool, bool\> result = sync\_binlog\_file(false);
  }

    // 在这里 sync\_binlog = 1, 更新 binlog end\_pos, 通知 dump 线程发送 event

if (update\_binlog\_end\_pos\_after\_sync)
  {
    THD \*tmp\_thd = final\_queue;
    const char \*binlog\_file = NULL;
    my\_off\_t pos \= 0;
    while (tmp\_thd->next\_to\_commit != NULL)
      tmp\_thd \= tmp\_thd->next\_to\_commit;
    if (flush\_error == 0 && sync\_error == 0)
    {
      tmp\_thd\->get\_trans\_fixed\_pos(&binlog\_file, &pos);  

        // 更新 binlog end pos, 通知 dump 线程

      update\_binlog\_end\_pos(binlog\_file, pos);
    }
  }
  DEBUG\_SYNC(thd, "bgc\_after\_sync\_stage\_before\_commit\_stage");
  leave\_mutex\_before\_commit\_stage \= &LOCK\_sync;
  /\*
    Stage #3: Commit all transactions in order.

    按顺序在 Innodb 层提交所有事务。

    如果我们不需要对提交顺序进行排序, 并且每个线程必须执行 handlerton 提交, 那么这个阶段可以跳过。

    然而, 由于我们保留了前一阶段的锁, 如果我们跳过这个阶段, 则必须进行解锁。

\*/
commit\_stage:

    // 如果需要顺序提交

if (opt\_binlog\_order\_commits &&
      (sync\_error \== 0 || binlog\_error\_action != ABORT\_SERVER))
  {

     // SYNC队列加入 COMMIT 队列, 第一个进入的 SYNC 队列的 leader 为本阶段的 leader。其他 sync 队列

     // 加入 commit 队列的 leade 会被阻塞, 直到 COMMIT 阶段后被 leader 线程唤醒。

     // 释放 lock\_sync mutex, 持有 lock\_commit mutex.

if (change\_stage(thd, Stage\_manager::COMMIT\_STAGE,
                     final\_queue, leave\_mutex\_before\_commit\_stage,
                     &LOCK\_commit))
    {
      DBUG\_PRINT("return", ("Thread ID: %u, commit\_error: %d",
                            thd\->thread\_id(), thd->commit\_error));
      DBUG\_RETURN(finish\_commit(thd));
    }
    THD \*commit\_queue = stage\_manager.fetch\_queue\_for(Stage\_manager::COMMIT\_STAGE);
    DBUG\_EXECUTE\_IF("semi\_sync\_3-way\_deadlock",
                    DEBUG\_SYNC(thd, "before\_process\_commit\_stage\_queue"););

    if (flush\_error == 0 && sync\_error == 0)
      // 调用 after\_sync hook.注意：对于after\_sync, 这里将等待binlog dump 线程收到slave节点关于队列中事务最新的 binlog\_file和 binlog\_pos的ACK。
      sync\_error = call\_after\_sync\_hook(commit\_queue);

     /\* process\_commit\_stage\_queue 将为队列中每个 thd 持有的 GTID

      调用 update\_on\_commit 或 update\_on\_rollback。

      这样做的目的是确保 gtid 按照顺序添加到 GTIDs中, 避免出现不必要的间隙

      如果我们只允许每个线程在完成提交时调用 update\_on\_commit, 则无法保证 GTID

      顺序, 并且 gtid\_executed 之间可能出现空隙。发生这种情况, server必须从

      Gtid\_set 中添加和删除间隔, 添加或删除间隔需要一个互斥锁, 这会降低性能。

    \*/

    // 在这里, 进入存储引擎中提交

    process\_commit\_stage\_queue(thd, commit\_queue);

    // 退出 Lock\_commit 锁

    mysql\_mutex\_unlock(&LOCK\_commit);

    /\* 在 LOCK\_commit 释放之后处理 after\_commit 来避免 user thread, rotate thread 和 dump thread的

       3路死锁。

    \*/

    // 处理 after\_commit HOOK

    process\_after\_commit\_stage\_queue(thd, commit\_queue);

  }
  else
  {

      // 释放锁, 调用 after\_sync hook.

if (leave\_mutex\_before\_commit\_stage)
      mysql\_mutex\_unlock(leave\_mutex\_before\_commit\_stage);
    if (flush\_error == 0 && sync\_error == 0)
      sync\_error \= call\_after\_sync\_hook(final\_queue);
  }  
  ....../\*
    Finish the commit before executing a rotate, or run the risk of a
    deadlock. We don't need the return value here since it is in
    thd->commit\_error, which is returned below.
  \*/
  (void)finish\_commit(thd);
  ......
}

在以上过程中，可以看到，在 flush 节点之后会执行 AFTER\_FLUSH hook， 这个 hook 会将当前的 binlog 文件和最新的 pos 点位记录到 active\_tranxs\_ 链表中，这个链表在半同步复制等待 slave 节点 apply 中使用：

AFTER\_FLUSH:
\-----------------------------------------------------------
int Binlog\_storage\_delegate::after\_flush(THD \*thd,
                                         const char \*log\_file,
                                         my\_off\_t log\_pos)
{
  DBUG\_ENTER("Binlog\_storage\_delegate::after\_flush");
  DBUG\_PRINT("enter", ("log\_file: %s, log\_pos: %llu",
                       log\_file, (ulonglong) log\_pos));
  Binlog\_storage\_param param;
  param.server\_id\= thd->server\_id;

  int ret= 0;  
  // 这里观察者模式
  FOREACH\_OBSERVER(ret, after\_flush, thd, (&param, log\_file, log\_pos));
  DBUG\_RETURN(ret);
}

int repl\_semi\_report\_binlog\_update(Binlog\_storage\_param \*param,
                   const char \*log\_file,
                   my\_off\_t log\_pos)
{
  int  error= 0;

  if (repl\_semisync.getMasterEnabled())
  {
    /\*
      Let us store the binlog file name and the position, so that
      we know how long to wait for the binlog to the replicated to
      the slave in synchronous replication.  
      // 这里将 binlog filename & pos 写入 active\_tranxs\_ 链表
    \*/
    error\= repl\_semisync.writeTranxInBinlog(log\_file,
                                            log\_pos);
  }

  return error;
}

半同步复制的关键是对 after\_sync 和 after\_commit 的不同选择，因此这里我们主要分析 call\_after\_sync\_hook(commit\_queue) 和 process\_after\_commit\_stage\_queue(thd, commit\_queue) 函数，这两个函数中分别调用了  RUN\_HOOK(binlog\_storage, after\_sync, (queue\_head, log\_file, pos)) 和 RUN\_HOOK(transaction, after\_commit, (head, all)) 函数，其分别对应 Binlog\_storage\_delegate::after\_sync(THD \*thd, const char \*log\_file,my\_off\_t log\_pos) 和 Trans\_delegate::after\_commit(THD \*thd, bool all) 函数, 这里采用观察者模式，我们直接找到其对应的实现：

AFTER\_SYNC:
\-----------------------------------------------------------------
static inline int call\_after\_sync\_hook(THD \*queue\_head)
{
  const char \*log\_file = NULL;
  my\_off\_t pos \= 0;

  if (NO\_HOOK(binlog\_storage))
    return 0;

  assert(queue\_head != NULL);
  for (THD \*thd = queue\_head; thd != NULL; thd = thd->next\_to\_commit)
    if (likely(thd->commit\_error == THD::CE\_NONE))  
      // 可以看到，这里获取了固化后的 commit 队列中的最新的事务的 binlog filename & pos
      thd\->get\_trans\_fixed\_pos(&log\_file, &pos);
  // 使用最新的 binlog filename & pos 调用 after\_sync hook
  if (DBUG\_EVALUATE\_IF("simulate\_after\_sync\_hook\_error", 1, 0) ||
      RUN\_HOOK(binlog\_storage, after\_sync, (queue\_head, log\_file, pos)))
  {
    sql\_print\_error("Failed to run 'after\_sync' hooks");
    return ER\_ERROR\_ON\_WRITE;
  }
  return 0;
}

// after\_sync 函数定义
int Binlog\_storage\_delegate::after\_sync(THD \*thd,
                                        const char \*log\_file,
                                        my\_off\_t log\_pos)
{
  DBUG\_ENTER("Binlog\_storage\_delegate::after\_sync");
  DBUG\_PRINT("enter", ("log\_file: %s, log\_pos: %llu",
                       log\_file, (ulonglong) log\_pos));
  Binlog\_storage\_param param;
  param.server\_id\= thd->server\_id;

  assert(log\_pos != 0);
  int ret= 0;
  FOREACH\_OBSERVER(ret, after\_sync, thd, (&param, log\_file, log\_pos));      // 找到观察器调用, 这是是观察者模式
  DEBUG\_SYNC(thd, "after\_call\_after\_sync\_observer");
  DBUG\_RETURN(ret);
}

AFTER\_SYNC:  
\----------------------------------------------------------------------------------------------------------
// after\_sync() 接口的具体实现
int repl\_semi\_report\_binlog\_sync(Binlog\_storage\_param \*param,
                                 const char \*log\_file,
                                 my\_off\_t log\_pos)
{ 
  // 是否是 after\_sync 模式
  if (rpl\_semi\_sync\_master\_wait\_point == WAIT\_AFTER\_SYNC)
    // 执行事务的线程等待从库的回复, 即等待 ACK 的实现函数
    return repl\_semisync.commitTrx(log\_file, log\_pos);   
  return 0;
}

AFTER\_COMMIT:
\-----------------------------------------------------------------------
void MYSQL\_BIN\_LOG::process\_after\_commit\_stage\_queue(THD \*thd, THD \*first)
{
  for (THD \*head = first; head; head = head->next\_to\_commit)
  {
    if (head->get\_transaction()->m\_flags.run\_hooks &&
        head\->commit\_error != THD::CE\_COMMIT\_ERROR)
    {

      /\*
        TODO: This hook here should probably move outside/below this
              if and be the only after\_commit invocation left in the
              code.
      \*/
#ifndef EMBEDDED\_LIBRARY
      Thd\_backup\_and\_restore switch\_thd(thd, head);
#endif /\* !EMBEDDED\_LIBRARY \*/
      bool all = head->get\_transaction()->m\_flags.real\_commit;  
      // 可以看到，这里针对固化的 commit 队列中的每一个事务都进行了 after\_commit HOOK.
      (void)RUN\_HOOK(transaction, after\_commit, (head, all));
      /\*
        When after\_commit finished for the transaction, clear the run\_hooks flag.
        This allow other parts of the system to check if after\_commit was called.
      \*/
      head\->get\_transaction()->m\_flags.run\_hooks = false;
    }
  }
}

int Trans\_delegate::after\_commit(THD \*thd, bool all)
{
  DBUG\_ENTER("Trans\_delegate::after\_commit");
  Trans\_param param;
  TRANS\_PARAM\_ZERO(param);
  param.server\_uuid\= server\_uuid;
  param.thread\_id\= thd->thread\_id();
  param.rpl\_channel\_type \= thd->rpl\_thd\_ctx.get\_rpl\_channel\_type();

  bool is\_real\_trans=
    (all || !thd->get\_transaction()->is\_active(Transaction\_ctx::SESSION));
  if (is\_real\_trans)
    param.flags|= TRANS\_IS\_REAL\_TRANS;

  thd\->get\_trans\_fixed\_pos(&param.log\_file, &param.log\_pos);
  param.server\_id\= thd->server\_id;

  DBUG\_PRINT("enter", ("log\_file: %s, log\_pos: %llu", param.log\_file, param.log\_pos));
  DEBUG\_SYNC(thd, "before\_call\_after\_commit\_observer");

  int ret= 0;  
  // 这里观察者模式
  FOREACH\_OBSERVER(ret, after\_commit, thd, (&param));
  DBUG\_RETURN(ret);
}

AFTER\_COMMIT：
\----------------------------------------------------------------------
// after\_commit 实际调用函数
int repl\_semi\_report\_commit(Trans\_param \*param)
{

  bool is\_real\_trans= param->flags & TRANS\_IS\_REAL\_TRANS;
  // semi\_sync 是 AFTER\_COMMIT && 是真正的事务 
  if (rpl\_semi\_sync\_master\_wait\_point == WAIT\_AFTER\_COMMIT &&
      is\_real\_trans && param->log\_pos)
  {
    const char \*binlog\_name= param->log\_file;
    // 执行事务的线程等待从库的回复, 即等待 ACK 的实现函数
    return repl\_semisync.commitTrx(binlog\_name, param->log\_pos);
  }
  return 0;
}

// 执行事务的线程等待从库的回复, 即等待 ACK 的实现函数
int ReplSemiSyncMaster::commitTrx(const char\* trx\_wait\_binlog\_name,
                  my\_off\_t trx\_wait\_binlog\_pos)
{
  const char \*kWho = "ReplSemiSyncMaster::commitTrx";

  function\_enter(kWho);
  PSI\_stage\_info old\_stage;

#if defined(ENABLED\_DEBUG\_SYNC)
  /\* debug sync may not be initialized for a master \*/
  if (current\_thd->debug\_sync\_control)
    DEBUG\_SYNC(current\_thd, "rpl\_semisync\_master\_commit\_trx\_before\_lock");
#endif
  /\* Acquire the mutex. 
  获取 LOCK\_binlog\_ 互斥锁
  \*/
  lock();
  
  TranxNode\* entry= NULL;
  mysql\_cond\_t\* thd\_cond= NULL;
  bool is\_semi\_sync\_trans= true;
  // active\_transx\_ 为当前活跃的事务链表，在 after\_flush HOOK 中会将 flush 队列中最新的事务的 binlog filename & pos 添加到该链表中
  // trx\_wait\_binlog\_name 为固化的 commit 队列中最新的事务的 binlog filename 
  if (active\_tranxs\_ != NULL && trx\_wait\_binlog\_name)
  {
    // 遍历 active\_tranxs\_ 活跃的事务链表, 找到大于等于 trx\_wait\_binlog\_name 和 trx\_wait\_binlog\_pos 
    // 的第一个事务
    entry=
      active\_tranxs\_\->find\_active\_tranx\_node(trx\_wait\_binlog\_name,
                                             trx\_wait\_binlog\_pos);
    // 如果找到了第一个事务                                         
    if (entry)
      thd\_cond\= &entry->cond;
  }
  /\* This must be called after acquired the lock \*/
  // 当前线程进入 thd\_cond 
  THD\_ENTER\_COND(NULL, thd\_cond, &LOCK\_binlog\_,
                 & stage\_waiting\_for\_semi\_sync\_ack\_from\_slave,
                 & old\_stage);
  // 如果主库启用了半同步 
  if (getMasterEnabled() && trx\_wait\_binlog\_name)
  {
    struct timespec start\_ts;
    struct timespec abstime;
    int wait\_result;
    // 设置当前时间 start\_ts
    set\_timespec(&start\_ts, 0);
    /\* This is the real check inside the mutex. \*/
    // 主库没有启动半同步 || 没有启动半同步复制, l\_end
    if (!getMasterEnabled() || !is\_on())
      goto l\_end;

    if (trace\_level\_ & kTraceDetail)
    {
      sql\_print\_information("%s: wait pos (%s, %lu), repl(%d)\\n", kWho,
                            trx\_wait\_binlog\_name, (unsigned long)trx\_wait\_binlog\_pos,
                            (int)is\_on());
    }

    /\* Calcuate the waiting period. \*/
#ifndef HAVE\_STRUCT\_TIMESPEC
      abstime.tv.i64 \= start\_ts.tv.i64 + (\_\_int64)wait\_timeout\_ \* TIME\_THOUSAND \* 10;
      abstime.max\_timeout\_msec\= (long)wait\_timeout\_;
#else
      // wait\_timeout 时间
      abstime.tv\_sec = start\_ts.tv\_sec + wait\_timeout\_ / TIME\_THOUSAND;
      abstime.tv\_nsec \= start\_ts.tv\_nsec +
        (wait\_timeout\_ % TIME\_THOUSAND) \* TIME\_MILLION;
      if (abstime.tv\_nsec >= TIME\_BILLION)
      {
        abstime.tv\_sec++;
        abstime.tv\_nsec \-= TIME\_BILLION;
      }
#endif /\* \_WIN32 \*/
    // 打开了半同步
    while (is\_on())
    {
      // 如果有从库回复
      if (reply\_file\_name\_inited\_)
      {
        // 比较从库回复的日志坐标(filename & fileops)和固化的 commit 队列中最新的事务的 binlog filename & pos
        int cmp = ActiveTranx::compare(reply\_file\_name\_, reply\_file\_pos\_,
                                       trx\_wait\_binlog\_name, trx\_wait\_binlog\_pos);
        // 如果回复的日志坐标大于当前的日志坐标                               
        if (cmp >= 0)
        {
          /\* We have already sent the relevant binlog to the slave: no need to
           \* wait here.
             我们已经确认将相应的 binlog 发送给了从库: 无需在此等待。
           \*/
          if (trace\_level\_ & kTraceDetail)
            sql\_print\_information("%s: Binlog reply is ahead (%s, %lu),",
                                  kWho, reply\_file\_name\_, (unsigned long)reply\_file\_pos\_);
          // 退出循环                        
          break;
        }
      }
      /\*
        When code reaches here an Entry object may not be present in the
        following scenario.
        当代码到了这里, 在一下场景中可能不存在 entry。
        Semi sync was not enabled when transaction entered into ordered\_commit
        process. During flush stage, semi sync was not enabled and there was no
        'Entry' object created for the transaction being committed and at a
        later stage it was enabled. In this case trx\_wait\_binlog\_name and
        trx\_wait\_binlog\_pos are set but the 'Entry' object is not present. Hence
        dump thread will not wait for reply from slave and it will not update
        reply\_file\_name. In such case the committing transaction should not wait
        for an ack from slave and it should be considered as an async
        transaction.
        事务进入 ordered\_commit 时未启用半同步。
        在 flush 阶段, 没有启用半同步, 没有为提交的事务创建 entry 对象, 但是在之后的节点启用了半同步。
        在这种情况下, 设置了 trx\_wait\_binlog\_name 和 trx\_wait\_binlog\_pos, 但是 entry 对象并不存在。
        此时, dump 线程将不会等待 slave 节点的 reply, 并且不会更新 reply\_file\_name。
        在这种情况下, 提交的事务不应等待来自 slave 节点的 ack, 而应被视为异步事务。
      \*/
      if (!entry)
      {
        is\_semi\_sync\_trans\= false;
        goto l\_end;
      }

      /\* Let us update the info about the minimum binlog position of waiting
       \* threads.
       \* 这里更新等待线程等待的 minimum binlog pos 。
       \*/
      if (wait\_file\_name\_inited\_)
      {
        // 对比当前 commit 队列最后的binlog点位 和 wait\_file\_name\_ & wait\_file\_pos\_ 大小
        int cmp = ActiveTranx::compare(trx\_wait\_binlog\_name, trx\_wait\_binlog\_pos,
                                       wait\_file\_name\_, wait\_file\_pos\_);
        if (cmp <= 0)
          {
          /\* This thd has a lower position, let's update the minimum info. 
          这里更新 wait\_file\_name\_ & wait\_file\_pos\_。
          \*/
          strncpy(wait\_file\_name\_, trx\_wait\_binlog\_name, sizeof(wait\_file\_name\_) - 1);
          wait\_file\_name\_\[sizeof(wait\_file\_name\_) - 1\]= '\\0';
          wait\_file\_pos\_ \= trx\_wait\_binlog\_pos;

          rpl\_semi\_sync\_master\_wait\_pos\_backtraverse++;
          if (trace\_level\_ & kTraceDetail)
            sql\_print\_information("%s: move back wait position (%s, %lu),",
                                  kWho, wait\_file\_name\_, (unsigned long)wait\_file\_pos\_);
        }
      }
      else
      {
        strncpy(wait\_file\_name\_, trx\_wait\_binlog\_name, sizeof(wait\_file\_name\_) - 1);
        wait\_file\_name\_\[sizeof(wait\_file\_name\_) - 1\]= '\\0';
        wait\_file\_pos\_ \= trx\_wait\_binlog\_pos;
        wait\_file\_name\_inited\_ \= true;

        if (trace\_level\_ & kTraceDetail)
          sql\_print\_information("%s: init wait position (%s, %lu),",
                                kWho, wait\_file\_name\_, (unsigned long)wait\_file\_pos\_);
      }

      /\* In semi-synchronous replication, we wait until the binlog-dump
       \* thread has received the reply on the relevant binlog segment from the
       \* replication slave.
       \* 在半同步复制中, 我们等待直到 binlog dump 线程收到相关 binlog 的 reply 信息。
       \* 
       \* Let us suspend this thread to wait on the condition;
       \* when replication has progressed far enough, we will release
       \* these waiting threads.
       \* 让我们暂停这个线程以等待这个条件; 
       \* 当复制进展足够时, 我们将释放等待的线程。
       \*/
      // 判断 slave 个数和半同步是否正常
      // 当前 slave 节点的数量 == rpl\_semi\_sync\_master\_wait\_for\_slave\_count -1 && 半同步复制正开启
      if (abort\_loop && (rpl\_semi\_sync\_master\_clients ==
                         rpl\_semi\_sync\_master\_wait\_for\_slave\_count \- 1) && is\_on())
      {
        sql\_print\_warning("SEMISYNC: Forced shutdown. Some updates might "
                          "not be replicated.");
        // 关闭半同步, 中断循环                
        switch\_off();
        break;
      }
      //正式进入等待binlog同步的步骤，将rpl\_semi\_sync\_master\_wait\_sessions+1
            //然后发起等待信号，进入信号等待后，只有2种情况可以退出等待。1是被其他线程唤醒（binlog dump）
            //2是等待超时时间。如果是被唤醒则返回值是0，否则是其他值
      rpl\_semi\_sync\_master\_wait\_sessions++;
      
      if (trace\_level\_ & kTraceDetail)
        sql\_print\_information("%s: wait %lu ms for binlog sent (%s, %lu)",
                              kWho, wait\_timeout\_,
                              wait\_file\_name\_, (unsigned long)wait\_file\_pos\_);
      
      /\* wait for the position to be ACK'ed back 
      实现 ACK 等待
      \*/
      assert(entry);
      entry\->n\_waiters++;
      // 第一个参数为条件量，第二个为等待之后释放LOCK\_binlog\_互斥锁，第三个为未来的超时绝对时间
      wait\_result= mysql\_cond\_timedwait(&entry->cond, &LOCK\_binlog\_, &abstime);
      entry\->n\_waiters--;
      /\*
        After we release LOCK\_binlog\_ above while waiting for the condition,
        it can happen that some other parallel client session executed
        RESET MASTER. That can set rpl\_semi\_sync\_master\_wait\_sessions to zero.
        Hence check the value before decrementing it and decrement it only if it is
        non-zero value.
        在等待之后释放 LOCK\_binlog\_互斥锁, 有可能其他客户端执行 RESET MASTER 命令, 这将把 rpl\_semi\_sync\_master\_wait\_sessions 重置为 0。
        因此, 在递减前需要检查该值。
      \*/
      if (rpl\_semi\_sync\_master\_wait\_sessions > 0)
        rpl\_semi\_sync\_master\_wait\_sessions\--;
      // wait\_result != 0, 这里表示等待超时
      if (wait\_result != 0)
      {
        /\* This is a real wait timeout. \*/
        sql\_print\_warning("Timeout waiting for reply of binlog (file: %s, pos: %lu), "
                          "semi-sync up to file %s, position %lu.",
                          trx\_wait\_binlog\_name, (unsigned long)trx\_wait\_binlog\_pos,
                          reply\_file\_name\_, (unsigned long)reply\_file\_pos\_);
        rpl\_semi\_sync\_master\_wait\_timeouts++;
        
        /\* switch semi-sync off ; 关闭 semi sync  \*/
        switch\_off();
      }
      else
      // 等待 ACK 成功
      {
        int wait\_time;
        
        wait\_time \= getWaitTime(start\_ts);
        // wait\_time < 0, 时钟错误
        if (wait\_time < 0)
        {
          if (trace\_level\_ & kTraceGeneral)
          {
            sql\_print\_information("Assessment of waiting time for commitTrx "
                                  "failed at wait position (%s, %lu)",
                                  trx\_wait\_binlog\_name,
                                  (unsigned long)trx\_wait\_binlog\_pos);
          }
          rpl\_semi\_sync\_master\_timefunc\_fails++;
        }
        else
        {
          //将等待事件与该等待计入总数  
          rpl\_semi\_sync\_master\_trx\_wait\_num++;
          rpl\_semi\_sync\_master\_trx\_wait\_time += wait\_time;
        }
      }
    }

l\_end:
    /\* Update the status counter. 
    更新状态计数
    \*/
    if (is\_on() && is\_semi\_sync\_trans)
      rpl\_semi\_sync\_master\_yes\_transactions++;
    else
      rpl\_semi\_sync\_master\_no\_transactions++;
  }

  /\* Last waiter removes the TranxNode 
  移除 active\_tranxs\_ 链表中 trx\_wait\_binlog\_name & trx\_wait\_binlog\_pos 之前的所有事务。
  \*/
  if (trx\_wait\_binlog\_name && active\_tranxs\_
      && entry && entry->n\_waiters == 0)
    active\_tranxs\_\->clear\_active\_tranx\_nodes(trx\_wait\_binlog\_name,
                                             trx\_wait\_binlog\_pos);

  unlock();
  THD\_EXIT\_COND(NULL, & old\_stage);
  return function\_exit(kWho, 0);
}

通过以上源码分析，可以看到在 after\_sync hook 之后会释放 Lock\_commit 锁，而后调用 after\_commit hook。

因此当 AFTER\_SYNC 时，会发现只有一个查询线程处于 Waiting for semi-sync ACK from slave 状态，其他查询线程处于 query end 状态。

而 AFTER\_COMMIT 时，所有的查询线程都处于 Waiting for semi-sync ACK from slave 状态。