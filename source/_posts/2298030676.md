---
layout: post
title: "从乘法求导法则到BPTT算法"
date: "2022-04-08T22:18:32.595Z"
---
从乘法求导法则到BPTT算法
==============

本文为手稿，旨在搞清楚为什么BPTT算法会多路反向求导，而不是一个感性的认识。

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408204958303-1309998013.png)

 ![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408205024086-854398301.png)

假设我们要对E3求导（上图中的L3），那么则有：

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408202412487-315248265.png)![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408202649623-1558592935.png)

所以S2是W的函数，也就是说，我们不能说：

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408202926413-1881162820.png)

 因为WS2 = WS2(w)，S2里面包含了W这个变量，S2是W的函数，也许有人会说：“S2里面的W是常数吧”，那么请想一想S2的一般表达式。（这里我其实还是有点过不去，但是我觉得应该是这样的，不知道各位是否有理解方法）

所以有：

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408203304753-897841804.png)

 而对函数WS2(w)求导（对W求导），结果为：

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408203543070-162381845.png)

 S02和W2在RNN中的位置为：

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408205146043-1243887026.png)

 再次注意，上面两个值不是变量，是一个具体的值。

然后再求(WS1)\`:

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408204332439-130392131.png)

**另外关于W1，这里我不太清楚是否继续要用W2，因为毕竟是对第t=3时刻的W求导，如果后面知道了，再改也不迟。**

 继续求下去：

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408204615075-1202874952.png)

 我们假设S-1是全0的向量，那么S0\`就会是0.

然后，我们把上面分开求的结果合并起来，直接计算S3对W的导数：

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408210353647-1477181988.png) ![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408210424175-1820926028.png)

 最后一行就是最终的结果，其实这三项分别对应：

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408210645766-1005364060.png)

 下面是数学表示： 

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408210533275-2123465815.png)

所以，

BPTT反向求导为什么必然会有多路，实际上是因为 S2是W的函数，所以要运用乘法求导法则，最后完全求出(S2W)\`之后，便可以写成这样的形式：

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408204958303-1309998013.png)

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408210056129-1300194391.png)

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408211026233-41349331.png)

 以下是完整草稿：

![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408211536468-1367518145.jpg)

 ![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408211559807-1048386676.jpg)

 ![](https://img2022.cnblogs.com/blog/2724624/202204/2724624-20220408211612793-1998588066.jpg)

 本文截图部分来自我的NLP课程乔波老师的PPT。