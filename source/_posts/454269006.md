---
layout: post
title: "JavaCV的摄像头实战之七：推流(带声音)"
date: "2022-04-19T01:43:35.284Z"
---
JavaCV的摄像头实战之七：推流(带声音)
======================

![JavaCV的摄像头实战之七：推流(带声音)](https://img2022.cnblogs.com/blog/485422/202204/485422-20220419085112352-924527691.png) 借助JavaCV，完成本地摄像头和麦克风数据推送到媒体服务器的操作，并用VLC验证

### 欢迎访问我的GitHub

> 这里分类和汇总了欣宸的全部原创(含配套源码)：[https://github.com/zq2599/blog\_demos](https://github.com/zq2599/blog_demos)

### 本篇概览

*   本文是《JavaCV的摄像头实战》的第七篇，在[《JavaCV的摄像头实战之五：推流》](https://www.cnblogs.com/bolingcavalry/p/15873597.html)一文中，咱们将摄像头的内容推送到媒体服务器，再用VLC成功播放，相信聪明的您一定觉察到了一缕瑕疵：没有声音
*   虽然《JavaCV的摄像头实战》系列的主题是摄像头处理，但显然音视频健全才是最常见的情况，因此就在本篇补全[前文](https://www.cnblogs.com/bolingcavalry/p/15877663.html)的不足吧：编码实现摄像头和麦克风的推流，并验证可以成功远程播放音视频

### 关于音频的采集和录制

*   本篇的代码是在[《JavaCV的摄像头实战之五：推流》](https://www.cnblogs.com/bolingcavalry/p/15873597.html)源码的基础上增加音频处理部分
*   编码前，咱们先来分析一下，增加音频处理后具体的代码逻辑会有哪些变化
*   只保存视频的操作，与保存音频相比，步骤的区别如下图所示，深色块就是新增的操作：  
    ![在这里插入图片描述](https://img2022.cnblogs.com/blog/485422/202204/485422-20220419085133132-810584927.png)
*   相对的，在应用结束时，释放所有资源的时候，音视频的操作也比只有视频时要多一些，如下图所示，深色就是释放音频相关资源的操作：  
    ![在这里插入图片描述](https://img2022.cnblogs.com/blog/485422/202204/485422-20220419085133133-1101407290.png)
*   为了让代码简洁一些，我将音频相关的处理都放在名为AudioService的类中，也就是说上面两幅图的深色部分的代码都在AudioService.java中，主程序使用此类来完成音频处理
*   接下来开始编码

### 开发音频处理类AudioService

*   首先是刚才提到的AudioService.java，主要内容就是前面图中深色块的功能，有几处要注意的地方稍后会提到：

    package com.bolingcavalry.grabpush.extend;
    
    import lombok.extern.slf4j.Slf4j;
    import org.bytedeco.ffmpeg.global.avcodec;
    import org.bytedeco.javacv.FFmpegFrameRecorder;
    import org.bytedeco.javacv.FrameRecorder;
    import javax.sound.sampled.AudioFormat;
    import javax.sound.sampled.AudioSystem;
    import javax.sound.sampled.DataLine;
    import javax.sound.sampled.TargetDataLine;
    import java.nio.ByteBuffer;
    import java.nio.ByteOrder;
    import java.nio.ShortBuffer;
    import java.util.concurrent.ScheduledThreadPoolExecutor;
    import java.util.concurrent.TimeUnit;
    
    /**
     * @author willzhao
     * @version 1.0
     * @description 音频相关的服务
     * @date 2021/12/3 8:09
     */
    @Slf4j
    public class AudioService {
    
        // 采样率
        private final static int SAMPLE_RATE = 44100;
    
        // 音频通道数，2表示立体声
        private final static int CHANNEL_NUM = 2;
    
        // 帧录制器
        private FFmpegFrameRecorder recorder;
    
        // 定时器
        private ScheduledThreadPoolExecutor sampleTask;
    
        // 目标数据线，音频数据从这里获取
        private TargetDataLine line;
    
        // 该数组用于保存从数据线中取得的音频数据
        byte[] audioBytes;
    
        // 定时任务的线程中会读此变量，而改变此变量的值是在主线程中，因此要用volatile保持可见性
        private volatile boolean isFinish = false;
    
        /**
         * 帧录制器的音频参数设置
         * @param recorder
         * @throws Exception
         */
        public void setRecorderParams(FrameRecorder recorder) throws Exception {
            this.recorder = (FFmpegFrameRecorder)recorder;
    
            // 码率恒定
            recorder.setAudioOption("crf", "0");
            // 最高音质
            recorder.setAudioQuality(0);
            // 192 Kbps
            recorder.setAudioBitrate(192000);
    
            // 采样率
            recorder.setSampleRate(SAMPLE_RATE);
    
            // 立体声
            recorder.setAudioChannels(2);
            // 编码器
            recorder.setAudioCodec(avcodec.AV_CODEC_ID_AAC);
        }
    
        /**
         * 音频采样对象的初始化
         * @throws Exception
         */
        public void initSampleService() throws Exception {
            // 音频格式的参数
            AudioFormat audioFormat = new AudioFormat(SAMPLE_RATE, 16, CHANNEL_NUM, true, false);
    
            // 获取数据线所需的参数
            DataLine.Info dataLineInfo = new DataLine.Info(TargetDataLine.class, audioFormat);
    
            // 从音频捕获设备取得其数据的数据线，之后的音频数据就从该数据线中获取
            line = (TargetDataLine)AudioSystem.getLine(dataLineInfo);
    
            line.open(audioFormat);
    
            // 数据线与音频数据的IO建立联系
            line.start();
    
            // 每次取得的原始数据大小
            final int audioBufferSize = SAMPLE_RATE * CHANNEL_NUM;
    
            // 初始化数组，用于暂存原始音频采样数据
            audioBytes = new byte[audioBufferSize];
    
            // 创建一个定时任务，任务的内容是定时做音频采样，再把采样数据交给帧录制器处理
            sampleTask = new ScheduledThreadPoolExecutor(1);
        }
    
        /**
         * 程序结束前，释放音频相关的资源
         */
        public void releaseOutputResource() {
            // 结束的标志，避免采样的代码在whlie循环中不退出
            isFinish = true;
            // 结束定时任务
            sampleTask.shutdown();
            // 停止数据线
            line.stop();
            // 关闭数据线
            line.close();
        }
    
        /**
         * 启动定时任务，每秒执行一次，采集音频数据给帧录制器
         * @param frameRate
         */
        public void startSample(double frameRate) {
    
            // 启动定时任务，每秒执行一次，采集音频数据给帧录制器
            sampleTask.scheduleAtFixedRate((Runnable) new Runnable() {
                @Override
                public void run() {
                    try
                    {
                        int nBytesRead = 0;
    
                        while (nBytesRead == 0 && !isFinish) {
                            // 音频数据是从数据线中取得的
                            nBytesRead = line.read(audioBytes, 0, line.available());
                        }
    
                        // 如果nBytesRead<1，表示isFinish标志被设置true，此时该结束了
                        if (nBytesRead<1) {
                            return;
                        }
    
                        // 采样数据是16比特，也就是2字节，对应的数据类型就是short，
                        // 所以准备一个short数组来接受原始的byte数组数据
                        // short是2字节，所以数组长度就是byte数组长度的二分之一
                        int nSamplesRead = nBytesRead / 2;
                        short[] samples = new short[nSamplesRead];
    
                        // 两个byte放入一个short中的时候，谁在前谁在后？这里用LITTLE_ENDIAN指定拜访顺序，
                        ByteBuffer.wrap(audioBytes).order(ByteOrder.LITTLE_ENDIAN).asShortBuffer().get(samples);
                        // 将short数组转为ShortBuffer对象，因为帧录制器的入参需要该类型
                        ShortBuffer sBuff = ShortBuffer.wrap(samples, 0, nSamplesRead);
    
                        // 音频帧交给帧录制器输出
                        recorder.recordSamples(SAMPLE_RATE, CHANNEL_NUM, sBuff);
                    }
                    catch (FrameRecorder.Exception e) {
                        e.printStackTrace();
                    }
                }
            }, 0, 1000 / (long)frameRate, TimeUnit.MILLISECONDS);
        }
    }
    

*   上述代码中，有两处要注意：

1.  重点关注recorder.recordSamples，该方法将音频存入了mp4文件
2.  定时任务是在一个新线程中执行的，因此当主线程结束录制后，需要中断定时任务中的while循环，因此新增了volatile类型的变量isFinish，帮助定时任务中的代码判断是否立即结束while循环

### 改造原本推流时只推视频的代码

*   接着是对[《JavaCV的摄像头实战之五：推流》](https://www.cnblogs.com/bolingcavalry/p/15873597.html)一文中RecordCamera.java的改造，为了不影响之前章节在github上的代码，这里我新增了一个类RecordCameraWithAudio.java，内容与RecordCamera.java一模一样，接下来咱们来改造这个RecordCameraWithAudio类
*   先增加AudioService类型的成员变量：

    	// 音频服务类
        private AudioService audioService = new AudioService();
    

*   接下来是关键，initOutput方法负责帧录制器的初始化，现在要加上音频相关的初始化操作，并且还要启动定时任务去采集和处理音频，如下所示，AudioService的三个方法都在此调用了，注意定时任务的启动要放在帧录制器初始化之后：

        @Override
        protected void initOutput() throws Exception {
            // 实例化FFmpegFrameRecorder，将SRS的推送地址传入
            recorder = FrameRecorder.createDefault(RECORD_ADDRESS, getCameraImageWidth(), getCameraImageHeight());
    
            // 降低启动时的延时，参考
            // https://trac.ffmpeg.org/wiki/StreamingGuide)
            recorder.setVideoOption("tune", "zerolatency");
            // 在视频质量和编码速度之间选择适合自己的方案，包括这些选项：
            // ultrafast,superfast, veryfast, faster, fast, medium, slow, slower, veryslow
            // ultrafast offers us the least amount of compression (lower encoder
            // CPU) at the cost of a larger stream size
            // at the other end, veryslow provides the best compression (high
            // encoder CPU) while lowering the stream size
            // (see: https://trac.ffmpeg.org/wiki/Encode/H.264)
            // ultrafast对CPU消耗最低
            recorder.setVideoOption("preset", "ultrafast");
            // Constant Rate Factor (see: https://trac.ffmpeg.org/wiki/Encode/H.264)
            recorder.setVideoOption("crf", "28");
            // 2000 kb/s, reasonable "sane" area for 720
            recorder.setVideoBitrate(2000000);
    
            // 设置编码格式
            recorder.setVideoCodec(avcodec.AV_CODEC_ID_H264);
    
            // 设置封装格式
            recorder.setFormat("flv");
    
            // FPS (frames per second)
            // 一秒内的帧数
            recorder.setFrameRate(getFrameRate());
            // Key frame interval, in our case every 2 seconds -> 30 (fps) * 2 = 60
            // 关键帧间隔
            recorder.setGopSize((int)getFrameRate()*2);
    
            // 设置帧录制器的音频相关参数
            audioService.setRecorderParams(recorder);
    
            // 音频采样相关的初始化操作
            audioService.initSampleService();
    
            // 帧录制器开始初始化
            recorder.start();
    
            // 启动定时任务，采集音频帧给帧录制器
            audioService.startSample(getFrameRate());
        }
    

*   output方法保存原样，只处理视频帧（音频处理在定时任务中）

        @Override
        protected void output(Frame frame) throws Exception {
            if (0L==startRecordTime) {
                startRecordTime = System.currentTimeMillis();
            }
    
            // 时间戳
            recorder.setTimestamp(1000 * (System.currentTimeMillis()-startRecordTime));
    
            // 存盘
            recorder.record(frame);
        }
    

*   释放资源的方法中，增加了音频资源释放的操作：

        @Override
        protected void releaseOutputResource() throws Exception {
            // 执行音频服务的资源释放操作
            audioService.releaseOutputResource();
    
            // 关闭帧录制器
            recorder.close();
        }
    

*   至此，将摄像头视频和麦克风音频推送到媒体服务器的功能已开发完成，再写上main方法，表示推流十分钟：

        public static void main(String[] args) {
            new RecordCameraWithAudio().action(600);
        }
    

*   运行main方法，等到控制台输出下图红框的内容时，表示正在推送中：  
    ![在这里插入图片描述](https://img2022.cnblogs.com/blog/485422/202204/485422-20220419085133119-1556139900.png)
    
*   在另一台电脑上用VLC软件打开刚才推流的地址rtmp://192.168.50.43:21935/hls/camera，稍等几秒钟后开始正常播放，图像声音都正常（注意不能用当前电脑播放，否则麦克风采集的是VLC播放的声音了）：  
    ![在这里插入图片描述](https://img2022.cnblogs.com/blog/485422/202204/485422-20220419085133149-473666585.png)
    
*   用VLC自带的工具查看媒体流信息，如下图，可见视频流和音频流都能正常识别：  
    ![在这里插入图片描述](https://img2022.cnblogs.com/blog/485422/202204/485422-20220419085133136-434139542.png)
    
*   打开媒体服务器自身的监控页面，如下图，可以看到各项实时数据：  
    ![在这里插入图片描述](https://img2022.cnblogs.com/blog/485422/202204/485422-20220419085133125-1276252813.png)
    
*   至此，咱们已完成了音视频推流的功能，（有点像直播的样子了），得益于JavaCV的强大，整个过程是如此的轻松愉快，接下来请继续关注欣宸原创，《JavaCV的摄像头实战》系列还会呈现更多丰富的应用；
    

### 源码下载

*   《JavaCV的摄像头实战》的完整源码可在GitHub下载到，地址和链接信息如下表所示([https://github.com/zq2599/blog\_demos](https://github.com/zq2599/blog_demos))：

名称

链接

备注

项目主页

[https://github.com/zq2599/blog\_demos](https://github.com/zq2599/blog_demos)

该项目在GitHub上的主页

git仓库地址(https)

[https://github.com/zq2599/blog\_demos.git](https://github.com/zq2599/blog_demos.git)

该项目源码的仓库地址，https协议

git仓库地址(ssh)

git@github.com:zq2599/blog\_demos.git

该项目源码的仓库地址，ssh协议

*   这个git项目中有多个文件夹，本篇的源码在javacv-tutorials文件夹下，如下图红框所示：  
    ![在这里插入图片描述](https://img2022.cnblogs.com/blog/485422/202204/485422-20220419085133095-994110803.png)
*   javacv-tutorials里面有多个子工程，《JavaCV的摄像头实战》系列的代码在**simple-grab-push**工程下：  
    ![在这里插入图片描述](https://img2022.cnblogs.com/blog/485422/202204/485422-20220419085133131-1868766819.png)

### 欢迎关注博客园：程序员欣宸

> [学习路上，你不孤单，欣宸原创一路相伴...](https://www.cnblogs.com/bolingcavalry/)