---
layout: post
title: "大数据HDFS凭啥能存下百亿数据？"
date: "2022-12-09T13:22:50.553Z"
---
大数据HDFS凭啥能存下百亿数据？
=================

> 欢迎关注[大数据系列课程](https://juejin.cn/column/7174004894997676062)

前言
--

大家平时经常用的百度网盘存放电影、照片、文档等，那有想过百度网盘是如何存下那么多文件的呢？难到是用一台计算机器存的吗？那得多大磁盘啊？显然不是的，那本文就带大家揭秘。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e4542ffc3956473d988e46166243ffe8~tplv-k3u1fbpfcp-zoom-1.image)

分布式存储思想
-------

既然一台机器的存储所需的磁盘有上限瓶颈，那么我们能否利用多台机器形成一个整体用来存储呢？这就是我们所说的分布式存储。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e9ec015a768f43438c2d2d1f92f2ce34~tplv-k3u1fbpfcp-zoom-1.image)

*   单机纵向扩展：磁盘不够加磁盘，有上限瓶颈限制
*   多机横向扩展：机器不够加机器，理论上无限扩展

Hadoop就是采用了这样的一个思想，设计出了分布式存储系统HDFS。

HDFS介绍和使用
---------

HDFS（`Hadoop Distributed File System` ），意为：`Hadoop`分布式文件系统。它是`Apache Hadoop`核心组件之一，作为大数据生态圈最底层的分布式存储服务而存在。也可以说大数据首先要解决的问题就是海量数据的存储问题。

*   HDFS主要是解决大数据如何存储问题的。分布式意味着是HDFS是横跨在多台计算机上的存储系统。
*   HDFS是一种能够在普通硬件上运行的分布式文件系统，它是高度容错的，适应于具有大数据集的应用程序，它非常适于存储大型数据 (比如 TB 和 PB)。
*   HDFS使用多台计算机存储文件, 并且提供统一的访问接口, 像是访问一个普通文件系统一样使用分布式文件系统。

### HDFS使用

HDFS安装好了，具体是如何使用呢，如何上传和下载文件呢？一共有两种方式，通过shell命令和web页面。

1.  **shell命令操作HDFS**

类似linux命令，可以直接通过在命令行界面操作。Hadoop提供了文件系统的shell命令行客户端: `hadoop fs [generic options]`

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bf4108d32bbd427f99a666d015fa9460~tplv-k3u1fbpfcp-zoom-1.image)

*   创建文件夹

`hadoop fs -mkdir [-p] <path> ...`

`path` 为待创建的目录

`-p` 选项的行为与`Unix mkdir -p`非常相似，它会沿着路径创建父目录。

*   查看指定目录下内容

`hadoop fs -ls [-h] [-R] [<path> ...]`

path 指定目录路径

\-h 人性化显示文件size

\-R 递归查看指定目录及其子目录

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/564664525a7042d7aaa6d0750a5acaca~tplv-k3u1fbpfcp-zoom-1.image)

*   上传文件到HDFS指定目录下

`hadoop fs -put [-f] [-p] <localsrc> ... <dst>`

\-f 覆盖目标文件（已存在下）

\-p 保留访问和修改时间，所有权和权限。

localsrc 本地文件系统（客户端所在机器）

dst 目标文件系统（HDFS）

    hadoop fs -put zookeeper.out /alvin
    hadoop fs -put file:///etc/profile hdfs://node1:8020/alvin
    

*   查看HDFS文件内容

`hadoop fs -cat <src> ...`

读取指定文件全部内容，显示在标准输出控制台。

**注意：对于大文件内容读取，慎重。**

*   下载HDFS文件

`hadoop fs -get [-f] [-p] <src> ... <localdst>`

下载文件到本地文件系统指定目录，localdst必须是目录

\-f 覆盖目标文件（已存在下）

\-p 保留访问和修改时间，所有权和权限。

更多命令可以查看官方文档

[https://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-common/FileSystemShell.html](https://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-common/FileSystemShell.html)

**2.web界面操作HDFS**

另外一种更简单直观的方式是通过web界面操作HDFS，默认是50070端口，如下图所示：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c9ddc0e6cd4f4e9cb3770c3f445327c5~tplv-k3u1fbpfcp-zoom-1.image)

HDFS的架构
-------

HFDS采用分布式的架构，可能有成百上千的服务器组成，每一个组件都有可能出现故障。因此故障检测和自动快速恢复是HDFS的核心架构目标，下面是HDFS的官方架构图：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/563a5c797614449fa09492030d52f765~tplv-k3u1fbpfcp-zoom-1.image)

### 主从架构

HDFS集群是标准的`master/slave`主从架构集群，一般一个HDFS集群是有一个`Namenode`和一定数目的`DataNode`组成。

**主角色：NameNode**

*   NameNode是Hadoop分布式文件系统的核心，架构中的主角色。 
*   NameNode维护和管理文件系统元数据，包括名称空间目录树结构、文件和块的位置信息、访问权限等信息。 
*   基于此，NameNode成为了访问HDFS的唯一入口。

**从角色：DataNode**

*   DataNode是Hadoop HDFS中的从角色，负责具体的数据块存储。 
*   DataNode的数量决定了HDFS集群的整体数据存储能力，通过和NameNode配合维护着数据块。

**主角色辅助角色： SecondaryNameNode**

此外，HDFS中还有一个SecondaryNameNode，虽然途中没有画出，那它有什么用呢？

*   Secondary NameNode充当NameNode的辅助节点，但不能替代NameNode。 
*   主要是帮助主角色进行元数据文件的合并动作。可以通俗的理解为主角色的“秘书”。

### 分块存储

由于有的文件很大，一台机器也存不下，于是HDFS会对我们的文件做一个物理上的切割，也就是分块存储。

HDFS中的文件在物理上是分块存储（`block`）的，默认大小是`128M（134217728）`，不足`128M`则本身就是一块。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/debec2c1d16342f5a4a328ca55392d16~tplv-k3u1fbpfcp-zoom-1.image)

### 副本机制

既然分布式存储海量数据，那么肯定需要成千上百的机器，这样很有可能其中一台机器宕机，出故障了怎么办呢？

当然HDFS也想到了解决方案，文件的所有block都会有副本。副本系数可以在文件创建的时候指定，也可以在之后通过命令改变。副本数由参数`dfs.replication`控制，默认值是3，也就是会额外再复制2份，连同本身总共3份副本，而且这个副本尽量会分散在不同的机架上，规避风险。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f36fe78c08d04c1f844985d97bca9012~tplv-k3u1fbpfcp-zoom-1.image)

### NameNode高可用

既然DataNode有副本，出现数据丢失可能性很小，那NameNode挂了不是照样凉凉？

不用担心，那我在启动一个NameNode备在那里不就行了吗。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b26567bf47e84dcab78abf9271c05ea1~tplv-k3u1fbpfcp-zoom-1.image)

存在两个 NameNode，一个是活动的 NameNode，称为 Active，另外一个是备用的 NameNode，称为 Standby。Active节点的数据通过JournalNode节点同步给Standby节点。 当 Active 节点出现问题时，需要将 Standby 节点切换为 Active 节点来为客户端提供服务，这样就保证了高可用。

### 元数据管理

前面提到NameNode中包含元数据，那么究竟具体是哪些内容呢？

在HDFS中，Namenode管理的元数据具有两种类型：

*   文件自身属性信息

文件名称、权限，修改时间，文件大小，复制因子，数据块大小。

*   文件块位置映射信息

记录文件块和DataNode之间的映射信息，即哪个块位于哪个节点上。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8c08b62cd5bd4ecbac7a4f864b562d7c~tplv-k3u1fbpfcp-zoom-1.image)

总结
--

现在你终于知道为什么百度网盘可以存下海量的数据了吧，主要采用的是分布式的存储，将数据分块多副本的方式存储到多个数据节点DataNode, 然后由唯一的`NameNode`节点去管理这个文件的信息，比如说它是在那些`DataNode`节点上，大小是多少等等，注意这里是`DataNode`主动告诉`NameNode`它这里有哪些文件块。

> 如果本文对你有帮助的话，请留下一个赞吧  
> 欢迎关注个人公众号——JAVA旭阳  
> 更多学习资料请移步：[程序员成神之路](https://www.cnblogs.com/alvinscript/p/16967755.html)

本文来自博客园，作者：[JAVA旭阳](https://www.cnblogs.com/alvinscript/)，转载请注明原文链接：[https://www.cnblogs.com/alvinscript/p/16970020.html](https://www.cnblogs.com/alvinscript/p/16970020.html)